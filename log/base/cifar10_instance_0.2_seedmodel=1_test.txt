Namespace(T=0.2, batch_size=32, data_path='./dataset2/cifar10', dataset='cifar10', fig_7=0, fluctuation_ablation=0, gpuid=0, k=3, lr=0.02, model='resnet18', noise_mode='instance', num_class=10, num_epochs=75, r=0.2, save_sel_sam=0, seed_model=1, seed_noise=1, semi='no', warm_up=10, wdecay=0.0005, without_Lcr=0, without_R=0)
============ Initialize data
============ Actual clean samples number:  39820
============ use resnet18 
============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 0 | Accuracy on train set: 7.55% 
cifar10:0.2-instance | Epoch [  0/ 75] Iter[  1/391]	 CE-loss: 2.4246cifar10:0.2-instance | Epoch [  0/ 75] Iter[ 51/391]	 CE-loss: 2.0530cifar10:0.2-instance | Epoch [  0/ 75] Iter[101/391]	 CE-loss: 1.8808cifar10:0.2-instance | Epoch [  0/ 75] Iter[151/391]	 CE-loss: 1.8698cifar10:0.2-instance | Epoch [  0/ 75] Iter[201/391]	 CE-loss: 1.7761cifar10:0.2-instance | Epoch [  0/ 75] Iter[251/391]	 CE-loss: 1.8290cifar10:0.2-instance | Epoch [  0/ 75] Iter[301/391]	 CE-loss: 1.5708cifar10:0.2-instance | Epoch [  0/ 75] Iter[351/391]	 CE-loss: 1.6810
| Test Epoch 0	 Accuracy: 46.67% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 1 | Accuracy on train set: 40.01% 
cifar10:0.2-instance | Epoch [  1/ 75] Iter[  1/391]	 CE-loss: 1.5990cifar10:0.2-instance | Epoch [  1/ 75] Iter[ 51/391]	 CE-loss: 1.5840cifar10:0.2-instance | Epoch [  1/ 75] Iter[101/391]	 CE-loss: 1.5945cifar10:0.2-instance | Epoch [  1/ 75] Iter[151/391]	 CE-loss: 1.5745cifar10:0.2-instance | Epoch [  1/ 75] Iter[201/391]	 CE-loss: 1.6170cifar10:0.2-instance | Epoch [  1/ 75] Iter[251/391]	 CE-loss: 1.4005cifar10:0.2-instance | Epoch [  1/ 75] Iter[301/391]	 CE-loss: 1.4176cifar10:0.2-instance | Epoch [  1/ 75] Iter[351/391]	 CE-loss: 1.4455
| Test Epoch 1	 Accuracy: 55.44% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 2 | Accuracy on train set: 46.22% 
cifar10:0.2-instance | Epoch [  2/ 75] Iter[  1/391]	 CE-loss: 1.2053cifar10:0.2-instance | Epoch [  2/ 75] Iter[ 51/391]	 CE-loss: 1.3239cifar10:0.2-instance | Epoch [  2/ 75] Iter[101/391]	 CE-loss: 1.2724cifar10:0.2-instance | Epoch [  2/ 75] Iter[151/391]	 CE-loss: 1.2949cifar10:0.2-instance | Epoch [  2/ 75] Iter[201/391]	 CE-loss: 1.4765cifar10:0.2-instance | Epoch [  2/ 75] Iter[251/391]	 CE-loss: 1.1888cifar10:0.2-instance | Epoch [  2/ 75] Iter[301/391]	 CE-loss: 1.3583cifar10:0.2-instance | Epoch [  2/ 75] Iter[351/391]	 CE-loss: 1.1706
| Test Epoch 2	 Accuracy: 63.25% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 3 | Accuracy on train set: 52.58% 
cifar10:0.2-instance | Epoch [  3/ 75] Iter[  1/391]	 CE-loss: 1.2150cifar10:0.2-instance | Epoch [  3/ 75] Iter[ 51/391]	 CE-loss: 1.3116cifar10:0.2-instance | Epoch [  3/ 75] Iter[101/391]	 CE-loss: 1.0878cifar10:0.2-instance | Epoch [  3/ 75] Iter[151/391]	 CE-loss: 1.1905cifar10:0.2-instance | Epoch [  3/ 75] Iter[201/391]	 CE-loss: 1.2004cifar10:0.2-instance | Epoch [  3/ 75] Iter[251/391]	 CE-loss: 1.1787cifar10:0.2-instance | Epoch [  3/ 75] Iter[301/391]	 CE-loss: 1.1841cifar10:0.2-instance | Epoch [  3/ 75] Iter[351/391]	 CE-loss: 1.1530
| Test Epoch 3	 Accuracy: 63.38% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 4 | Accuracy on train set: 54.95% 
cifar10:0.2-instance | Epoch [  4/ 75] Iter[  1/391]	 CE-loss: 1.3159cifar10:0.2-instance | Epoch [  4/ 75] Iter[ 51/391]	 CE-loss: 1.4034cifar10:0.2-instance | Epoch [  4/ 75] Iter[101/391]	 CE-loss: 1.0540cifar10:0.2-instance | Epoch [  4/ 75] Iter[151/391]	 CE-loss: 1.2228cifar10:0.2-instance | Epoch [  4/ 75] Iter[201/391]	 CE-loss: 1.1885cifar10:0.2-instance | Epoch [  4/ 75] Iter[251/391]	 CE-loss: 0.9691cifar10:0.2-instance | Epoch [  4/ 75] Iter[301/391]	 CE-loss: 1.1214cifar10:0.2-instance | Epoch [  4/ 75] Iter[351/391]	 CE-loss: 1.2995
| Test Epoch 4	 Accuracy: 76.57% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 5 | Accuracy on train set: 63.15% 
cifar10:0.2-instance | Epoch [  5/ 75] Iter[  1/391]	 CE-loss: 1.1711cifar10:0.2-instance | Epoch [  5/ 75] Iter[ 51/391]	 CE-loss: 1.1720cifar10:0.2-instance | Epoch [  5/ 75] Iter[101/391]	 CE-loss: 1.1158cifar10:0.2-instance | Epoch [  5/ 75] Iter[151/391]	 CE-loss: 1.1337cifar10:0.2-instance | Epoch [  5/ 75] Iter[201/391]	 CE-loss: 0.9653cifar10:0.2-instance | Epoch [  5/ 75] Iter[251/391]	 CE-loss: 1.0975cifar10:0.2-instance | Epoch [  5/ 75] Iter[301/391]	 CE-loss: 1.2997cifar10:0.2-instance | Epoch [  5/ 75] Iter[351/391]	 CE-loss: 1.1095
| Test Epoch 5	 Accuracy: 77.45% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 6 | Accuracy on train set: 64.61% 
cifar10:0.2-instance | Epoch [  6/ 75] Iter[  1/391]	 CE-loss: 1.1526cifar10:0.2-instance | Epoch [  6/ 75] Iter[ 51/391]	 CE-loss: 1.0322cifar10:0.2-instance | Epoch [  6/ 75] Iter[101/391]	 CE-loss: 1.0567cifar10:0.2-instance | Epoch [  6/ 75] Iter[151/391]	 CE-loss: 1.1621cifar10:0.2-instance | Epoch [  6/ 75] Iter[201/391]	 CE-loss: 1.0186cifar10:0.2-instance | Epoch [  6/ 75] Iter[251/391]	 CE-loss: 1.1258cifar10:0.2-instance | Epoch [  6/ 75] Iter[301/391]	 CE-loss: 1.0803cifar10:0.2-instance | Epoch [  6/ 75] Iter[351/391]	 CE-loss: 0.9883
| Test Epoch 6	 Accuracy: 77.16% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 7 | Accuracy on train set: 64.41% 
cifar10:0.2-instance | Epoch [  7/ 75] Iter[  1/391]	 CE-loss: 1.0954cifar10:0.2-instance | Epoch [  7/ 75] Iter[ 51/391]	 CE-loss: 0.9392cifar10:0.2-instance | Epoch [  7/ 75] Iter[101/391]	 CE-loss: 1.0324cifar10:0.2-instance | Epoch [  7/ 75] Iter[151/391]	 CE-loss: 1.0110cifar10:0.2-instance | Epoch [  7/ 75] Iter[201/391]	 CE-loss: 0.9738cifar10:0.2-instance | Epoch [  7/ 75] Iter[251/391]	 CE-loss: 0.9089cifar10:0.2-instance | Epoch [  7/ 75] Iter[301/391]	 CE-loss: 1.1581cifar10:0.2-instance | Epoch [  7/ 75] Iter[351/391]	 CE-loss: 1.0329
| Test Epoch 7	 Accuracy: 78.51% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 8 | Accuracy on train set: 65.27% 
cifar10:0.2-instance | Epoch [  8/ 75] Iter[  1/391]	 CE-loss: 0.8246cifar10:0.2-instance | Epoch [  8/ 75] Iter[ 51/391]	 CE-loss: 0.9922cifar10:0.2-instance | Epoch [  8/ 75] Iter[101/391]	 CE-loss: 0.9803cifar10:0.2-instance | Epoch [  8/ 75] Iter[151/391]	 CE-loss: 0.8961cifar10:0.2-instance | Epoch [  8/ 75] Iter[201/391]	 CE-loss: 1.0206cifar10:0.2-instance | Epoch [  8/ 75] Iter[251/391]	 CE-loss: 1.0855cifar10:0.2-instance | Epoch [  8/ 75] Iter[301/391]	 CE-loss: 1.1031cifar10:0.2-instance | Epoch [  8/ 75] Iter[351/391]	 CE-loss: 0.8066
| Test Epoch 8	 Accuracy: 80.95% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 9 | Accuracy on train set: 67.54% 
cifar10:0.2-instance | Epoch [  9/ 75] Iter[  1/391]	 CE-loss: 0.9122cifar10:0.2-instance | Epoch [  9/ 75] Iter[ 51/391]	 CE-loss: 0.9039cifar10:0.2-instance | Epoch [  9/ 75] Iter[101/391]	 CE-loss: 0.9949cifar10:0.2-instance | Epoch [  9/ 75] Iter[151/391]	 CE-loss: 1.1064cifar10:0.2-instance | Epoch [  9/ 75] Iter[201/391]	 CE-loss: 0.9213cifar10:0.2-instance | Epoch [  9/ 75] Iter[251/391]	 CE-loss: 1.0228cifar10:0.2-instance | Epoch [  9/ 75] Iter[301/391]	 CE-loss: 0.8148cifar10:0.2-instance | Epoch [  9/ 75] Iter[351/391]	 CE-loss: 0.8994
| Test Epoch 9	 Accuracy: 81.49% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 10 | Accuracy on train set: 68.04% 
labeled data has a size of 38299, f-score: 0.971461
cifar10:0.2-instance | Epoch [ 10/ 75] Iter[  1/1197]	  loss: 0.66cifar10:0.2-instance | Epoch [ 10/ 75] Iter[ 51/1197]	  loss: 1.47cifar10:0.2-instance | Epoch [ 10/ 75] Iter[101/1197]	  loss: 0.77cifar10:0.2-instance | Epoch [ 10/ 75] Iter[151/1197]	  loss: 0.64cifar10:0.2-instance | Epoch [ 10/ 75] Iter[201/1197]	  loss: 1.07cifar10:0.2-instance | Epoch [ 10/ 75] Iter[251/1197]	  loss: 0.60cifar10:0.2-instance | Epoch [ 10/ 75] Iter[301/1197]	  loss: 0.63cifar10:0.2-instance | Epoch [ 10/ 75] Iter[351/1197]	  loss: 0.74cifar10:0.2-instance | Epoch [ 10/ 75] Iter[401/1197]	  loss: 0.64cifar10:0.2-instance | Epoch [ 10/ 75] Iter[451/1197]	  loss: 0.56cifar10:0.2-instance | Epoch [ 10/ 75] Iter[501/1197]	  loss: 0.94cifar10:0.2-instance | Epoch [ 10/ 75] Iter[551/1197]	  loss: 0.81cifar10:0.2-instance | Epoch [ 10/ 75] Iter[601/1197]	  loss: 0.66cifar10:0.2-instance | Epoch [ 10/ 75] Iter[651/1197]	  loss: 1.05cifar10:0.2-instance | Epoch [ 10/ 75] Iter[701/1197]	  loss: 0.64cifar10:0.2-instance | Epoch [ 10/ 75] Iter[751/1197]	  loss: 0.43cifar10:0.2-instance | Epoch [ 10/ 75] Iter[801/1197]	  loss: 0.69cifar10:0.2-instance | Epoch [ 10/ 75] Iter[851/1197]	  loss: 0.81cifar10:0.2-instance | Epoch [ 10/ 75] Iter[901/1197]	  loss: 0.75cifar10:0.2-instance | Epoch [ 10/ 75] Iter[951/1197]	  loss: 0.85cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1001/1197]	  loss: 0.81cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1051/1197]	  loss: 0.52cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1101/1197]	  loss: 0.88cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1151/1197]	  loss: 0.83
| Test Epoch 10	 Accuracy: 78.09% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 11 | Accuracy on train set: 64.13% 
labeled data has a size of 38067, f-score: 0.976200
cifar10:0.2-instance | Epoch [ 11/ 75] Iter[  1/1190]	  loss: 0.51cifar10:0.2-instance | Epoch [ 11/ 75] Iter[ 51/1190]	  loss: 0.45cifar10:0.2-instance | Epoch [ 11/ 75] Iter[101/1190]	  loss: 0.34cifar10:0.2-instance | Epoch [ 11/ 75] Iter[151/1190]	  loss: 0.59cifar10:0.2-instance | Epoch [ 11/ 75] Iter[201/1190]	  loss: 0.54cifar10:0.2-instance | Epoch [ 11/ 75] Iter[251/1190]	  loss: 0.61cifar10:0.2-instance | Epoch [ 11/ 75] Iter[301/1190]	  loss: 0.72cifar10:0.2-instance | Epoch [ 11/ 75] Iter[351/1190]	  loss: 1.13cifar10:0.2-instance | Epoch [ 11/ 75] Iter[401/1190]	  loss: 0.68cifar10:0.2-instance | Epoch [ 11/ 75] Iter[451/1190]	  loss: 0.62cifar10:0.2-instance | Epoch [ 11/ 75] Iter[501/1190]	  loss: 0.61cifar10:0.2-instance | Epoch [ 11/ 75] Iter[551/1190]	  loss: 0.55cifar10:0.2-instance | Epoch [ 11/ 75] Iter[601/1190]	  loss: 0.82cifar10:0.2-instance | Epoch [ 11/ 75] Iter[651/1190]	  loss: 0.45cifar10:0.2-instance | Epoch [ 11/ 75] Iter[701/1190]	  loss: 0.62cifar10:0.2-instance | Epoch [ 11/ 75] Iter[751/1190]	  loss: 0.55cifar10:0.2-instance | Epoch [ 11/ 75] Iter[801/1190]	  loss: 0.43cifar10:0.2-instance | Epoch [ 11/ 75] Iter[851/1190]	  loss: 0.48cifar10:0.2-instance | Epoch [ 11/ 75] Iter[901/1190]	  loss: 0.62cifar10:0.2-instance | Epoch [ 11/ 75] Iter[951/1190]	  loss: 0.76cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1001/1190]	  loss: 0.54cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1051/1190]	  loss: 0.42cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1101/1190]	  loss: 0.47cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1151/1190]	  loss: 0.68
| Test Epoch 11	 Accuracy: 79.72% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 12 | Accuracy on train set: 66.18% 
labeled data has a size of 37883, f-score: 0.977325
cifar10:0.2-instance | Epoch [ 12/ 75] Iter[  1/1184]	  loss: 0.45cifar10:0.2-instance | Epoch [ 12/ 75] Iter[ 51/1184]	  loss: 0.51cifar10:0.2-instance | Epoch [ 12/ 75] Iter[101/1184]	  loss: 0.49cifar10:0.2-instance | Epoch [ 12/ 75] Iter[151/1184]	  loss: 0.45cifar10:0.2-instance | Epoch [ 12/ 75] Iter[201/1184]	  loss: 0.58cifar10:0.2-instance | Epoch [ 12/ 75] Iter[251/1184]	  loss: 0.41cifar10:0.2-instance | Epoch [ 12/ 75] Iter[301/1184]	  loss: 0.43cifar10:0.2-instance | Epoch [ 12/ 75] Iter[351/1184]	  loss: 0.47cifar10:0.2-instance | Epoch [ 12/ 75] Iter[401/1184]	  loss: 0.37cifar10:0.2-instance | Epoch [ 12/ 75] Iter[451/1184]	  loss: 0.45cifar10:0.2-instance | Epoch [ 12/ 75] Iter[501/1184]	  loss: 0.62cifar10:0.2-instance | Epoch [ 12/ 75] Iter[551/1184]	  loss: 0.61cifar10:0.2-instance | Epoch [ 12/ 75] Iter[601/1184]	  loss: 0.55cifar10:0.2-instance | Epoch [ 12/ 75] Iter[651/1184]	  loss: 0.45cifar10:0.2-instance | Epoch [ 12/ 75] Iter[701/1184]	  loss: 0.35cifar10:0.2-instance | Epoch [ 12/ 75] Iter[751/1184]	  loss: 0.48cifar10:0.2-instance | Epoch [ 12/ 75] Iter[801/1184]	  loss: 0.33cifar10:0.2-instance | Epoch [ 12/ 75] Iter[851/1184]	  loss: 0.54cifar10:0.2-instance | Epoch [ 12/ 75] Iter[901/1184]	  loss: 0.56cifar10:0.2-instance | Epoch [ 12/ 75] Iter[951/1184]	  loss: 0.78cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1001/1184]	  loss: 0.72cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1051/1184]	  loss: 0.68cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1101/1184]	  loss: 0.51cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1151/1184]	  loss: 0.76
| Test Epoch 12	 Accuracy: 79.58% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 13 | Accuracy on train set: 66.15% 
labeled data has a size of 37557, f-score: 0.978167
cifar10:0.2-instance | Epoch [ 13/ 75] Iter[  1/1174]	  loss: 0.41cifar10:0.2-instance | Epoch [ 13/ 75] Iter[ 51/1174]	  loss: 0.41cifar10:0.2-instance | Epoch [ 13/ 75] Iter[101/1174]	  loss: 0.44cifar10:0.2-instance | Epoch [ 13/ 75] Iter[151/1174]	  loss: 0.51cifar10:0.2-instance | Epoch [ 13/ 75] Iter[201/1174]	  loss: 0.30cifar10:0.2-instance | Epoch [ 13/ 75] Iter[251/1174]	  loss: 0.40cifar10:0.2-instance | Epoch [ 13/ 75] Iter[301/1174]	  loss: 0.44cifar10:0.2-instance | Epoch [ 13/ 75] Iter[351/1174]	  loss: 0.46cifar10:0.2-instance | Epoch [ 13/ 75] Iter[401/1174]	  loss: 0.34cifar10:0.2-instance | Epoch [ 13/ 75] Iter[451/1174]	  loss: 0.56cifar10:0.2-instance | Epoch [ 13/ 75] Iter[501/1174]	  loss: 0.31cifar10:0.2-instance | Epoch [ 13/ 75] Iter[551/1174]	  loss: 0.50cifar10:0.2-instance | Epoch [ 13/ 75] Iter[601/1174]	  loss: 0.72cifar10:0.2-instance | Epoch [ 13/ 75] Iter[651/1174]	  loss: 0.56cifar10:0.2-instance | Epoch [ 13/ 75] Iter[701/1174]	  loss: 0.41cifar10:0.2-instance | Epoch [ 13/ 75] Iter[751/1174]	  loss: 0.22cifar10:0.2-instance | Epoch [ 13/ 75] Iter[801/1174]	  loss: 0.48cifar10:0.2-instance | Epoch [ 13/ 75] Iter[851/1174]	  loss: 0.42cifar10:0.2-instance | Epoch [ 13/ 75] Iter[901/1174]	  loss: 0.64cifar10:0.2-instance | Epoch [ 13/ 75] Iter[951/1174]	  loss: 0.35cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1001/1174]	  loss: 0.48cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1051/1174]	  loss: 0.54cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1101/1174]	  loss: 0.44cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1151/1174]	  loss: 0.37
| Test Epoch 13	 Accuracy: 81.11% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 14 | Accuracy on train set: 66.96% 
labeled data has a size of 37691, f-score: 0.979916
cifar10:0.2-instance | Epoch [ 14/ 75] Iter[  1/1178]	  loss: 0.36cifar10:0.2-instance | Epoch [ 14/ 75] Iter[ 51/1178]	  loss: 0.78cifar10:0.2-instance | Epoch [ 14/ 75] Iter[101/1178]	  loss: 0.34cifar10:0.2-instance | Epoch [ 14/ 75] Iter[151/1178]	  loss: 0.24cifar10:0.2-instance | Epoch [ 14/ 75] Iter[201/1178]	  loss: 0.65cifar10:0.2-instance | Epoch [ 14/ 75] Iter[251/1178]	  loss: 0.49cifar10:0.2-instance | Epoch [ 14/ 75] Iter[301/1178]	  loss: 0.39cifar10:0.2-instance | Epoch [ 14/ 75] Iter[351/1178]	  loss: 0.53cifar10:0.2-instance | Epoch [ 14/ 75] Iter[401/1178]	  loss: 0.53cifar10:0.2-instance | Epoch [ 14/ 75] Iter[451/1178]	  loss: 0.25cifar10:0.2-instance | Epoch [ 14/ 75] Iter[501/1178]	  loss: 0.34cifar10:0.2-instance | Epoch [ 14/ 75] Iter[551/1178]	  loss: 0.54cifar10:0.2-instance | Epoch [ 14/ 75] Iter[601/1178]	  loss: 0.49cifar10:0.2-instance | Epoch [ 14/ 75] Iter[651/1178]	  loss: 0.57cifar10:0.2-instance | Epoch [ 14/ 75] Iter[701/1178]	  loss: 0.47cifar10:0.2-instance | Epoch [ 14/ 75] Iter[751/1178]	  loss: 0.56cifar10:0.2-instance | Epoch [ 14/ 75] Iter[801/1178]	  loss: 0.71cifar10:0.2-instance | Epoch [ 14/ 75] Iter[851/1178]	  loss: 0.31cifar10:0.2-instance | Epoch [ 14/ 75] Iter[901/1178]	  loss: 0.72cifar10:0.2-instance | Epoch [ 14/ 75] Iter[951/1178]	  loss: 0.52cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1001/1178]	  loss: 0.60cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1051/1178]	  loss: 0.37cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1101/1178]	  loss: 0.81cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1151/1178]	  loss: 0.38
| Test Epoch 14	 Accuracy: 80.27% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 15 | Accuracy on train set: 66.55% 
labeled data has a size of 38015, f-score: 0.979929
cifar10:0.2-instance | Epoch [ 15/ 75] Iter[  1/1188]	  loss: 0.68cifar10:0.2-instance | Epoch [ 15/ 75] Iter[ 51/1188]	  loss: 0.32cifar10:0.2-instance | Epoch [ 15/ 75] Iter[101/1188]	  loss: 0.47cifar10:0.2-instance | Epoch [ 15/ 75] Iter[151/1188]	  loss: 0.19cifar10:0.2-instance | Epoch [ 15/ 75] Iter[201/1188]	  loss: 0.48cifar10:0.2-instance | Epoch [ 15/ 75] Iter[251/1188]	  loss: 0.74cifar10:0.2-instance | Epoch [ 15/ 75] Iter[301/1188]	  loss: 0.34cifar10:0.2-instance | Epoch [ 15/ 75] Iter[351/1188]	  loss: 0.25cifar10:0.2-instance | Epoch [ 15/ 75] Iter[401/1188]	  loss: 0.39cifar10:0.2-instance | Epoch [ 15/ 75] Iter[451/1188]	  loss: 0.31cifar10:0.2-instance | Epoch [ 15/ 75] Iter[501/1188]	  loss: 0.46cifar10:0.2-instance | Epoch [ 15/ 75] Iter[551/1188]	  loss: 0.49cifar10:0.2-instance | Epoch [ 15/ 75] Iter[601/1188]	  loss: 0.44cifar10:0.2-instance | Epoch [ 15/ 75] Iter[651/1188]	  loss: 0.56cifar10:0.2-instance | Epoch [ 15/ 75] Iter[701/1188]	  loss: 0.32cifar10:0.2-instance | Epoch [ 15/ 75] Iter[751/1188]	  loss: 0.58cifar10:0.2-instance | Epoch [ 15/ 75] Iter[801/1188]	  loss: 0.35cifar10:0.2-instance | Epoch [ 15/ 75] Iter[851/1188]	  loss: 0.46cifar10:0.2-instance | Epoch [ 15/ 75] Iter[901/1188]	  loss: 0.44cifar10:0.2-instance | Epoch [ 15/ 75] Iter[951/1188]	  loss: 0.80cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1001/1188]	  loss: 0.75cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1051/1188]	  loss: 0.70cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1101/1188]	  loss: 0.38cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1151/1188]	  loss: 0.60
| Test Epoch 15	 Accuracy: 77.64% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 16 | Accuracy on train set: 65.07% 
labeled data has a size of 38139, f-score: 0.978421
cifar10:0.2-instance | Epoch [ 16/ 75] Iter[  1/1192]	  loss: 0.33cifar10:0.2-instance | Epoch [ 16/ 75] Iter[ 51/1192]	  loss: 0.38cifar10:0.2-instance | Epoch [ 16/ 75] Iter[101/1192]	  loss: 0.55cifar10:0.2-instance | Epoch [ 16/ 75] Iter[151/1192]	  loss: 0.39cifar10:0.2-instance | Epoch [ 16/ 75] Iter[201/1192]	  loss: 0.72cifar10:0.2-instance | Epoch [ 16/ 75] Iter[251/1192]	  loss: 0.31cifar10:0.2-instance | Epoch [ 16/ 75] Iter[301/1192]	  loss: 0.37cifar10:0.2-instance | Epoch [ 16/ 75] Iter[351/1192]	  loss: 0.39cifar10:0.2-instance | Epoch [ 16/ 75] Iter[401/1192]	  loss: 0.40cifar10:0.2-instance | Epoch [ 16/ 75] Iter[451/1192]	  loss: 0.50cifar10:0.2-instance | Epoch [ 16/ 75] Iter[501/1192]	  loss: 0.45cifar10:0.2-instance | Epoch [ 16/ 75] Iter[551/1192]	  loss: 0.47cifar10:0.2-instance | Epoch [ 16/ 75] Iter[601/1192]	  loss: 0.56cifar10:0.2-instance | Epoch [ 16/ 75] Iter[651/1192]	  loss: 0.61cifar10:0.2-instance | Epoch [ 16/ 75] Iter[701/1192]	  loss: 0.34cifar10:0.2-instance | Epoch [ 16/ 75] Iter[751/1192]	  loss: 0.46cifar10:0.2-instance | Epoch [ 16/ 75] Iter[801/1192]	  loss: 0.67cifar10:0.2-instance | Epoch [ 16/ 75] Iter[851/1192]	  loss: 0.52cifar10:0.2-instance | Epoch [ 16/ 75] Iter[901/1192]	  loss: 0.66cifar10:0.2-instance | Epoch [ 16/ 75] Iter[951/1192]	  loss: 0.40cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1001/1192]	  loss: 0.57cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1051/1192]	  loss: 0.41cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1101/1192]	  loss: 0.33cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1151/1192]	  loss: 0.54
| Test Epoch 16	 Accuracy: 83.36% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 17 | Accuracy on train set: 69.45% 
labeled data has a size of 38165, f-score: 0.978069
cifar10:0.2-instance | Epoch [ 17/ 75] Iter[  1/1193]	  loss: 0.42cifar10:0.2-instance | Epoch [ 17/ 75] Iter[ 51/1193]	  loss: 0.34cifar10:0.2-instance | Epoch [ 17/ 75] Iter[101/1193]	  loss: 0.46cifar10:0.2-instance | Epoch [ 17/ 75] Iter[151/1193]	  loss: 0.57cifar10:0.2-instance | Epoch [ 17/ 75] Iter[201/1193]	  loss: 0.34cifar10:0.2-instance | Epoch [ 17/ 75] Iter[251/1193]	  loss: 0.39cifar10:0.2-instance | Epoch [ 17/ 75] Iter[301/1193]	  loss: 0.55cifar10:0.2-instance | Epoch [ 17/ 75] Iter[351/1193]	  loss: 0.55cifar10:0.2-instance | Epoch [ 17/ 75] Iter[401/1193]	  loss: 0.44cifar10:0.2-instance | Epoch [ 17/ 75] Iter[451/1193]	  loss: 0.71cifar10:0.2-instance | Epoch [ 17/ 75] Iter[501/1193]	  loss: 0.62cifar10:0.2-instance | Epoch [ 17/ 75] Iter[551/1193]	  loss: 0.48cifar10:0.2-instance | Epoch [ 17/ 75] Iter[601/1193]	  loss: 0.67cifar10:0.2-instance | Epoch [ 17/ 75] Iter[651/1193]	  loss: 0.40cifar10:0.2-instance | Epoch [ 17/ 75] Iter[701/1193]	  loss: 0.50cifar10:0.2-instance | Epoch [ 17/ 75] Iter[751/1193]	  loss: 0.61cifar10:0.2-instance | Epoch [ 17/ 75] Iter[801/1193]	  loss: 0.54cifar10:0.2-instance | Epoch [ 17/ 75] Iter[851/1193]	  loss: 0.55cifar10:0.2-instance | Epoch [ 17/ 75] Iter[901/1193]	  loss: 0.28cifar10:0.2-instance | Epoch [ 17/ 75] Iter[951/1193]	  loss: 0.37cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1001/1193]	  loss: 0.49cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1051/1193]	  loss: 0.68cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1101/1193]	  loss: 0.76cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1151/1193]	  loss: 0.41
| Test Epoch 17	 Accuracy: 83.58% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 18 | Accuracy on train set: 69.65% 
labeled data has a size of 38269, f-score: 0.977710
cifar10:0.2-instance | Epoch [ 18/ 75] Iter[  1/1196]	  loss: 0.54cifar10:0.2-instance | Epoch [ 18/ 75] Iter[ 51/1196]	  loss: 0.47cifar10:0.2-instance | Epoch [ 18/ 75] Iter[101/1196]	  loss: 0.34cifar10:0.2-instance | Epoch [ 18/ 75] Iter[151/1196]	  loss: 0.46cifar10:0.2-instance | Epoch [ 18/ 75] Iter[201/1196]	  loss: 0.46cifar10:0.2-instance | Epoch [ 18/ 75] Iter[251/1196]	  loss: 0.36cifar10:0.2-instance | Epoch [ 18/ 75] Iter[301/1196]	  loss: 0.52cifar10:0.2-instance | Epoch [ 18/ 75] Iter[351/1196]	  loss: 0.39cifar10:0.2-instance | Epoch [ 18/ 75] Iter[401/1196]	  loss: 0.45cifar10:0.2-instance | Epoch [ 18/ 75] Iter[451/1196]	  loss: 0.24cifar10:0.2-instance | Epoch [ 18/ 75] Iter[501/1196]	  loss: 0.46cifar10:0.2-instance | Epoch [ 18/ 75] Iter[551/1196]	  loss: 0.45cifar10:0.2-instance | Epoch [ 18/ 75] Iter[601/1196]	  loss: 0.38cifar10:0.2-instance | Epoch [ 18/ 75] Iter[651/1196]	  loss: 0.44cifar10:0.2-instance | Epoch [ 18/ 75] Iter[701/1196]	  loss: 0.38cifar10:0.2-instance | Epoch [ 18/ 75] Iter[751/1196]	  loss: 0.47cifar10:0.2-instance | Epoch [ 18/ 75] Iter[801/1196]	  loss: 0.47cifar10:0.2-instance | Epoch [ 18/ 75] Iter[851/1196]	  loss: 0.53cifar10:0.2-instance | Epoch [ 18/ 75] Iter[901/1196]	  loss: 0.36cifar10:0.2-instance | Epoch [ 18/ 75] Iter[951/1196]	  loss: 0.46cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1001/1196]	  loss: 0.32cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1051/1196]	  loss: 0.52cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1101/1196]	  loss: 0.62cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1151/1196]	  loss: 0.54
| Test Epoch 18	 Accuracy: 82.33% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 19 | Accuracy on train set: 69.26% 
labeled data has a size of 38227, f-score: 0.979046
cifar10:0.2-instance | Epoch [ 19/ 75] Iter[  1/1195]	  loss: 0.35cifar10:0.2-instance | Epoch [ 19/ 75] Iter[ 51/1195]	  loss: 0.32cifar10:0.2-instance | Epoch [ 19/ 75] Iter[101/1195]	  loss: 0.47cifar10:0.2-instance | Epoch [ 19/ 75] Iter[151/1195]	  loss: 0.37cifar10:0.2-instance | Epoch [ 19/ 75] Iter[201/1195]	  loss: 0.36cifar10:0.2-instance | Epoch [ 19/ 75] Iter[251/1195]	  loss: 0.47cifar10:0.2-instance | Epoch [ 19/ 75] Iter[301/1195]	  loss: 0.32cifar10:0.2-instance | Epoch [ 19/ 75] Iter[351/1195]	  loss: 0.52cifar10:0.2-instance | Epoch [ 19/ 75] Iter[401/1195]	  loss: 0.52cifar10:0.2-instance | Epoch [ 19/ 75] Iter[451/1195]	  loss: 0.40cifar10:0.2-instance | Epoch [ 19/ 75] Iter[501/1195]	  loss: 0.42cifar10:0.2-instance | Epoch [ 19/ 75] Iter[551/1195]	  loss: 0.64cifar10:0.2-instance | Epoch [ 19/ 75] Iter[601/1195]	  loss: 0.41cifar10:0.2-instance | Epoch [ 19/ 75] Iter[651/1195]	  loss: 0.33cifar10:0.2-instance | Epoch [ 19/ 75] Iter[701/1195]	  loss: 0.41cifar10:0.2-instance | Epoch [ 19/ 75] Iter[751/1195]	  loss: 0.55cifar10:0.2-instance | Epoch [ 19/ 75] Iter[801/1195]	  loss: 0.50cifar10:0.2-instance | Epoch [ 19/ 75] Iter[851/1195]	  loss: 0.39cifar10:0.2-instance | Epoch [ 19/ 75] Iter[901/1195]	  loss: 0.58cifar10:0.2-instance | Epoch [ 19/ 75] Iter[951/1195]	  loss: 0.41cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1001/1195]	  loss: 0.58cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1051/1195]	  loss: 0.39cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1101/1195]	  loss: 0.50cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1151/1195]	  loss: 0.47
| Test Epoch 19	 Accuracy: 84.45% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 20 | Accuracy on train set: 70.35% 
labeled data has a size of 38469, f-score: 0.979334
cifar10:0.2-instance | Epoch [ 20/ 75] Iter[  1/1203]	  loss: 0.36cifar10:0.2-instance | Epoch [ 20/ 75] Iter[ 51/1203]	  loss: 0.62cifar10:0.2-instance | Epoch [ 20/ 75] Iter[101/1203]	  loss: 0.81cifar10:0.2-instance | Epoch [ 20/ 75] Iter[151/1203]	  loss: 0.31cifar10:0.2-instance | Epoch [ 20/ 75] Iter[201/1203]	  loss: 0.33cifar10:0.2-instance | Epoch [ 20/ 75] Iter[251/1203]	  loss: 0.36cifar10:0.2-instance | Epoch [ 20/ 75] Iter[301/1203]	  loss: 0.31cifar10:0.2-instance | Epoch [ 20/ 75] Iter[351/1203]	  loss: 0.58cifar10:0.2-instance | Epoch [ 20/ 75] Iter[401/1203]	  loss: 0.49cifar10:0.2-instance | Epoch [ 20/ 75] Iter[451/1203]	  loss: 0.41cifar10:0.2-instance | Epoch [ 20/ 75] Iter[501/1203]	  loss: 0.46cifar10:0.2-instance | Epoch [ 20/ 75] Iter[551/1203]	  loss: 0.50cifar10:0.2-instance | Epoch [ 20/ 75] Iter[601/1203]	  loss: 0.33cifar10:0.2-instance | Epoch [ 20/ 75] Iter[651/1203]	  loss: 0.47cifar10:0.2-instance | Epoch [ 20/ 75] Iter[701/1203]	  loss: 0.47cifar10:0.2-instance | Epoch [ 20/ 75] Iter[751/1203]	  loss: 0.27cifar10:0.2-instance | Epoch [ 20/ 75] Iter[801/1203]	  loss: 0.51cifar10:0.2-instance | Epoch [ 20/ 75] Iter[851/1203]	  loss: 0.59cifar10:0.2-instance | Epoch [ 20/ 75] Iter[901/1203]	  loss: 0.57cifar10:0.2-instance | Epoch [ 20/ 75] Iter[951/1203]	  loss: 0.67cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1001/1203]	  loss: 0.36cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1051/1203]	  loss: 0.42cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1101/1203]	  loss: 0.41cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1151/1203]	  loss: 0.45cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1201/1203]	  loss: 0.27
| Test Epoch 20	 Accuracy: 83.28% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 21 | Accuracy on train set: 70.22% 
labeled data has a size of 38576, f-score: 0.978847
cifar10:0.2-instance | Epoch [ 21/ 75] Iter[  1/1206]	  loss: 0.39cifar10:0.2-instance | Epoch [ 21/ 75] Iter[ 51/1206]	  loss: 0.44cifar10:0.2-instance | Epoch [ 21/ 75] Iter[101/1206]	  loss: 0.27cifar10:0.2-instance | Epoch [ 21/ 75] Iter[151/1206]	  loss: 0.29cifar10:0.2-instance | Epoch [ 21/ 75] Iter[201/1206]	  loss: 0.59cifar10:0.2-instance | Epoch [ 21/ 75] Iter[251/1206]	  loss: 0.34cifar10:0.2-instance | Epoch [ 21/ 75] Iter[301/1206]	  loss: 0.63cifar10:0.2-instance | Epoch [ 21/ 75] Iter[351/1206]	  loss: 0.99cifar10:0.2-instance | Epoch [ 21/ 75] Iter[401/1206]	  loss: 0.25cifar10:0.2-instance | Epoch [ 21/ 75] Iter[451/1206]	  loss: 0.38cifar10:0.2-instance | Epoch [ 21/ 75] Iter[501/1206]	  loss: 0.37cifar10:0.2-instance | Epoch [ 21/ 75] Iter[551/1206]	  loss: 0.60cifar10:0.2-instance | Epoch [ 21/ 75] Iter[601/1206]	  loss: 0.46cifar10:0.2-instance | Epoch [ 21/ 75] Iter[651/1206]	  loss: 0.45cifar10:0.2-instance | Epoch [ 21/ 75] Iter[701/1206]	  loss: 0.31cifar10:0.2-instance | Epoch [ 21/ 75] Iter[751/1206]	  loss: 0.37cifar10:0.2-instance | Epoch [ 21/ 75] Iter[801/1206]	  loss: 0.37cifar10:0.2-instance | Epoch [ 21/ 75] Iter[851/1206]	  loss: 0.58cifar10:0.2-instance | Epoch [ 21/ 75] Iter[901/1206]	  loss: 0.55cifar10:0.2-instance | Epoch [ 21/ 75] Iter[951/1206]	  loss: 0.47cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1001/1206]	  loss: 0.28cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1051/1206]	  loss: 0.32cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1101/1206]	  loss: 0.44cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1151/1206]	  loss: 0.43cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1201/1206]	  loss: 0.21
| Test Epoch 21	 Accuracy: 81.79% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 22 | Accuracy on train set: 68.49% 
labeled data has a size of 38492, f-score: 0.980334
cifar10:0.2-instance | Epoch [ 22/ 75] Iter[  1/1203]	  loss: 0.51cifar10:0.2-instance | Epoch [ 22/ 75] Iter[ 51/1203]	  loss: 0.48cifar10:0.2-instance | Epoch [ 22/ 75] Iter[101/1203]	  loss: 0.39cifar10:0.2-instance | Epoch [ 22/ 75] Iter[151/1203]	  loss: 0.44cifar10:0.2-instance | Epoch [ 22/ 75] Iter[201/1203]	  loss: 0.32cifar10:0.2-instance | Epoch [ 22/ 75] Iter[251/1203]	  loss: 0.40cifar10:0.2-instance | Epoch [ 22/ 75] Iter[301/1203]	  loss: 0.34cifar10:0.2-instance | Epoch [ 22/ 75] Iter[351/1203]	  loss: 0.42cifar10:0.2-instance | Epoch [ 22/ 75] Iter[401/1203]	  loss: 0.47cifar10:0.2-instance | Epoch [ 22/ 75] Iter[451/1203]	  loss: 0.54cifar10:0.2-instance | Epoch [ 22/ 75] Iter[501/1203]	  loss: 0.37cifar10:0.2-instance | Epoch [ 22/ 75] Iter[551/1203]	  loss: 0.53cifar10:0.2-instance | Epoch [ 22/ 75] Iter[601/1203]	  loss: 0.42cifar10:0.2-instance | Epoch [ 22/ 75] Iter[651/1203]	  loss: 0.44cifar10:0.2-instance | Epoch [ 22/ 75] Iter[701/1203]	  loss: 0.41cifar10:0.2-instance | Epoch [ 22/ 75] Iter[751/1203]	  loss: 0.41cifar10:0.2-instance | Epoch [ 22/ 75] Iter[801/1203]	  loss: 0.50cifar10:0.2-instance | Epoch [ 22/ 75] Iter[851/1203]	  loss: 0.52cifar10:0.2-instance | Epoch [ 22/ 75] Iter[901/1203]	  loss: 0.27cifar10:0.2-instance | Epoch [ 22/ 75] Iter[951/1203]	  loss: 0.49cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1001/1203]	  loss: 0.45cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1051/1203]	  loss: 0.33cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1101/1203]	  loss: 0.41cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1151/1203]	  loss: 0.39cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1201/1203]	  loss: 0.46
| Test Epoch 22	 Accuracy: 82.74% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 23 | Accuracy on train set: 69.63% 
labeled data has a size of 38695, f-score: 0.979377
cifar10:0.2-instance | Epoch [ 23/ 75] Iter[  1/1210]	  loss: 0.68cifar10:0.2-instance | Epoch [ 23/ 75] Iter[ 51/1210]	  loss: 0.35cifar10:0.2-instance | Epoch [ 23/ 75] Iter[101/1210]	  loss: 0.29cifar10:0.2-instance | Epoch [ 23/ 75] Iter[151/1210]	  loss: 0.37cifar10:0.2-instance | Epoch [ 23/ 75] Iter[201/1210]	  loss: 0.54cifar10:0.2-instance | Epoch [ 23/ 75] Iter[251/1210]	  loss: 0.46cifar10:0.2-instance | Epoch [ 23/ 75] Iter[301/1210]	  loss: 0.26cifar10:0.2-instance | Epoch [ 23/ 75] Iter[351/1210]	  loss: 0.54cifar10:0.2-instance | Epoch [ 23/ 75] Iter[401/1210]	  loss: 0.29cifar10:0.2-instance | Epoch [ 23/ 75] Iter[451/1210]	  loss: 0.39cifar10:0.2-instance | Epoch [ 23/ 75] Iter[501/1210]	  loss: 0.59cifar10:0.2-instance | Epoch [ 23/ 75] Iter[551/1210]	  loss: 0.50cifar10:0.2-instance | Epoch [ 23/ 75] Iter[601/1210]	  loss: 0.65cifar10:0.2-instance | Epoch [ 23/ 75] Iter[651/1210]	  loss: 0.50cifar10:0.2-instance | Epoch [ 23/ 75] Iter[701/1210]	  loss: 0.27cifar10:0.2-instance | Epoch [ 23/ 75] Iter[751/1210]	  loss: 0.45cifar10:0.2-instance | Epoch [ 23/ 75] Iter[801/1210]	  loss: 0.44cifar10:0.2-instance | Epoch [ 23/ 75] Iter[851/1210]	  loss: 0.53cifar10:0.2-instance | Epoch [ 23/ 75] Iter[901/1210]	  loss: 0.39cifar10:0.2-instance | Epoch [ 23/ 75] Iter[951/1210]	  loss: 0.47cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1001/1210]	  loss: 0.39cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1051/1210]	  loss: 0.39cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1101/1210]	  loss: 0.34cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1151/1210]	  loss: 0.39cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1201/1210]	  loss: 0.60
| Test Epoch 23	 Accuracy: 82.73% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 24 | Accuracy on train set: 69.56% 
labeled data has a size of 38762, f-score: 0.979464
cifar10:0.2-instance | Epoch [ 24/ 75] Iter[  1/1212]	  loss: 0.41cifar10:0.2-instance | Epoch [ 24/ 75] Iter[ 51/1212]	  loss: 0.78cifar10:0.2-instance | Epoch [ 24/ 75] Iter[101/1212]	  loss: 0.20cifar10:0.2-instance | Epoch [ 24/ 75] Iter[151/1212]	  loss: 0.62cifar10:0.2-instance | Epoch [ 24/ 75] Iter[201/1212]	  loss: 0.47cifar10:0.2-instance | Epoch [ 24/ 75] Iter[251/1212]	  loss: 0.38cifar10:0.2-instance | Epoch [ 24/ 75] Iter[301/1212]	  loss: 0.42cifar10:0.2-instance | Epoch [ 24/ 75] Iter[351/1212]	  loss: 0.35cifar10:0.2-instance | Epoch [ 24/ 75] Iter[401/1212]	  loss: 0.64cifar10:0.2-instance | Epoch [ 24/ 75] Iter[451/1212]	  loss: 0.56cifar10:0.2-instance | Epoch [ 24/ 75] Iter[501/1212]	  loss: 0.35cifar10:0.2-instance | Epoch [ 24/ 75] Iter[551/1212]	  loss: 0.33cifar10:0.2-instance | Epoch [ 24/ 75] Iter[601/1212]	  loss: 0.49cifar10:0.2-instance | Epoch [ 24/ 75] Iter[651/1212]	  loss: 0.53cifar10:0.2-instance | Epoch [ 24/ 75] Iter[701/1212]	  loss: 0.31cifar10:0.2-instance | Epoch [ 24/ 75] Iter[751/1212]	  loss: 0.34cifar10:0.2-instance | Epoch [ 24/ 75] Iter[801/1212]	  loss: 0.40cifar10:0.2-instance | Epoch [ 24/ 75] Iter[851/1212]	  loss: 0.69cifar10:0.2-instance | Epoch [ 24/ 75] Iter[901/1212]	  loss: 0.62cifar10:0.2-instance | Epoch [ 24/ 75] Iter[951/1212]	  loss: 0.29cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1001/1212]	  loss: 0.53cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1051/1212]	  loss: 0.38cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1101/1212]	  loss: 0.59cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1151/1212]	  loss: 0.35cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1201/1212]	  loss: 0.61
| Test Epoch 24	 Accuracy: 84.37% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 25 | Accuracy on train set: 70.48% 
labeled data has a size of 38671, f-score: 0.979623
cifar10:0.2-instance | Epoch [ 25/ 75] Iter[  1/1209]	  loss: 0.39cifar10:0.2-instance | Epoch [ 25/ 75] Iter[ 51/1209]	  loss: 0.32cifar10:0.2-instance | Epoch [ 25/ 75] Iter[101/1209]	  loss: 0.52cifar10:0.2-instance | Epoch [ 25/ 75] Iter[151/1209]	  loss: 0.34cifar10:0.2-instance | Epoch [ 25/ 75] Iter[201/1209]	  loss: 0.50cifar10:0.2-instance | Epoch [ 25/ 75] Iter[251/1209]	  loss: 0.30cifar10:0.2-instance | Epoch [ 25/ 75] Iter[301/1209]	  loss: 0.48cifar10:0.2-instance | Epoch [ 25/ 75] Iter[351/1209]	  loss: 0.43cifar10:0.2-instance | Epoch [ 25/ 75] Iter[401/1209]	  loss: 0.57cifar10:0.2-instance | Epoch [ 25/ 75] Iter[451/1209]	  loss: 0.45cifar10:0.2-instance | Epoch [ 25/ 75] Iter[501/1209]	  loss: 0.34cifar10:0.2-instance | Epoch [ 25/ 75] Iter[551/1209]	  loss: 0.64cifar10:0.2-instance | Epoch [ 25/ 75] Iter[601/1209]	  loss: 0.34cifar10:0.2-instance | Epoch [ 25/ 75] Iter[651/1209]	  loss: 0.64cifar10:0.2-instance | Epoch [ 25/ 75] Iter[701/1209]	  loss: 0.33cifar10:0.2-instance | Epoch [ 25/ 75] Iter[751/1209]	  loss: 0.48cifar10:0.2-instance | Epoch [ 25/ 75] Iter[801/1209]	  loss: 0.40cifar10:0.2-instance | Epoch [ 25/ 75] Iter[851/1209]	  loss: 0.33cifar10:0.2-instance | Epoch [ 25/ 75] Iter[901/1209]	  loss: 0.27cifar10:0.2-instance | Epoch [ 25/ 75] Iter[951/1209]	  loss: 0.32cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1001/1209]	  loss: 0.46cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1051/1209]	  loss: 0.29cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1101/1209]	  loss: 0.28cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1151/1209]	  loss: 0.68cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1201/1209]	  loss: 0.56
| Test Epoch 25	 Accuracy: 83.65% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 26 | Accuracy on train set: 70.55% 
labeled data has a size of 38709, f-score: 0.979307
cifar10:0.2-instance | Epoch [ 26/ 75] Iter[  1/1210]	  loss: 0.32cifar10:0.2-instance | Epoch [ 26/ 75] Iter[ 51/1210]	  loss: 0.18cifar10:0.2-instance | Epoch [ 26/ 75] Iter[101/1210]	  loss: 0.23cifar10:0.2-instance | Epoch [ 26/ 75] Iter[151/1210]	  loss: 0.36cifar10:0.2-instance | Epoch [ 26/ 75] Iter[201/1210]	  loss: 0.43cifar10:0.2-instance | Epoch [ 26/ 75] Iter[251/1210]	  loss: 0.34cifar10:0.2-instance | Epoch [ 26/ 75] Iter[301/1210]	  loss: 0.38cifar10:0.2-instance | Epoch [ 26/ 75] Iter[351/1210]	  loss: 0.51cifar10:0.2-instance | Epoch [ 26/ 75] Iter[401/1210]	  loss: 0.28cifar10:0.2-instance | Epoch [ 26/ 75] Iter[451/1210]	  loss: 0.32cifar10:0.2-instance | Epoch [ 26/ 75] Iter[501/1210]	  loss: 0.52cifar10:0.2-instance | Epoch [ 26/ 75] Iter[551/1210]	  loss: 0.34cifar10:0.2-instance | Epoch [ 26/ 75] Iter[601/1210]	  loss: 0.33cifar10:0.2-instance | Epoch [ 26/ 75] Iter[651/1210]	  loss: 0.27cifar10:0.2-instance | Epoch [ 26/ 75] Iter[701/1210]	  loss: 0.29cifar10:0.2-instance | Epoch [ 26/ 75] Iter[751/1210]	  loss: 0.57cifar10:0.2-instance | Epoch [ 26/ 75] Iter[801/1210]	  loss: 0.63cifar10:0.2-instance | Epoch [ 26/ 75] Iter[851/1210]	  loss: 0.53cifar10:0.2-instance | Epoch [ 26/ 75] Iter[901/1210]	  loss: 0.54cifar10:0.2-instance | Epoch [ 26/ 75] Iter[951/1210]	  loss: 0.38cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1001/1210]	  loss: 0.33cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1051/1210]	  loss: 0.26cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1101/1210]	  loss: 0.46cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1151/1210]	  loss: 0.30cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1201/1210]	  loss: 0.35
| Test Epoch 26	 Accuracy: 84.19% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 27 | Accuracy on train set: 70.74% 
labeled data has a size of 38706, f-score: 0.978530
cifar10:0.2-instance | Epoch [ 27/ 75] Iter[  1/1210]	  loss: 0.51cifar10:0.2-instance | Epoch [ 27/ 75] Iter[ 51/1210]	  loss: 0.34cifar10:0.2-instance | Epoch [ 27/ 75] Iter[101/1210]	  loss: 0.37cifar10:0.2-instance | Epoch [ 27/ 75] Iter[151/1210]	  loss: 0.47cifar10:0.2-instance | Epoch [ 27/ 75] Iter[201/1210]	  loss: 0.53cifar10:0.2-instance | Epoch [ 27/ 75] Iter[251/1210]	  loss: 0.73cifar10:0.2-instance | Epoch [ 27/ 75] Iter[301/1210]	  loss: 0.43cifar10:0.2-instance | Epoch [ 27/ 75] Iter[351/1210]	  loss: 0.32cifar10:0.2-instance | Epoch [ 27/ 75] Iter[401/1210]	  loss: 0.36cifar10:0.2-instance | Epoch [ 27/ 75] Iter[451/1210]	  loss: 0.32cifar10:0.2-instance | Epoch [ 27/ 75] Iter[501/1210]	  loss: 0.31cifar10:0.2-instance | Epoch [ 27/ 75] Iter[551/1210]	  loss: 0.64cifar10:0.2-instance | Epoch [ 27/ 75] Iter[601/1210]	  loss: 0.53cifar10:0.2-instance | Epoch [ 27/ 75] Iter[651/1210]	  loss: 0.41cifar10:0.2-instance | Epoch [ 27/ 75] Iter[701/1210]	  loss: 0.49cifar10:0.2-instance | Epoch [ 27/ 75] Iter[751/1210]	  loss: 0.41cifar10:0.2-instance | Epoch [ 27/ 75] Iter[801/1210]	  loss: 0.38cifar10:0.2-instance | Epoch [ 27/ 75] Iter[851/1210]	  loss: 0.35cifar10:0.2-instance | Epoch [ 27/ 75] Iter[901/1210]	  loss: 0.27cifar10:0.2-instance | Epoch [ 27/ 75] Iter[951/1210]	  loss: 0.49cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1001/1210]	  loss: 0.65cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1051/1210]	  loss: 0.26cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1101/1210]	  loss: 0.55cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1151/1210]	  loss: 0.33cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1201/1210]	  loss: 0.42
| Test Epoch 27	 Accuracy: 81.91% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 28 | Accuracy on train set: 68.37% 
labeled data has a size of 38796, f-score: 0.978812
cifar10:0.2-instance | Epoch [ 28/ 75] Iter[  1/1213]	  loss: 0.48cifar10:0.2-instance | Epoch [ 28/ 75] Iter[ 51/1213]	  loss: 0.22cifar10:0.2-instance | Epoch [ 28/ 75] Iter[101/1213]	  loss: 0.40cifar10:0.2-instance | Epoch [ 28/ 75] Iter[151/1213]	  loss: 0.54cifar10:0.2-instance | Epoch [ 28/ 75] Iter[201/1213]	  loss: 0.34cifar10:0.2-instance | Epoch [ 28/ 75] Iter[251/1213]	  loss: 0.64cifar10:0.2-instance | Epoch [ 28/ 75] Iter[301/1213]	  loss: 0.52cifar10:0.2-instance | Epoch [ 28/ 75] Iter[351/1213]	  loss: 0.42cifar10:0.2-instance | Epoch [ 28/ 75] Iter[401/1213]	  loss: 0.30cifar10:0.2-instance | Epoch [ 28/ 75] Iter[451/1213]	  loss: 0.59cifar10:0.2-instance | Epoch [ 28/ 75] Iter[501/1213]	  loss: 0.52cifar10:0.2-instance | Epoch [ 28/ 75] Iter[551/1213]	  loss: 0.29cifar10:0.2-instance | Epoch [ 28/ 75] Iter[601/1213]	  loss: 0.34cifar10:0.2-instance | Epoch [ 28/ 75] Iter[651/1213]	  loss: 0.41cifar10:0.2-instance | Epoch [ 28/ 75] Iter[701/1213]	  loss: 0.32cifar10:0.2-instance | Epoch [ 28/ 75] Iter[751/1213]	  loss: 0.37cifar10:0.2-instance | Epoch [ 28/ 75] Iter[801/1213]	  loss: 0.75cifar10:0.2-instance | Epoch [ 28/ 75] Iter[851/1213]	  loss: 0.43cifar10:0.2-instance | Epoch [ 28/ 75] Iter[901/1213]	  loss: 0.35cifar10:0.2-instance | Epoch [ 28/ 75] Iter[951/1213]	  loss: 0.76cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1001/1213]	  loss: 0.38cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1051/1213]	  loss: 0.28cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1101/1213]	  loss: 0.25cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1151/1213]	  loss: 0.36cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1201/1213]	  loss: 0.29
| Test Epoch 28	 Accuracy: 83.69% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 29 | Accuracy on train set: 70.76% 
labeled data has a size of 38786, f-score: 0.979709
cifar10:0.2-instance | Epoch [ 29/ 75] Iter[  1/1213]	  loss: 0.28cifar10:0.2-instance | Epoch [ 29/ 75] Iter[ 51/1213]	  loss: 0.51cifar10:0.2-instance | Epoch [ 29/ 75] Iter[101/1213]	  loss: 0.39cifar10:0.2-instance | Epoch [ 29/ 75] Iter[151/1213]	  loss: 0.46cifar10:0.2-instance | Epoch [ 29/ 75] Iter[201/1213]	  loss: 0.65cifar10:0.2-instance | Epoch [ 29/ 75] Iter[251/1213]	  loss: 0.46cifar10:0.2-instance | Epoch [ 29/ 75] Iter[301/1213]	  loss: 0.30cifar10:0.2-instance | Epoch [ 29/ 75] Iter[351/1213]	  loss: 0.25cifar10:0.2-instance | Epoch [ 29/ 75] Iter[401/1213]	  loss: 0.52cifar10:0.2-instance | Epoch [ 29/ 75] Iter[451/1213]	  loss: 0.33cifar10:0.2-instance | Epoch [ 29/ 75] Iter[501/1213]	  loss: 0.27cifar10:0.2-instance | Epoch [ 29/ 75] Iter[551/1213]	  loss: 0.51cifar10:0.2-instance | Epoch [ 29/ 75] Iter[601/1213]	  loss: 0.44cifar10:0.2-instance | Epoch [ 29/ 75] Iter[651/1213]	  loss: 0.40cifar10:0.2-instance | Epoch [ 29/ 75] Iter[701/1213]	  loss: 0.34cifar10:0.2-instance | Epoch [ 29/ 75] Iter[751/1213]	  loss: 0.41cifar10:0.2-instance | Epoch [ 29/ 75] Iter[801/1213]	  loss: 0.63cifar10:0.2-instance | Epoch [ 29/ 75] Iter[851/1213]	  loss: 0.37cifar10:0.2-instance | Epoch [ 29/ 75] Iter[901/1213]	  loss: 0.31cifar10:0.2-instance | Epoch [ 29/ 75] Iter[951/1213]	  loss: 0.62cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1001/1213]	  loss: 0.41cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1051/1213]	  loss: 0.46cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1101/1213]	  loss: 0.91cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1151/1213]	  loss: 0.66cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1201/1213]	  loss: 0.35
| Test Epoch 29	 Accuracy: 85.62% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 30 | Accuracy on train set: 71.91% 
labeled data has a size of 38763, f-score: 0.980600
cifar10:0.2-instance | Epoch [ 30/ 75] Iter[  1/1212]	  loss: 0.38cifar10:0.2-instance | Epoch [ 30/ 75] Iter[ 51/1212]	  loss: 0.32cifar10:0.2-instance | Epoch [ 30/ 75] Iter[101/1212]	  loss: 0.35cifar10:0.2-instance | Epoch [ 30/ 75] Iter[151/1212]	  loss: 0.40cifar10:0.2-instance | Epoch [ 30/ 75] Iter[201/1212]	  loss: 0.56cifar10:0.2-instance | Epoch [ 30/ 75] Iter[251/1212]	  loss: 0.42cifar10:0.2-instance | Epoch [ 30/ 75] Iter[301/1212]	  loss: 0.37cifar10:0.2-instance | Epoch [ 30/ 75] Iter[351/1212]	  loss: 0.45cifar10:0.2-instance | Epoch [ 30/ 75] Iter[401/1212]	  loss: 0.46cifar10:0.2-instance | Epoch [ 30/ 75] Iter[451/1212]	  loss: 0.39cifar10:0.2-instance | Epoch [ 30/ 75] Iter[501/1212]	  loss: 0.43cifar10:0.2-instance | Epoch [ 30/ 75] Iter[551/1212]	  loss: 0.27cifar10:0.2-instance | Epoch [ 30/ 75] Iter[601/1212]	  loss: 0.81cifar10:0.2-instance | Epoch [ 30/ 75] Iter[651/1212]	  loss: 0.40cifar10:0.2-instance | Epoch [ 30/ 75] Iter[701/1212]	  loss: 0.62cifar10:0.2-instance | Epoch [ 30/ 75] Iter[751/1212]	  loss: 0.54cifar10:0.2-instance | Epoch [ 30/ 75] Iter[801/1212]	  loss: 0.49cifar10:0.2-instance | Epoch [ 30/ 75] Iter[851/1212]	  loss: 0.42cifar10:0.2-instance | Epoch [ 30/ 75] Iter[901/1212]	  loss: 0.32cifar10:0.2-instance | Epoch [ 30/ 75] Iter[951/1212]	  loss: 0.31cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1001/1212]	  loss: 0.38cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1051/1212]	  loss: 0.45cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1101/1212]	  loss: 0.32cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1151/1212]	  loss: 0.25cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1201/1212]	  loss: 0.37
| Test Epoch 30	 Accuracy: 84.71% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 31 | Accuracy on train set: 71.03% 
labeled data has a size of 38746, f-score: 0.980953
cifar10:0.2-instance | Epoch [ 31/ 75] Iter[  1/1211]	  loss: 0.42cifar10:0.2-instance | Epoch [ 31/ 75] Iter[ 51/1211]	  loss: 0.45cifar10:0.2-instance | Epoch [ 31/ 75] Iter[101/1211]	  loss: 0.41cifar10:0.2-instance | Epoch [ 31/ 75] Iter[151/1211]	  loss: 0.38cifar10:0.2-instance | Epoch [ 31/ 75] Iter[201/1211]	  loss: 0.62cifar10:0.2-instance | Epoch [ 31/ 75] Iter[251/1211]	  loss: 0.32cifar10:0.2-instance | Epoch [ 31/ 75] Iter[301/1211]	  loss: 0.65cifar10:0.2-instance | Epoch [ 31/ 75] Iter[351/1211]	  loss: 0.27cifar10:0.2-instance | Epoch [ 31/ 75] Iter[401/1211]	  loss: 0.58cifar10:0.2-instance | Epoch [ 31/ 75] Iter[451/1211]	  loss: 0.50cifar10:0.2-instance | Epoch [ 31/ 75] Iter[501/1211]	  loss: 0.41cifar10:0.2-instance | Epoch [ 31/ 75] Iter[551/1211]	  loss: 0.52cifar10:0.2-instance | Epoch [ 31/ 75] Iter[601/1211]	  loss: 0.46cifar10:0.2-instance | Epoch [ 31/ 75] Iter[651/1211]	  loss: 0.42cifar10:0.2-instance | Epoch [ 31/ 75] Iter[701/1211]	  loss: 0.40cifar10:0.2-instance | Epoch [ 31/ 75] Iter[751/1211]	  loss: 0.22cifar10:0.2-instance | Epoch [ 31/ 75] Iter[801/1211]	  loss: 0.32cifar10:0.2-instance | Epoch [ 31/ 75] Iter[851/1211]	  loss: 0.26cifar10:0.2-instance | Epoch [ 31/ 75] Iter[901/1211]	  loss: 0.32cifar10:0.2-instance | Epoch [ 31/ 75] Iter[951/1211]	  loss: 0.33cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1001/1211]	  loss: 0.49cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1051/1211]	  loss: 0.28cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1101/1211]	  loss: 0.49cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1151/1211]	  loss: 0.37cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1201/1211]	  loss: 0.59
| Test Epoch 31	 Accuracy: 85.21% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 32 | Accuracy on train set: 71.69% 
labeled data has a size of 38821, f-score: 0.981582
cifar10:0.2-instance | Epoch [ 32/ 75] Iter[  1/1214]	  loss: 0.43cifar10:0.2-instance | Epoch [ 32/ 75] Iter[ 51/1214]	  loss: 0.44cifar10:0.2-instance | Epoch [ 32/ 75] Iter[101/1214]	  loss: 0.35cifar10:0.2-instance | Epoch [ 32/ 75] Iter[151/1214]	  loss: 0.43cifar10:0.2-instance | Epoch [ 32/ 75] Iter[201/1214]	  loss: 0.44cifar10:0.2-instance | Epoch [ 32/ 75] Iter[251/1214]	  loss: 0.41cifar10:0.2-instance | Epoch [ 32/ 75] Iter[301/1214]	  loss: 0.32cifar10:0.2-instance | Epoch [ 32/ 75] Iter[351/1214]	  loss: 0.35cifar10:0.2-instance | Epoch [ 32/ 75] Iter[401/1214]	  loss: 0.30cifar10:0.2-instance | Epoch [ 32/ 75] Iter[451/1214]	  loss: 0.24cifar10:0.2-instance | Epoch [ 32/ 75] Iter[501/1214]	  loss: 0.43cifar10:0.2-instance | Epoch [ 32/ 75] Iter[551/1214]	  loss: 0.41cifar10:0.2-instance | Epoch [ 32/ 75] Iter[601/1214]	  loss: 0.41cifar10:0.2-instance | Epoch [ 32/ 75] Iter[651/1214]	  loss: 0.35cifar10:0.2-instance | Epoch [ 32/ 75] Iter[701/1214]	  loss: 0.31cifar10:0.2-instance | Epoch [ 32/ 75] Iter[751/1214]	  loss: 0.41cifar10:0.2-instance | Epoch [ 32/ 75] Iter[801/1214]	  loss: 0.31cifar10:0.2-instance | Epoch [ 32/ 75] Iter[851/1214]	  loss: 0.69cifar10:0.2-instance | Epoch [ 32/ 75] Iter[901/1214]	  loss: 0.54cifar10:0.2-instance | Epoch [ 32/ 75] Iter[951/1214]	  loss: 0.48cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1001/1214]	  loss: 0.51cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1051/1214]	  loss: 0.74cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1101/1214]	  loss: 0.60cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1151/1214]	  loss: 0.34cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1201/1214]	  loss: 0.29
| Test Epoch 32	 Accuracy: 82.93% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 33 | Accuracy on train set: 70.20% 
labeled data has a size of 38988, f-score: 0.979609
cifar10:0.2-instance | Epoch [ 33/ 75] Iter[  1/1219]	  loss: 0.34cifar10:0.2-instance | Epoch [ 33/ 75] Iter[ 51/1219]	  loss: 0.55cifar10:0.2-instance | Epoch [ 33/ 75] Iter[101/1219]	  loss: 0.38cifar10:0.2-instance | Epoch [ 33/ 75] Iter[151/1219]	  loss: 0.44cifar10:0.2-instance | Epoch [ 33/ 75] Iter[201/1219]	  loss: 0.36cifar10:0.2-instance | Epoch [ 33/ 75] Iter[251/1219]	  loss: 0.52cifar10:0.2-instance | Epoch [ 33/ 75] Iter[301/1219]	  loss: 0.35cifar10:0.2-instance | Epoch [ 33/ 75] Iter[351/1219]	  loss: 0.37cifar10:0.2-instance | Epoch [ 33/ 75] Iter[401/1219]	  loss: 0.67cifar10:0.2-instance | Epoch [ 33/ 75] Iter[451/1219]	  loss: 0.44cifar10:0.2-instance | Epoch [ 33/ 75] Iter[501/1219]	  loss: 0.42cifar10:0.2-instance | Epoch [ 33/ 75] Iter[551/1219]	  loss: 0.49cifar10:0.2-instance | Epoch [ 33/ 75] Iter[601/1219]	  loss: 0.56cifar10:0.2-instance | Epoch [ 33/ 75] Iter[651/1219]	  loss: 0.43cifar10:0.2-instance | Epoch [ 33/ 75] Iter[701/1219]	  loss: 0.33cifar10:0.2-instance | Epoch [ 33/ 75] Iter[751/1219]	  loss: 0.48cifar10:0.2-instance | Epoch [ 33/ 75] Iter[801/1219]	  loss: 0.33cifar10:0.2-instance | Epoch [ 33/ 75] Iter[851/1219]	  loss: 0.51cifar10:0.2-instance | Epoch [ 33/ 75] Iter[901/1219]	  loss: 0.36cifar10:0.2-instance | Epoch [ 33/ 75] Iter[951/1219]	  loss: 0.75cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1001/1219]	  loss: 0.37cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1051/1219]	  loss: 0.27cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1101/1219]	  loss: 0.22cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1151/1219]	  loss: 0.46cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1201/1219]	  loss: 0.39
| Test Epoch 33	 Accuracy: 85.59% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 34 | Accuracy on train set: 71.83% 
labeled data has a size of 39053, f-score: 0.980002
cifar10:0.2-instance | Epoch [ 34/ 75] Iter[  1/1221]	  loss: 0.41cifar10:0.2-instance | Epoch [ 34/ 75] Iter[ 51/1221]	  loss: 0.44cifar10:0.2-instance | Epoch [ 34/ 75] Iter[101/1221]	  loss: 0.34cifar10:0.2-instance | Epoch [ 34/ 75] Iter[151/1221]	  loss: 0.78cifar10:0.2-instance | Epoch [ 34/ 75] Iter[201/1221]	  loss: 0.40cifar10:0.2-instance | Epoch [ 34/ 75] Iter[251/1221]	  loss: 0.22cifar10:0.2-instance | Epoch [ 34/ 75] Iter[301/1221]	  loss: 0.22cifar10:0.2-instance | Epoch [ 34/ 75] Iter[351/1221]	  loss: 0.64cifar10:0.2-instance | Epoch [ 34/ 75] Iter[401/1221]	  loss: 0.66cifar10:0.2-instance | Epoch [ 34/ 75] Iter[451/1221]	  loss: 0.47cifar10:0.2-instance | Epoch [ 34/ 75] Iter[501/1221]	  loss: 0.39cifar10:0.2-instance | Epoch [ 34/ 75] Iter[551/1221]	  loss: 0.57cifar10:0.2-instance | Epoch [ 34/ 75] Iter[601/1221]	  loss: 0.40cifar10:0.2-instance | Epoch [ 34/ 75] Iter[651/1221]	  loss: 0.40cifar10:0.2-instance | Epoch [ 34/ 75] Iter[701/1221]	  loss: 0.29cifar10:0.2-instance | Epoch [ 34/ 75] Iter[751/1221]	  loss: 0.35cifar10:0.2-instance | Epoch [ 34/ 75] Iter[801/1221]	  loss: 0.45cifar10:0.2-instance | Epoch [ 34/ 75] Iter[851/1221]	  loss: 0.38cifar10:0.2-instance | Epoch [ 34/ 75] Iter[901/1221]	  loss: 0.17cifar10:0.2-instance | Epoch [ 34/ 75] Iter[951/1221]	  loss: 0.43cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1001/1221]	  loss: 0.46cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1051/1221]	  loss: 0.54cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1101/1221]	  loss: 0.61cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1151/1221]	  loss: 0.36cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1201/1221]	  loss: 0.54
| Test Epoch 34	 Accuracy: 84.62% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 35 | Accuracy on train set: 71.25% 
labeled data has a size of 39136, f-score: 0.978971
cifar10:0.2-instance | Epoch [ 35/ 75] Iter[  1/1224]	  loss: 0.28cifar10:0.2-instance | Epoch [ 35/ 75] Iter[ 51/1224]	  loss: 0.45cifar10:0.2-instance | Epoch [ 35/ 75] Iter[101/1224]	  loss: 0.41cifar10:0.2-instance | Epoch [ 35/ 75] Iter[151/1224]	  loss: 0.38cifar10:0.2-instance | Epoch [ 35/ 75] Iter[201/1224]	  loss: 0.59cifar10:0.2-instance | Epoch [ 35/ 75] Iter[251/1224]	  loss: 0.35cifar10:0.2-instance | Epoch [ 35/ 75] Iter[301/1224]	  loss: 0.40cifar10:0.2-instance | Epoch [ 35/ 75] Iter[351/1224]	  loss: 0.48cifar10:0.2-instance | Epoch [ 35/ 75] Iter[401/1224]	  loss: 0.29cifar10:0.2-instance | Epoch [ 35/ 75] Iter[451/1224]	  loss: 0.39cifar10:0.2-instance | Epoch [ 35/ 75] Iter[501/1224]	  loss: 0.37cifar10:0.2-instance | Epoch [ 35/ 75] Iter[551/1224]	  loss: 0.59cifar10:0.2-instance | Epoch [ 35/ 75] Iter[601/1224]	  loss: 0.34cifar10:0.2-instance | Epoch [ 35/ 75] Iter[651/1224]	  loss: 0.34cifar10:0.2-instance | Epoch [ 35/ 75] Iter[701/1224]	  loss: 0.46cifar10:0.2-instance | Epoch [ 35/ 75] Iter[751/1224]	  loss: 0.40cifar10:0.2-instance | Epoch [ 35/ 75] Iter[801/1224]	  loss: 0.42cifar10:0.2-instance | Epoch [ 35/ 75] Iter[851/1224]	  loss: 0.46cifar10:0.2-instance | Epoch [ 35/ 75] Iter[901/1224]	  loss: 0.39cifar10:0.2-instance | Epoch [ 35/ 75] Iter[951/1224]	  loss: 0.28cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1001/1224]	  loss: 0.37cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1051/1224]	  loss: 0.33cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1101/1224]	  loss: 0.51cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1151/1224]	  loss: 0.39cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1201/1224]	  loss: 0.35
| Test Epoch 35	 Accuracy: 85.31% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 36 | Accuracy on train set: 71.62% 
labeled data has a size of 39077, f-score: 0.980474
cifar10:0.2-instance | Epoch [ 36/ 75] Iter[  1/1222]	  loss: 0.35cifar10:0.2-instance | Epoch [ 36/ 75] Iter[ 51/1222]	  loss: 0.38cifar10:0.2-instance | Epoch [ 36/ 75] Iter[101/1222]	  loss: 0.43cifar10:0.2-instance | Epoch [ 36/ 75] Iter[151/1222]	  loss: 0.23cifar10:0.2-instance | Epoch [ 36/ 75] Iter[201/1222]	  loss: 0.37cifar10:0.2-instance | Epoch [ 36/ 75] Iter[251/1222]	  loss: 0.42cifar10:0.2-instance | Epoch [ 36/ 75] Iter[301/1222]	  loss: 0.35cifar10:0.2-instance | Epoch [ 36/ 75] Iter[351/1222]	  loss: 0.51cifar10:0.2-instance | Epoch [ 36/ 75] Iter[401/1222]	  loss: 0.58cifar10:0.2-instance | Epoch [ 36/ 75] Iter[451/1222]	  loss: 0.64cifar10:0.2-instance | Epoch [ 36/ 75] Iter[501/1222]	  loss: 0.27cifar10:0.2-instance | Epoch [ 36/ 75] Iter[551/1222]	  loss: 0.50cifar10:0.2-instance | Epoch [ 36/ 75] Iter[601/1222]	  loss: 0.34cifar10:0.2-instance | Epoch [ 36/ 75] Iter[651/1222]	  loss: 0.83cifar10:0.2-instance | Epoch [ 36/ 75] Iter[701/1222]	  loss: 0.39cifar10:0.2-instance | Epoch [ 36/ 75] Iter[751/1222]	  loss: 0.42cifar10:0.2-instance | Epoch [ 36/ 75] Iter[801/1222]	  loss: 0.57cifar10:0.2-instance | Epoch [ 36/ 75] Iter[851/1222]	  loss: 0.31cifar10:0.2-instance | Epoch [ 36/ 75] Iter[901/1222]	  loss: 0.24cifar10:0.2-instance | Epoch [ 36/ 75] Iter[951/1222]	  loss: 0.38cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1001/1222]	  loss: 0.42cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1051/1222]	  loss: 0.52cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1101/1222]	  loss: 0.35cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1151/1222]	  loss: 0.45cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1201/1222]	  loss: 0.28
| Test Epoch 36	 Accuracy: 85.93% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 37 | Accuracy on train set: 72.18% 
labeled data has a size of 39156, f-score: 0.980412
cifar10:0.2-instance | Epoch [ 37/ 75] Iter[  1/1224]	  loss: 0.38cifar10:0.2-instance | Epoch [ 37/ 75] Iter[ 51/1224]	  loss: 0.24cifar10:0.2-instance | Epoch [ 37/ 75] Iter[101/1224]	  loss: 0.43cifar10:0.2-instance | Epoch [ 37/ 75] Iter[151/1224]	  loss: 0.26cifar10:0.2-instance | Epoch [ 37/ 75] Iter[201/1224]	  loss: 0.29cifar10:0.2-instance | Epoch [ 37/ 75] Iter[251/1224]	  loss: 0.39cifar10:0.2-instance | Epoch [ 37/ 75] Iter[301/1224]	  loss: 0.52cifar10:0.2-instance | Epoch [ 37/ 75] Iter[351/1224]	  loss: 0.41cifar10:0.2-instance | Epoch [ 37/ 75] Iter[401/1224]	  loss: 0.66cifar10:0.2-instance | Epoch [ 37/ 75] Iter[451/1224]	  loss: 0.28cifar10:0.2-instance | Epoch [ 37/ 75] Iter[501/1224]	  loss: 0.37cifar10:0.2-instance | Epoch [ 37/ 75] Iter[551/1224]	  loss: 0.22cifar10:0.2-instance | Epoch [ 37/ 75] Iter[601/1224]	  loss: 0.47cifar10:0.2-instance | Epoch [ 37/ 75] Iter[651/1224]	  loss: 0.42cifar10:0.2-instance | Epoch [ 37/ 75] Iter[701/1224]	  loss: 0.30cifar10:0.2-instance | Epoch [ 37/ 75] Iter[751/1224]	  loss: 0.42cifar10:0.2-instance | Epoch [ 37/ 75] Iter[801/1224]	  loss: 0.28cifar10:0.2-instance | Epoch [ 37/ 75] Iter[851/1224]	  loss: 0.27cifar10:0.2-instance | Epoch [ 37/ 75] Iter[901/1224]	  loss: 0.60cifar10:0.2-instance | Epoch [ 37/ 75] Iter[951/1224]	  loss: 0.48cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1001/1224]	  loss: 0.29cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1051/1224]	  loss: 0.34cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1101/1224]	  loss: 0.45cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1151/1224]	  loss: 0.38cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1201/1224]	  loss: 0.50
| Test Epoch 37	 Accuracy: 85.70% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 38 | Accuracy on train set: 71.68% 
labeled data has a size of 39135, f-score: 0.981091
cifar10:0.2-instance | Epoch [ 38/ 75] Iter[  1/1223]	  loss: 0.35cifar10:0.2-instance | Epoch [ 38/ 75] Iter[ 51/1223]	  loss: 0.53cifar10:0.2-instance | Epoch [ 38/ 75] Iter[101/1223]	  loss: 0.48cifar10:0.2-instance | Epoch [ 38/ 75] Iter[151/1223]	  loss: 0.46cifar10:0.2-instance | Epoch [ 38/ 75] Iter[201/1223]	  loss: 0.27cifar10:0.2-instance | Epoch [ 38/ 75] Iter[251/1223]	  loss: 0.34cifar10:0.2-instance | Epoch [ 38/ 75] Iter[301/1223]	  loss: 0.41cifar10:0.2-instance | Epoch [ 38/ 75] Iter[351/1223]	  loss: 0.28cifar10:0.2-instance | Epoch [ 38/ 75] Iter[401/1223]	  loss: 0.38cifar10:0.2-instance | Epoch [ 38/ 75] Iter[451/1223]	  loss: 0.40cifar10:0.2-instance | Epoch [ 38/ 75] Iter[501/1223]	  loss: 0.29cifar10:0.2-instance | Epoch [ 38/ 75] Iter[551/1223]	  loss: 0.25cifar10:0.2-instance | Epoch [ 38/ 75] Iter[601/1223]	  loss: 0.54cifar10:0.2-instance | Epoch [ 38/ 75] Iter[651/1223]	  loss: 0.37cifar10:0.2-instance | Epoch [ 38/ 75] Iter[701/1223]	  loss: 0.49cifar10:0.2-instance | Epoch [ 38/ 75] Iter[751/1223]	  loss: 0.45cifar10:0.2-instance | Epoch [ 38/ 75] Iter[801/1223]	  loss: 0.38cifar10:0.2-instance | Epoch [ 38/ 75] Iter[851/1223]	  loss: 0.58cifar10:0.2-instance | Epoch [ 38/ 75] Iter[901/1223]	  loss: 0.95cifar10:0.2-instance | Epoch [ 38/ 75] Iter[951/1223]	  loss: 0.40cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1001/1223]	  loss: 0.55cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1051/1223]	  loss: 0.46cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1101/1223]	  loss: 0.56cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1151/1223]	  loss: 0.34cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1201/1223]	  loss: 0.45
| Test Epoch 38	 Accuracy: 83.90% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 39 | Accuracy on train set: 70.95% 
labeled data has a size of 39086, f-score: 0.981119
cifar10:0.2-instance | Epoch [ 39/ 75] Iter[  1/1222]	  loss: 0.47cifar10:0.2-instance | Epoch [ 39/ 75] Iter[ 51/1222]	  loss: 0.34cifar10:0.2-instance | Epoch [ 39/ 75] Iter[101/1222]	  loss: 0.52cifar10:0.2-instance | Epoch [ 39/ 75] Iter[151/1222]	  loss: 0.59cifar10:0.2-instance | Epoch [ 39/ 75] Iter[201/1222]	  loss: 0.31cifar10:0.2-instance | Epoch [ 39/ 75] Iter[251/1222]	  loss: 0.71cifar10:0.2-instance | Epoch [ 39/ 75] Iter[301/1222]	  loss: 0.34cifar10:0.2-instance | Epoch [ 39/ 75] Iter[351/1222]	  loss: 0.33cifar10:0.2-instance | Epoch [ 39/ 75] Iter[401/1222]	  loss: 0.22cifar10:0.2-instance | Epoch [ 39/ 75] Iter[451/1222]	  loss: 0.36cifar10:0.2-instance | Epoch [ 39/ 75] Iter[501/1222]	  loss: 0.28cifar10:0.2-instance | Epoch [ 39/ 75] Iter[551/1222]	  loss: 0.57cifar10:0.2-instance | Epoch [ 39/ 75] Iter[601/1222]	  loss: 0.53cifar10:0.2-instance | Epoch [ 39/ 75] Iter[651/1222]	  loss: 0.42cifar10:0.2-instance | Epoch [ 39/ 75] Iter[701/1222]	  loss: 0.42cifar10:0.2-instance | Epoch [ 39/ 75] Iter[751/1222]	  loss: 0.49cifar10:0.2-instance | Epoch [ 39/ 75] Iter[801/1222]	  loss: 0.41cifar10:0.2-instance | Epoch [ 39/ 75] Iter[851/1222]	  loss: 0.59cifar10:0.2-instance | Epoch [ 39/ 75] Iter[901/1222]	  loss: 0.35cifar10:0.2-instance | Epoch [ 39/ 75] Iter[951/1222]	  loss: 0.45cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1001/1222]	  loss: 0.54cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1051/1222]	  loss: 0.32cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1101/1222]	  loss: 0.31cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1151/1222]	  loss: 0.56cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1201/1222]	  loss: 0.51
| Test Epoch 39	 Accuracy: 85.61% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 40 | Accuracy on train set: 72.24% 
labeled data has a size of 39199, f-score: 0.980178
cifar10:0.2-instance | Epoch [ 40/ 75] Iter[  1/1225]	  loss: 0.41cifar10:0.2-instance | Epoch [ 40/ 75] Iter[ 51/1225]	  loss: 0.31cifar10:0.2-instance | Epoch [ 40/ 75] Iter[101/1225]	  loss: 0.58cifar10:0.2-instance | Epoch [ 40/ 75] Iter[151/1225]	  loss: 0.43cifar10:0.2-instance | Epoch [ 40/ 75] Iter[201/1225]	  loss: 0.48cifar10:0.2-instance | Epoch [ 40/ 75] Iter[251/1225]	  loss: 0.47cifar10:0.2-instance | Epoch [ 40/ 75] Iter[301/1225]	  loss: 0.27cifar10:0.2-instance | Epoch [ 40/ 75] Iter[351/1225]	  loss: 0.45cifar10:0.2-instance | Epoch [ 40/ 75] Iter[401/1225]	  loss: 0.50cifar10:0.2-instance | Epoch [ 40/ 75] Iter[451/1225]	  loss: 0.28cifar10:0.2-instance | Epoch [ 40/ 75] Iter[501/1225]	  loss: 0.33cifar10:0.2-instance | Epoch [ 40/ 75] Iter[551/1225]	  loss: 0.60cifar10:0.2-instance | Epoch [ 40/ 75] Iter[601/1225]	  loss: 0.34cifar10:0.2-instance | Epoch [ 40/ 75] Iter[651/1225]	  loss: 0.41cifar10:0.2-instance | Epoch [ 40/ 75] Iter[701/1225]	  loss: 0.26cifar10:0.2-instance | Epoch [ 40/ 75] Iter[751/1225]	  loss: 0.53cifar10:0.2-instance | Epoch [ 40/ 75] Iter[801/1225]	  loss: 0.28cifar10:0.2-instance | Epoch [ 40/ 75] Iter[851/1225]	  loss: 0.46cifar10:0.2-instance | Epoch [ 40/ 75] Iter[901/1225]	  loss: 0.34cifar10:0.2-instance | Epoch [ 40/ 75] Iter[951/1225]	  loss: 0.53cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1001/1225]	  loss: 0.30cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1051/1225]	  loss: 0.59cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1101/1225]	  loss: 0.68cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1151/1225]	  loss: 0.32cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1201/1225]	  loss: 0.43
| Test Epoch 40	 Accuracy: 85.72% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 41 | Accuracy on train set: 71.85% 
labeled data has a size of 39132, f-score: 0.979965
cifar10:0.2-instance | Epoch [ 41/ 75] Iter[  1/1223]	  loss: 0.45cifar10:0.2-instance | Epoch [ 41/ 75] Iter[ 51/1223]	  loss: 0.35cifar10:0.2-instance | Epoch [ 41/ 75] Iter[101/1223]	  loss: 0.40cifar10:0.2-instance | Epoch [ 41/ 75] Iter[151/1223]	  loss: 0.44cifar10:0.2-instance | Epoch [ 41/ 75] Iter[201/1223]	  loss: 0.41cifar10:0.2-instance | Epoch [ 41/ 75] Iter[251/1223]	  loss: 0.29cifar10:0.2-instance | Epoch [ 41/ 75] Iter[301/1223]	  loss: 0.63cifar10:0.2-instance | Epoch [ 41/ 75] Iter[351/1223]	  loss: 0.38cifar10:0.2-instance | Epoch [ 41/ 75] Iter[401/1223]	  loss: 0.31cifar10:0.2-instance | Epoch [ 41/ 75] Iter[451/1223]	  loss: 0.41cifar10:0.2-instance | Epoch [ 41/ 75] Iter[501/1223]	  loss: 0.45cifar10:0.2-instance | Epoch [ 41/ 75] Iter[551/1223]	  loss: 0.56cifar10:0.2-instance | Epoch [ 41/ 75] Iter[601/1223]	  loss: 0.54cifar10:0.2-instance | Epoch [ 41/ 75] Iter[651/1223]	  loss: 0.36cifar10:0.2-instance | Epoch [ 41/ 75] Iter[701/1223]	  loss: 0.42cifar10:0.2-instance | Epoch [ 41/ 75] Iter[751/1223]	  loss: 0.43cifar10:0.2-instance | Epoch [ 41/ 75] Iter[801/1223]	  loss: 0.41cifar10:0.2-instance | Epoch [ 41/ 75] Iter[851/1223]	  loss: 0.29cifar10:0.2-instance | Epoch [ 41/ 75] Iter[901/1223]	  loss: 0.50cifar10:0.2-instance | Epoch [ 41/ 75] Iter[951/1223]	  loss: 0.51cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1001/1223]	  loss: 0.29cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1051/1223]	  loss: 0.28cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1101/1223]	  loss: 0.42cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1151/1223]	  loss: 0.60cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1201/1223]	  loss: 0.43
| Test Epoch 41	 Accuracy: 84.28% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 42 | Accuracy on train set: 71.25% 
labeled data has a size of 39207, f-score: 0.980080
cifar10:0.2-instance | Epoch [ 42/ 75] Iter[  1/1226]	  loss: 0.44cifar10:0.2-instance | Epoch [ 42/ 75] Iter[ 51/1226]	  loss: 0.34cifar10:0.2-instance | Epoch [ 42/ 75] Iter[101/1226]	  loss: 0.40cifar10:0.2-instance | Epoch [ 42/ 75] Iter[151/1226]	  loss: 0.34cifar10:0.2-instance | Epoch [ 42/ 75] Iter[201/1226]	  loss: 0.42cifar10:0.2-instance | Epoch [ 42/ 75] Iter[251/1226]	  loss: 0.31cifar10:0.2-instance | Epoch [ 42/ 75] Iter[301/1226]	  loss: 0.51cifar10:0.2-instance | Epoch [ 42/ 75] Iter[351/1226]	  loss: 0.24cifar10:0.2-instance | Epoch [ 42/ 75] Iter[401/1226]	  loss: 0.38cifar10:0.2-instance | Epoch [ 42/ 75] Iter[451/1226]	  loss: 0.64cifar10:0.2-instance | Epoch [ 42/ 75] Iter[501/1226]	  loss: 0.35cifar10:0.2-instance | Epoch [ 42/ 75] Iter[551/1226]	  loss: 0.38cifar10:0.2-instance | Epoch [ 42/ 75] Iter[601/1226]	  loss: 0.43cifar10:0.2-instance | Epoch [ 42/ 75] Iter[651/1226]	  loss: 0.29cifar10:0.2-instance | Epoch [ 42/ 75] Iter[701/1226]	  loss: 0.31cifar10:0.2-instance | Epoch [ 42/ 75] Iter[751/1226]	  loss: 0.47cifar10:0.2-instance | Epoch [ 42/ 75] Iter[801/1226]	  loss: 0.40cifar10:0.2-instance | Epoch [ 42/ 75] Iter[851/1226]	  loss: 0.60cifar10:0.2-instance | Epoch [ 42/ 75] Iter[901/1226]	  loss: 0.50cifar10:0.2-instance | Epoch [ 42/ 75] Iter[951/1226]	  loss: 0.34cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1001/1226]	  loss: 0.39cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1051/1226]	  loss: 0.38cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1101/1226]	  loss: 0.61cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1151/1226]	  loss: 0.24cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1201/1226]	  loss: 0.34
| Test Epoch 42	 Accuracy: 85.82% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 43 | Accuracy on train set: 72.12% 
labeled data has a size of 39249, f-score: 0.979719
cifar10:0.2-instance | Epoch [ 43/ 75] Iter[  1/1227]	  loss: 0.38cifar10:0.2-instance | Epoch [ 43/ 75] Iter[ 51/1227]	  loss: 0.43cifar10:0.2-instance | Epoch [ 43/ 75] Iter[101/1227]	  loss: 0.29cifar10:0.2-instance | Epoch [ 43/ 75] Iter[151/1227]	  loss: 0.45cifar10:0.2-instance | Epoch [ 43/ 75] Iter[201/1227]	  loss: 0.64cifar10:0.2-instance | Epoch [ 43/ 75] Iter[251/1227]	  loss: 0.35cifar10:0.2-instance | Epoch [ 43/ 75] Iter[301/1227]	  loss: 0.35cifar10:0.2-instance | Epoch [ 43/ 75] Iter[351/1227]	  loss: 0.57cifar10:0.2-instance | Epoch [ 43/ 75] Iter[401/1227]	  loss: 0.32cifar10:0.2-instance | Epoch [ 43/ 75] Iter[451/1227]	  loss: 0.28cifar10:0.2-instance | Epoch [ 43/ 75] Iter[501/1227]	  loss: 0.35cifar10:0.2-instance | Epoch [ 43/ 75] Iter[551/1227]	  loss: 0.32cifar10:0.2-instance | Epoch [ 43/ 75] Iter[601/1227]	  loss: 0.21cifar10:0.2-instance | Epoch [ 43/ 75] Iter[651/1227]	  loss: 0.43cifar10:0.2-instance | Epoch [ 43/ 75] Iter[701/1227]	  loss: 0.63cifar10:0.2-instance | Epoch [ 43/ 75] Iter[751/1227]	  loss: 0.33cifar10:0.2-instance | Epoch [ 43/ 75] Iter[801/1227]	  loss: 0.56cifar10:0.2-instance | Epoch [ 43/ 75] Iter[851/1227]	  loss: 0.47cifar10:0.2-instance | Epoch [ 43/ 75] Iter[901/1227]	  loss: 0.30cifar10:0.2-instance | Epoch [ 43/ 75] Iter[951/1227]	  loss: 0.39cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1001/1227]	  loss: 0.55cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1051/1227]	  loss: 0.30cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1101/1227]	  loss: 0.48cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1151/1227]	  loss: 0.21cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1201/1227]	  loss: 0.44
| Test Epoch 43	 Accuracy: 83.48% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 44 | Accuracy on train set: 69.79% 
labeled data has a size of 39331, f-score: 0.979787
cifar10:0.2-instance | Epoch [ 44/ 75] Iter[  1/1230]	  loss: 0.22cifar10:0.2-instance | Epoch [ 44/ 75] Iter[ 51/1230]	  loss: 0.31cifar10:0.2-instance | Epoch [ 44/ 75] Iter[101/1230]	  loss: 0.30cifar10:0.2-instance | Epoch [ 44/ 75] Iter[151/1230]	  loss: 0.27cifar10:0.2-instance | Epoch [ 44/ 75] Iter[201/1230]	  loss: 0.43cifar10:0.2-instance | Epoch [ 44/ 75] Iter[251/1230]	  loss: 0.46cifar10:0.2-instance | Epoch [ 44/ 75] Iter[301/1230]	  loss: 0.70cifar10:0.2-instance | Epoch [ 44/ 75] Iter[351/1230]	  loss: 0.44cifar10:0.2-instance | Epoch [ 44/ 75] Iter[401/1230]	  loss: 0.43cifar10:0.2-instance | Epoch [ 44/ 75] Iter[451/1230]	  loss: 0.26cifar10:0.2-instance | Epoch [ 44/ 75] Iter[501/1230]	  loss: 0.41cifar10:0.2-instance | Epoch [ 44/ 75] Iter[551/1230]	  loss: 0.50cifar10:0.2-instance | Epoch [ 44/ 75] Iter[601/1230]	  loss: 0.45cifar10:0.2-instance | Epoch [ 44/ 75] Iter[651/1230]	  loss: 0.25cifar10:0.2-instance | Epoch [ 44/ 75] Iter[701/1230]	  loss: 0.57cifar10:0.2-instance | Epoch [ 44/ 75] Iter[751/1230]	  loss: 0.57cifar10:0.2-instance | Epoch [ 44/ 75] Iter[801/1230]	  loss: 0.54cifar10:0.2-instance | Epoch [ 44/ 75] Iter[851/1230]	  loss: 0.61cifar10:0.2-instance | Epoch [ 44/ 75] Iter[901/1230]	  loss: 0.47cifar10:0.2-instance | Epoch [ 44/ 75] Iter[951/1230]	  loss: 0.37cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1001/1230]	  loss: 0.37cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1051/1230]	  loss: 0.63cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1101/1230]	  loss: 0.38cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1151/1230]	  loss: 0.36cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1201/1230]	  loss: 0.26
| Test Epoch 44	 Accuracy: 81.77% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 45 | Accuracy on train set: 69.22% 
labeled data has a size of 39145, f-score: 0.979308
cifar10:0.2-instance | Epoch [ 45/ 75] Iter[  1/1224]	  loss: 0.48cifar10:0.2-instance | Epoch [ 45/ 75] Iter[ 51/1224]	  loss: 0.43cifar10:0.2-instance | Epoch [ 45/ 75] Iter[101/1224]	  loss: 0.31cifar10:0.2-instance | Epoch [ 45/ 75] Iter[151/1224]	  loss: 0.32cifar10:0.2-instance | Epoch [ 45/ 75] Iter[201/1224]	  loss: 0.66cifar10:0.2-instance | Epoch [ 45/ 75] Iter[251/1224]	  loss: 0.32cifar10:0.2-instance | Epoch [ 45/ 75] Iter[301/1224]	  loss: 0.21cifar10:0.2-instance | Epoch [ 45/ 75] Iter[351/1224]	  loss: 0.21cifar10:0.2-instance | Epoch [ 45/ 75] Iter[401/1224]	  loss: 0.27cifar10:0.2-instance | Epoch [ 45/ 75] Iter[451/1224]	  loss: 0.44cifar10:0.2-instance | Epoch [ 45/ 75] Iter[501/1224]	  loss: 0.63cifar10:0.2-instance | Epoch [ 45/ 75] Iter[551/1224]	  loss: 0.33cifar10:0.2-instance | Epoch [ 45/ 75] Iter[601/1224]	  loss: 0.41cifar10:0.2-instance | Epoch [ 45/ 75] Iter[651/1224]	  loss: 0.46cifar10:0.2-instance | Epoch [ 45/ 75] Iter[701/1224]	  loss: 0.52cifar10:0.2-instance | Epoch [ 45/ 75] Iter[751/1224]	  loss: 0.31cifar10:0.2-instance | Epoch [ 45/ 75] Iter[801/1224]	  loss: 0.46cifar10:0.2-instance | Epoch [ 45/ 75] Iter[851/1224]	  loss: 0.44cifar10:0.2-instance | Epoch [ 45/ 75] Iter[901/1224]	  loss: 0.36cifar10:0.2-instance | Epoch [ 45/ 75] Iter[951/1224]	  loss: 0.23cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1001/1224]	  loss: 0.34cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1051/1224]	  loss: 0.69cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1101/1224]	  loss: 0.34cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1151/1224]	  loss: 0.30cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1201/1224]	  loss: 0.41
| Test Epoch 45	 Accuracy: 86.41% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 46 | Accuracy on train set: 72.59% 
labeled data has a size of 39134, f-score: 0.980068
cifar10:0.2-instance | Epoch [ 46/ 75] Iter[  1/1223]	  loss: 0.35cifar10:0.2-instance | Epoch [ 46/ 75] Iter[ 51/1223]	  loss: 0.76cifar10:0.2-instance | Epoch [ 46/ 75] Iter[101/1223]	  loss: 0.49cifar10:0.2-instance | Epoch [ 46/ 75] Iter[151/1223]	  loss: 0.23cifar10:0.2-instance | Epoch [ 46/ 75] Iter[201/1223]	  loss: 0.62cifar10:0.2-instance | Epoch [ 46/ 75] Iter[251/1223]	  loss: 0.40cifar10:0.2-instance | Epoch [ 46/ 75] Iter[301/1223]	  loss: 0.60cifar10:0.2-instance | Epoch [ 46/ 75] Iter[351/1223]	  loss: 0.34cifar10:0.2-instance | Epoch [ 46/ 75] Iter[401/1223]	  loss: 0.27cifar10:0.2-instance | Epoch [ 46/ 75] Iter[451/1223]	  loss: 0.34cifar10:0.2-instance | Epoch [ 46/ 75] Iter[501/1223]	  loss: 0.27cifar10:0.2-instance | Epoch [ 46/ 75] Iter[551/1223]	  loss: 0.39cifar10:0.2-instance | Epoch [ 46/ 75] Iter[601/1223]	  loss: 0.22cifar10:0.2-instance | Epoch [ 46/ 75] Iter[651/1223]	  loss: 0.53cifar10:0.2-instance | Epoch [ 46/ 75] Iter[701/1223]	  loss: 0.40cifar10:0.2-instance | Epoch [ 46/ 75] Iter[751/1223]	  loss: 0.58cifar10:0.2-instance | Epoch [ 46/ 75] Iter[801/1223]	  loss: 0.39cifar10:0.2-instance | Epoch [ 46/ 75] Iter[851/1223]	  loss: 0.41cifar10:0.2-instance | Epoch [ 46/ 75] Iter[901/1223]	  loss: 0.46cifar10:0.2-instance | Epoch [ 46/ 75] Iter[951/1223]	  loss: 0.40cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1001/1223]	  loss: 0.48cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1051/1223]	  loss: 0.62cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1101/1223]	  loss: 0.31cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1151/1223]	  loss: 0.27cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1201/1223]	  loss: 0.30
| Test Epoch 46	 Accuracy: 85.32% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 47 | Accuracy on train set: 72.14% 
labeled data has a size of 39105, f-score: 0.981025
cifar10:0.2-instance | Epoch [ 47/ 75] Iter[  1/1223]	  loss: 0.44cifar10:0.2-instance | Epoch [ 47/ 75] Iter[ 51/1223]	  loss: 0.45cifar10:0.2-instance | Epoch [ 47/ 75] Iter[101/1223]	  loss: 0.20cifar10:0.2-instance | Epoch [ 47/ 75] Iter[151/1223]	  loss: 0.65cifar10:0.2-instance | Epoch [ 47/ 75] Iter[201/1223]	  loss: 0.39cifar10:0.2-instance | Epoch [ 47/ 75] Iter[251/1223]	  loss: 0.25cifar10:0.2-instance | Epoch [ 47/ 75] Iter[301/1223]	  loss: 0.74cifar10:0.2-instance | Epoch [ 47/ 75] Iter[351/1223]	  loss: 0.33cifar10:0.2-instance | Epoch [ 47/ 75] Iter[401/1223]	  loss: 0.26cifar10:0.2-instance | Epoch [ 47/ 75] Iter[451/1223]	  loss: 0.37cifar10:0.2-instance | Epoch [ 47/ 75] Iter[501/1223]	  loss: 0.41cifar10:0.2-instance | Epoch [ 47/ 75] Iter[551/1223]	  loss: 0.43cifar10:0.2-instance | Epoch [ 47/ 75] Iter[601/1223]	  loss: 0.26cifar10:0.2-instance | Epoch [ 47/ 75] Iter[651/1223]	  loss: 0.65cifar10:0.2-instance | Epoch [ 47/ 75] Iter[701/1223]	  loss: 0.35cifar10:0.2-instance | Epoch [ 47/ 75] Iter[751/1223]	  loss: 0.53cifar10:0.2-instance | Epoch [ 47/ 75] Iter[801/1223]	  loss: 0.29cifar10:0.2-instance | Epoch [ 47/ 75] Iter[851/1223]	  loss: 0.43cifar10:0.2-instance | Epoch [ 47/ 75] Iter[901/1223]	  loss: 0.26cifar10:0.2-instance | Epoch [ 47/ 75] Iter[951/1223]	  loss: 0.34cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1001/1223]	  loss: 0.59cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1051/1223]	  loss: 0.45cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1101/1223]	  loss: 0.26cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1151/1223]	  loss: 0.26cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1201/1223]	  loss: 0.40
| Test Epoch 47	 Accuracy: 85.97% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 48 | Accuracy on train set: 72.53% 
labeled data has a size of 39278, f-score: 0.982331
cifar10:0.2-instance | Epoch [ 48/ 75] Iter[  1/1228]	  loss: 0.49cifar10:0.2-instance | Epoch [ 48/ 75] Iter[ 51/1228]	  loss: 0.36cifar10:0.2-instance | Epoch [ 48/ 75] Iter[101/1228]	  loss: 0.44cifar10:0.2-instance | Epoch [ 48/ 75] Iter[151/1228]	  loss: 0.34cifar10:0.2-instance | Epoch [ 48/ 75] Iter[201/1228]	  loss: 0.52cifar10:0.2-instance | Epoch [ 48/ 75] Iter[251/1228]	  loss: 0.25cifar10:0.2-instance | Epoch [ 48/ 75] Iter[301/1228]	  loss: 0.33cifar10:0.2-instance | Epoch [ 48/ 75] Iter[351/1228]	  loss: 0.45cifar10:0.2-instance | Epoch [ 48/ 75] Iter[401/1228]	  loss: 0.32cifar10:0.2-instance | Epoch [ 48/ 75] Iter[451/1228]	  loss: 0.53cifar10:0.2-instance | Epoch [ 48/ 75] Iter[501/1228]	  loss: 0.43cifar10:0.2-instance | Epoch [ 48/ 75] Iter[551/1228]	  loss: 0.41cifar10:0.2-instance | Epoch [ 48/ 75] Iter[601/1228]	  loss: 0.43cifar10:0.2-instance | Epoch [ 48/ 75] Iter[651/1228]	  loss: 0.42cifar10:0.2-instance | Epoch [ 48/ 75] Iter[701/1228]	  loss: 0.45cifar10:0.2-instance | Epoch [ 48/ 75] Iter[751/1228]	  loss: 0.42cifar10:0.2-instance | Epoch [ 48/ 75] Iter[801/1228]	  loss: 0.47cifar10:0.2-instance | Epoch [ 48/ 75] Iter[851/1228]	  loss: 0.53cifar10:0.2-instance | Epoch [ 48/ 75] Iter[901/1228]	  loss: 0.30cifar10:0.2-instance | Epoch [ 48/ 75] Iter[951/1228]	  loss: 0.34cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1001/1228]	  loss: 0.27cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1051/1228]	  loss: 0.20cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1101/1228]	  loss: 0.47cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1151/1228]	  loss: 0.30cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1201/1228]	  loss: 0.37
| Test Epoch 48	 Accuracy: 84.80% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 49 | Accuracy on train set: 71.81% 
labeled data has a size of 39283, f-score: 0.981977
cifar10:0.2-instance | Epoch [ 49/ 75] Iter[  1/1228]	  loss: 0.26cifar10:0.2-instance | Epoch [ 49/ 75] Iter[ 51/1228]	  loss: 0.40cifar10:0.2-instance | Epoch [ 49/ 75] Iter[101/1228]	  loss: 0.46cifar10:0.2-instance | Epoch [ 49/ 75] Iter[151/1228]	  loss: 0.49cifar10:0.2-instance | Epoch [ 49/ 75] Iter[201/1228]	  loss: 0.49cifar10:0.2-instance | Epoch [ 49/ 75] Iter[251/1228]	  loss: 0.61cifar10:0.2-instance | Epoch [ 49/ 75] Iter[301/1228]	  loss: 0.60cifar10:0.2-instance | Epoch [ 49/ 75] Iter[351/1228]	  loss: 0.25cifar10:0.2-instance | Epoch [ 49/ 75] Iter[401/1228]	  loss: 0.49cifar10:0.2-instance | Epoch [ 49/ 75] Iter[451/1228]	  loss: 0.35cifar10:0.2-instance | Epoch [ 49/ 75] Iter[501/1228]	  loss: 0.47cifar10:0.2-instance | Epoch [ 49/ 75] Iter[551/1228]	  loss: 0.55cifar10:0.2-instance | Epoch [ 49/ 75] Iter[601/1228]	  loss: 0.32cifar10:0.2-instance | Epoch [ 49/ 75] Iter[651/1228]	  loss: 0.48cifar10:0.2-instance | Epoch [ 49/ 75] Iter[701/1228]	  loss: 0.44cifar10:0.2-instance | Epoch [ 49/ 75] Iter[751/1228]	  loss: 0.46cifar10:0.2-instance | Epoch [ 49/ 75] Iter[801/1228]	  loss: 0.46cifar10:0.2-instance | Epoch [ 49/ 75] Iter[851/1228]	  loss: 0.42cifar10:0.2-instance | Epoch [ 49/ 75] Iter[901/1228]	  loss: 0.39cifar10:0.2-instance | Epoch [ 49/ 75] Iter[951/1228]	  loss: 0.74cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1001/1228]	  loss: 0.51cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1051/1228]	  loss: 0.50cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1101/1228]	  loss: 0.37cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1151/1228]	  loss: 0.57cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1201/1228]	  loss: 0.32
| Test Epoch 49	 Accuracy: 85.17% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 50 | Accuracy on train set: 72.16% 
labeled data has a size of 39181, f-score: 0.982262
cifar10:0.2-instance | Epoch [ 50/ 75] Iter[  1/1225]	  loss: 0.45cifar10:0.2-instance | Epoch [ 50/ 75] Iter[ 51/1225]	  loss: 0.26cifar10:0.2-instance | Epoch [ 50/ 75] Iter[101/1225]	  loss: 0.19cifar10:0.2-instance | Epoch [ 50/ 75] Iter[151/1225]	  loss: 0.29cifar10:0.2-instance | Epoch [ 50/ 75] Iter[201/1225]	  loss: 0.41cifar10:0.2-instance | Epoch [ 50/ 75] Iter[251/1225]	  loss: 0.61cifar10:0.2-instance | Epoch [ 50/ 75] Iter[301/1225]	  loss: 0.23cifar10:0.2-instance | Epoch [ 50/ 75] Iter[351/1225]	  loss: 0.44cifar10:0.2-instance | Epoch [ 50/ 75] Iter[401/1225]	  loss: 0.37cifar10:0.2-instance | Epoch [ 50/ 75] Iter[451/1225]	  loss: 0.37cifar10:0.2-instance | Epoch [ 50/ 75] Iter[501/1225]	  loss: 0.33cifar10:0.2-instance | Epoch [ 50/ 75] Iter[551/1225]	  loss: 0.46cifar10:0.2-instance | Epoch [ 50/ 75] Iter[601/1225]	  loss: 0.52cifar10:0.2-instance | Epoch [ 50/ 75] Iter[651/1225]	  loss: 0.39cifar10:0.2-instance | Epoch [ 50/ 75] Iter[701/1225]	  loss: 0.32cifar10:0.2-instance | Epoch [ 50/ 75] Iter[751/1225]	  loss: 0.48cifar10:0.2-instance | Epoch [ 50/ 75] Iter[801/1225]	  loss: 0.40cifar10:0.2-instance | Epoch [ 50/ 75] Iter[851/1225]	  loss: 0.57cifar10:0.2-instance | Epoch [ 50/ 75] Iter[901/1225]	  loss: 0.26cifar10:0.2-instance | Epoch [ 50/ 75] Iter[951/1225]	  loss: 0.50cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1001/1225]	  loss: 0.28cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1051/1225]	  loss: 0.60cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1101/1225]	  loss: 0.33cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1151/1225]	  loss: 0.51cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1201/1225]	  loss: 0.24
| Test Epoch 50	 Accuracy: 86.96% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 51 | Accuracy on train set: 72.91% 
labeled data has a size of 39264, f-score: 0.982325
cifar10:0.2-instance | Epoch [ 51/ 75] Iter[  1/1228]	  loss: 0.40cifar10:0.2-instance | Epoch [ 51/ 75] Iter[ 51/1228]	  loss: 0.37cifar10:0.2-instance | Epoch [ 51/ 75] Iter[101/1228]	  loss: 0.38cifar10:0.2-instance | Epoch [ 51/ 75] Iter[151/1228]	  loss: 0.38cifar10:0.2-instance | Epoch [ 51/ 75] Iter[201/1228]	  loss: 0.39cifar10:0.2-instance | Epoch [ 51/ 75] Iter[251/1228]	  loss: 0.39cifar10:0.2-instance | Epoch [ 51/ 75] Iter[301/1228]	  loss: 0.29cifar10:0.2-instance | Epoch [ 51/ 75] Iter[351/1228]	  loss: 0.34cifar10:0.2-instance | Epoch [ 51/ 75] Iter[401/1228]	  loss: 0.59cifar10:0.2-instance | Epoch [ 51/ 75] Iter[451/1228]	  loss: 0.57cifar10:0.2-instance | Epoch [ 51/ 75] Iter[501/1228]	  loss: 0.27cifar10:0.2-instance | Epoch [ 51/ 75] Iter[551/1228]	  loss: 0.42cifar10:0.2-instance | Epoch [ 51/ 75] Iter[601/1228]	  loss: 0.34cifar10:0.2-instance | Epoch [ 51/ 75] Iter[651/1228]	  loss: 0.46cifar10:0.2-instance | Epoch [ 51/ 75] Iter[701/1228]	  loss: 0.40cifar10:0.2-instance | Epoch [ 51/ 75] Iter[751/1228]	  loss: 0.38cifar10:0.2-instance | Epoch [ 51/ 75] Iter[801/1228]	  loss: 0.48cifar10:0.2-instance | Epoch [ 51/ 75] Iter[851/1228]	  loss: 0.52cifar10:0.2-instance | Epoch [ 51/ 75] Iter[901/1228]	  loss: 0.40cifar10:0.2-instance | Epoch [ 51/ 75] Iter[951/1228]	  loss: 0.31cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1001/1228]	  loss: 0.50cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1051/1228]	  loss: 0.26cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1101/1228]	  loss: 0.57cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1151/1228]	  loss: 0.58cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1201/1228]	  loss: 0.44
| Test Epoch 51	 Accuracy: 86.45% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 52 | Accuracy on train set: 72.93% 
labeled data has a size of 39203, f-score: 0.983624
cifar10:0.2-instance | Epoch [ 52/ 75] Iter[  1/1226]	  loss: 0.27cifar10:0.2-instance | Epoch [ 52/ 75] Iter[ 51/1226]	  loss: 0.60cifar10:0.2-instance | Epoch [ 52/ 75] Iter[101/1226]	  loss: 0.32cifar10:0.2-instance | Epoch [ 52/ 75] Iter[151/1226]	  loss: 0.46cifar10:0.2-instance | Epoch [ 52/ 75] Iter[201/1226]	  loss: 0.58cifar10:0.2-instance | Epoch [ 52/ 75] Iter[251/1226]	  loss: 0.27cifar10:0.2-instance | Epoch [ 52/ 75] Iter[301/1226]	  loss: 0.43cifar10:0.2-instance | Epoch [ 52/ 75] Iter[351/1226]	  loss: 0.48cifar10:0.2-instance | Epoch [ 52/ 75] Iter[401/1226]	  loss: 0.52cifar10:0.2-instance | Epoch [ 52/ 75] Iter[451/1226]	  loss: 0.37cifar10:0.2-instance | Epoch [ 52/ 75] Iter[501/1226]	  loss: 0.30cifar10:0.2-instance | Epoch [ 52/ 75] Iter[551/1226]	  loss: 0.33cifar10:0.2-instance | Epoch [ 52/ 75] Iter[601/1226]	  loss: 0.37cifar10:0.2-instance | Epoch [ 52/ 75] Iter[651/1226]	  loss: 0.30cifar10:0.2-instance | Epoch [ 52/ 75] Iter[701/1226]	  loss: 0.46cifar10:0.2-instance | Epoch [ 52/ 75] Iter[751/1226]	  loss: 0.39cifar10:0.2-instance | Epoch [ 52/ 75] Iter[801/1226]	  loss: 0.54cifar10:0.2-instance | Epoch [ 52/ 75] Iter[851/1226]	  loss: 0.39cifar10:0.2-instance | Epoch [ 52/ 75] Iter[901/1226]	  loss: 0.33cifar10:0.2-instance | Epoch [ 52/ 75] Iter[951/1226]	  loss: 0.54cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1001/1226]	  loss: 0.29cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1051/1226]	  loss: 0.48cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1101/1226]	  loss: 0.28cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1151/1226]	  loss: 0.33cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1201/1226]	  loss: 0.45
| Test Epoch 52	 Accuracy: 84.11% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 53 | Accuracy on train set: 71.04% 
labeled data has a size of 39187, f-score: 0.983209
cifar10:0.2-instance | Epoch [ 53/ 75] Iter[  1/1225]	  loss: 0.23cifar10:0.2-instance | Epoch [ 53/ 75] Iter[ 51/1225]	  loss: 0.48cifar10:0.2-instance | Epoch [ 53/ 75] Iter[101/1225]	  loss: 0.34cifar10:0.2-instance | Epoch [ 53/ 75] Iter[151/1225]	  loss: 0.26cifar10:0.2-instance | Epoch [ 53/ 75] Iter[201/1225]	  loss: 0.39cifar10:0.2-instance | Epoch [ 53/ 75] Iter[251/1225]	  loss: 0.30cifar10:0.2-instance | Epoch [ 53/ 75] Iter[301/1225]	  loss: 0.41cifar10:0.2-instance | Epoch [ 53/ 75] Iter[351/1225]	  loss: 0.30cifar10:0.2-instance | Epoch [ 53/ 75] Iter[401/1225]	  loss: 0.49cifar10:0.2-instance | Epoch [ 53/ 75] Iter[451/1225]	  loss: 0.28cifar10:0.2-instance | Epoch [ 53/ 75] Iter[501/1225]	  loss: 0.19cifar10:0.2-instance | Epoch [ 53/ 75] Iter[551/1225]	  loss: 0.44cifar10:0.2-instance | Epoch [ 53/ 75] Iter[601/1225]	  loss: 0.27cifar10:0.2-instance | Epoch [ 53/ 75] Iter[651/1225]	  loss: 0.35cifar10:0.2-instance | Epoch [ 53/ 75] Iter[701/1225]	  loss: 0.40cifar10:0.2-instance | Epoch [ 53/ 75] Iter[751/1225]	  loss: 0.24cifar10:0.2-instance | Epoch [ 53/ 75] Iter[801/1225]	  loss: 0.31cifar10:0.2-instance | Epoch [ 53/ 75] Iter[851/1225]	  loss: 0.35cifar10:0.2-instance | Epoch [ 53/ 75] Iter[901/1225]	  loss: 0.32cifar10:0.2-instance | Epoch [ 53/ 75] Iter[951/1225]	  loss: 0.32cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1001/1225]	  loss: 0.56cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1051/1225]	  loss: 0.58cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1101/1225]	  loss: 0.44cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1151/1225]	  loss: 0.34cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1201/1225]	  loss: 0.77
| Test Epoch 53	 Accuracy: 86.06% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 54 | Accuracy on train set: 72.62% 
labeled data has a size of 39207, f-score: 0.983268
cifar10:0.2-instance | Epoch [ 54/ 75] Iter[  1/1226]	  loss: 0.32cifar10:0.2-instance | Epoch [ 54/ 75] Iter[ 51/1226]	  loss: 0.44cifar10:0.2-instance | Epoch [ 54/ 75] Iter[101/1226]	  loss: 0.35cifar10:0.2-instance | Epoch [ 54/ 75] Iter[151/1226]	  loss: 0.41cifar10:0.2-instance | Epoch [ 54/ 75] Iter[201/1226]	  loss: 0.57cifar10:0.2-instance | Epoch [ 54/ 75] Iter[251/1226]	  loss: 0.27cifar10:0.2-instance | Epoch [ 54/ 75] Iter[301/1226]	  loss: 0.45cifar10:0.2-instance | Epoch [ 54/ 75] Iter[351/1226]	  loss: 0.30cifar10:0.2-instance | Epoch [ 54/ 75] Iter[401/1226]	  loss: 0.60cifar10:0.2-instance | Epoch [ 54/ 75] Iter[451/1226]	  loss: 0.29cifar10:0.2-instance | Epoch [ 54/ 75] Iter[501/1226]	  loss: 0.33cifar10:0.2-instance | Epoch [ 54/ 75] Iter[551/1226]	  loss: 0.30cifar10:0.2-instance | Epoch [ 54/ 75] Iter[601/1226]	  loss: 0.38cifar10:0.2-instance | Epoch [ 54/ 75] Iter[651/1226]	  loss: 0.31cifar10:0.2-instance | Epoch [ 54/ 75] Iter[701/1226]	  loss: 0.34cifar10:0.2-instance | Epoch [ 54/ 75] Iter[751/1226]	  loss: 0.36cifar10:0.2-instance | Epoch [ 54/ 75] Iter[801/1226]	  loss: 0.48cifar10:0.2-instance | Epoch [ 54/ 75] Iter[851/1226]	  loss: 0.32cifar10:0.2-instance | Epoch [ 54/ 75] Iter[901/1226]	  loss: 0.24cifar10:0.2-instance | Epoch [ 54/ 75] Iter[951/1226]	  loss: 0.43cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1001/1226]	  loss: 0.33cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1051/1226]	  loss: 0.58cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1101/1226]	  loss: 0.40cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1151/1226]	  loss: 0.53cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1201/1226]	  loss: 0.36
| Test Epoch 54	 Accuracy: 85.49% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 55 | Accuracy on train set: 72.03% 
labeled data has a size of 39227, f-score: 0.982665
cifar10:0.2-instance | Epoch [ 55/ 75] Iter[  1/1226]	  loss: 0.40cifar10:0.2-instance | Epoch [ 55/ 75] Iter[ 51/1226]	  loss: 0.25cifar10:0.2-instance | Epoch [ 55/ 75] Iter[101/1226]	  loss: 0.40cifar10:0.2-instance | Epoch [ 55/ 75] Iter[151/1226]	  loss: 0.63cifar10:0.2-instance | Epoch [ 55/ 75] Iter[201/1226]	  loss: 0.37cifar10:0.2-instance | Epoch [ 55/ 75] Iter[251/1226]	  loss: 0.26cifar10:0.2-instance | Epoch [ 55/ 75] Iter[301/1226]	  loss: 0.51cifar10:0.2-instance | Epoch [ 55/ 75] Iter[351/1226]	  loss: 0.54cifar10:0.2-instance | Epoch [ 55/ 75] Iter[401/1226]	  loss: 0.51cifar10:0.2-instance | Epoch [ 55/ 75] Iter[451/1226]	  loss: 0.73cifar10:0.2-instance | Epoch [ 55/ 75] Iter[501/1226]	  loss: 0.39cifar10:0.2-instance | Epoch [ 55/ 75] Iter[551/1226]	  loss: 0.43cifar10:0.2-instance | Epoch [ 55/ 75] Iter[601/1226]	  loss: 0.27cifar10:0.2-instance | Epoch [ 55/ 75] Iter[651/1226]	  loss: 0.44cifar10:0.2-instance | Epoch [ 55/ 75] Iter[701/1226]	  loss: 0.28cifar10:0.2-instance | Epoch [ 55/ 75] Iter[751/1226]	  loss: 0.47cifar10:0.2-instance | Epoch [ 55/ 75] Iter[801/1226]	  loss: 0.56cifar10:0.2-instance | Epoch [ 55/ 75] Iter[851/1226]	  loss: 0.98cifar10:0.2-instance | Epoch [ 55/ 75] Iter[901/1226]	  loss: 0.48cifar10:0.2-instance | Epoch [ 55/ 75] Iter[951/1226]	  loss: 0.51cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1001/1226]	  loss: 0.23cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1051/1226]	  loss: 0.52cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1101/1226]	  loss: 0.52cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1151/1226]	  loss: 0.36cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1201/1226]	  loss: 0.38
| Test Epoch 55	 Accuracy: 86.16% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 56 | Accuracy on train set: 72.45% 
labeled data has a size of 39178, f-score: 0.983639
cifar10:0.2-instance | Epoch [ 56/ 75] Iter[  1/1225]	  loss: 0.34cifar10:0.2-instance | Epoch [ 56/ 75] Iter[ 51/1225]	  loss: 0.41cifar10:0.2-instance | Epoch [ 56/ 75] Iter[101/1225]	  loss: 0.24cifar10:0.2-instance | Epoch [ 56/ 75] Iter[151/1225]	  loss: 0.27cifar10:0.2-instance | Epoch [ 56/ 75] Iter[201/1225]	  loss: 0.44cifar10:0.2-instance | Epoch [ 56/ 75] Iter[251/1225]	  loss: 0.50cifar10:0.2-instance | Epoch [ 56/ 75] Iter[301/1225]	  loss: 0.30cifar10:0.2-instance | Epoch [ 56/ 75] Iter[351/1225]	  loss: 0.29cifar10:0.2-instance | Epoch [ 56/ 75] Iter[401/1225]	  loss: 0.17cifar10:0.2-instance | Epoch [ 56/ 75] Iter[451/1225]	  loss: 0.29cifar10:0.2-instance | Epoch [ 56/ 75] Iter[501/1225]	  loss: 0.27cifar10:0.2-instance | Epoch [ 56/ 75] Iter[551/1225]	  loss: 0.44cifar10:0.2-instance | Epoch [ 56/ 75] Iter[601/1225]	  loss: 0.41cifar10:0.2-instance | Epoch [ 56/ 75] Iter[651/1225]	  loss: 0.38cifar10:0.2-instance | Epoch [ 56/ 75] Iter[701/1225]	  loss: 0.43cifar10:0.2-instance | Epoch [ 56/ 75] Iter[751/1225]	  loss: 0.23cifar10:0.2-instance | Epoch [ 56/ 75] Iter[801/1225]	  loss: 0.44cifar10:0.2-instance | Epoch [ 56/ 75] Iter[851/1225]	  loss: 0.58cifar10:0.2-instance | Epoch [ 56/ 75] Iter[901/1225]	  loss: 0.44cifar10:0.2-instance | Epoch [ 56/ 75] Iter[951/1225]	  loss: 0.39cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1001/1225]	  loss: 0.53cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1051/1225]	  loss: 0.35cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1101/1225]	  loss: 0.56cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1151/1225]	  loss: 0.34cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1201/1225]	  loss: 0.24
| Test Epoch 56	 Accuracy: 86.57% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 57 | Accuracy on train set: 72.64% 
labeled data has a size of 39153, f-score: 0.983424
cifar10:0.2-instance | Epoch [ 57/ 75] Iter[  1/1224]	  loss: 0.42cifar10:0.2-instance | Epoch [ 57/ 75] Iter[ 51/1224]	  loss: 0.51cifar10:0.2-instance | Epoch [ 57/ 75] Iter[101/1224]	  loss: 0.67cifar10:0.2-instance | Epoch [ 57/ 75] Iter[151/1224]	  loss: 0.27cifar10:0.2-instance | Epoch [ 57/ 75] Iter[201/1224]	  loss: 0.46cifar10:0.2-instance | Epoch [ 57/ 75] Iter[251/1224]	  loss: 0.38cifar10:0.2-instance | Epoch [ 57/ 75] Iter[301/1224]	  loss: 0.65cifar10:0.2-instance | Epoch [ 57/ 75] Iter[351/1224]	  loss: 0.45cifar10:0.2-instance | Epoch [ 57/ 75] Iter[401/1224]	  loss: 0.32cifar10:0.2-instance | Epoch [ 57/ 75] Iter[451/1224]	  loss: 0.33cifar10:0.2-instance | Epoch [ 57/ 75] Iter[501/1224]	  loss: 0.41cifar10:0.2-instance | Epoch [ 57/ 75] Iter[551/1224]	  loss: 0.30cifar10:0.2-instance | Epoch [ 57/ 75] Iter[601/1224]	  loss: 0.52cifar10:0.2-instance | Epoch [ 57/ 75] Iter[651/1224]	  loss: 0.49cifar10:0.2-instance | Epoch [ 57/ 75] Iter[701/1224]	  loss: 0.53cifar10:0.2-instance | Epoch [ 57/ 75] Iter[751/1224]	  loss: 0.35cifar10:0.2-instance | Epoch [ 57/ 75] Iter[801/1224]	  loss: 0.39cifar10:0.2-instance | Epoch [ 57/ 75] Iter[851/1224]	  loss: 0.28cifar10:0.2-instance | Epoch [ 57/ 75] Iter[901/1224]	  loss: 0.45cifar10:0.2-instance | Epoch [ 57/ 75] Iter[951/1224]	  loss: 0.50cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1001/1224]	  loss: 0.33cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1051/1224]	  loss: 0.47cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1101/1224]	  loss: 0.26cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1151/1224]	  loss: 0.29cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1201/1224]	  loss: 0.45
| Test Epoch 57	 Accuracy: 86.95% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 58 | Accuracy on train set: 72.86% 
labeled data has a size of 39193, f-score: 0.983543
cifar10:0.2-instance | Epoch [ 58/ 75] Iter[  1/1225]	  loss: 0.35cifar10:0.2-instance | Epoch [ 58/ 75] Iter[ 51/1225]	  loss: 0.37cifar10:0.2-instance | Epoch [ 58/ 75] Iter[101/1225]	  loss: 0.26cifar10:0.2-instance | Epoch [ 58/ 75] Iter[151/1225]	  loss: 0.36cifar10:0.2-instance | Epoch [ 58/ 75] Iter[201/1225]	  loss: 0.62cifar10:0.2-instance | Epoch [ 58/ 75] Iter[251/1225]	  loss: 0.24cifar10:0.2-instance | Epoch [ 58/ 75] Iter[301/1225]	  loss: 0.49cifar10:0.2-instance | Epoch [ 58/ 75] Iter[351/1225]	  loss: 0.46cifar10:0.2-instance | Epoch [ 58/ 75] Iter[401/1225]	  loss: 0.32cifar10:0.2-instance | Epoch [ 58/ 75] Iter[451/1225]	  loss: 0.35cifar10:0.2-instance | Epoch [ 58/ 75] Iter[501/1225]	  loss: 0.33cifar10:0.2-instance | Epoch [ 58/ 75] Iter[551/1225]	  loss: 0.36cifar10:0.2-instance | Epoch [ 58/ 75] Iter[601/1225]	  loss: 0.52cifar10:0.2-instance | Epoch [ 58/ 75] Iter[651/1225]	  loss: 0.32cifar10:0.2-instance | Epoch [ 58/ 75] Iter[701/1225]	  loss: 0.36cifar10:0.2-instance | Epoch [ 58/ 75] Iter[751/1225]	  loss: 0.39cifar10:0.2-instance | Epoch [ 58/ 75] Iter[801/1225]	  loss: 0.33cifar10:0.2-instance | Epoch [ 58/ 75] Iter[851/1225]	  loss: 0.40cifar10:0.2-instance | Epoch [ 58/ 75] Iter[901/1225]	  loss: 0.47cifar10:0.2-instance | Epoch [ 58/ 75] Iter[951/1225]	  loss: 0.46cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1001/1225]	  loss: 0.40cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1051/1225]	  loss: 0.67cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1101/1225]	  loss: 0.41cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1151/1225]	  loss: 0.37cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1201/1225]	  loss: 0.25
| Test Epoch 58	 Accuracy: 84.57% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 59 | Accuracy on train set: 71.65% 
labeled data has a size of 39171, f-score: 0.982308
cifar10:0.2-instance | Epoch [ 59/ 75] Iter[  1/1225]	  loss: 0.46cifar10:0.2-instance | Epoch [ 59/ 75] Iter[ 51/1225]	  loss: 0.58cifar10:0.2-instance | Epoch [ 59/ 75] Iter[101/1225]	  loss: 0.35cifar10:0.2-instance | Epoch [ 59/ 75] Iter[151/1225]	  loss: 0.33cifar10:0.2-instance | Epoch [ 59/ 75] Iter[201/1225]	  loss: 0.44cifar10:0.2-instance | Epoch [ 59/ 75] Iter[251/1225]	  loss: 0.32cifar10:0.2-instance | Epoch [ 59/ 75] Iter[301/1225]	  loss: 0.39cifar10:0.2-instance | Epoch [ 59/ 75] Iter[351/1225]	  loss: 0.67cifar10:0.2-instance | Epoch [ 59/ 75] Iter[401/1225]	  loss: 0.25cifar10:0.2-instance | Epoch [ 59/ 75] Iter[451/1225]	  loss: 0.24cifar10:0.2-instance | Epoch [ 59/ 75] Iter[501/1225]	  loss: 0.34cifar10:0.2-instance | Epoch [ 59/ 75] Iter[551/1225]	  loss: 0.41cifar10:0.2-instance | Epoch [ 59/ 75] Iter[601/1225]	  loss: 0.30cifar10:0.2-instance | Epoch [ 59/ 75] Iter[651/1225]	  loss: 0.43cifar10:0.2-instance | Epoch [ 59/ 75] Iter[701/1225]	  loss: 0.28cifar10:0.2-instance | Epoch [ 59/ 75] Iter[751/1225]	  loss: 0.32cifar10:0.2-instance | Epoch [ 59/ 75] Iter[801/1225]	  loss: 0.44cifar10:0.2-instance | Epoch [ 59/ 75] Iter[851/1225]	  loss: 0.17cifar10:0.2-instance | Epoch [ 59/ 75] Iter[901/1225]	  loss: 0.46cifar10:0.2-instance | Epoch [ 59/ 75] Iter[951/1225]	  loss: 0.60cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1001/1225]	  loss: 0.39cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1051/1225]	  loss: 0.41cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1101/1225]	  loss: 0.58cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1151/1225]	  loss: 0.43cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1201/1225]	  loss: 0.65
| Test Epoch 59	 Accuracy: 85.33% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 60 | Accuracy on train set: 72.28% 
labeled data has a size of 39214, f-score: 0.980364
cifar10:0.2-instance | Epoch [ 60/ 75] Iter[  1/1226]	  loss: 0.38cifar10:0.2-instance | Epoch [ 60/ 75] Iter[ 51/1226]	  loss: 0.41cifar10:0.2-instance | Epoch [ 60/ 75] Iter[101/1226]	  loss: 0.22cifar10:0.2-instance | Epoch [ 60/ 75] Iter[151/1226]	  loss: 0.32cifar10:0.2-instance | Epoch [ 60/ 75] Iter[201/1226]	  loss: 0.24cifar10:0.2-instance | Epoch [ 60/ 75] Iter[251/1226]	  loss: 0.20cifar10:0.2-instance | Epoch [ 60/ 75] Iter[301/1226]	  loss: 0.32cifar10:0.2-instance | Epoch [ 60/ 75] Iter[351/1226]	  loss: 0.21cifar10:0.2-instance | Epoch [ 60/ 75] Iter[401/1226]	  loss: 0.23cifar10:0.2-instance | Epoch [ 60/ 75] Iter[451/1226]	  loss: 0.31cifar10:0.2-instance | Epoch [ 60/ 75] Iter[501/1226]	  loss: 0.33cifar10:0.2-instance | Epoch [ 60/ 75] Iter[551/1226]	  loss: 0.33cifar10:0.2-instance | Epoch [ 60/ 75] Iter[601/1226]	  loss: 0.17cifar10:0.2-instance | Epoch [ 60/ 75] Iter[651/1226]	  loss: 0.28cifar10:0.2-instance | Epoch [ 60/ 75] Iter[701/1226]	  loss: 0.18cifar10:0.2-instance | Epoch [ 60/ 75] Iter[751/1226]	  loss: 0.30cifar10:0.2-instance | Epoch [ 60/ 75] Iter[801/1226]	  loss: 0.20cifar10:0.2-instance | Epoch [ 60/ 75] Iter[851/1226]	  loss: 0.52cifar10:0.2-instance | Epoch [ 60/ 75] Iter[901/1226]	  loss: 0.29cifar10:0.2-instance | Epoch [ 60/ 75] Iter[951/1226]	  loss: 0.28cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1001/1226]	  loss: 0.17cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1051/1226]	  loss: 0.25cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1101/1226]	  loss: 0.21cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1151/1226]	  loss: 0.27cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1201/1226]	  loss: 0.43
| Test Epoch 60	 Accuracy: 91.11% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 61 | Accuracy on train set: 76.85% 
labeled data has a size of 39381, f-score: 0.981260
cifar10:0.2-instance | Epoch [ 61/ 75] Iter[  1/1231]	  loss: 0.21cifar10:0.2-instance | Epoch [ 61/ 75] Iter[ 51/1231]	  loss: 0.16cifar10:0.2-instance | Epoch [ 61/ 75] Iter[101/1231]	  loss: 0.16cifar10:0.2-instance | Epoch [ 61/ 75] Iter[151/1231]	  loss: 0.17cifar10:0.2-instance | Epoch [ 61/ 75] Iter[201/1231]	  loss: 0.20cifar10:0.2-instance | Epoch [ 61/ 75] Iter[251/1231]	  loss: 0.26cifar10:0.2-instance | Epoch [ 61/ 75] Iter[301/1231]	  loss: 0.17cifar10:0.2-instance | Epoch [ 61/ 75] Iter[351/1231]	  loss: 0.17cifar10:0.2-instance | Epoch [ 61/ 75] Iter[401/1231]	  loss: 0.32cifar10:0.2-instance | Epoch [ 61/ 75] Iter[451/1231]	  loss: 0.25cifar10:0.2-instance | Epoch [ 61/ 75] Iter[501/1231]	  loss: 0.34cifar10:0.2-instance | Epoch [ 61/ 75] Iter[551/1231]	  loss: 0.21cifar10:0.2-instance | Epoch [ 61/ 75] Iter[601/1231]	  loss: 0.17cifar10:0.2-instance | Epoch [ 61/ 75] Iter[651/1231]	  loss: 0.24cifar10:0.2-instance | Epoch [ 61/ 75] Iter[701/1231]	  loss: 0.22cifar10:0.2-instance | Epoch [ 61/ 75] Iter[751/1231]	  loss: 0.43cifar10:0.2-instance | Epoch [ 61/ 75] Iter[801/1231]	  loss: 0.23cifar10:0.2-instance | Epoch [ 61/ 75] Iter[851/1231]	  loss: 0.19cifar10:0.2-instance | Epoch [ 61/ 75] Iter[901/1231]	  loss: 0.22cifar10:0.2-instance | Epoch [ 61/ 75] Iter[951/1231]	  loss: 0.29cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1001/1231]	  loss: 0.19cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1051/1231]	  loss: 0.20cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1101/1231]	  loss: 0.18cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1151/1231]	  loss: 0.24cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1201/1231]	  loss: 0.20
| Test Epoch 61	 Accuracy: 91.76% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 62 | Accuracy on train set: 77.42% 
labeled data has a size of 39463, f-score: 0.982237
cifar10:0.2-instance | Epoch [ 62/ 75] Iter[  1/1234]	  loss: 0.34cifar10:0.2-instance | Epoch [ 62/ 75] Iter[ 51/1234]	  loss: 0.27cifar10:0.2-instance | Epoch [ 62/ 75] Iter[101/1234]	  loss: 0.20cifar10:0.2-instance | Epoch [ 62/ 75] Iter[151/1234]	  loss: 0.21cifar10:0.2-instance | Epoch [ 62/ 75] Iter[201/1234]	  loss: 0.30cifar10:0.2-instance | Epoch [ 62/ 75] Iter[251/1234]	  loss: 0.19cifar10:0.2-instance | Epoch [ 62/ 75] Iter[301/1234]	  loss: 0.36cifar10:0.2-instance | Epoch [ 62/ 75] Iter[351/1234]	  loss: 0.20cifar10:0.2-instance | Epoch [ 62/ 75] Iter[401/1234]	  loss: 0.17cifar10:0.2-instance | Epoch [ 62/ 75] Iter[451/1234]	  loss: 0.16cifar10:0.2-instance | Epoch [ 62/ 75] Iter[501/1234]	  loss: 0.16cifar10:0.2-instance | Epoch [ 62/ 75] Iter[551/1234]	  loss: 0.22cifar10:0.2-instance | Epoch [ 62/ 75] Iter[601/1234]	  loss: 0.22cifar10:0.2-instance | Epoch [ 62/ 75] Iter[651/1234]	  loss: 0.32cifar10:0.2-instance | Epoch [ 62/ 75] Iter[701/1234]	  loss: 0.24cifar10:0.2-instance | Epoch [ 62/ 75] Iter[751/1234]	  loss: 0.24cifar10:0.2-instance | Epoch [ 62/ 75] Iter[801/1234]	  loss: 0.34cifar10:0.2-instance | Epoch [ 62/ 75] Iter[851/1234]	  loss: 0.24cifar10:0.2-instance | Epoch [ 62/ 75] Iter[901/1234]	  loss: 0.18cifar10:0.2-instance | Epoch [ 62/ 75] Iter[951/1234]	  loss: 0.16cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1001/1234]	  loss: 0.22cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1051/1234]	  loss: 0.24cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1101/1234]	  loss: 0.25cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1151/1234]	  loss: 0.36cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1201/1234]	  loss: 0.17
| Test Epoch 62	 Accuracy: 91.75% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 63 | Accuracy on train set: 77.66% 
labeled data has a size of 39463, f-score: 0.984542
cifar10:0.2-instance | Epoch [ 63/ 75] Iter[  1/1234]	  loss: 0.23cifar10:0.2-instance | Epoch [ 63/ 75] Iter[ 51/1234]	  loss: 0.37cifar10:0.2-instance | Epoch [ 63/ 75] Iter[101/1234]	  loss: 0.24cifar10:0.2-instance | Epoch [ 63/ 75] Iter[151/1234]	  loss: 0.21cifar10:0.2-instance | Epoch [ 63/ 75] Iter[201/1234]	  loss: 0.15cifar10:0.2-instance | Epoch [ 63/ 75] Iter[251/1234]	  loss: 0.20cifar10:0.2-instance | Epoch [ 63/ 75] Iter[301/1234]	  loss: 0.18cifar10:0.2-instance | Epoch [ 63/ 75] Iter[351/1234]	  loss: 0.22cifar10:0.2-instance | Epoch [ 63/ 75] Iter[401/1234]	  loss: 0.20cifar10:0.2-instance | Epoch [ 63/ 75] Iter[451/1234]	  loss: 0.22cifar10:0.2-instance | Epoch [ 63/ 75] Iter[501/1234]	  loss: 0.18cifar10:0.2-instance | Epoch [ 63/ 75] Iter[551/1234]	  loss: 0.18cifar10:0.2-instance | Epoch [ 63/ 75] Iter[601/1234]	  loss: 0.19cifar10:0.2-instance | Epoch [ 63/ 75] Iter[651/1234]	  loss: 0.25cifar10:0.2-instance | Epoch [ 63/ 75] Iter[701/1234]	  loss: 0.19cifar10:0.2-instance | Epoch [ 63/ 75] Iter[751/1234]	  loss: 0.16cifar10:0.2-instance | Epoch [ 63/ 75] Iter[801/1234]	  loss: 0.18cifar10:0.2-instance | Epoch [ 63/ 75] Iter[851/1234]	  loss: 0.30cifar10:0.2-instance | Epoch [ 63/ 75] Iter[901/1234]	  loss: 0.18cifar10:0.2-instance | Epoch [ 63/ 75] Iter[951/1234]	  loss: 0.18cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1001/1234]	  loss: 0.22cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1051/1234]	  loss: 0.17cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1101/1234]	  loss: 0.32cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1151/1234]	  loss: 0.16cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1201/1234]	  loss: 0.21
| Test Epoch 63	 Accuracy: 92.05% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 64 | Accuracy on train set: 78.06% 
labeled data has a size of 39551, f-score: 0.984552
cifar10:0.2-instance | Epoch [ 64/ 75] Iter[  1/1236]	  loss: 0.28cifar10:0.2-instance | Epoch [ 64/ 75] Iter[ 51/1236]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[101/1236]	  loss: 0.21cifar10:0.2-instance | Epoch [ 64/ 75] Iter[151/1236]	  loss: 0.30cifar10:0.2-instance | Epoch [ 64/ 75] Iter[201/1236]	  loss: 0.24cifar10:0.2-instance | Epoch [ 64/ 75] Iter[251/1236]	  loss: 0.27cifar10:0.2-instance | Epoch [ 64/ 75] Iter[301/1236]	  loss: 0.47cifar10:0.2-instance | Epoch [ 64/ 75] Iter[351/1236]	  loss: 0.18cifar10:0.2-instance | Epoch [ 64/ 75] Iter[401/1236]	  loss: 0.17cifar10:0.2-instance | Epoch [ 64/ 75] Iter[451/1236]	  loss: 0.24cifar10:0.2-instance | Epoch [ 64/ 75] Iter[501/1236]	  loss: 0.17cifar10:0.2-instance | Epoch [ 64/ 75] Iter[551/1236]	  loss: 0.17cifar10:0.2-instance | Epoch [ 64/ 75] Iter[601/1236]	  loss: 0.22cifar10:0.2-instance | Epoch [ 64/ 75] Iter[651/1236]	  loss: 0.20cifar10:0.2-instance | Epoch [ 64/ 75] Iter[701/1236]	  loss: 0.18cifar10:0.2-instance | Epoch [ 64/ 75] Iter[751/1236]	  loss: 0.40cifar10:0.2-instance | Epoch [ 64/ 75] Iter[801/1236]	  loss: 0.21cifar10:0.2-instance | Epoch [ 64/ 75] Iter[851/1236]	  loss: 0.18cifar10:0.2-instance | Epoch [ 64/ 75] Iter[901/1236]	  loss: 0.22cifar10:0.2-instance | Epoch [ 64/ 75] Iter[951/1236]	  loss: 0.17cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1001/1236]	  loss: 0.19cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1051/1236]	  loss: 0.17cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1101/1236]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1151/1236]	  loss: 0.17cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1201/1236]	  loss: 0.17
| Test Epoch 64	 Accuracy: 92.13% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 65 | Accuracy on train set: 78.28% 
labeled data has a size of 39598, f-score: 0.984494
cifar10:0.2-instance | Epoch [ 65/ 75] Iter[  1/1238]	  loss: 0.21cifar10:0.2-instance | Epoch [ 65/ 75] Iter[ 51/1238]	  loss: 0.29cifar10:0.2-instance | Epoch [ 65/ 75] Iter[101/1238]	  loss: 0.15cifar10:0.2-instance | Epoch [ 65/ 75] Iter[151/1238]	  loss: 0.18cifar10:0.2-instance | Epoch [ 65/ 75] Iter[201/1238]	  loss: 0.16cifar10:0.2-instance | Epoch [ 65/ 75] Iter[251/1238]	  loss: 0.26cifar10:0.2-instance | Epoch [ 65/ 75] Iter[301/1238]	  loss: 0.23cifar10:0.2-instance | Epoch [ 65/ 75] Iter[351/1238]	  loss: 0.22cifar10:0.2-instance | Epoch [ 65/ 75] Iter[401/1238]	  loss: 0.29cifar10:0.2-instance | Epoch [ 65/ 75] Iter[451/1238]	  loss: 0.16cifar10:0.2-instance | Epoch [ 65/ 75] Iter[501/1238]	  loss: 0.16cifar10:0.2-instance | Epoch [ 65/ 75] Iter[551/1238]	  loss: 0.16cifar10:0.2-instance | Epoch [ 65/ 75] Iter[601/1238]	  loss: 0.24cifar10:0.2-instance | Epoch [ 65/ 75] Iter[651/1238]	  loss: 0.19cifar10:0.2-instance | Epoch [ 65/ 75] Iter[701/1238]	  loss: 0.17cifar10:0.2-instance | Epoch [ 65/ 75] Iter[751/1238]	  loss: 0.17cifar10:0.2-instance | Epoch [ 65/ 75] Iter[801/1238]	  loss: 0.25cifar10:0.2-instance | Epoch [ 65/ 75] Iter[851/1238]	  loss: 0.23cifar10:0.2-instance | Epoch [ 65/ 75] Iter[901/1238]	  loss: 0.19cifar10:0.2-instance | Epoch [ 65/ 75] Iter[951/1238]	  loss: 0.16cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1001/1238]	  loss: 0.25cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1051/1238]	  loss: 0.20cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1101/1238]	  loss: 0.26cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1151/1238]	  loss: 0.17cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1201/1238]	  loss: 0.17
| Test Epoch 65	 Accuracy: 91.76% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 66 | Accuracy on train set: 78.38% 
labeled data has a size of 39667, f-score: 0.984193
cifar10:0.2-instance | Epoch [ 66/ 75] Iter[  1/1240]	  loss: 0.18cifar10:0.2-instance | Epoch [ 66/ 75] Iter[ 51/1240]	  loss: 0.20cifar10:0.2-instance | Epoch [ 66/ 75] Iter[101/1240]	  loss: 0.15cifar10:0.2-instance | Epoch [ 66/ 75] Iter[151/1240]	  loss: 0.16cifar10:0.2-instance | Epoch [ 66/ 75] Iter[201/1240]	  loss: 0.17cifar10:0.2-instance | Epoch [ 66/ 75] Iter[251/1240]	  loss: 0.19cifar10:0.2-instance | Epoch [ 66/ 75] Iter[301/1240]	  loss: 0.16cifar10:0.2-instance | Epoch [ 66/ 75] Iter[351/1240]	  loss: 0.19cifar10:0.2-instance | Epoch [ 66/ 75] Iter[401/1240]	  loss: 0.39cifar10:0.2-instance | Epoch [ 66/ 75] Iter[451/1240]	  loss: 0.21cifar10:0.2-instance | Epoch [ 66/ 75] Iter[501/1240]	  loss: 0.17cifar10:0.2-instance | Epoch [ 66/ 75] Iter[551/1240]	  loss: 0.20cifar10:0.2-instance | Epoch [ 66/ 75] Iter[601/1240]	  loss: 0.18cifar10:0.2-instance | Epoch [ 66/ 75] Iter[651/1240]	  loss: 0.25cifar10:0.2-instance | Epoch [ 66/ 75] Iter[701/1240]	  loss: 0.17cifar10:0.2-instance | Epoch [ 66/ 75] Iter[751/1240]	  loss: 0.18cifar10:0.2-instance | Epoch [ 66/ 75] Iter[801/1240]	  loss: 0.24cifar10:0.2-instance | Epoch [ 66/ 75] Iter[851/1240]	  loss: 0.17cifar10:0.2-instance | Epoch [ 66/ 75] Iter[901/1240]	  loss: 0.17cifar10:0.2-instance | Epoch [ 66/ 75] Iter[951/1240]	  loss: 0.30cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1001/1240]	  loss: 0.26cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1051/1240]	  loss: 0.15cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1101/1240]	  loss: 0.22cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1151/1240]	  loss: 0.25cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1201/1240]	  loss: 0.17
| Test Epoch 66	 Accuracy: 92.09% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 67 | Accuracy on train set: 78.55% 
labeled data has a size of 39708, f-score: 0.983882
cifar10:0.2-instance | Epoch [ 67/ 75] Iter[  1/1241]	  loss: 0.24cifar10:0.2-instance | Epoch [ 67/ 75] Iter[ 51/1241]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[101/1241]	  loss: 0.19cifar10:0.2-instance | Epoch [ 67/ 75] Iter[151/1241]	  loss: 0.27cifar10:0.2-instance | Epoch [ 67/ 75] Iter[201/1241]	  loss: 0.19cifar10:0.2-instance | Epoch [ 67/ 75] Iter[251/1241]	  loss: 0.21cifar10:0.2-instance | Epoch [ 67/ 75] Iter[301/1241]	  loss: 0.41cifar10:0.2-instance | Epoch [ 67/ 75] Iter[351/1241]	  loss: 0.15cifar10:0.2-instance | Epoch [ 67/ 75] Iter[401/1241]	  loss: 0.17cifar10:0.2-instance | Epoch [ 67/ 75] Iter[451/1241]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[501/1241]	  loss: 0.18cifar10:0.2-instance | Epoch [ 67/ 75] Iter[551/1241]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[601/1241]	  loss: 0.20cifar10:0.2-instance | Epoch [ 67/ 75] Iter[651/1241]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[701/1241]	  loss: 0.23cifar10:0.2-instance | Epoch [ 67/ 75] Iter[751/1241]	  loss: 0.17cifar10:0.2-instance | Epoch [ 67/ 75] Iter[801/1241]	  loss: 0.23cifar10:0.2-instance | Epoch [ 67/ 75] Iter[851/1241]	  loss: 0.18cifar10:0.2-instance | Epoch [ 67/ 75] Iter[901/1241]	  loss: 0.20cifar10:0.2-instance | Epoch [ 67/ 75] Iter[951/1241]	  loss: 0.15cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1001/1241]	  loss: 0.18cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1051/1241]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1101/1241]	  loss: 0.20cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1151/1241]	  loss: 0.27cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1201/1241]	  loss: 0.15
| Test Epoch 67	 Accuracy: 92.08% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 68 | Accuracy on train set: 78.70% 
labeled data has a size of 39759, f-score: 0.983148
cifar10:0.2-instance | Epoch [ 68/ 75] Iter[  1/1243]	  loss: 0.20cifar10:0.2-instance | Epoch [ 68/ 75] Iter[ 51/1243]	  loss: 0.17cifar10:0.2-instance | Epoch [ 68/ 75] Iter[101/1243]	  loss: 0.23cifar10:0.2-instance | Epoch [ 68/ 75] Iter[151/1243]	  loss: 0.29cifar10:0.2-instance | Epoch [ 68/ 75] Iter[201/1243]	  loss: 0.21cifar10:0.2-instance | Epoch [ 68/ 75] Iter[251/1243]	  loss: 0.16cifar10:0.2-instance | Epoch [ 68/ 75] Iter[301/1243]	  loss: 0.19cifar10:0.2-instance | Epoch [ 68/ 75] Iter[351/1243]	  loss: 0.25cifar10:0.2-instance | Epoch [ 68/ 75] Iter[401/1243]	  loss: 0.20cifar10:0.2-instance | Epoch [ 68/ 75] Iter[451/1243]	  loss: 0.16cifar10:0.2-instance | Epoch [ 68/ 75] Iter[501/1243]	  loss: 0.19cifar10:0.2-instance | Epoch [ 68/ 75] Iter[551/1243]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[601/1243]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[651/1243]	  loss: 0.16cifar10:0.2-instance | Epoch [ 68/ 75] Iter[701/1243]	  loss: 0.16cifar10:0.2-instance | Epoch [ 68/ 75] Iter[751/1243]	  loss: 0.23cifar10:0.2-instance | Epoch [ 68/ 75] Iter[801/1243]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[851/1243]	  loss: 0.19cifar10:0.2-instance | Epoch [ 68/ 75] Iter[901/1243]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[951/1243]	  loss: 0.20cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1001/1243]	  loss: 0.28cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1051/1243]	  loss: 0.33cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1101/1243]	  loss: 0.30cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1151/1243]	  loss: 0.16cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1201/1243]	  loss: 0.19
| Test Epoch 68	 Accuracy: 91.99% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 69 | Accuracy on train set: 78.85% 
labeled data has a size of 39807, f-score: 0.982842
cifar10:0.2-instance | Epoch [ 69/ 75] Iter[  1/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[ 51/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[101/1244]	  loss: 0.34cifar10:0.2-instance | Epoch [ 69/ 75] Iter[151/1244]	  loss: 0.23cifar10:0.2-instance | Epoch [ 69/ 75] Iter[201/1244]	  loss: 0.24cifar10:0.2-instance | Epoch [ 69/ 75] Iter[251/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[301/1244]	  loss: 0.17cifar10:0.2-instance | Epoch [ 69/ 75] Iter[351/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[401/1244]	  loss: 0.17cifar10:0.2-instance | Epoch [ 69/ 75] Iter[451/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[501/1244]	  loss: 0.23cifar10:0.2-instance | Epoch [ 69/ 75] Iter[551/1244]	  loss: 0.19cifar10:0.2-instance | Epoch [ 69/ 75] Iter[601/1244]	  loss: 0.20cifar10:0.2-instance | Epoch [ 69/ 75] Iter[651/1244]	  loss: 0.21cifar10:0.2-instance | Epoch [ 69/ 75] Iter[701/1244]	  loss: 0.17cifar10:0.2-instance | Epoch [ 69/ 75] Iter[751/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[801/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[851/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[901/1244]	  loss: 0.18cifar10:0.2-instance | Epoch [ 69/ 75] Iter[951/1244]	  loss: 0.18cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1001/1244]	  loss: 0.17cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1051/1244]	  loss: 0.16cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1101/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1151/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1201/1244]	  loss: 0.28
| Test Epoch 69	 Accuracy: 91.80% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 70 | Accuracy on train set: 78.85% 
labeled data has a size of 39858, f-score: 0.982638
cifar10:0.2-instance | Epoch [ 70/ 75] Iter[  1/1246]	  loss: 0.21cifar10:0.2-instance | Epoch [ 70/ 75] Iter[ 51/1246]	  loss: 0.19cifar10:0.2-instance | Epoch [ 70/ 75] Iter[101/1246]	  loss: 0.29cifar10:0.2-instance | Epoch [ 70/ 75] Iter[151/1246]	  loss: 0.22cifar10:0.2-instance | Epoch [ 70/ 75] Iter[201/1246]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[251/1246]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[301/1246]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[351/1246]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[401/1246]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[451/1246]	  loss: 0.23cifar10:0.2-instance | Epoch [ 70/ 75] Iter[501/1246]	  loss: 0.17cifar10:0.2-instance | Epoch [ 70/ 75] Iter[551/1246]	  loss: 0.18cifar10:0.2-instance | Epoch [ 70/ 75] Iter[601/1246]	  loss: 0.31cifar10:0.2-instance | Epoch [ 70/ 75] Iter[651/1246]	  loss: 0.20cifar10:0.2-instance | Epoch [ 70/ 75] Iter[701/1246]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[751/1246]	  loss: 0.17cifar10:0.2-instance | Epoch [ 70/ 75] Iter[801/1246]	  loss: 0.23cifar10:0.2-instance | Epoch [ 70/ 75] Iter[851/1246]	  loss: 0.17cifar10:0.2-instance | Epoch [ 70/ 75] Iter[901/1246]	  loss: 0.21cifar10:0.2-instance | Epoch [ 70/ 75] Iter[951/1246]	  loss: 0.21cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1001/1246]	  loss: 0.20cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1051/1246]	  loss: 0.19cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1101/1246]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1151/1246]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1201/1246]	  loss: 0.15
| Test Epoch 70	 Accuracy: 92.18% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 71 | Accuracy on train set: 79.12% 
labeled data has a size of 39908, f-score: 0.982259
cifar10:0.2-instance | Epoch [ 71/ 75] Iter[  1/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[ 51/1248]	  loss: 0.17cifar10:0.2-instance | Epoch [ 71/ 75] Iter[101/1248]	  loss: 0.26cifar10:0.2-instance | Epoch [ 71/ 75] Iter[151/1248]	  loss: 0.18cifar10:0.2-instance | Epoch [ 71/ 75] Iter[201/1248]	  loss: 0.42cifar10:0.2-instance | Epoch [ 71/ 75] Iter[251/1248]	  loss: 0.36cifar10:0.2-instance | Epoch [ 71/ 75] Iter[301/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[351/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[401/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[451/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[501/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[551/1248]	  loss: 0.17cifar10:0.2-instance | Epoch [ 71/ 75] Iter[601/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[651/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[701/1248]	  loss: 0.34cifar10:0.2-instance | Epoch [ 71/ 75] Iter[751/1248]	  loss: 0.20cifar10:0.2-instance | Epoch [ 71/ 75] Iter[801/1248]	  loss: 0.17cifar10:0.2-instance | Epoch [ 71/ 75] Iter[851/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[901/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[951/1248]	  loss: 0.24cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1001/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1051/1248]	  loss: 0.17cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1101/1248]	  loss: 0.27cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1151/1248]	  loss: 0.20cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1201/1248]	  loss: 0.16
| Test Epoch 71	 Accuracy: 92.01% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 72 | Accuracy on train set: 79.24% 
labeled data has a size of 39933, f-score: 0.982145
cifar10:0.2-instance | Epoch [ 72/ 75] Iter[  1/1248]	  loss: 0.18cifar10:0.2-instance | Epoch [ 72/ 75] Iter[ 51/1248]	  loss: 0.20cifar10:0.2-instance | Epoch [ 72/ 75] Iter[101/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[151/1248]	  loss: 0.32cifar10:0.2-instance | Epoch [ 72/ 75] Iter[201/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[251/1248]	  loss: 0.17cifar10:0.2-instance | Epoch [ 72/ 75] Iter[301/1248]	  loss: 0.24cifar10:0.2-instance | Epoch [ 72/ 75] Iter[351/1248]	  loss: 0.17cifar10:0.2-instance | Epoch [ 72/ 75] Iter[401/1248]	  loss: 0.36cifar10:0.2-instance | Epoch [ 72/ 75] Iter[451/1248]	  loss: 0.18cifar10:0.2-instance | Epoch [ 72/ 75] Iter[501/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[551/1248]	  loss: 0.28cifar10:0.2-instance | Epoch [ 72/ 75] Iter[601/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[651/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[701/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[751/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[801/1248]	  loss: 0.24cifar10:0.2-instance | Epoch [ 72/ 75] Iter[851/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[901/1248]	  loss: 0.21cifar10:0.2-instance | Epoch [ 72/ 75] Iter[951/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1001/1248]	  loss: 0.30cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1051/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1101/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1151/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1201/1248]	  loss: 0.17
| Test Epoch 72	 Accuracy: 91.69% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 73 | Accuracy on train set: 79.34% 
labeled data has a size of 39984, f-score: 0.981443
cifar10:0.2-instance | Epoch [ 73/ 75] Iter[  1/1250]	  loss: 0.33cifar10:0.2-instance | Epoch [ 73/ 75] Iter[ 51/1250]	  loss: 0.19cifar10:0.2-instance | Epoch [ 73/ 75] Iter[101/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[151/1250]	  loss: 0.21cifar10:0.2-instance | Epoch [ 73/ 75] Iter[201/1250]	  loss: 0.32cifar10:0.2-instance | Epoch [ 73/ 75] Iter[251/1250]	  loss: 0.20cifar10:0.2-instance | Epoch [ 73/ 75] Iter[301/1250]	  loss: 0.22cifar10:0.2-instance | Epoch [ 73/ 75] Iter[351/1250]	  loss: 0.17cifar10:0.2-instance | Epoch [ 73/ 75] Iter[401/1250]	  loss: 0.17cifar10:0.2-instance | Epoch [ 73/ 75] Iter[451/1250]	  loss: 0.20cifar10:0.2-instance | Epoch [ 73/ 75] Iter[501/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[551/1250]	  loss: 0.18cifar10:0.2-instance | Epoch [ 73/ 75] Iter[601/1250]	  loss: 0.17cifar10:0.2-instance | Epoch [ 73/ 75] Iter[651/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[701/1250]	  loss: 0.17cifar10:0.2-instance | Epoch [ 73/ 75] Iter[751/1250]	  loss: 0.18cifar10:0.2-instance | Epoch [ 73/ 75] Iter[801/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[851/1250]	  loss: 0.23cifar10:0.2-instance | Epoch [ 73/ 75] Iter[901/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[951/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1001/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1051/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1101/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1151/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1201/1250]	  loss: 0.19
| Test Epoch 73	 Accuracy: 91.92% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 74 | Accuracy on train set: 79.41% 
labeled data has a size of 40007, f-score: 0.981203
cifar10:0.2-instance | Epoch [ 74/ 75] Iter[  1/1251]	  loss: 0.19cifar10:0.2-instance | Epoch [ 74/ 75] Iter[ 51/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[101/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[151/1251]	  loss: 0.18cifar10:0.2-instance | Epoch [ 74/ 75] Iter[201/1251]	  loss: 0.19cifar10:0.2-instance | Epoch [ 74/ 75] Iter[251/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[301/1251]	  loss: 0.20cifar10:0.2-instance | Epoch [ 74/ 75] Iter[351/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[401/1251]	  loss: 0.23cifar10:0.2-instance | Epoch [ 74/ 75] Iter[451/1251]	  loss: 0.17cifar10:0.2-instance | Epoch [ 74/ 75] Iter[501/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[551/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[601/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[651/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[701/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[751/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[801/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[851/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[901/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[951/1251]	  loss: 0.17cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1001/1251]	  loss: 0.19cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1051/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1101/1251]	  loss: 0.21cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1151/1251]	  loss: 0.24cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1201/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1251/1251]	  loss: 0.19
| Test Epoch 74	 Accuracy: 91.86% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 75 | Accuracy on train set: 79.54% 
labeled data has a size of 40043, f-score: 0.980821
cifar10:0.2-instance | Epoch [ 75/ 75] Iter[  1/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[ 51/1252]	  loss: 0.18cifar10:0.2-instance | Epoch [ 75/ 75] Iter[101/1252]	  loss: 0.23cifar10:0.2-instance | Epoch [ 75/ 75] Iter[151/1252]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[201/1252]	  loss: 0.24cifar10:0.2-instance | Epoch [ 75/ 75] Iter[251/1252]	  loss: 0.20cifar10:0.2-instance | Epoch [ 75/ 75] Iter[301/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[351/1252]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[401/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[451/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[501/1252]	  loss: 0.14cifar10:0.2-instance | Epoch [ 75/ 75] Iter[551/1252]	  loss: 0.27cifar10:0.2-instance | Epoch [ 75/ 75] Iter[601/1252]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[651/1252]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[701/1252]	  loss: 0.17cifar10:0.2-instance | Epoch [ 75/ 75] Iter[751/1252]	  loss: 0.23cifar10:0.2-instance | Epoch [ 75/ 75] Iter[801/1252]	  loss: 0.17cifar10:0.2-instance | Epoch [ 75/ 75] Iter[851/1252]	  loss: 0.35cifar10:0.2-instance | Epoch [ 75/ 75] Iter[901/1252]	  loss: 0.19cifar10:0.2-instance | Epoch [ 75/ 75] Iter[951/1252]	  loss: 0.18cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1001/1252]	  loss: 0.20cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1051/1252]	  loss: 0.22cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1101/1252]	  loss: 0.20cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1151/1252]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1201/1252]	  loss: 0.39cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1251/1252]	  loss: 0.17
| Test Epoch 75	 Accuracy: 91.61% 



best test Acc:  92.18
