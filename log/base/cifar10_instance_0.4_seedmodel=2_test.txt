Namespace(T=0.2, batch_size=32, data_path='./dataset2/cifar10', dataset='cifar10', fig_7=0, fluctuation_ablation=0, gpuid=0, k=3, lr=0.02, model='resnet18', noise_mode='instance', num_class=10, num_epochs=75, r=0.4, save_sel_sam=0, seed_model=2, seed_noise=1, semi='no', warm_up=10, wdecay=0.0005, without_Lcr=0, without_R=0)
============ Initialize data
============ Actual clean samples number:  30098
============ use resnet18 
============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 0 | Accuracy on train set: 6.42% 
cifar10:0.4-instance | Epoch [  0/ 75] Iter[  1/391]	 CE-loss: 2.4313cifar10:0.4-instance | Epoch [  0/ 75] Iter[ 51/391]	 CE-loss: 2.0253cifar10:0.4-instance | Epoch [  0/ 75] Iter[101/391]	 CE-loss: 2.0359cifar10:0.4-instance | Epoch [  0/ 75] Iter[151/391]	 CE-loss: 2.1167cifar10:0.4-instance | Epoch [  0/ 75] Iter[201/391]	 CE-loss: 1.8652cifar10:0.4-instance | Epoch [  0/ 75] Iter[251/391]	 CE-loss: 1.9296cifar10:0.4-instance | Epoch [  0/ 75] Iter[301/391]	 CE-loss: 1.7167cifar10:0.4-instance | Epoch [  0/ 75] Iter[351/391]	 CE-loss: 1.8208
| Test Epoch 0	 Accuracy: 29.83% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 1 | Accuracy on train set: 29.11% 
cifar10:0.4-instance | Epoch [  1/ 75] Iter[  1/391]	 CE-loss: 1.8098cifar10:0.4-instance | Epoch [  1/ 75] Iter[ 51/391]	 CE-loss: 1.7404cifar10:0.4-instance | Epoch [  1/ 75] Iter[101/391]	 CE-loss: 1.7182cifar10:0.4-instance | Epoch [  1/ 75] Iter[151/391]	 CE-loss: 1.6841cifar10:0.4-instance | Epoch [  1/ 75] Iter[201/391]	 CE-loss: 1.7634cifar10:0.4-instance | Epoch [  1/ 75] Iter[251/391]	 CE-loss: 1.5549cifar10:0.4-instance | Epoch [  1/ 75] Iter[301/391]	 CE-loss: 1.5504cifar10:0.4-instance | Epoch [  1/ 75] Iter[351/391]	 CE-loss: 1.5881
| Test Epoch 1	 Accuracy: 44.47% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 2 | Accuracy on train set: 35.82% 
cifar10:0.4-instance | Epoch [  2/ 75] Iter[  1/391]	 CE-loss: 1.5282cifar10:0.4-instance | Epoch [  2/ 75] Iter[ 51/391]	 CE-loss: 1.6285cifar10:0.4-instance | Epoch [  2/ 75] Iter[101/391]	 CE-loss: 1.5384cifar10:0.4-instance | Epoch [  2/ 75] Iter[151/391]	 CE-loss: 1.6033cifar10:0.4-instance | Epoch [  2/ 75] Iter[201/391]	 CE-loss: 1.6419cifar10:0.4-instance | Epoch [  2/ 75] Iter[251/391]	 CE-loss: 1.4918cifar10:0.4-instance | Epoch [  2/ 75] Iter[301/391]	 CE-loss: 1.4671cifar10:0.4-instance | Epoch [  2/ 75] Iter[351/391]	 CE-loss: 1.5319
| Test Epoch 2	 Accuracy: 53.58% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 3 | Accuracy on train set: 41.25% 
cifar10:0.4-instance | Epoch [  3/ 75] Iter[  1/391]	 CE-loss: 1.3989cifar10:0.4-instance | Epoch [  3/ 75] Iter[ 51/391]	 CE-loss: 1.5503cifar10:0.4-instance | Epoch [  3/ 75] Iter[101/391]	 CE-loss: 1.4793cifar10:0.4-instance | Epoch [  3/ 75] Iter[151/391]	 CE-loss: 1.3700cifar10:0.4-instance | Epoch [  3/ 75] Iter[201/391]	 CE-loss: 1.4624cifar10:0.4-instance | Epoch [  3/ 75] Iter[251/391]	 CE-loss: 1.5227cifar10:0.4-instance | Epoch [  3/ 75] Iter[301/391]	 CE-loss: 1.4530cifar10:0.4-instance | Epoch [  3/ 75] Iter[351/391]	 CE-loss: 1.4185
| Test Epoch 3	 Accuracy: 55.53% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 4 | Accuracy on train set: 42.56% 
cifar10:0.4-instance | Epoch [  4/ 75] Iter[  1/391]	 CE-loss: 1.5993cifar10:0.4-instance | Epoch [  4/ 75] Iter[ 51/391]	 CE-loss: 1.6585cifar10:0.4-instance | Epoch [  4/ 75] Iter[101/391]	 CE-loss: 1.3233cifar10:0.4-instance | Epoch [  4/ 75] Iter[151/391]	 CE-loss: 1.4051cifar10:0.4-instance | Epoch [  4/ 75] Iter[201/391]	 CE-loss: 1.3874cifar10:0.4-instance | Epoch [  4/ 75] Iter[251/391]	 CE-loss: 1.2883cifar10:0.4-instance | Epoch [  4/ 75] Iter[301/391]	 CE-loss: 1.3683cifar10:0.4-instance | Epoch [  4/ 75] Iter[351/391]	 CE-loss: 1.4478
| Test Epoch 4	 Accuracy: 70.83% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 5 | Accuracy on train set: 47.28% 
cifar10:0.4-instance | Epoch [  5/ 75] Iter[  1/391]	 CE-loss: 1.4499cifar10:0.4-instance | Epoch [  5/ 75] Iter[ 51/391]	 CE-loss: 1.3752cifar10:0.4-instance | Epoch [  5/ 75] Iter[101/391]	 CE-loss: 1.4953cifar10:0.4-instance | Epoch [  5/ 75] Iter[151/391]	 CE-loss: 1.4468cifar10:0.4-instance | Epoch [  5/ 75] Iter[201/391]	 CE-loss: 1.3487cifar10:0.4-instance | Epoch [  5/ 75] Iter[251/391]	 CE-loss: 1.4980cifar10:0.4-instance | Epoch [  5/ 75] Iter[301/391]	 CE-loss: 1.4886cifar10:0.4-instance | Epoch [  5/ 75] Iter[351/391]	 CE-loss: 1.3685
| Test Epoch 5	 Accuracy: 68.84% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 6 | Accuracy on train set: 47.38% 
cifar10:0.4-instance | Epoch [  6/ 75] Iter[  1/391]	 CE-loss: 1.4034cifar10:0.4-instance | Epoch [  6/ 75] Iter[ 51/391]	 CE-loss: 1.2110cifar10:0.4-instance | Epoch [  6/ 75] Iter[101/391]	 CE-loss: 1.3336cifar10:0.4-instance | Epoch [  6/ 75] Iter[151/391]	 CE-loss: 1.4548cifar10:0.4-instance | Epoch [  6/ 75] Iter[201/391]	 CE-loss: 1.2091cifar10:0.4-instance | Epoch [  6/ 75] Iter[251/391]	 CE-loss: 1.3490cifar10:0.4-instance | Epoch [  6/ 75] Iter[301/391]	 CE-loss: 1.2822cifar10:0.4-instance | Epoch [  6/ 75] Iter[351/391]	 CE-loss: 1.2925
| Test Epoch 6	 Accuracy: 61.48% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 7 | Accuracy on train set: 46.58% 
cifar10:0.4-instance | Epoch [  7/ 75] Iter[  1/391]	 CE-loss: 1.4083cifar10:0.4-instance | Epoch [  7/ 75] Iter[ 51/391]	 CE-loss: 1.2052cifar10:0.4-instance | Epoch [  7/ 75] Iter[101/391]	 CE-loss: 1.3128cifar10:0.4-instance | Epoch [  7/ 75] Iter[151/391]	 CE-loss: 1.2989cifar10:0.4-instance | Epoch [  7/ 75] Iter[201/391]	 CE-loss: 1.3484cifar10:0.4-instance | Epoch [  7/ 75] Iter[251/391]	 CE-loss: 1.2014cifar10:0.4-instance | Epoch [  7/ 75] Iter[301/391]	 CE-loss: 1.3600cifar10:0.4-instance | Epoch [  7/ 75] Iter[351/391]	 CE-loss: 1.2040
| Test Epoch 7	 Accuracy: 71.82% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 8 | Accuracy on train set: 49.41% 
cifar10:0.4-instance | Epoch [  8/ 75] Iter[  1/391]	 CE-loss: 1.1499cifar10:0.4-instance | Epoch [  8/ 75] Iter[ 51/391]	 CE-loss: 1.1689cifar10:0.4-instance | Epoch [  8/ 75] Iter[101/391]	 CE-loss: 1.1986cifar10:0.4-instance | Epoch [  8/ 75] Iter[151/391]	 CE-loss: 1.1665cifar10:0.4-instance | Epoch [  8/ 75] Iter[201/391]	 CE-loss: 1.4012cifar10:0.4-instance | Epoch [  8/ 75] Iter[251/391]	 CE-loss: 1.2527cifar10:0.4-instance | Epoch [  8/ 75] Iter[301/391]	 CE-loss: 1.2609cifar10:0.4-instance | Epoch [  8/ 75] Iter[351/391]	 CE-loss: 1.1848
| Test Epoch 8	 Accuracy: 70.08% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 9 | Accuracy on train set: 50.40% 
cifar10:0.4-instance | Epoch [  9/ 75] Iter[  1/391]	 CE-loss: 1.1972cifar10:0.4-instance | Epoch [  9/ 75] Iter[ 51/391]	 CE-loss: 1.2496cifar10:0.4-instance | Epoch [  9/ 75] Iter[101/391]	 CE-loss: 1.2100cifar10:0.4-instance | Epoch [  9/ 75] Iter[151/391]	 CE-loss: 1.3423cifar10:0.4-instance | Epoch [  9/ 75] Iter[201/391]	 CE-loss: 1.2269cifar10:0.4-instance | Epoch [  9/ 75] Iter[251/391]	 CE-loss: 1.3822cifar10:0.4-instance | Epoch [  9/ 75] Iter[301/391]	 CE-loss: 1.1263cifar10:0.4-instance | Epoch [  9/ 75] Iter[351/391]	 CE-loss: 1.1541
| Test Epoch 9	 Accuracy: 68.40% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 10 | Accuracy on train set: 49.23% 
labeled data has a size of 33503, f-score: 0.812226
cifar10:0.4-instance | Epoch [ 10/ 75] Iter[  1/1047]	  loss: 0.97cifar10:0.4-instance | Epoch [ 10/ 75] Iter[ 51/1047]	  loss: 0.95cifar10:0.4-instance | Epoch [ 10/ 75] Iter[101/1047]	  loss: 0.79cifar10:0.4-instance | Epoch [ 10/ 75] Iter[151/1047]	  loss: 0.91cifar10:0.4-instance | Epoch [ 10/ 75] Iter[201/1047]	  loss: 1.00cifar10:0.4-instance | Epoch [ 10/ 75] Iter[251/1047]	  loss: 1.07cifar10:0.4-instance | Epoch [ 10/ 75] Iter[301/1047]	  loss: 1.26cifar10:0.4-instance | Epoch [ 10/ 75] Iter[351/1047]	  loss: 0.97cifar10:0.4-instance | Epoch [ 10/ 75] Iter[401/1047]	  loss: 1.25cifar10:0.4-instance | Epoch [ 10/ 75] Iter[451/1047]	  loss: 0.74cifar10:0.4-instance | Epoch [ 10/ 75] Iter[501/1047]	  loss: 0.96cifar10:0.4-instance | Epoch [ 10/ 75] Iter[551/1047]	  loss: 0.93cifar10:0.4-instance | Epoch [ 10/ 75] Iter[601/1047]	  loss: 0.86cifar10:0.4-instance | Epoch [ 10/ 75] Iter[651/1047]	  loss: 0.99cifar10:0.4-instance | Epoch [ 10/ 75] Iter[701/1047]	  loss: 0.69cifar10:0.4-instance | Epoch [ 10/ 75] Iter[751/1047]	  loss: 0.92cifar10:0.4-instance | Epoch [ 10/ 75] Iter[801/1047]	  loss: 1.19cifar10:0.4-instance | Epoch [ 10/ 75] Iter[851/1047]	  loss: 0.89cifar10:0.4-instance | Epoch [ 10/ 75] Iter[901/1047]	  loss: 0.87cifar10:0.4-instance | Epoch [ 10/ 75] Iter[951/1047]	  loss: 0.79cifar10:0.4-instance | Epoch [ 10/ 75] Iter[1001/1047]	  loss: 0.82
| Test Epoch 10	 Accuracy: 71.01% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 11 | Accuracy on train set: 47.15% 
labeled data has a size of 33209, f-score: 0.819718
cifar10:0.4-instance | Epoch [ 11/ 75] Iter[  1/1038]	  loss: 0.90cifar10:0.4-instance | Epoch [ 11/ 75] Iter[ 51/1038]	  loss: 0.77cifar10:0.4-instance | Epoch [ 11/ 75] Iter[101/1038]	  loss: 1.05cifar10:0.4-instance | Epoch [ 11/ 75] Iter[151/1038]	  loss: 0.86cifar10:0.4-instance | Epoch [ 11/ 75] Iter[201/1038]	  loss: 0.78cifar10:0.4-instance | Epoch [ 11/ 75] Iter[251/1038]	  loss: 0.74cifar10:0.4-instance | Epoch [ 11/ 75] Iter[301/1038]	  loss: 0.90cifar10:0.4-instance | Epoch [ 11/ 75] Iter[351/1038]	  loss: 1.13cifar10:0.4-instance | Epoch [ 11/ 75] Iter[401/1038]	  loss: 0.83cifar10:0.4-instance | Epoch [ 11/ 75] Iter[451/1038]	  loss: 1.06cifar10:0.4-instance | Epoch [ 11/ 75] Iter[501/1038]	  loss: 0.97cifar10:0.4-instance | Epoch [ 11/ 75] Iter[551/1038]	  loss: 0.68cifar10:0.4-instance | Epoch [ 11/ 75] Iter[601/1038]	  loss: 1.16cifar10:0.4-instance | Epoch [ 11/ 75] Iter[651/1038]	  loss: 0.84cifar10:0.4-instance | Epoch [ 11/ 75] Iter[701/1038]	  loss: 0.77cifar10:0.4-instance | Epoch [ 11/ 75] Iter[751/1038]	  loss: 0.65cifar10:0.4-instance | Epoch [ 11/ 75] Iter[801/1038]	  loss: 0.68cifar10:0.4-instance | Epoch [ 11/ 75] Iter[851/1038]	  loss: 1.13cifar10:0.4-instance | Epoch [ 11/ 75] Iter[901/1038]	  loss: 0.78cifar10:0.4-instance | Epoch [ 11/ 75] Iter[951/1038]	  loss: 1.01cifar10:0.4-instance | Epoch [ 11/ 75] Iter[1001/1038]	  loss: 0.65
| Test Epoch 11	 Accuracy: 74.44% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 12 | Accuracy on train set: 49.02% 
labeled data has a size of 32313, f-score: 0.843871
cifar10:0.4-instance | Epoch [ 12/ 75] Iter[  1/1010]	  loss: 0.66cifar10:0.4-instance | Epoch [ 12/ 75] Iter[ 51/1010]	  loss: 0.88cifar10:0.4-instance | Epoch [ 12/ 75] Iter[101/1010]	  loss: 0.95cifar10:0.4-instance | Epoch [ 12/ 75] Iter[151/1010]	  loss: 0.82cifar10:0.4-instance | Epoch [ 12/ 75] Iter[201/1010]	  loss: 0.65cifar10:0.4-instance | Epoch [ 12/ 75] Iter[251/1010]	  loss: 0.96cifar10:0.4-instance | Epoch [ 12/ 75] Iter[301/1010]	  loss: 0.69cifar10:0.4-instance | Epoch [ 12/ 75] Iter[351/1010]	  loss: 0.60cifar10:0.4-instance | Epoch [ 12/ 75] Iter[401/1010]	  loss: 0.59cifar10:0.4-instance | Epoch [ 12/ 75] Iter[451/1010]	  loss: 1.09cifar10:0.4-instance | Epoch [ 12/ 75] Iter[501/1010]	  loss: 0.59cifar10:0.4-instance | Epoch [ 12/ 75] Iter[551/1010]	  loss: 1.33cifar10:0.4-instance | Epoch [ 12/ 75] Iter[601/1010]	  loss: 0.77cifar10:0.4-instance | Epoch [ 12/ 75] Iter[651/1010]	  loss: 0.47cifar10:0.4-instance | Epoch [ 12/ 75] Iter[701/1010]	  loss: 0.85cifar10:0.4-instance | Epoch [ 12/ 75] Iter[751/1010]	  loss: 0.72cifar10:0.4-instance | Epoch [ 12/ 75] Iter[801/1010]	  loss: 0.66cifar10:0.4-instance | Epoch [ 12/ 75] Iter[851/1010]	  loss: 0.69cifar10:0.4-instance | Epoch [ 12/ 75] Iter[901/1010]	  loss: 0.62cifar10:0.4-instance | Epoch [ 12/ 75] Iter[951/1010]	  loss: 1.04cifar10:0.4-instance | Epoch [ 12/ 75] Iter[1001/1010]	  loss: 0.67
| Test Epoch 12	 Accuracy: 77.92% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 13 | Accuracy on train set: 50.10% 
labeled data has a size of 30558, f-score: 0.897245
cifar10:0.4-instance | Epoch [ 13/ 75] Iter[  1/955]	  loss: 0.61cifar10:0.4-instance | Epoch [ 13/ 75] Iter[ 51/955]	  loss: 0.82cifar10:0.4-instance | Epoch [ 13/ 75] Iter[101/955]	  loss: 0.83cifar10:0.4-instance | Epoch [ 13/ 75] Iter[151/955]	  loss: 0.77cifar10:0.4-instance | Epoch [ 13/ 75] Iter[201/955]	  loss: 0.64cifar10:0.4-instance | Epoch [ 13/ 75] Iter[251/955]	  loss: 0.57cifar10:0.4-instance | Epoch [ 13/ 75] Iter[301/955]	  loss: 0.64cifar10:0.4-instance | Epoch [ 13/ 75] Iter[351/955]	  loss: 0.49cifar10:0.4-instance | Epoch [ 13/ 75] Iter[401/955]	  loss: 0.55cifar10:0.4-instance | Epoch [ 13/ 75] Iter[451/955]	  loss: 0.48cifar10:0.4-instance | Epoch [ 13/ 75] Iter[501/955]	  loss: 0.96cifar10:0.4-instance | Epoch [ 13/ 75] Iter[551/955]	  loss: 0.52cifar10:0.4-instance | Epoch [ 13/ 75] Iter[601/955]	  loss: 0.47cifar10:0.4-instance | Epoch [ 13/ 75] Iter[651/955]	  loss: 0.53cifar10:0.4-instance | Epoch [ 13/ 75] Iter[701/955]	  loss: 0.47cifar10:0.4-instance | Epoch [ 13/ 75] Iter[751/955]	  loss: 0.67cifar10:0.4-instance | Epoch [ 13/ 75] Iter[801/955]	  loss: 0.46cifar10:0.4-instance | Epoch [ 13/ 75] Iter[851/955]	  loss: 0.62cifar10:0.4-instance | Epoch [ 13/ 75] Iter[901/955]	  loss: 0.93cifar10:0.4-instance | Epoch [ 13/ 75] Iter[951/955]	  loss: 0.73
| Test Epoch 13	 Accuracy: 79.44% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 14 | Accuracy on train set: 51.14% 
labeled data has a size of 29715, f-score: 0.925627
cifar10:0.4-instance | Epoch [ 14/ 75] Iter[  1/929]	  loss: 0.37cifar10:0.4-instance | Epoch [ 14/ 75] Iter[ 51/929]	  loss: 0.37cifar10:0.4-instance | Epoch [ 14/ 75] Iter[101/929]	  loss: 0.92cifar10:0.4-instance | Epoch [ 14/ 75] Iter[151/929]	  loss: 0.64cifar10:0.4-instance | Epoch [ 14/ 75] Iter[201/929]	  loss: 0.65cifar10:0.4-instance | Epoch [ 14/ 75] Iter[251/929]	  loss: 0.63cifar10:0.4-instance | Epoch [ 14/ 75] Iter[301/929]	  loss: 0.48cifar10:0.4-instance | Epoch [ 14/ 75] Iter[351/929]	  loss: 0.61cifar10:0.4-instance | Epoch [ 14/ 75] Iter[401/929]	  loss: 0.82cifar10:0.4-instance | Epoch [ 14/ 75] Iter[451/929]	  loss: 0.59cifar10:0.4-instance | Epoch [ 14/ 75] Iter[501/929]	  loss: 0.50cifar10:0.4-instance | Epoch [ 14/ 75] Iter[551/929]	  loss: 0.59cifar10:0.4-instance | Epoch [ 14/ 75] Iter[601/929]	  loss: 0.54cifar10:0.4-instance | Epoch [ 14/ 75] Iter[651/929]	  loss: 0.63cifar10:0.4-instance | Epoch [ 14/ 75] Iter[701/929]	  loss: 0.37cifar10:0.4-instance | Epoch [ 14/ 75] Iter[751/929]	  loss: 0.65cifar10:0.4-instance | Epoch [ 14/ 75] Iter[801/929]	  loss: 0.52cifar10:0.4-instance | Epoch [ 14/ 75] Iter[851/929]	  loss: 0.50cifar10:0.4-instance | Epoch [ 14/ 75] Iter[901/929]	  loss: 0.79
| Test Epoch 14	 Accuracy: 80.19% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 15 | Accuracy on train set: 51.72% 
labeled data has a size of 29124, f-score: 0.943071
cifar10:0.4-instance | Epoch [ 15/ 75] Iter[  1/911]	  loss: 0.50cifar10:0.4-instance | Epoch [ 15/ 75] Iter[ 51/911]	  loss: 0.90cifar10:0.4-instance | Epoch [ 15/ 75] Iter[101/911]	  loss: 0.54cifar10:0.4-instance | Epoch [ 15/ 75] Iter[151/911]	  loss: 0.48cifar10:0.4-instance | Epoch [ 15/ 75] Iter[201/911]	  loss: 0.45cifar10:0.4-instance | Epoch [ 15/ 75] Iter[251/911]	  loss: 0.54cifar10:0.4-instance | Epoch [ 15/ 75] Iter[301/911]	  loss: 0.49cifar10:0.4-instance | Epoch [ 15/ 75] Iter[351/911]	  loss: 0.80cifar10:0.4-instance | Epoch [ 15/ 75] Iter[401/911]	  loss: 0.39cifar10:0.4-instance | Epoch [ 15/ 75] Iter[451/911]	  loss: 0.48cifar10:0.4-instance | Epoch [ 15/ 75] Iter[501/911]	  loss: 0.31cifar10:0.4-instance | Epoch [ 15/ 75] Iter[551/911]	  loss: 0.57cifar10:0.4-instance | Epoch [ 15/ 75] Iter[601/911]	  loss: 0.65cifar10:0.4-instance | Epoch [ 15/ 75] Iter[651/911]	  loss: 0.46cifar10:0.4-instance | Epoch [ 15/ 75] Iter[701/911]	  loss: 0.52cifar10:0.4-instance | Epoch [ 15/ 75] Iter[751/911]	  loss: 0.38cifar10:0.4-instance | Epoch [ 15/ 75] Iter[801/911]	  loss: 0.62cifar10:0.4-instance | Epoch [ 15/ 75] Iter[851/911]	  loss: 0.33cifar10:0.4-instance | Epoch [ 15/ 75] Iter[901/911]	  loss: 0.30
| Test Epoch 15	 Accuracy: 80.04% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 16 | Accuracy on train set: 51.88% 
labeled data has a size of 29127, f-score: 0.945892
cifar10:0.4-instance | Epoch [ 16/ 75] Iter[  1/911]	  loss: 0.53cifar10:0.4-instance | Epoch [ 16/ 75] Iter[ 51/911]	  loss: 0.49cifar10:0.4-instance | Epoch [ 16/ 75] Iter[101/911]	  loss: 0.32cifar10:0.4-instance | Epoch [ 16/ 75] Iter[151/911]	  loss: 0.61cifar10:0.4-instance | Epoch [ 16/ 75] Iter[201/911]	  loss: 0.40cifar10:0.4-instance | Epoch [ 16/ 75] Iter[251/911]	  loss: 0.37cifar10:0.4-instance | Epoch [ 16/ 75] Iter[301/911]	  loss: 0.77cifar10:0.4-instance | Epoch [ 16/ 75] Iter[351/911]	  loss: 0.62cifar10:0.4-instance | Epoch [ 16/ 75] Iter[401/911]	  loss: 0.55cifar10:0.4-instance | Epoch [ 16/ 75] Iter[451/911]	  loss: 0.59cifar10:0.4-instance | Epoch [ 16/ 75] Iter[501/911]	  loss: 0.46cifar10:0.4-instance | Epoch [ 16/ 75] Iter[551/911]	  loss: 0.80cifar10:0.4-instance | Epoch [ 16/ 75] Iter[601/911]	  loss: 0.44cifar10:0.4-instance | Epoch [ 16/ 75] Iter[651/911]	  loss: 0.40cifar10:0.4-instance | Epoch [ 16/ 75] Iter[701/911]	  loss: 0.73cifar10:0.4-instance | Epoch [ 16/ 75] Iter[751/911]	  loss: 0.46cifar10:0.4-instance | Epoch [ 16/ 75] Iter[801/911]	  loss: 0.57cifar10:0.4-instance | Epoch [ 16/ 75] Iter[851/911]	  loss: 0.58cifar10:0.4-instance | Epoch [ 16/ 75] Iter[901/911]	  loss: 0.54
| Test Epoch 16	 Accuracy: 80.74% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 17 | Accuracy on train set: 52.91% 
labeled data has a size of 29313, f-score: 0.943267
cifar10:0.4-instance | Epoch [ 17/ 75] Iter[  1/917]	  loss: 0.33cifar10:0.4-instance | Epoch [ 17/ 75] Iter[ 51/917]	  loss: 0.88cifar10:0.4-instance | Epoch [ 17/ 75] Iter[101/917]	  loss: 0.48cifar10:0.4-instance | Epoch [ 17/ 75] Iter[151/917]	  loss: 0.49cifar10:0.4-instance | Epoch [ 17/ 75] Iter[201/917]	  loss: 0.42cifar10:0.4-instance | Epoch [ 17/ 75] Iter[251/917]	  loss: 0.52cifar10:0.4-instance | Epoch [ 17/ 75] Iter[301/917]	  loss: 0.53cifar10:0.4-instance | Epoch [ 17/ 75] Iter[351/917]	  loss: 0.52cifar10:0.4-instance | Epoch [ 17/ 75] Iter[401/917]	  loss: 0.48cifar10:0.4-instance | Epoch [ 17/ 75] Iter[451/917]	  loss: 0.58cifar10:0.4-instance | Epoch [ 17/ 75] Iter[501/917]	  loss: 0.52cifar10:0.4-instance | Epoch [ 17/ 75] Iter[551/917]	  loss: 0.48cifar10:0.4-instance | Epoch [ 17/ 75] Iter[601/917]	  loss: 0.34cifar10:0.4-instance | Epoch [ 17/ 75] Iter[651/917]	  loss: 0.48cifar10:0.4-instance | Epoch [ 17/ 75] Iter[701/917]	  loss: 0.50cifar10:0.4-instance | Epoch [ 17/ 75] Iter[751/917]	  loss: 0.69cifar10:0.4-instance | Epoch [ 17/ 75] Iter[801/917]	  loss: 0.80cifar10:0.4-instance | Epoch [ 17/ 75] Iter[851/917]	  loss: 0.53cifar10:0.4-instance | Epoch [ 17/ 75] Iter[901/917]	  loss: 0.43
| Test Epoch 17	 Accuracy: 80.31% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 18 | Accuracy on train set: 52.33% 
labeled data has a size of 29525, f-score: 0.940931
cifar10:0.4-instance | Epoch [ 18/ 75] Iter[  1/923]	  loss: 0.32cifar10:0.4-instance | Epoch [ 18/ 75] Iter[ 51/923]	  loss: 0.44cifar10:0.4-instance | Epoch [ 18/ 75] Iter[101/923]	  loss: 0.47cifar10:0.4-instance | Epoch [ 18/ 75] Iter[151/923]	  loss: 0.57cifar10:0.4-instance | Epoch [ 18/ 75] Iter[201/923]	  loss: 0.37cifar10:0.4-instance | Epoch [ 18/ 75] Iter[251/923]	  loss: 0.40cifar10:0.4-instance | Epoch [ 18/ 75] Iter[301/923]	  loss: 0.56cifar10:0.4-instance | Epoch [ 18/ 75] Iter[351/923]	  loss: 0.45cifar10:0.4-instance | Epoch [ 18/ 75] Iter[401/923]	  loss: 0.62cifar10:0.4-instance | Epoch [ 18/ 75] Iter[451/923]	  loss: 0.84cifar10:0.4-instance | Epoch [ 18/ 75] Iter[501/923]	  loss: 0.48cifar10:0.4-instance | Epoch [ 18/ 75] Iter[551/923]	  loss: 0.40cifar10:0.4-instance | Epoch [ 18/ 75] Iter[601/923]	  loss: 0.51cifar10:0.4-instance | Epoch [ 18/ 75] Iter[651/923]	  loss: 0.64cifar10:0.4-instance | Epoch [ 18/ 75] Iter[701/923]	  loss: 0.35cifar10:0.4-instance | Epoch [ 18/ 75] Iter[751/923]	  loss: 0.49cifar10:0.4-instance | Epoch [ 18/ 75] Iter[801/923]	  loss: 0.58cifar10:0.4-instance | Epoch [ 18/ 75] Iter[851/923]	  loss: 0.64cifar10:0.4-instance | Epoch [ 18/ 75] Iter[901/923]	  loss: 0.42
| Test Epoch 18	 Accuracy: 81.74% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 19 | Accuracy on train set: 53.18% 
labeled data has a size of 29547, f-score: 0.941652
cifar10:0.4-instance | Epoch [ 19/ 75] Iter[  1/924]	  loss: 0.73cifar10:0.4-instance | Epoch [ 19/ 75] Iter[ 51/924]	  loss: 0.48cifar10:0.4-instance | Epoch [ 19/ 75] Iter[101/924]	  loss: 0.68cifar10:0.4-instance | Epoch [ 19/ 75] Iter[151/924]	  loss: 0.55cifar10:0.4-instance | Epoch [ 19/ 75] Iter[201/924]	  loss: 0.52cifar10:0.4-instance | Epoch [ 19/ 75] Iter[251/924]	  loss: 0.56cifar10:0.4-instance | Epoch [ 19/ 75] Iter[301/924]	  loss: 0.43cifar10:0.4-instance | Epoch [ 19/ 75] Iter[351/924]	  loss: 0.44cifar10:0.4-instance | Epoch [ 19/ 75] Iter[401/924]	  loss: 0.56cifar10:0.4-instance | Epoch [ 19/ 75] Iter[451/924]	  loss: 0.52cifar10:0.4-instance | Epoch [ 19/ 75] Iter[501/924]	  loss: 0.54cifar10:0.4-instance | Epoch [ 19/ 75] Iter[551/924]	  loss: 0.54cifar10:0.4-instance | Epoch [ 19/ 75] Iter[601/924]	  loss: 0.42cifar10:0.4-instance | Epoch [ 19/ 75] Iter[651/924]	  loss: 0.64cifar10:0.4-instance | Epoch [ 19/ 75] Iter[701/924]	  loss: 0.32cifar10:0.4-instance | Epoch [ 19/ 75] Iter[751/924]	  loss: 0.56cifar10:0.4-instance | Epoch [ 19/ 75] Iter[801/924]	  loss: 0.36cifar10:0.4-instance | Epoch [ 19/ 75] Iter[851/924]	  loss: 0.39cifar10:0.4-instance | Epoch [ 19/ 75] Iter[901/924]	  loss: 0.60
| Test Epoch 19	 Accuracy: 79.69% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 20 | Accuracy on train set: 52.43% 
labeled data has a size of 29742, f-score: 0.941766
cifar10:0.4-instance | Epoch [ 20/ 75] Iter[  1/930]	  loss: 0.34cifar10:0.4-instance | Epoch [ 20/ 75] Iter[ 51/930]	  loss: 0.30cifar10:0.4-instance | Epoch [ 20/ 75] Iter[101/930]	  loss: 0.35cifar10:0.4-instance | Epoch [ 20/ 75] Iter[151/930]	  loss: 0.72cifar10:0.4-instance | Epoch [ 20/ 75] Iter[201/930]	  loss: 0.39cifar10:0.4-instance | Epoch [ 20/ 75] Iter[251/930]	  loss: 0.47cifar10:0.4-instance | Epoch [ 20/ 75] Iter[301/930]	  loss: 0.35cifar10:0.4-instance | Epoch [ 20/ 75] Iter[351/930]	  loss: 0.53cifar10:0.4-instance | Epoch [ 20/ 75] Iter[401/930]	  loss: 0.47cifar10:0.4-instance | Epoch [ 20/ 75] Iter[451/930]	  loss: 0.76cifar10:0.4-instance | Epoch [ 20/ 75] Iter[501/930]	  loss: 0.35cifar10:0.4-instance | Epoch [ 20/ 75] Iter[551/930]	  loss: 0.71cifar10:0.4-instance | Epoch [ 20/ 75] Iter[601/930]	  loss: 0.45cifar10:0.4-instance | Epoch [ 20/ 75] Iter[651/930]	  loss: 0.42cifar10:0.4-instance | Epoch [ 20/ 75] Iter[701/930]	  loss: 0.42cifar10:0.4-instance | Epoch [ 20/ 75] Iter[751/930]	  loss: 0.40cifar10:0.4-instance | Epoch [ 20/ 75] Iter[801/930]	  loss: 0.41cifar10:0.4-instance | Epoch [ 20/ 75] Iter[851/930]	  loss: 0.67cifar10:0.4-instance | Epoch [ 20/ 75] Iter[901/930]	  loss: 0.68
| Test Epoch 20	 Accuracy: 80.97% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 21 | Accuracy on train set: 52.86% 
labeled data has a size of 29691, f-score: 0.941194
cifar10:0.4-instance | Epoch [ 21/ 75] Iter[  1/928]	  loss: 0.44cifar10:0.4-instance | Epoch [ 21/ 75] Iter[ 51/928]	  loss: 0.49cifar10:0.4-instance | Epoch [ 21/ 75] Iter[101/928]	  loss: 0.57cifar10:0.4-instance | Epoch [ 21/ 75] Iter[151/928]	  loss: 0.30cifar10:0.4-instance | Epoch [ 21/ 75] Iter[201/928]	  loss: 0.53cifar10:0.4-instance | Epoch [ 21/ 75] Iter[251/928]	  loss: 0.56cifar10:0.4-instance | Epoch [ 21/ 75] Iter[301/928]	  loss: 0.40cifar10:0.4-instance | Epoch [ 21/ 75] Iter[351/928]	  loss: 0.60cifar10:0.4-instance | Epoch [ 21/ 75] Iter[401/928]	  loss: 0.73cifar10:0.4-instance | Epoch [ 21/ 75] Iter[451/928]	  loss: 0.50cifar10:0.4-instance | Epoch [ 21/ 75] Iter[501/928]	  loss: 0.53cifar10:0.4-instance | Epoch [ 21/ 75] Iter[551/928]	  loss: 0.34cifar10:0.4-instance | Epoch [ 21/ 75] Iter[601/928]	  loss: 0.70cifar10:0.4-instance | Epoch [ 21/ 75] Iter[651/928]	  loss: 0.37cifar10:0.4-instance | Epoch [ 21/ 75] Iter[701/928]	  loss: 0.65cifar10:0.4-instance | Epoch [ 21/ 75] Iter[751/928]	  loss: 0.50cifar10:0.4-instance | Epoch [ 21/ 75] Iter[801/928]	  loss: 0.64cifar10:0.4-instance | Epoch [ 21/ 75] Iter[851/928]	  loss: 0.43cifar10:0.4-instance | Epoch [ 21/ 75] Iter[901/928]	  loss: 0.43
| Test Epoch 21	 Accuracy: 81.05% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 22 | Accuracy on train set: 53.29% 
labeled data has a size of 29929, f-score: 0.939056
cifar10:0.4-instance | Epoch [ 22/ 75] Iter[  1/936]	  loss: 0.50cifar10:0.4-instance | Epoch [ 22/ 75] Iter[ 51/936]	  loss: 0.71cifar10:0.4-instance | Epoch [ 22/ 75] Iter[101/936]	  loss: 0.63cifar10:0.4-instance | Epoch [ 22/ 75] Iter[151/936]	  loss: 0.59cifar10:0.4-instance | Epoch [ 22/ 75] Iter[201/936]	  loss: 0.40cifar10:0.4-instance | Epoch [ 22/ 75] Iter[251/936]	  loss: 0.45cifar10:0.4-instance | Epoch [ 22/ 75] Iter[301/936]	  loss: 0.43cifar10:0.4-instance | Epoch [ 22/ 75] Iter[351/936]	  loss: 0.48cifar10:0.4-instance | Epoch [ 22/ 75] Iter[401/936]	  loss: 0.49cifar10:0.4-instance | Epoch [ 22/ 75] Iter[451/936]	  loss: 0.59cifar10:0.4-instance | Epoch [ 22/ 75] Iter[501/936]	  loss: 0.41cifar10:0.4-instance | Epoch [ 22/ 75] Iter[551/936]	  loss: 0.56cifar10:0.4-instance | Epoch [ 22/ 75] Iter[601/936]	  loss: 0.68cifar10:0.4-instance | Epoch [ 22/ 75] Iter[651/936]	  loss: 0.41cifar10:0.4-instance | Epoch [ 22/ 75] Iter[701/936]	  loss: 0.59cifar10:0.4-instance | Epoch [ 22/ 75] Iter[751/936]	  loss: 0.40cifar10:0.4-instance | Epoch [ 22/ 75] Iter[801/936]	  loss: 0.62cifar10:0.4-instance | Epoch [ 22/ 75] Iter[851/936]	  loss: 0.45cifar10:0.4-instance | Epoch [ 22/ 75] Iter[901/936]	  loss: 0.76
| Test Epoch 22	 Accuracy: 80.35% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 23 | Accuracy on train set: 52.95% 
labeled data has a size of 29914, f-score: 0.937019
cifar10:0.4-instance | Epoch [ 23/ 75] Iter[  1/935]	  loss: 0.61cifar10:0.4-instance | Epoch [ 23/ 75] Iter[ 51/935]	  loss: 0.31cifar10:0.4-instance | Epoch [ 23/ 75] Iter[101/935]	  loss: 0.47cifar10:0.4-instance | Epoch [ 23/ 75] Iter[151/935]	  loss: 0.24cifar10:0.4-instance | Epoch [ 23/ 75] Iter[201/935]	  loss: 0.33cifar10:0.4-instance | Epoch [ 23/ 75] Iter[251/935]	  loss: 0.54cifar10:0.4-instance | Epoch [ 23/ 75] Iter[301/935]	  loss: 0.45cifar10:0.4-instance | Epoch [ 23/ 75] Iter[351/935]	  loss: 0.55cifar10:0.4-instance | Epoch [ 23/ 75] Iter[401/935]	  loss: 0.43cifar10:0.4-instance | Epoch [ 23/ 75] Iter[451/935]	  loss: 0.41cifar10:0.4-instance | Epoch [ 23/ 75] Iter[501/935]	  loss: 0.61cifar10:0.4-instance | Epoch [ 23/ 75] Iter[551/935]	  loss: 0.57cifar10:0.4-instance | Epoch [ 23/ 75] Iter[601/935]	  loss: 0.54cifar10:0.4-instance | Epoch [ 23/ 75] Iter[651/935]	  loss: 0.58cifar10:0.4-instance | Epoch [ 23/ 75] Iter[701/935]	  loss: 0.50cifar10:0.4-instance | Epoch [ 23/ 75] Iter[751/935]	  loss: 0.69cifar10:0.4-instance | Epoch [ 23/ 75] Iter[801/935]	  loss: 0.48cifar10:0.4-instance | Epoch [ 23/ 75] Iter[851/935]	  loss: 0.89cifar10:0.4-instance | Epoch [ 23/ 75] Iter[901/935]	  loss: 0.46
| Test Epoch 23	 Accuracy: 80.01% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 24 | Accuracy on train set: 52.91% 
labeled data has a size of 30098, f-score: 0.934514
cifar10:0.4-instance | Epoch [ 24/ 75] Iter[  1/941]	  loss: 0.63cifar10:0.4-instance | Epoch [ 24/ 75] Iter[ 51/941]	  loss: 0.36cifar10:0.4-instance | Epoch [ 24/ 75] Iter[101/941]	  loss: 0.73cifar10:0.4-instance | Epoch [ 24/ 75] Iter[151/941]	  loss: 0.55cifar10:0.4-instance | Epoch [ 24/ 75] Iter[201/941]	  loss: 0.53cifar10:0.4-instance | Epoch [ 24/ 75] Iter[251/941]	  loss: 0.57cifar10:0.4-instance | Epoch [ 24/ 75] Iter[301/941]	  loss: 0.45cifar10:0.4-instance | Epoch [ 24/ 75] Iter[351/941]	  loss: 0.50cifar10:0.4-instance | Epoch [ 24/ 75] Iter[401/941]	  loss: 0.66cifar10:0.4-instance | Epoch [ 24/ 75] Iter[451/941]	  loss: 0.38cifar10:0.4-instance | Epoch [ 24/ 75] Iter[501/941]	  loss: 0.57cifar10:0.4-instance | Epoch [ 24/ 75] Iter[551/941]	  loss: 0.82cifar10:0.4-instance | Epoch [ 24/ 75] Iter[601/941]	  loss: 0.47cifar10:0.4-instance | Epoch [ 24/ 75] Iter[651/941]	  loss: 0.53cifar10:0.4-instance | Epoch [ 24/ 75] Iter[701/941]	  loss: 0.41cifar10:0.4-instance | Epoch [ 24/ 75] Iter[751/941]	  loss: 0.31cifar10:0.4-instance | Epoch [ 24/ 75] Iter[801/941]	  loss: 0.61cifar10:0.4-instance | Epoch [ 24/ 75] Iter[851/941]	  loss: 0.62cifar10:0.4-instance | Epoch [ 24/ 75] Iter[901/941]	  loss: 0.52
| Test Epoch 24	 Accuracy: 79.83% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 25 | Accuracy on train set: 53.22% 
labeled data has a size of 29992, f-score: 0.933616
cifar10:0.4-instance | Epoch [ 25/ 75] Iter[  1/938]	  loss: 0.40cifar10:0.4-instance | Epoch [ 25/ 75] Iter[ 51/938]	  loss: 0.62cifar10:0.4-instance | Epoch [ 25/ 75] Iter[101/938]	  loss: 0.55cifar10:0.4-instance | Epoch [ 25/ 75] Iter[151/938]	  loss: 0.41cifar10:0.4-instance | Epoch [ 25/ 75] Iter[201/938]	  loss: 0.67cifar10:0.4-instance | Epoch [ 25/ 75] Iter[251/938]	  loss: 0.46cifar10:0.4-instance | Epoch [ 25/ 75] Iter[301/938]	  loss: 0.51cifar10:0.4-instance | Epoch [ 25/ 75] Iter[351/938]	  loss: 0.57cifar10:0.4-instance | Epoch [ 25/ 75] Iter[401/938]	  loss: 0.26cifar10:0.4-instance | Epoch [ 25/ 75] Iter[451/938]	  loss: 0.36cifar10:0.4-instance | Epoch [ 25/ 75] Iter[501/938]	  loss: 0.34cifar10:0.4-instance | Epoch [ 25/ 75] Iter[551/938]	  loss: 0.75cifar10:0.4-instance | Epoch [ 25/ 75] Iter[601/938]	  loss: 0.54cifar10:0.4-instance | Epoch [ 25/ 75] Iter[651/938]	  loss: 0.48cifar10:0.4-instance | Epoch [ 25/ 75] Iter[701/938]	  loss: 0.50cifar10:0.4-instance | Epoch [ 25/ 75] Iter[751/938]	  loss: 0.50cifar10:0.4-instance | Epoch [ 25/ 75] Iter[801/938]	  loss: 0.36cifar10:0.4-instance | Epoch [ 25/ 75] Iter[851/938]	  loss: 0.64cifar10:0.4-instance | Epoch [ 25/ 75] Iter[901/938]	  loss: 0.73
| Test Epoch 25	 Accuracy: 82.79% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 26 | Accuracy on train set: 54.60% 
labeled data has a size of 30328, f-score: 0.932966
cifar10:0.4-instance | Epoch [ 26/ 75] Iter[  1/948]	  loss: 0.55cifar10:0.4-instance | Epoch [ 26/ 75] Iter[ 51/948]	  loss: 0.48cifar10:0.4-instance | Epoch [ 26/ 75] Iter[101/948]	  loss: 0.54cifar10:0.4-instance | Epoch [ 26/ 75] Iter[151/948]	  loss: 0.52cifar10:0.4-instance | Epoch [ 26/ 75] Iter[201/948]	  loss: 0.51cifar10:0.4-instance | Epoch [ 26/ 75] Iter[251/948]	  loss: 0.39cifar10:0.4-instance | Epoch [ 26/ 75] Iter[301/948]	  loss: 0.44cifar10:0.4-instance | Epoch [ 26/ 75] Iter[351/948]	  loss: 0.35cifar10:0.4-instance | Epoch [ 26/ 75] Iter[401/948]	  loss: 0.46cifar10:0.4-instance | Epoch [ 26/ 75] Iter[451/948]	  loss: 0.37cifar10:0.4-instance | Epoch [ 26/ 75] Iter[501/948]	  loss: 0.57cifar10:0.4-instance | Epoch [ 26/ 75] Iter[551/948]	  loss: 0.77cifar10:0.4-instance | Epoch [ 26/ 75] Iter[601/948]	  loss: 0.48cifar10:0.4-instance | Epoch [ 26/ 75] Iter[651/948]	  loss: 0.98cifar10:0.4-instance | Epoch [ 26/ 75] Iter[701/948]	  loss: 0.47cifar10:0.4-instance | Epoch [ 26/ 75] Iter[751/948]	  loss: 0.77cifar10:0.4-instance | Epoch [ 26/ 75] Iter[801/948]	  loss: 0.31cifar10:0.4-instance | Epoch [ 26/ 75] Iter[851/948]	  loss: 0.32cifar10:0.4-instance | Epoch [ 26/ 75] Iter[901/948]	  loss: 0.82
| Test Epoch 26	 Accuracy: 81.59% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 27 | Accuracy on train set: 53.94% 
labeled data has a size of 30337, f-score: 0.933645
cifar10:0.4-instance | Epoch [ 27/ 75] Iter[  1/949]	  loss: 0.39cifar10:0.4-instance | Epoch [ 27/ 75] Iter[ 51/949]	  loss: 0.64cifar10:0.4-instance | Epoch [ 27/ 75] Iter[101/949]	  loss: 0.44cifar10:0.4-instance | Epoch [ 27/ 75] Iter[151/949]	  loss: 0.44cifar10:0.4-instance | Epoch [ 27/ 75] Iter[201/949]	  loss: 0.38cifar10:0.4-instance | Epoch [ 27/ 75] Iter[251/949]	  loss: 0.62cifar10:0.4-instance | Epoch [ 27/ 75] Iter[301/949]	  loss: 0.46cifar10:0.4-instance | Epoch [ 27/ 75] Iter[351/949]	  loss: 0.56cifar10:0.4-instance | Epoch [ 27/ 75] Iter[401/949]	  loss: 0.84cifar10:0.4-instance | Epoch [ 27/ 75] Iter[451/949]	  loss: 0.43cifar10:0.4-instance | Epoch [ 27/ 75] Iter[501/949]	  loss: 0.52cifar10:0.4-instance | Epoch [ 27/ 75] Iter[551/949]	  loss: 0.33cifar10:0.4-instance | Epoch [ 27/ 75] Iter[601/949]	  loss: 0.61cifar10:0.4-instance | Epoch [ 27/ 75] Iter[651/949]	  loss: 0.39cifar10:0.4-instance | Epoch [ 27/ 75] Iter[701/949]	  loss: 0.63cifar10:0.4-instance | Epoch [ 27/ 75] Iter[751/949]	  loss: 0.51cifar10:0.4-instance | Epoch [ 27/ 75] Iter[801/949]	  loss: 0.48cifar10:0.4-instance | Epoch [ 27/ 75] Iter[851/949]	  loss: 0.39cifar10:0.4-instance | Epoch [ 27/ 75] Iter[901/949]	  loss: 0.74
| Test Epoch 27	 Accuracy: 82.29% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 28 | Accuracy on train set: 54.22% 
labeled data has a size of 30349, f-score: 0.936505
cifar10:0.4-instance | Epoch [ 28/ 75] Iter[  1/949]	  loss: 0.61cifar10:0.4-instance | Epoch [ 28/ 75] Iter[ 51/949]	  loss: 0.41cifar10:0.4-instance | Epoch [ 28/ 75] Iter[101/949]	  loss: 0.37cifar10:0.4-instance | Epoch [ 28/ 75] Iter[151/949]	  loss: 0.49cifar10:0.4-instance | Epoch [ 28/ 75] Iter[201/949]	  loss: 0.41cifar10:0.4-instance | Epoch [ 28/ 75] Iter[251/949]	  loss: 0.65cifar10:0.4-instance | Epoch [ 28/ 75] Iter[301/949]	  loss: 0.45cifar10:0.4-instance | Epoch [ 28/ 75] Iter[351/949]	  loss: 0.42cifar10:0.4-instance | Epoch [ 28/ 75] Iter[401/949]	  loss: 0.65cifar10:0.4-instance | Epoch [ 28/ 75] Iter[451/949]	  loss: 0.51cifar10:0.4-instance | Epoch [ 28/ 75] Iter[501/949]	  loss: 0.42cifar10:0.4-instance | Epoch [ 28/ 75] Iter[551/949]	  loss: 0.66cifar10:0.4-instance | Epoch [ 28/ 75] Iter[601/949]	  loss: 0.24cifar10:0.4-instance | Epoch [ 28/ 75] Iter[651/949]	  loss: 0.54cifar10:0.4-instance | Epoch [ 28/ 75] Iter[701/949]	  loss: 0.68cifar10:0.4-instance | Epoch [ 28/ 75] Iter[751/949]	  loss: 0.42cifar10:0.4-instance | Epoch [ 28/ 75] Iter[801/949]	  loss: 0.41cifar10:0.4-instance | Epoch [ 28/ 75] Iter[851/949]	  loss: 0.36cifar10:0.4-instance | Epoch [ 28/ 75] Iter[901/949]	  loss: 0.50
| Test Epoch 28	 Accuracy: 78.60% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 29 | Accuracy on train set: 52.12% 
labeled data has a size of 30295, f-score: 0.931738
cifar10:0.4-instance | Epoch [ 29/ 75] Iter[  1/947]	  loss: 0.43cifar10:0.4-instance | Epoch [ 29/ 75] Iter[ 51/947]	  loss: 0.44cifar10:0.4-instance | Epoch [ 29/ 75] Iter[101/947]	  loss: 0.41cifar10:0.4-instance | Epoch [ 29/ 75] Iter[151/947]	  loss: 0.54cifar10:0.4-instance | Epoch [ 29/ 75] Iter[201/947]	  loss: 0.60cifar10:0.4-instance | Epoch [ 29/ 75] Iter[251/947]	  loss: 0.38cifar10:0.4-instance | Epoch [ 29/ 75] Iter[301/947]	  loss: 0.32cifar10:0.4-instance | Epoch [ 29/ 75] Iter[351/947]	  loss: 0.53cifar10:0.4-instance | Epoch [ 29/ 75] Iter[401/947]	  loss: 0.33cifar10:0.4-instance | Epoch [ 29/ 75] Iter[451/947]	  loss: 0.37cifar10:0.4-instance | Epoch [ 29/ 75] Iter[501/947]	  loss: 0.72cifar10:0.4-instance | Epoch [ 29/ 75] Iter[551/947]	  loss: 0.43cifar10:0.4-instance | Epoch [ 29/ 75] Iter[601/947]	  loss: 0.84cifar10:0.4-instance | Epoch [ 29/ 75] Iter[651/947]	  loss: 0.50cifar10:0.4-instance | Epoch [ 29/ 75] Iter[701/947]	  loss: 0.53cifar10:0.4-instance | Epoch [ 29/ 75] Iter[751/947]	  loss: 0.44cifar10:0.4-instance | Epoch [ 29/ 75] Iter[801/947]	  loss: 0.37cifar10:0.4-instance | Epoch [ 29/ 75] Iter[851/947]	  loss: 0.32cifar10:0.4-instance | Epoch [ 29/ 75] Iter[901/947]	  loss: 0.78
| Test Epoch 29	 Accuracy: 81.45% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 30 | Accuracy on train set: 54.54% 
labeled data has a size of 30307, f-score: 0.930016
cifar10:0.4-instance | Epoch [ 30/ 75] Iter[  1/948]	  loss: 0.39cifar10:0.4-instance | Epoch [ 30/ 75] Iter[ 51/948]	  loss: 0.64cifar10:0.4-instance | Epoch [ 30/ 75] Iter[101/948]	  loss: 0.50cifar10:0.4-instance | Epoch [ 30/ 75] Iter[151/948]	  loss: 0.50cifar10:0.4-instance | Epoch [ 30/ 75] Iter[201/948]	  loss: 0.44cifar10:0.4-instance | Epoch [ 30/ 75] Iter[251/948]	  loss: 0.46cifar10:0.4-instance | Epoch [ 30/ 75] Iter[301/948]	  loss: 0.74cifar10:0.4-instance | Epoch [ 30/ 75] Iter[351/948]	  loss: 0.44cifar10:0.4-instance | Epoch [ 30/ 75] Iter[401/948]	  loss: 0.23cifar10:0.4-instance | Epoch [ 30/ 75] Iter[451/948]	  loss: 0.26cifar10:0.4-instance | Epoch [ 30/ 75] Iter[501/948]	  loss: 0.56cifar10:0.4-instance | Epoch [ 30/ 75] Iter[551/948]	  loss: 0.39cifar10:0.4-instance | Epoch [ 30/ 75] Iter[601/948]	  loss: 0.41cifar10:0.4-instance | Epoch [ 30/ 75] Iter[651/948]	  loss: 0.66cifar10:0.4-instance | Epoch [ 30/ 75] Iter[701/948]	  loss: 0.38cifar10:0.4-instance | Epoch [ 30/ 75] Iter[751/948]	  loss: 0.46cifar10:0.4-instance | Epoch [ 30/ 75] Iter[801/948]	  loss: 0.62cifar10:0.4-instance | Epoch [ 30/ 75] Iter[851/948]	  loss: 0.37cifar10:0.4-instance | Epoch [ 30/ 75] Iter[901/948]	  loss: 0.75
| Test Epoch 30	 Accuracy: 81.95% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 31 | Accuracy on train set: 53.57% 
labeled data has a size of 30327, f-score: 0.931975
cifar10:0.4-instance | Epoch [ 31/ 75] Iter[  1/948]	  loss: 0.37cifar10:0.4-instance | Epoch [ 31/ 75] Iter[ 51/948]	  loss: 0.72cifar10:0.4-instance | Epoch [ 31/ 75] Iter[101/948]	  loss: 0.35cifar10:0.4-instance | Epoch [ 31/ 75] Iter[151/948]	  loss: 0.52cifar10:0.4-instance | Epoch [ 31/ 75] Iter[201/948]	  loss: 0.33cifar10:0.4-instance | Epoch [ 31/ 75] Iter[251/948]	  loss: 0.45cifar10:0.4-instance | Epoch [ 31/ 75] Iter[301/948]	  loss: 0.42cifar10:0.4-instance | Epoch [ 31/ 75] Iter[351/948]	  loss: 0.32cifar10:0.4-instance | Epoch [ 31/ 75] Iter[401/948]	  loss: 0.41cifar10:0.4-instance | Epoch [ 31/ 75] Iter[451/948]	  loss: 0.58cifar10:0.4-instance | Epoch [ 31/ 75] Iter[501/948]	  loss: 0.40cifar10:0.4-instance | Epoch [ 31/ 75] Iter[551/948]	  loss: 0.41cifar10:0.4-instance | Epoch [ 31/ 75] Iter[601/948]	  loss: 0.33cifar10:0.4-instance | Epoch [ 31/ 75] Iter[651/948]	  loss: 0.55cifar10:0.4-instance | Epoch [ 31/ 75] Iter[701/948]	  loss: 0.34cifar10:0.4-instance | Epoch [ 31/ 75] Iter[751/948]	  loss: 0.48cifar10:0.4-instance | Epoch [ 31/ 75] Iter[801/948]	  loss: 0.48cifar10:0.4-instance | Epoch [ 31/ 75] Iter[851/948]	  loss: 0.55cifar10:0.4-instance | Epoch [ 31/ 75] Iter[901/948]	  loss: 0.82
| Test Epoch 31	 Accuracy: 82.26% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 32 | Accuracy on train set: 54.44% 
labeled data has a size of 30370, f-score: 0.936154
cifar10:0.4-instance | Epoch [ 32/ 75] Iter[  1/950]	  loss: 0.59cifar10:0.4-instance | Epoch [ 32/ 75] Iter[ 51/950]	  loss: 0.34cifar10:0.4-instance | Epoch [ 32/ 75] Iter[101/950]	  loss: 0.40cifar10:0.4-instance | Epoch [ 32/ 75] Iter[151/950]	  loss: 0.53cifar10:0.4-instance | Epoch [ 32/ 75] Iter[201/950]	  loss: 0.63cifar10:0.4-instance | Epoch [ 32/ 75] Iter[251/950]	  loss: 0.48cifar10:0.4-instance | Epoch [ 32/ 75] Iter[301/950]	  loss: 0.47cifar10:0.4-instance | Epoch [ 32/ 75] Iter[351/950]	  loss: 0.51cifar10:0.4-instance | Epoch [ 32/ 75] Iter[401/950]	  loss: 0.50cifar10:0.4-instance | Epoch [ 32/ 75] Iter[451/950]	  loss: 0.36cifar10:0.4-instance | Epoch [ 32/ 75] Iter[501/950]	  loss: 0.61cifar10:0.4-instance | Epoch [ 32/ 75] Iter[551/950]	  loss: 0.38cifar10:0.4-instance | Epoch [ 32/ 75] Iter[601/950]	  loss: 0.26cifar10:0.4-instance | Epoch [ 32/ 75] Iter[651/950]	  loss: 0.47cifar10:0.4-instance | Epoch [ 32/ 75] Iter[701/950]	  loss: 0.56cifar10:0.4-instance | Epoch [ 32/ 75] Iter[751/950]	  loss: 0.77cifar10:0.4-instance | Epoch [ 32/ 75] Iter[801/950]	  loss: 0.50cifar10:0.4-instance | Epoch [ 32/ 75] Iter[851/950]	  loss: 0.36cifar10:0.4-instance | Epoch [ 32/ 75] Iter[901/950]	  loss: 0.55
| Test Epoch 32	 Accuracy: 80.37% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 33 | Accuracy on train set: 53.83% 
labeled data has a size of 30518, f-score: 0.932990
cifar10:0.4-instance | Epoch [ 33/ 75] Iter[  1/954]	  loss: 0.40cifar10:0.4-instance | Epoch [ 33/ 75] Iter[ 51/954]	  loss: 0.68cifar10:0.4-instance | Epoch [ 33/ 75] Iter[101/954]	  loss: 0.55cifar10:0.4-instance | Epoch [ 33/ 75] Iter[151/954]	  loss: 0.64cifar10:0.4-instance | Epoch [ 33/ 75] Iter[201/954]	  loss: 0.41cifar10:0.4-instance | Epoch [ 33/ 75] Iter[251/954]	  loss: 0.62cifar10:0.4-instance | Epoch [ 33/ 75] Iter[301/954]	  loss: 0.50cifar10:0.4-instance | Epoch [ 33/ 75] Iter[351/954]	  loss: 0.74cifar10:0.4-instance | Epoch [ 33/ 75] Iter[401/954]	  loss: 0.53cifar10:0.4-instance | Epoch [ 33/ 75] Iter[451/954]	  loss: 0.47cifar10:0.4-instance | Epoch [ 33/ 75] Iter[501/954]	  loss: 0.60cifar10:0.4-instance | Epoch [ 33/ 75] Iter[551/954]	  loss: 0.32cifar10:0.4-instance | Epoch [ 33/ 75] Iter[601/954]	  loss: 0.63cifar10:0.4-instance | Epoch [ 33/ 75] Iter[651/954]	  loss: 0.73cifar10:0.4-instance | Epoch [ 33/ 75] Iter[701/954]	  loss: 0.49cifar10:0.4-instance | Epoch [ 33/ 75] Iter[751/954]	  loss: 0.46cifar10:0.4-instance | Epoch [ 33/ 75] Iter[801/954]	  loss: 0.53cifar10:0.4-instance | Epoch [ 33/ 75] Iter[851/954]	  loss: 0.34cifar10:0.4-instance | Epoch [ 33/ 75] Iter[901/954]	  loss: 0.47cifar10:0.4-instance | Epoch [ 33/ 75] Iter[951/954]	  loss: 0.50
| Test Epoch 33	 Accuracy: 81.39% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 34 | Accuracy on train set: 54.26% 
labeled data has a size of 30633, f-score: 0.926844
cifar10:0.4-instance | Epoch [ 34/ 75] Iter[  1/958]	  loss: 0.53cifar10:0.4-instance | Epoch [ 34/ 75] Iter[ 51/958]	  loss: 0.28cifar10:0.4-instance | Epoch [ 34/ 75] Iter[101/958]	  loss: 0.59cifar10:0.4-instance | Epoch [ 34/ 75] Iter[151/958]	  loss: 0.52cifar10:0.4-instance | Epoch [ 34/ 75] Iter[201/958]	  loss: 0.54cifar10:0.4-instance | Epoch [ 34/ 75] Iter[251/958]	  loss: 0.60cifar10:0.4-instance | Epoch [ 34/ 75] Iter[301/958]	  loss: 0.35cifar10:0.4-instance | Epoch [ 34/ 75] Iter[351/958]	  loss: 0.51cifar10:0.4-instance | Epoch [ 34/ 75] Iter[401/958]	  loss: 0.49cifar10:0.4-instance | Epoch [ 34/ 75] Iter[451/958]	  loss: 0.74cifar10:0.4-instance | Epoch [ 34/ 75] Iter[501/958]	  loss: 0.39cifar10:0.4-instance | Epoch [ 34/ 75] Iter[551/958]	  loss: 0.42cifar10:0.4-instance | Epoch [ 34/ 75] Iter[601/958]	  loss: 0.59cifar10:0.4-instance | Epoch [ 34/ 75] Iter[651/958]	  loss: 0.41cifar10:0.4-instance | Epoch [ 34/ 75] Iter[701/958]	  loss: 0.83cifar10:0.4-instance | Epoch [ 34/ 75] Iter[751/958]	  loss: 0.73cifar10:0.4-instance | Epoch [ 34/ 75] Iter[801/958]	  loss: 0.36cifar10:0.4-instance | Epoch [ 34/ 75] Iter[851/958]	  loss: 0.48cifar10:0.4-instance | Epoch [ 34/ 75] Iter[901/958]	  loss: 0.55cifar10:0.4-instance | Epoch [ 34/ 75] Iter[951/958]	  loss: 0.62
| Test Epoch 34	 Accuracy: 77.42% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 35 | Accuracy on train set: 51.42% 
labeled data has a size of 30972, f-score: 0.921445
cifar10:0.4-instance | Epoch [ 35/ 75] Iter[  1/968]	  loss: 0.50cifar10:0.4-instance | Epoch [ 35/ 75] Iter[ 51/968]	  loss: 0.46cifar10:0.4-instance | Epoch [ 35/ 75] Iter[101/968]	  loss: 0.69cifar10:0.4-instance | Epoch [ 35/ 75] Iter[151/968]	  loss: 0.54cifar10:0.4-instance | Epoch [ 35/ 75] Iter[201/968]	  loss: 0.38cifar10:0.4-instance | Epoch [ 35/ 75] Iter[251/968]	  loss: 0.43cifar10:0.4-instance | Epoch [ 35/ 75] Iter[301/968]	  loss: 0.63cifar10:0.4-instance | Epoch [ 35/ 75] Iter[351/968]	  loss: 0.45cifar10:0.4-instance | Epoch [ 35/ 75] Iter[401/968]	  loss: 0.54cifar10:0.4-instance | Epoch [ 35/ 75] Iter[451/968]	  loss: 0.63cifar10:0.4-instance | Epoch [ 35/ 75] Iter[501/968]	  loss: 0.50cifar10:0.4-instance | Epoch [ 35/ 75] Iter[551/968]	  loss: 0.50cifar10:0.4-instance | Epoch [ 35/ 75] Iter[601/968]	  loss: 0.49cifar10:0.4-instance | Epoch [ 35/ 75] Iter[651/968]	  loss: 0.43cifar10:0.4-instance | Epoch [ 35/ 75] Iter[701/968]	  loss: 0.35cifar10:0.4-instance | Epoch [ 35/ 75] Iter[751/968]	  loss: 0.35cifar10:0.4-instance | Epoch [ 35/ 75] Iter[801/968]	  loss: 0.54cifar10:0.4-instance | Epoch [ 35/ 75] Iter[851/968]	  loss: 0.47cifar10:0.4-instance | Epoch [ 35/ 75] Iter[901/968]	  loss: 0.70cifar10:0.4-instance | Epoch [ 35/ 75] Iter[951/968]	  loss: 0.80
| Test Epoch 35	 Accuracy: 83.42% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 36 | Accuracy on train set: 55.34% 
labeled data has a size of 30750, f-score: 0.928065
cifar10:0.4-instance | Epoch [ 36/ 75] Iter[  1/961]	  loss: 0.37cifar10:0.4-instance | Epoch [ 36/ 75] Iter[ 51/961]	  loss: 0.52cifar10:0.4-instance | Epoch [ 36/ 75] Iter[101/961]	  loss: 0.41cifar10:0.4-instance | Epoch [ 36/ 75] Iter[151/961]	  loss: 0.45cifar10:0.4-instance | Epoch [ 36/ 75] Iter[201/961]	  loss: 0.58cifar10:0.4-instance | Epoch [ 36/ 75] Iter[251/961]	  loss: 0.49cifar10:0.4-instance | Epoch [ 36/ 75] Iter[301/961]	  loss: 0.48cifar10:0.4-instance | Epoch [ 36/ 75] Iter[351/961]	  loss: 0.37cifar10:0.4-instance | Epoch [ 36/ 75] Iter[401/961]	  loss: 0.55cifar10:0.4-instance | Epoch [ 36/ 75] Iter[451/961]	  loss: 0.65cifar10:0.4-instance | Epoch [ 36/ 75] Iter[501/961]	  loss: 0.62cifar10:0.4-instance | Epoch [ 36/ 75] Iter[551/961]	  loss: 0.44cifar10:0.4-instance | Epoch [ 36/ 75] Iter[601/961]	  loss: 0.32cifar10:0.4-instance | Epoch [ 36/ 75] Iter[651/961]	  loss: 0.52cifar10:0.4-instance | Epoch [ 36/ 75] Iter[701/961]	  loss: 0.38cifar10:0.4-instance | Epoch [ 36/ 75] Iter[751/961]	  loss: 0.58cifar10:0.4-instance | Epoch [ 36/ 75] Iter[801/961]	  loss: 0.41cifar10:0.4-instance | Epoch [ 36/ 75] Iter[851/961]	  loss: 0.31cifar10:0.4-instance | Epoch [ 36/ 75] Iter[901/961]	  loss: 0.53cifar10:0.4-instance | Epoch [ 36/ 75] Iter[951/961]	  loss: 0.65
| Test Epoch 36	 Accuracy: 82.96% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 37 | Accuracy on train set: 55.08% 
labeled data has a size of 30614, f-score: 0.932482
cifar10:0.4-instance | Epoch [ 37/ 75] Iter[  1/957]	  loss: 0.34cifar10:0.4-instance | Epoch [ 37/ 75] Iter[ 51/957]	  loss: 0.41cifar10:0.4-instance | Epoch [ 37/ 75] Iter[101/957]	  loss: 0.57cifar10:0.4-instance | Epoch [ 37/ 75] Iter[151/957]	  loss: 0.45cifar10:0.4-instance | Epoch [ 37/ 75] Iter[201/957]	  loss: 0.33cifar10:0.4-instance | Epoch [ 37/ 75] Iter[251/957]	  loss: 0.38cifar10:0.4-instance | Epoch [ 37/ 75] Iter[301/957]	  loss: 0.64cifar10:0.4-instance | Epoch [ 37/ 75] Iter[351/957]	  loss: 0.58cifar10:0.4-instance | Epoch [ 37/ 75] Iter[401/957]	  loss: 0.44cifar10:0.4-instance | Epoch [ 37/ 75] Iter[451/957]	  loss: 0.39cifar10:0.4-instance | Epoch [ 37/ 75] Iter[501/957]	  loss: 0.39cifar10:0.4-instance | Epoch [ 37/ 75] Iter[551/957]	  loss: 0.53cifar10:0.4-instance | Epoch [ 37/ 75] Iter[601/957]	  loss: 0.40cifar10:0.4-instance | Epoch [ 37/ 75] Iter[651/957]	  loss: 0.34cifar10:0.4-instance | Epoch [ 37/ 75] Iter[701/957]	  loss: 0.57cifar10:0.4-instance | Epoch [ 37/ 75] Iter[751/957]	  loss: 0.44cifar10:0.4-instance | Epoch [ 37/ 75] Iter[801/957]	  loss: 0.39cifar10:0.4-instance | Epoch [ 37/ 75] Iter[851/957]	  loss: 0.71cifar10:0.4-instance | Epoch [ 37/ 75] Iter[901/957]	  loss: 0.63cifar10:0.4-instance | Epoch [ 37/ 75] Iter[951/957]	  loss: 0.54
| Test Epoch 37	 Accuracy: 80.88% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 38 | Accuracy on train set: 54.65% 
labeled data has a size of 30963, f-score: 0.924297
cifar10:0.4-instance | Epoch [ 38/ 75] Iter[  1/968]	  loss: 0.48cifar10:0.4-instance | Epoch [ 38/ 75] Iter[ 51/968]	  loss: 0.29cifar10:0.4-instance | Epoch [ 38/ 75] Iter[101/968]	  loss: 0.33cifar10:0.4-instance | Epoch [ 38/ 75] Iter[151/968]	  loss: 0.54cifar10:0.4-instance | Epoch [ 38/ 75] Iter[201/968]	  loss: 0.67cifar10:0.4-instance | Epoch [ 38/ 75] Iter[251/968]	  loss: 0.25cifar10:0.4-instance | Epoch [ 38/ 75] Iter[301/968]	  loss: 0.55cifar10:0.4-instance | Epoch [ 38/ 75] Iter[351/968]	  loss: 0.42cifar10:0.4-instance | Epoch [ 38/ 75] Iter[401/968]	  loss: 0.71cifar10:0.4-instance | Epoch [ 38/ 75] Iter[451/968]	  loss: 0.23cifar10:0.4-instance | Epoch [ 38/ 75] Iter[501/968]	  loss: 0.41cifar10:0.4-instance | Epoch [ 38/ 75] Iter[551/968]	  loss: 0.60cifar10:0.4-instance | Epoch [ 38/ 75] Iter[601/968]	  loss: 0.74cifar10:0.4-instance | Epoch [ 38/ 75] Iter[651/968]	  loss: 0.30cifar10:0.4-instance | Epoch [ 38/ 75] Iter[701/968]	  loss: 0.51cifar10:0.4-instance | Epoch [ 38/ 75] Iter[751/968]	  loss: 0.58cifar10:0.4-instance | Epoch [ 38/ 75] Iter[801/968]	  loss: 0.65cifar10:0.4-instance | Epoch [ 38/ 75] Iter[851/968]	  loss: 0.33cifar10:0.4-instance | Epoch [ 38/ 75] Iter[901/968]	  loss: 0.52cifar10:0.4-instance | Epoch [ 38/ 75] Iter[951/968]	  loss: 0.49
| Test Epoch 38	 Accuracy: 82.30% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 39 | Accuracy on train set: 54.59% 
labeled data has a size of 30876, f-score: 0.925930
cifar10:0.4-instance | Epoch [ 39/ 75] Iter[  1/965]	  loss: 0.32cifar10:0.4-instance | Epoch [ 39/ 75] Iter[ 51/965]	  loss: 0.53cifar10:0.4-instance | Epoch [ 39/ 75] Iter[101/965]	  loss: 0.42cifar10:0.4-instance | Epoch [ 39/ 75] Iter[151/965]	  loss: 0.31cifar10:0.4-instance | Epoch [ 39/ 75] Iter[201/965]	  loss: 0.54cifar10:0.4-instance | Epoch [ 39/ 75] Iter[251/965]	  loss: 0.57cifar10:0.4-instance | Epoch [ 39/ 75] Iter[301/965]	  loss: 0.50cifar10:0.4-instance | Epoch [ 39/ 75] Iter[351/965]	  loss: 0.59cifar10:0.4-instance | Epoch [ 39/ 75] Iter[401/965]	  loss: 0.55cifar10:0.4-instance | Epoch [ 39/ 75] Iter[451/965]	  loss: 0.42cifar10:0.4-instance | Epoch [ 39/ 75] Iter[501/965]	  loss: 0.42cifar10:0.4-instance | Epoch [ 39/ 75] Iter[551/965]	  loss: 0.49cifar10:0.4-instance | Epoch [ 39/ 75] Iter[601/965]	  loss: 0.54cifar10:0.4-instance | Epoch [ 39/ 75] Iter[651/965]	  loss: 0.53cifar10:0.4-instance | Epoch [ 39/ 75] Iter[701/965]	  loss: 0.52cifar10:0.4-instance | Epoch [ 39/ 75] Iter[751/965]	  loss: 0.53cifar10:0.4-instance | Epoch [ 39/ 75] Iter[801/965]	  loss: 0.45cifar10:0.4-instance | Epoch [ 39/ 75] Iter[851/965]	  loss: 0.34cifar10:0.4-instance | Epoch [ 39/ 75] Iter[901/965]	  loss: 0.84cifar10:0.4-instance | Epoch [ 39/ 75] Iter[951/965]	  loss: 0.76
| Test Epoch 39	 Accuracy: 82.37% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 40 | Accuracy on train set: 54.08% 
labeled data has a size of 30853, f-score: 0.929310
cifar10:0.4-instance | Epoch [ 40/ 75] Iter[  1/965]	  loss: 0.42cifar10:0.4-instance | Epoch [ 40/ 75] Iter[ 51/965]	  loss: 0.46cifar10:0.4-instance | Epoch [ 40/ 75] Iter[101/965]	  loss: 0.49cifar10:0.4-instance | Epoch [ 40/ 75] Iter[151/965]	  loss: 0.65cifar10:0.4-instance | Epoch [ 40/ 75] Iter[201/965]	  loss: 0.41cifar10:0.4-instance | Epoch [ 40/ 75] Iter[251/965]	  loss: 0.47cifar10:0.4-instance | Epoch [ 40/ 75] Iter[301/965]	  loss: 0.79cifar10:0.4-instance | Epoch [ 40/ 75] Iter[351/965]	  loss: 0.50cifar10:0.4-instance | Epoch [ 40/ 75] Iter[401/965]	  loss: 0.50cifar10:0.4-instance | Epoch [ 40/ 75] Iter[451/965]	  loss: 0.66cifar10:0.4-instance | Epoch [ 40/ 75] Iter[501/965]	  loss: 0.76cifar10:0.4-instance | Epoch [ 40/ 75] Iter[551/965]	  loss: 0.51cifar10:0.4-instance | Epoch [ 40/ 75] Iter[601/965]	  loss: 0.26cifar10:0.4-instance | Epoch [ 40/ 75] Iter[651/965]	  loss: 0.43cifar10:0.4-instance | Epoch [ 40/ 75] Iter[701/965]	  loss: 0.49cifar10:0.4-instance | Epoch [ 40/ 75] Iter[751/965]	  loss: 0.44cifar10:0.4-instance | Epoch [ 40/ 75] Iter[801/965]	  loss: 0.46cifar10:0.4-instance | Epoch [ 40/ 75] Iter[851/965]	  loss: 0.54cifar10:0.4-instance | Epoch [ 40/ 75] Iter[901/965]	  loss: 0.50cifar10:0.4-instance | Epoch [ 40/ 75] Iter[951/965]	  loss: 0.41
| Test Epoch 40	 Accuracy: 81.07% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 41 | Accuracy on train set: 54.08% 
labeled data has a size of 30783, f-score: 0.932625
cifar10:0.4-instance | Epoch [ 41/ 75] Iter[  1/962]	  loss: 0.47cifar10:0.4-instance | Epoch [ 41/ 75] Iter[ 51/962]	  loss: 0.36cifar10:0.4-instance | Epoch [ 41/ 75] Iter[101/962]	  loss: 0.29cifar10:0.4-instance | Epoch [ 41/ 75] Iter[151/962]	  loss: 0.37cifar10:0.4-instance | Epoch [ 41/ 75] Iter[201/962]	  loss: 0.63cifar10:0.4-instance | Epoch [ 41/ 75] Iter[251/962]	  loss: 0.57cifar10:0.4-instance | Epoch [ 41/ 75] Iter[301/962]	  loss: 0.50cifar10:0.4-instance | Epoch [ 41/ 75] Iter[351/962]	  loss: 0.38cifar10:0.4-instance | Epoch [ 41/ 75] Iter[401/962]	  loss: 0.59cifar10:0.4-instance | Epoch [ 41/ 75] Iter[451/962]	  loss: 0.29cifar10:0.4-instance | Epoch [ 41/ 75] Iter[501/962]	  loss: 0.41cifar10:0.4-instance | Epoch [ 41/ 75] Iter[551/962]	  loss: 0.37cifar10:0.4-instance | Epoch [ 41/ 75] Iter[601/962]	  loss: 0.45cifar10:0.4-instance | Epoch [ 41/ 75] Iter[651/962]	  loss: 0.39cifar10:0.4-instance | Epoch [ 41/ 75] Iter[701/962]	  loss: 0.54cifar10:0.4-instance | Epoch [ 41/ 75] Iter[751/962]	  loss: 0.70cifar10:0.4-instance | Epoch [ 41/ 75] Iter[801/962]	  loss: 0.67cifar10:0.4-instance | Epoch [ 41/ 75] Iter[851/962]	  loss: 0.41cifar10:0.4-instance | Epoch [ 41/ 75] Iter[901/962]	  loss: 0.34cifar10:0.4-instance | Epoch [ 41/ 75] Iter[951/962]	  loss: 0.77
| Test Epoch 41	 Accuracy: 83.17% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 42 | Accuracy on train set: 55.36% 
labeled data has a size of 30807, f-score: 0.932321
cifar10:0.4-instance | Epoch [ 42/ 75] Iter[  1/963]	  loss: 0.51cifar10:0.4-instance | Epoch [ 42/ 75] Iter[ 51/963]	  loss: 0.62cifar10:0.4-instance | Epoch [ 42/ 75] Iter[101/963]	  loss: 0.49cifar10:0.4-instance | Epoch [ 42/ 75] Iter[151/963]	  loss: 0.62cifar10:0.4-instance | Epoch [ 42/ 75] Iter[201/963]	  loss: 0.62cifar10:0.4-instance | Epoch [ 42/ 75] Iter[251/963]	  loss: 0.42cifar10:0.4-instance | Epoch [ 42/ 75] Iter[301/963]	  loss: 0.37cifar10:0.4-instance | Epoch [ 42/ 75] Iter[351/963]	  loss: 0.51cifar10:0.4-instance | Epoch [ 42/ 75] Iter[401/963]	  loss: 0.37cifar10:0.4-instance | Epoch [ 42/ 75] Iter[451/963]	  loss: 0.39cifar10:0.4-instance | Epoch [ 42/ 75] Iter[501/963]	  loss: 0.38cifar10:0.4-instance | Epoch [ 42/ 75] Iter[551/963]	  loss: 0.34cifar10:0.4-instance | Epoch [ 42/ 75] Iter[601/963]	  loss: 0.53cifar10:0.4-instance | Epoch [ 42/ 75] Iter[651/963]	  loss: 0.39cifar10:0.4-instance | Epoch [ 42/ 75] Iter[701/963]	  loss: 0.36cifar10:0.4-instance | Epoch [ 42/ 75] Iter[751/963]	  loss: 0.31cifar10:0.4-instance | Epoch [ 42/ 75] Iter[801/963]	  loss: 0.40cifar10:0.4-instance | Epoch [ 42/ 75] Iter[851/963]	  loss: 0.29cifar10:0.4-instance | Epoch [ 42/ 75] Iter[901/963]	  loss: 0.45cifar10:0.4-instance | Epoch [ 42/ 75] Iter[951/963]	  loss: 0.38
| Test Epoch 42	 Accuracy: 82.52% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 43 | Accuracy on train set: 55.09% 
labeled data has a size of 30795, f-score: 0.931093
cifar10:0.4-instance | Epoch [ 43/ 75] Iter[  1/963]	  loss: 0.34cifar10:0.4-instance | Epoch [ 43/ 75] Iter[ 51/963]	  loss: 0.26cifar10:0.4-instance | Epoch [ 43/ 75] Iter[101/963]	  loss: 0.49cifar10:0.4-instance | Epoch [ 43/ 75] Iter[151/963]	  loss: 0.39cifar10:0.4-instance | Epoch [ 43/ 75] Iter[201/963]	  loss: 0.44cifar10:0.4-instance | Epoch [ 43/ 75] Iter[251/963]	  loss: 0.33cifar10:0.4-instance | Epoch [ 43/ 75] Iter[301/963]	  loss: 0.43cifar10:0.4-instance | Epoch [ 43/ 75] Iter[351/963]	  loss: 0.36cifar10:0.4-instance | Epoch [ 43/ 75] Iter[401/963]	  loss: 0.59cifar10:0.4-instance | Epoch [ 43/ 75] Iter[451/963]	  loss: 0.47cifar10:0.4-instance | Epoch [ 43/ 75] Iter[501/963]	  loss: 0.72cifar10:0.4-instance | Epoch [ 43/ 75] Iter[551/963]	  loss: 0.70cifar10:0.4-instance | Epoch [ 43/ 75] Iter[601/963]	  loss: 0.35cifar10:0.4-instance | Epoch [ 43/ 75] Iter[651/963]	  loss: 0.37cifar10:0.4-instance | Epoch [ 43/ 75] Iter[701/963]	  loss: 0.39cifar10:0.4-instance | Epoch [ 43/ 75] Iter[751/963]	  loss: 0.40cifar10:0.4-instance | Epoch [ 43/ 75] Iter[801/963]	  loss: 0.55cifar10:0.4-instance | Epoch [ 43/ 75] Iter[851/963]	  loss: 0.71cifar10:0.4-instance | Epoch [ 43/ 75] Iter[901/963]	  loss: 0.69cifar10:0.4-instance | Epoch [ 43/ 75] Iter[951/963]	  loss: 0.62
| Test Epoch 43	 Accuracy: 83.35% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 44 | Accuracy on train set: 55.93% 
labeled data has a size of 30729, f-score: 0.932474
cifar10:0.4-instance | Epoch [ 44/ 75] Iter[  1/961]	  loss: 0.41cifar10:0.4-instance | Epoch [ 44/ 75] Iter[ 51/961]	  loss: 0.58cifar10:0.4-instance | Epoch [ 44/ 75] Iter[101/961]	  loss: 0.31cifar10:0.4-instance | Epoch [ 44/ 75] Iter[151/961]	  loss: 0.60cifar10:0.4-instance | Epoch [ 44/ 75] Iter[201/961]	  loss: 0.61cifar10:0.4-instance | Epoch [ 44/ 75] Iter[251/961]	  loss: 0.70cifar10:0.4-instance | Epoch [ 44/ 75] Iter[301/961]	  loss: 0.54cifar10:0.4-instance | Epoch [ 44/ 75] Iter[351/961]	  loss: 0.57cifar10:0.4-instance | Epoch [ 44/ 75] Iter[401/961]	  loss: 0.58cifar10:0.4-instance | Epoch [ 44/ 75] Iter[451/961]	  loss: 0.38cifar10:0.4-instance | Epoch [ 44/ 75] Iter[501/961]	  loss: 0.42cifar10:0.4-instance | Epoch [ 44/ 75] Iter[551/961]	  loss: 0.44cifar10:0.4-instance | Epoch [ 44/ 75] Iter[601/961]	  loss: 0.45cifar10:0.4-instance | Epoch [ 44/ 75] Iter[651/961]	  loss: 0.70cifar10:0.4-instance | Epoch [ 44/ 75] Iter[701/961]	  loss: 0.49cifar10:0.4-instance | Epoch [ 44/ 75] Iter[751/961]	  loss: 0.40cifar10:0.4-instance | Epoch [ 44/ 75] Iter[801/961]	  loss: 0.46cifar10:0.4-instance | Epoch [ 44/ 75] Iter[851/961]	  loss: 0.53cifar10:0.4-instance | Epoch [ 44/ 75] Iter[901/961]	  loss: 0.47cifar10:0.4-instance | Epoch [ 44/ 75] Iter[951/961]	  loss: 0.29
| Test Epoch 44	 Accuracy: 83.04% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 45 | Accuracy on train set: 55.30% 
labeled data has a size of 30757, f-score: 0.932601
cifar10:0.4-instance | Epoch [ 45/ 75] Iter[  1/962]	  loss: 0.26cifar10:0.4-instance | Epoch [ 45/ 75] Iter[ 51/962]	  loss: 0.35cifar10:0.4-instance | Epoch [ 45/ 75] Iter[101/962]	  loss: 0.56cifar10:0.4-instance | Epoch [ 45/ 75] Iter[151/962]	  loss: 0.39cifar10:0.4-instance | Epoch [ 45/ 75] Iter[201/962]	  loss: 0.31cifar10:0.4-instance | Epoch [ 45/ 75] Iter[251/962]	  loss: 0.42cifar10:0.4-instance | Epoch [ 45/ 75] Iter[301/962]	  loss: 0.42cifar10:0.4-instance | Epoch [ 45/ 75] Iter[351/962]	  loss: 0.25cifar10:0.4-instance | Epoch [ 45/ 75] Iter[401/962]	  loss: 0.39cifar10:0.4-instance | Epoch [ 45/ 75] Iter[451/962]	  loss: 0.49cifar10:0.4-instance | Epoch [ 45/ 75] Iter[501/962]	  loss: 0.57cifar10:0.4-instance | Epoch [ 45/ 75] Iter[551/962]	  loss: 0.63cifar10:0.4-instance | Epoch [ 45/ 75] Iter[601/962]	  loss: 0.37cifar10:0.4-instance | Epoch [ 45/ 75] Iter[651/962]	  loss: 0.39cifar10:0.4-instance | Epoch [ 45/ 75] Iter[701/962]	  loss: 0.46cifar10:0.4-instance | Epoch [ 45/ 75] Iter[751/962]	  loss: 0.67cifar10:0.4-instance | Epoch [ 45/ 75] Iter[801/962]	  loss: 0.75cifar10:0.4-instance | Epoch [ 45/ 75] Iter[851/962]	  loss: 0.46cifar10:0.4-instance | Epoch [ 45/ 75] Iter[901/962]	  loss: 0.36cifar10:0.4-instance | Epoch [ 45/ 75] Iter[951/962]	  loss: 0.42
| Test Epoch 45	 Accuracy: 83.56% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 46 | Accuracy on train set: 55.69% 
labeled data has a size of 30766, f-score: 0.934928
cifar10:0.4-instance | Epoch [ 46/ 75] Iter[  1/962]	  loss: 0.42cifar10:0.4-instance | Epoch [ 46/ 75] Iter[ 51/962]	  loss: 0.24cifar10:0.4-instance | Epoch [ 46/ 75] Iter[101/962]	  loss: 0.43cifar10:0.4-instance | Epoch [ 46/ 75] Iter[151/962]	  loss: 0.58cifar10:0.4-instance | Epoch [ 46/ 75] Iter[201/962]	  loss: 0.54cifar10:0.4-instance | Epoch [ 46/ 75] Iter[251/962]	  loss: 0.63cifar10:0.4-instance | Epoch [ 46/ 75] Iter[301/962]	  loss: 0.52cifar10:0.4-instance | Epoch [ 46/ 75] Iter[351/962]	  loss: 0.76cifar10:0.4-instance | Epoch [ 46/ 75] Iter[401/962]	  loss: 0.62cifar10:0.4-instance | Epoch [ 46/ 75] Iter[451/962]	  loss: 0.35cifar10:0.4-instance | Epoch [ 46/ 75] Iter[501/962]	  loss: 0.39cifar10:0.4-instance | Epoch [ 46/ 75] Iter[551/962]	  loss: 0.33cifar10:0.4-instance | Epoch [ 46/ 75] Iter[601/962]	  loss: 0.37cifar10:0.4-instance | Epoch [ 46/ 75] Iter[651/962]	  loss: 0.33cifar10:0.4-instance | Epoch [ 46/ 75] Iter[701/962]	  loss: 0.71cifar10:0.4-instance | Epoch [ 46/ 75] Iter[751/962]	  loss: 0.46cifar10:0.4-instance | Epoch [ 46/ 75] Iter[801/962]	  loss: 0.32cifar10:0.4-instance | Epoch [ 46/ 75] Iter[851/962]	  loss: 0.60cifar10:0.4-instance | Epoch [ 46/ 75] Iter[901/962]	  loss: 0.48cifar10:0.4-instance | Epoch [ 46/ 75] Iter[951/962]	  loss: 0.31
| Test Epoch 46	 Accuracy: 83.33% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 47 | Accuracy on train set: 55.43% 
labeled data has a size of 30763, f-score: 0.936092
cifar10:0.4-instance | Epoch [ 47/ 75] Iter[  1/962]	  loss: 0.35cifar10:0.4-instance | Epoch [ 47/ 75] Iter[ 51/962]	  loss: 0.35cifar10:0.4-instance | Epoch [ 47/ 75] Iter[101/962]	  loss: 0.37cifar10:0.4-instance | Epoch [ 47/ 75] Iter[151/962]	  loss: 0.26cifar10:0.4-instance | Epoch [ 47/ 75] Iter[201/962]	  loss: 0.57cifar10:0.4-instance | Epoch [ 47/ 75] Iter[251/962]	  loss: 0.49cifar10:0.4-instance | Epoch [ 47/ 75] Iter[301/962]	  loss: 0.39cifar10:0.4-instance | Epoch [ 47/ 75] Iter[351/962]	  loss: 0.41cifar10:0.4-instance | Epoch [ 47/ 75] Iter[401/962]	  loss: 0.47cifar10:0.4-instance | Epoch [ 47/ 75] Iter[451/962]	  loss: 0.48cifar10:0.4-instance | Epoch [ 47/ 75] Iter[501/962]	  loss: 0.35cifar10:0.4-instance | Epoch [ 47/ 75] Iter[551/962]	  loss: 0.28cifar10:0.4-instance | Epoch [ 47/ 75] Iter[601/962]	  loss: 0.42cifar10:0.4-instance | Epoch [ 47/ 75] Iter[651/962]	  loss: 0.62cifar10:0.4-instance | Epoch [ 47/ 75] Iter[701/962]	  loss: 0.52cifar10:0.4-instance | Epoch [ 47/ 75] Iter[751/962]	  loss: 0.38cifar10:0.4-instance | Epoch [ 47/ 75] Iter[801/962]	  loss: 0.43cifar10:0.4-instance | Epoch [ 47/ 75] Iter[851/962]	  loss: 0.34cifar10:0.4-instance | Epoch [ 47/ 75] Iter[901/962]	  loss: 0.36cifar10:0.4-instance | Epoch [ 47/ 75] Iter[951/962]	  loss: 0.55
| Test Epoch 47	 Accuracy: 83.19% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 48 | Accuracy on train set: 55.33% 
labeled data has a size of 30654, f-score: 0.937496
cifar10:0.4-instance | Epoch [ 48/ 75] Iter[  1/958]	  loss: 0.59cifar10:0.4-instance | Epoch [ 48/ 75] Iter[ 51/958]	  loss: 0.28cifar10:0.4-instance | Epoch [ 48/ 75] Iter[101/958]	  loss: 0.33cifar10:0.4-instance | Epoch [ 48/ 75] Iter[151/958]	  loss: 0.31cifar10:0.4-instance | Epoch [ 48/ 75] Iter[201/958]	  loss: 0.35cifar10:0.4-instance | Epoch [ 48/ 75] Iter[251/958]	  loss: 0.75cifar10:0.4-instance | Epoch [ 48/ 75] Iter[301/958]	  loss: 0.42cifar10:0.4-instance | Epoch [ 48/ 75] Iter[351/958]	  loss: 0.30cifar10:0.4-instance | Epoch [ 48/ 75] Iter[401/958]	  loss: 0.50cifar10:0.4-instance | Epoch [ 48/ 75] Iter[451/958]	  loss: 0.41cifar10:0.4-instance | Epoch [ 48/ 75] Iter[501/958]	  loss: 0.35cifar10:0.4-instance | Epoch [ 48/ 75] Iter[551/958]	  loss: 0.43cifar10:0.4-instance | Epoch [ 48/ 75] Iter[601/958]	  loss: 0.49cifar10:0.4-instance | Epoch [ 48/ 75] Iter[651/958]	  loss: 0.39cifar10:0.4-instance | Epoch [ 48/ 75] Iter[701/958]	  loss: 0.39cifar10:0.4-instance | Epoch [ 48/ 75] Iter[751/958]	  loss: 0.29cifar10:0.4-instance | Epoch [ 48/ 75] Iter[801/958]	  loss: 0.41cifar10:0.4-instance | Epoch [ 48/ 75] Iter[851/958]	  loss: 0.52cifar10:0.4-instance | Epoch [ 48/ 75] Iter[901/958]	  loss: 0.65cifar10:0.4-instance | Epoch [ 48/ 75] Iter[951/958]	  loss: 0.62
| Test Epoch 48	 Accuracy: 83.03% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 49 | Accuracy on train set: 55.53% 
labeled data has a size of 30792, f-score: 0.934821
cifar10:0.4-instance | Epoch [ 49/ 75] Iter[  1/963]	  loss: 0.41cifar10:0.4-instance | Epoch [ 49/ 75] Iter[ 51/963]	  loss: 0.41cifar10:0.4-instance | Epoch [ 49/ 75] Iter[101/963]	  loss: 0.55cifar10:0.4-instance | Epoch [ 49/ 75] Iter[151/963]	  loss: 0.51cifar10:0.4-instance | Epoch [ 49/ 75] Iter[201/963]	  loss: 0.52cifar10:0.4-instance | Epoch [ 49/ 75] Iter[251/963]	  loss: 0.66cifar10:0.4-instance | Epoch [ 49/ 75] Iter[301/963]	  loss: 0.48cifar10:0.4-instance | Epoch [ 49/ 75] Iter[351/963]	  loss: 0.66cifar10:0.4-instance | Epoch [ 49/ 75] Iter[401/963]	  loss: 0.40cifar10:0.4-instance | Epoch [ 49/ 75] Iter[451/963]	  loss: 0.63cifar10:0.4-instance | Epoch [ 49/ 75] Iter[501/963]	  loss: 0.60cifar10:0.4-instance | Epoch [ 49/ 75] Iter[551/963]	  loss: 0.58cifar10:0.4-instance | Epoch [ 49/ 75] Iter[601/963]	  loss: 0.60cifar10:0.4-instance | Epoch [ 49/ 75] Iter[651/963]	  loss: 0.69cifar10:0.4-instance | Epoch [ 49/ 75] Iter[701/963]	  loss: 0.48cifar10:0.4-instance | Epoch [ 49/ 75] Iter[751/963]	  loss: 0.44cifar10:0.4-instance | Epoch [ 49/ 75] Iter[801/963]	  loss: 0.59cifar10:0.4-instance | Epoch [ 49/ 75] Iter[851/963]	  loss: 0.36cifar10:0.4-instance | Epoch [ 49/ 75] Iter[901/963]	  loss: 0.57cifar10:0.4-instance | Epoch [ 49/ 75] Iter[951/963]	  loss: 0.62
| Test Epoch 49	 Accuracy: 80.51% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 50 | Accuracy on train set: 54.48% 
labeled data has a size of 30903, f-score: 0.928777
cifar10:0.4-instance | Epoch [ 50/ 75] Iter[  1/966]	  loss: 0.56cifar10:0.4-instance | Epoch [ 50/ 75] Iter[ 51/966]	  loss: 0.27cifar10:0.4-instance | Epoch [ 50/ 75] Iter[101/966]	  loss: 0.81cifar10:0.4-instance | Epoch [ 50/ 75] Iter[151/966]	  loss: 0.35cifar10:0.4-instance | Epoch [ 50/ 75] Iter[201/966]	  loss: 0.63cifar10:0.4-instance | Epoch [ 50/ 75] Iter[251/966]	  loss: 0.56cifar10:0.4-instance | Epoch [ 50/ 75] Iter[301/966]	  loss: 0.52cifar10:0.4-instance | Epoch [ 50/ 75] Iter[351/966]	  loss: 0.30cifar10:0.4-instance | Epoch [ 50/ 75] Iter[401/966]	  loss: 0.36cifar10:0.4-instance | Epoch [ 50/ 75] Iter[451/966]	  loss: 0.43cifar10:0.4-instance | Epoch [ 50/ 75] Iter[501/966]	  loss: 0.53cifar10:0.4-instance | Epoch [ 50/ 75] Iter[551/966]	  loss: 0.48cifar10:0.4-instance | Epoch [ 50/ 75] Iter[601/966]	  loss: 0.49cifar10:0.4-instance | Epoch [ 50/ 75] Iter[651/966]	  loss: 0.66cifar10:0.4-instance | Epoch [ 50/ 75] Iter[701/966]	  loss: 0.49cifar10:0.4-instance | Epoch [ 50/ 75] Iter[751/966]	  loss: 0.46cifar10:0.4-instance | Epoch [ 50/ 75] Iter[801/966]	  loss: 0.50cifar10:0.4-instance | Epoch [ 50/ 75] Iter[851/966]	  loss: 0.61cifar10:0.4-instance | Epoch [ 50/ 75] Iter[901/966]	  loss: 0.65cifar10:0.4-instance | Epoch [ 50/ 75] Iter[951/966]	  loss: 0.62
| Test Epoch 50	 Accuracy: 83.22% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 51 | Accuracy on train set: 55.27% 
labeled data has a size of 30921, f-score: 0.929789
cifar10:0.4-instance | Epoch [ 51/ 75] Iter[  1/967]	  loss: 0.60cifar10:0.4-instance | Epoch [ 51/ 75] Iter[ 51/967]	  loss: 0.48cifar10:0.4-instance | Epoch [ 51/ 75] Iter[101/967]	  loss: 0.36cifar10:0.4-instance | Epoch [ 51/ 75] Iter[151/967]	  loss: 0.46cifar10:0.4-instance | Epoch [ 51/ 75] Iter[201/967]	  loss: 0.44cifar10:0.4-instance | Epoch [ 51/ 75] Iter[251/967]	  loss: 0.60cifar10:0.4-instance | Epoch [ 51/ 75] Iter[301/967]	  loss: 0.36cifar10:0.4-instance | Epoch [ 51/ 75] Iter[351/967]	  loss: 0.72cifar10:0.4-instance | Epoch [ 51/ 75] Iter[401/967]	  loss: 0.38cifar10:0.4-instance | Epoch [ 51/ 75] Iter[451/967]	  loss: 0.51cifar10:0.4-instance | Epoch [ 51/ 75] Iter[501/967]	  loss: 0.52cifar10:0.4-instance | Epoch [ 51/ 75] Iter[551/967]	  loss: 0.36cifar10:0.4-instance | Epoch [ 51/ 75] Iter[601/967]	  loss: 0.53cifar10:0.4-instance | Epoch [ 51/ 75] Iter[651/967]	  loss: 0.51cifar10:0.4-instance | Epoch [ 51/ 75] Iter[701/967]	  loss: 0.50cifar10:0.4-instance | Epoch [ 51/ 75] Iter[751/967]	  loss: 0.29cifar10:0.4-instance | Epoch [ 51/ 75] Iter[801/967]	  loss: 0.56cifar10:0.4-instance | Epoch [ 51/ 75] Iter[851/967]	  loss: 0.46cifar10:0.4-instance | Epoch [ 51/ 75] Iter[901/967]	  loss: 0.52cifar10:0.4-instance | Epoch [ 51/ 75] Iter[951/967]	  loss: 0.30
| Test Epoch 51	 Accuracy: 82.57% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 52 | Accuracy on train set: 55.30% 
labeled data has a size of 31006, f-score: 0.929046
cifar10:0.4-instance | Epoch [ 52/ 75] Iter[  1/969]	  loss: 0.46cifar10:0.4-instance | Epoch [ 52/ 75] Iter[ 51/969]	  loss: 0.39cifar10:0.4-instance | Epoch [ 52/ 75] Iter[101/969]	  loss: 0.52cifar10:0.4-instance | Epoch [ 52/ 75] Iter[151/969]	  loss: 0.39cifar10:0.4-instance | Epoch [ 52/ 75] Iter[201/969]	  loss: 0.39cifar10:0.4-instance | Epoch [ 52/ 75] Iter[251/969]	  loss: 0.61cifar10:0.4-instance | Epoch [ 52/ 75] Iter[301/969]	  loss: 0.41cifar10:0.4-instance | Epoch [ 52/ 75] Iter[351/969]	  loss: 0.69cifar10:0.4-instance | Epoch [ 52/ 75] Iter[401/969]	  loss: 0.52cifar10:0.4-instance | Epoch [ 52/ 75] Iter[451/969]	  loss: 0.52cifar10:0.4-instance | Epoch [ 52/ 75] Iter[501/969]	  loss: 0.55cifar10:0.4-instance | Epoch [ 52/ 75] Iter[551/969]	  loss: 0.35cifar10:0.4-instance | Epoch [ 52/ 75] Iter[601/969]	  loss: 0.45cifar10:0.4-instance | Epoch [ 52/ 75] Iter[651/969]	  loss: 0.65cifar10:0.4-instance | Epoch [ 52/ 75] Iter[701/969]	  loss: 1.06cifar10:0.4-instance | Epoch [ 52/ 75] Iter[751/969]	  loss: 0.32cifar10:0.4-instance | Epoch [ 52/ 75] Iter[801/969]	  loss: 0.51cifar10:0.4-instance | Epoch [ 52/ 75] Iter[851/969]	  loss: 0.64cifar10:0.4-instance | Epoch [ 52/ 75] Iter[901/969]	  loss: 0.39cifar10:0.4-instance | Epoch [ 52/ 75] Iter[951/969]	  loss: 0.57
| Test Epoch 52	 Accuracy: 79.72% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 53 | Accuracy on train set: 53.07% 
labeled data has a size of 30809, f-score: 0.936447
cifar10:0.4-instance | Epoch [ 53/ 75] Iter[  1/963]	  loss: 0.46cifar10:0.4-instance | Epoch [ 53/ 75] Iter[ 51/963]	  loss: 0.63cifar10:0.4-instance | Epoch [ 53/ 75] Iter[101/963]	  loss: 0.36cifar10:0.4-instance | Epoch [ 53/ 75] Iter[151/963]	  loss: 0.61cifar10:0.4-instance | Epoch [ 53/ 75] Iter[201/963]	  loss: 0.38cifar10:0.4-instance | Epoch [ 53/ 75] Iter[251/963]	  loss: 0.88cifar10:0.4-instance | Epoch [ 53/ 75] Iter[301/963]	  loss: 0.40cifar10:0.4-instance | Epoch [ 53/ 75] Iter[351/963]	  loss: 0.47cifar10:0.4-instance | Epoch [ 53/ 75] Iter[401/963]	  loss: 0.27cifar10:0.4-instance | Epoch [ 53/ 75] Iter[451/963]	  loss: 0.43cifar10:0.4-instance | Epoch [ 53/ 75] Iter[501/963]	  loss: 0.84cifar10:0.4-instance | Epoch [ 53/ 75] Iter[551/963]	  loss: 0.45cifar10:0.4-instance | Epoch [ 53/ 75] Iter[601/963]	  loss: 0.59cifar10:0.4-instance | Epoch [ 53/ 75] Iter[651/963]	  loss: 0.55cifar10:0.4-instance | Epoch [ 53/ 75] Iter[701/963]	  loss: 0.40cifar10:0.4-instance | Epoch [ 53/ 75] Iter[751/963]	  loss: 0.36cifar10:0.4-instance | Epoch [ 53/ 75] Iter[801/963]	  loss: 0.73cifar10:0.4-instance | Epoch [ 53/ 75] Iter[851/963]	  loss: 0.29cifar10:0.4-instance | Epoch [ 53/ 75] Iter[901/963]	  loss: 0.38cifar10:0.4-instance | Epoch [ 53/ 75] Iter[951/963]	  loss: 0.42
| Test Epoch 53	 Accuracy: 84.70% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 54 | Accuracy on train set: 56.19% 
labeled data has a size of 30855, f-score: 0.938324
cifar10:0.4-instance | Epoch [ 54/ 75] Iter[  1/965]	  loss: 0.35cifar10:0.4-instance | Epoch [ 54/ 75] Iter[ 51/965]	  loss: 0.38cifar10:0.4-instance | Epoch [ 54/ 75] Iter[101/965]	  loss: 0.39cifar10:0.4-instance | Epoch [ 54/ 75] Iter[151/965]	  loss: 0.39cifar10:0.4-instance | Epoch [ 54/ 75] Iter[201/965]	  loss: 0.26cifar10:0.4-instance | Epoch [ 54/ 75] Iter[251/965]	  loss: 0.40cifar10:0.4-instance | Epoch [ 54/ 75] Iter[301/965]	  loss: 0.78cifar10:0.4-instance | Epoch [ 54/ 75] Iter[351/965]	  loss: 0.58cifar10:0.4-instance | Epoch [ 54/ 75] Iter[401/965]	  loss: 0.45cifar10:0.4-instance | Epoch [ 54/ 75] Iter[451/965]	  loss: 0.62cifar10:0.4-instance | Epoch [ 54/ 75] Iter[501/965]	  loss: 0.74cifar10:0.4-instance | Epoch [ 54/ 75] Iter[551/965]	  loss: 0.42cifar10:0.4-instance | Epoch [ 54/ 75] Iter[601/965]	  loss: 0.73cifar10:0.4-instance | Epoch [ 54/ 75] Iter[651/965]	  loss: 0.61cifar10:0.4-instance | Epoch [ 54/ 75] Iter[701/965]	  loss: 0.53cifar10:0.4-instance | Epoch [ 54/ 75] Iter[751/965]	  loss: 0.57cifar10:0.4-instance | Epoch [ 54/ 75] Iter[801/965]	  loss: 0.41cifar10:0.4-instance | Epoch [ 54/ 75] Iter[851/965]	  loss: 0.60cifar10:0.4-instance | Epoch [ 54/ 75] Iter[901/965]	  loss: 0.62cifar10:0.4-instance | Epoch [ 54/ 75] Iter[951/965]	  loss: 0.44
| Test Epoch 54	 Accuracy: 84.23% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 55 | Accuracy on train set: 55.91% 
labeled data has a size of 30819, f-score: 0.939648
cifar10:0.4-instance | Epoch [ 55/ 75] Iter[  1/964]	  loss: 0.54cifar10:0.4-instance | Epoch [ 55/ 75] Iter[ 51/964]	  loss: 0.67cifar10:0.4-instance | Epoch [ 55/ 75] Iter[101/964]	  loss: 0.65cifar10:0.4-instance | Epoch [ 55/ 75] Iter[151/964]	  loss: 0.53cifar10:0.4-instance | Epoch [ 55/ 75] Iter[201/964]	  loss: 0.41cifar10:0.4-instance | Epoch [ 55/ 75] Iter[251/964]	  loss: 0.29cifar10:0.4-instance | Epoch [ 55/ 75] Iter[301/964]	  loss: 0.32cifar10:0.4-instance | Epoch [ 55/ 75] Iter[351/964]	  loss: 0.46cifar10:0.4-instance | Epoch [ 55/ 75] Iter[401/964]	  loss: 0.57cifar10:0.4-instance | Epoch [ 55/ 75] Iter[451/964]	  loss: 0.38cifar10:0.4-instance | Epoch [ 55/ 75] Iter[501/964]	  loss: 0.37cifar10:0.4-instance | Epoch [ 55/ 75] Iter[551/964]	  loss: 0.36cifar10:0.4-instance | Epoch [ 55/ 75] Iter[601/964]	  loss: 0.37cifar10:0.4-instance | Epoch [ 55/ 75] Iter[651/964]	  loss: 0.36cifar10:0.4-instance | Epoch [ 55/ 75] Iter[701/964]	  loss: 0.32cifar10:0.4-instance | Epoch [ 55/ 75] Iter[751/964]	  loss: 0.38cifar10:0.4-instance | Epoch [ 55/ 75] Iter[801/964]	  loss: 0.47cifar10:0.4-instance | Epoch [ 55/ 75] Iter[851/964]	  loss: 0.39cifar10:0.4-instance | Epoch [ 55/ 75] Iter[901/964]	  loss: 0.29cifar10:0.4-instance | Epoch [ 55/ 75] Iter[951/964]	  loss: 0.69
| Test Epoch 55	 Accuracy: 82.61% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 56 | Accuracy on train set: 54.93% 
labeled data has a size of 30797, f-score: 0.938695
cifar10:0.4-instance | Epoch [ 56/ 75] Iter[  1/963]	  loss: 0.38cifar10:0.4-instance | Epoch [ 56/ 75] Iter[ 51/963]	  loss: 0.42cifar10:0.4-instance | Epoch [ 56/ 75] Iter[101/963]	  loss: 0.62cifar10:0.4-instance | Epoch [ 56/ 75] Iter[151/963]	  loss: 0.54cifar10:0.4-instance | Epoch [ 56/ 75] Iter[201/963]	  loss: 0.25cifar10:0.4-instance | Epoch [ 56/ 75] Iter[251/963]	  loss: 0.40cifar10:0.4-instance | Epoch [ 56/ 75] Iter[301/963]	  loss: 0.44cifar10:0.4-instance | Epoch [ 56/ 75] Iter[351/963]	  loss: 0.31cifar10:0.4-instance | Epoch [ 56/ 75] Iter[401/963]	  loss: 0.38cifar10:0.4-instance | Epoch [ 56/ 75] Iter[451/963]	  loss: 0.56cifar10:0.4-instance | Epoch [ 56/ 75] Iter[501/963]	  loss: 0.62cifar10:0.4-instance | Epoch [ 56/ 75] Iter[551/963]	  loss: 0.31cifar10:0.4-instance | Epoch [ 56/ 75] Iter[601/963]	  loss: 0.51cifar10:0.4-instance | Epoch [ 56/ 75] Iter[651/963]	  loss: 0.45cifar10:0.4-instance | Epoch [ 56/ 75] Iter[701/963]	  loss: 0.67cifar10:0.4-instance | Epoch [ 56/ 75] Iter[751/963]	  loss: 0.60cifar10:0.4-instance | Epoch [ 56/ 75] Iter[801/963]	  loss: 0.36cifar10:0.4-instance | Epoch [ 56/ 75] Iter[851/963]	  loss: 0.63cifar10:0.4-instance | Epoch [ 56/ 75] Iter[901/963]	  loss: 0.38cifar10:0.4-instance | Epoch [ 56/ 75] Iter[951/963]	  loss: 0.37
| Test Epoch 56	 Accuracy: 83.29% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 57 | Accuracy on train set: 55.29% 
labeled data has a size of 30914, f-score: 0.936889
cifar10:0.4-instance | Epoch [ 57/ 75] Iter[  1/967]	  loss: 0.32cifar10:0.4-instance | Epoch [ 57/ 75] Iter[ 51/967]	  loss: 0.43cifar10:0.4-instance | Epoch [ 57/ 75] Iter[101/967]	  loss: 0.63cifar10:0.4-instance | Epoch [ 57/ 75] Iter[151/967]	  loss: 0.68cifar10:0.4-instance | Epoch [ 57/ 75] Iter[201/967]	  loss: 0.63cifar10:0.4-instance | Epoch [ 57/ 75] Iter[251/967]	  loss: 0.62cifar10:0.4-instance | Epoch [ 57/ 75] Iter[301/967]	  loss: 0.33cifar10:0.4-instance | Epoch [ 57/ 75] Iter[351/967]	  loss: 0.58cifar10:0.4-instance | Epoch [ 57/ 75] Iter[401/967]	  loss: 0.36cifar10:0.4-instance | Epoch [ 57/ 75] Iter[451/967]	  loss: 0.53cifar10:0.4-instance | Epoch [ 57/ 75] Iter[501/967]	  loss: 0.32cifar10:0.4-instance | Epoch [ 57/ 75] Iter[551/967]	  loss: 0.71cifar10:0.4-instance | Epoch [ 57/ 75] Iter[601/967]	  loss: 0.37cifar10:0.4-instance | Epoch [ 57/ 75] Iter[651/967]	  loss: 0.49cifar10:0.4-instance | Epoch [ 57/ 75] Iter[701/967]	  loss: 0.56cifar10:0.4-instance | Epoch [ 57/ 75] Iter[751/967]	  loss: 0.40cifar10:0.4-instance | Epoch [ 57/ 75] Iter[801/967]	  loss: 0.75cifar10:0.4-instance | Epoch [ 57/ 75] Iter[851/967]	  loss: 0.40cifar10:0.4-instance | Epoch [ 57/ 75] Iter[901/967]	  loss: 0.82cifar10:0.4-instance | Epoch [ 57/ 75] Iter[951/967]	  loss: 0.47
| Test Epoch 57	 Accuracy: 83.60% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 58 | Accuracy on train set: 55.16% 
labeled data has a size of 30761, f-score: 0.940542
cifar10:0.4-instance | Epoch [ 58/ 75] Iter[  1/962]	  loss: 0.35cifar10:0.4-instance | Epoch [ 58/ 75] Iter[ 51/962]	  loss: 0.86cifar10:0.4-instance | Epoch [ 58/ 75] Iter[101/962]	  loss: 0.42cifar10:0.4-instance | Epoch [ 58/ 75] Iter[151/962]	  loss: 0.55cifar10:0.4-instance | Epoch [ 58/ 75] Iter[201/962]	  loss: 0.54cifar10:0.4-instance | Epoch [ 58/ 75] Iter[251/962]	  loss: 0.45cifar10:0.4-instance | Epoch [ 58/ 75] Iter[301/962]	  loss: 0.35cifar10:0.4-instance | Epoch [ 58/ 75] Iter[351/962]	  loss: 0.63cifar10:0.4-instance | Epoch [ 58/ 75] Iter[401/962]	  loss: 0.44cifar10:0.4-instance | Epoch [ 58/ 75] Iter[451/962]	  loss: 0.92cifar10:0.4-instance | Epoch [ 58/ 75] Iter[501/962]	  loss: 0.46cifar10:0.4-instance | Epoch [ 58/ 75] Iter[551/962]	  loss: 0.35cifar10:0.4-instance | Epoch [ 58/ 75] Iter[601/962]	  loss: 0.76cifar10:0.4-instance | Epoch [ 58/ 75] Iter[651/962]	  loss: 0.45cifar10:0.4-instance | Epoch [ 58/ 75] Iter[701/962]	  loss: 0.53cifar10:0.4-instance | Epoch [ 58/ 75] Iter[751/962]	  loss: 0.47cifar10:0.4-instance | Epoch [ 58/ 75] Iter[801/962]	  loss: 0.55cifar10:0.4-instance | Epoch [ 58/ 75] Iter[851/962]	  loss: 0.38cifar10:0.4-instance | Epoch [ 58/ 75] Iter[901/962]	  loss: 0.37cifar10:0.4-instance | Epoch [ 58/ 75] Iter[951/962]	  loss: 0.23
| Test Epoch 58	 Accuracy: 82.70% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 59 | Accuracy on train set: 54.93% 
labeled data has a size of 30658, f-score: 0.944289
cifar10:0.4-instance | Epoch [ 59/ 75] Iter[  1/959]	  loss: 0.33cifar10:0.4-instance | Epoch [ 59/ 75] Iter[ 51/959]	  loss: 0.33cifar10:0.4-instance | Epoch [ 59/ 75] Iter[101/959]	  loss: 0.95cifar10:0.4-instance | Epoch [ 59/ 75] Iter[151/959]	  loss: 0.27cifar10:0.4-instance | Epoch [ 59/ 75] Iter[201/959]	  loss: 0.49cifar10:0.4-instance | Epoch [ 59/ 75] Iter[251/959]	  loss: 0.48cifar10:0.4-instance | Epoch [ 59/ 75] Iter[301/959]	  loss: 0.32cifar10:0.4-instance | Epoch [ 59/ 75] Iter[351/959]	  loss: 0.50cifar10:0.4-instance | Epoch [ 59/ 75] Iter[401/959]	  loss: 0.26cifar10:0.4-instance | Epoch [ 59/ 75] Iter[451/959]	  loss: 0.54cifar10:0.4-instance | Epoch [ 59/ 75] Iter[501/959]	  loss: 0.43cifar10:0.4-instance | Epoch [ 59/ 75] Iter[551/959]	  loss: 0.40cifar10:0.4-instance | Epoch [ 59/ 75] Iter[601/959]	  loss: 0.46cifar10:0.4-instance | Epoch [ 59/ 75] Iter[651/959]	  loss: 0.32cifar10:0.4-instance | Epoch [ 59/ 75] Iter[701/959]	  loss: 0.34cifar10:0.4-instance | Epoch [ 59/ 75] Iter[751/959]	  loss: 0.79cifar10:0.4-instance | Epoch [ 59/ 75] Iter[801/959]	  loss: 0.77cifar10:0.4-instance | Epoch [ 59/ 75] Iter[851/959]	  loss: 0.35cifar10:0.4-instance | Epoch [ 59/ 75] Iter[901/959]	  loss: 0.42cifar10:0.4-instance | Epoch [ 59/ 75] Iter[951/959]	  loss: 0.80
| Test Epoch 59	 Accuracy: 84.42% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 60 | Accuracy on train set: 56.14% 
labeled data has a size of 30676, f-score: 0.943506
cifar10:0.4-instance | Epoch [ 60/ 75] Iter[  1/959]	  loss: 0.53cifar10:0.4-instance | Epoch [ 60/ 75] Iter[ 51/959]	  loss: 0.33cifar10:0.4-instance | Epoch [ 60/ 75] Iter[101/959]	  loss: 0.29cifar10:0.4-instance | Epoch [ 60/ 75] Iter[151/959]	  loss: 0.44cifar10:0.4-instance | Epoch [ 60/ 75] Iter[201/959]	  loss: 0.44cifar10:0.4-instance | Epoch [ 60/ 75] Iter[251/959]	  loss: 0.22cifar10:0.4-instance | Epoch [ 60/ 75] Iter[301/959]	  loss: 0.59cifar10:0.4-instance | Epoch [ 60/ 75] Iter[351/959]	  loss: 0.40cifar10:0.4-instance | Epoch [ 60/ 75] Iter[401/959]	  loss: 0.38cifar10:0.4-instance | Epoch [ 60/ 75] Iter[451/959]	  loss: 0.48cifar10:0.4-instance | Epoch [ 60/ 75] Iter[501/959]	  loss: 0.46cifar10:0.4-instance | Epoch [ 60/ 75] Iter[551/959]	  loss: 0.26cifar10:0.4-instance | Epoch [ 60/ 75] Iter[601/959]	  loss: 0.40cifar10:0.4-instance | Epoch [ 60/ 75] Iter[651/959]	  loss: 0.24cifar10:0.4-instance | Epoch [ 60/ 75] Iter[701/959]	  loss: 0.19cifar10:0.4-instance | Epoch [ 60/ 75] Iter[751/959]	  loss: 0.29cifar10:0.4-instance | Epoch [ 60/ 75] Iter[801/959]	  loss: 0.20cifar10:0.4-instance | Epoch [ 60/ 75] Iter[851/959]	  loss: 0.40cifar10:0.4-instance | Epoch [ 60/ 75] Iter[901/959]	  loss: 0.30cifar10:0.4-instance | Epoch [ 60/ 75] Iter[951/959]	  loss: 0.33
| Test Epoch 60	 Accuracy: 88.63% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 61 | Accuracy on train set: 59.33% 
labeled data has a size of 30775, f-score: 0.944468
cifar10:0.4-instance | Epoch [ 61/ 75] Iter[  1/962]	  loss: 0.22cifar10:0.4-instance | Epoch [ 61/ 75] Iter[ 51/962]	  loss: 0.24cifar10:0.4-instance | Epoch [ 61/ 75] Iter[101/962]	  loss: 0.39cifar10:0.4-instance | Epoch [ 61/ 75] Iter[151/962]	  loss: 0.20cifar10:0.4-instance | Epoch [ 61/ 75] Iter[201/962]	  loss: 0.26cifar10:0.4-instance | Epoch [ 61/ 75] Iter[251/962]	  loss: 0.36cifar10:0.4-instance | Epoch [ 61/ 75] Iter[301/962]	  loss: 0.42cifar10:0.4-instance | Epoch [ 61/ 75] Iter[351/962]	  loss: 0.37cifar10:0.4-instance | Epoch [ 61/ 75] Iter[401/962]	  loss: 0.26cifar10:0.4-instance | Epoch [ 61/ 75] Iter[451/962]	  loss: 0.18cifar10:0.4-instance | Epoch [ 61/ 75] Iter[501/962]	  loss: 0.28cifar10:0.4-instance | Epoch [ 61/ 75] Iter[551/962]	  loss: 0.28cifar10:0.4-instance | Epoch [ 61/ 75] Iter[601/962]	  loss: 0.21cifar10:0.4-instance | Epoch [ 61/ 75] Iter[651/962]	  loss: 0.28cifar10:0.4-instance | Epoch [ 61/ 75] Iter[701/962]	  loss: 0.54cifar10:0.4-instance | Epoch [ 61/ 75] Iter[751/962]	  loss: 0.57cifar10:0.4-instance | Epoch [ 61/ 75] Iter[801/962]	  loss: 0.33cifar10:0.4-instance | Epoch [ 61/ 75] Iter[851/962]	  loss: 0.26cifar10:0.4-instance | Epoch [ 61/ 75] Iter[901/962]	  loss: 0.35cifar10:0.4-instance | Epoch [ 61/ 75] Iter[951/962]	  loss: 0.26
| Test Epoch 61	 Accuracy: 89.00% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 62 | Accuracy on train set: 59.93% 
labeled data has a size of 30827, f-score: 0.945243
cifar10:0.4-instance | Epoch [ 62/ 75] Iter[  1/964]	  loss: 0.46cifar10:0.4-instance | Epoch [ 62/ 75] Iter[ 51/964]	  loss: 0.32cifar10:0.4-instance | Epoch [ 62/ 75] Iter[101/964]	  loss: 0.36cifar10:0.4-instance | Epoch [ 62/ 75] Iter[151/964]	  loss: 0.23cifar10:0.4-instance | Epoch [ 62/ 75] Iter[201/964]	  loss: 0.27cifar10:0.4-instance | Epoch [ 62/ 75] Iter[251/964]	  loss: 0.19cifar10:0.4-instance | Epoch [ 62/ 75] Iter[301/964]	  loss: 0.27cifar10:0.4-instance | Epoch [ 62/ 75] Iter[351/964]	  loss: 0.29cifar10:0.4-instance | Epoch [ 62/ 75] Iter[401/964]	  loss: 0.23cifar10:0.4-instance | Epoch [ 62/ 75] Iter[451/964]	  loss: 0.22cifar10:0.4-instance | Epoch [ 62/ 75] Iter[501/964]	  loss: 0.16cifar10:0.4-instance | Epoch [ 62/ 75] Iter[551/964]	  loss: 0.26cifar10:0.4-instance | Epoch [ 62/ 75] Iter[601/964]	  loss: 0.20cifar10:0.4-instance | Epoch [ 62/ 75] Iter[651/964]	  loss: 0.19cifar10:0.4-instance | Epoch [ 62/ 75] Iter[701/964]	  loss: 0.19cifar10:0.4-instance | Epoch [ 62/ 75] Iter[751/964]	  loss: 0.29cifar10:0.4-instance | Epoch [ 62/ 75] Iter[801/964]	  loss: 0.16cifar10:0.4-instance | Epoch [ 62/ 75] Iter[851/964]	  loss: 0.28cifar10:0.4-instance | Epoch [ 62/ 75] Iter[901/964]	  loss: 0.27cifar10:0.4-instance | Epoch [ 62/ 75] Iter[951/964]	  loss: 0.29
| Test Epoch 62	 Accuracy: 89.06% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 63 | Accuracy on train set: 60.19% 
labeled data has a size of 30861, f-score: 0.945660
cifar10:0.4-instance | Epoch [ 63/ 75] Iter[  1/965]	  loss: 0.29cifar10:0.4-instance | Epoch [ 63/ 75] Iter[ 51/965]	  loss: 0.23cifar10:0.4-instance | Epoch [ 63/ 75] Iter[101/965]	  loss: 0.24cifar10:0.4-instance | Epoch [ 63/ 75] Iter[151/965]	  loss: 0.39cifar10:0.4-instance | Epoch [ 63/ 75] Iter[201/965]	  loss: 0.29cifar10:0.4-instance | Epoch [ 63/ 75] Iter[251/965]	  loss: 0.27cifar10:0.4-instance | Epoch [ 63/ 75] Iter[301/965]	  loss: 0.17cifar10:0.4-instance | Epoch [ 63/ 75] Iter[351/965]	  loss: 0.26cifar10:0.4-instance | Epoch [ 63/ 75] Iter[401/965]	  loss: 0.31cifar10:0.4-instance | Epoch [ 63/ 75] Iter[451/965]	  loss: 0.20cifar10:0.4-instance | Epoch [ 63/ 75] Iter[501/965]	  loss: 0.28cifar10:0.4-instance | Epoch [ 63/ 75] Iter[551/965]	  loss: 0.27cifar10:0.4-instance | Epoch [ 63/ 75] Iter[601/965]	  loss: 0.36cifar10:0.4-instance | Epoch [ 63/ 75] Iter[651/965]	  loss: 0.32cifar10:0.4-instance | Epoch [ 63/ 75] Iter[701/965]	  loss: 0.31cifar10:0.4-instance | Epoch [ 63/ 75] Iter[751/965]	  loss: 0.26cifar10:0.4-instance | Epoch [ 63/ 75] Iter[801/965]	  loss: 0.15cifar10:0.4-instance | Epoch [ 63/ 75] Iter[851/965]	  loss: 0.35cifar10:0.4-instance | Epoch [ 63/ 75] Iter[901/965]	  loss: 0.31cifar10:0.4-instance | Epoch [ 63/ 75] Iter[951/965]	  loss: 0.21
| Test Epoch 63	 Accuracy: 89.02% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 64 | Accuracy on train set: 60.49% 
labeled data has a size of 30977, f-score: 0.943636
cifar10:0.4-instance | Epoch [ 64/ 75] Iter[  1/969]	  loss: 0.26cifar10:0.4-instance | Epoch [ 64/ 75] Iter[ 51/969]	  loss: 0.19cifar10:0.4-instance | Epoch [ 64/ 75] Iter[101/969]	  loss: 0.18cifar10:0.4-instance | Epoch [ 64/ 75] Iter[151/969]	  loss: 0.28cifar10:0.4-instance | Epoch [ 64/ 75] Iter[201/969]	  loss: 0.26cifar10:0.4-instance | Epoch [ 64/ 75] Iter[251/969]	  loss: 0.28cifar10:0.4-instance | Epoch [ 64/ 75] Iter[301/969]	  loss: 0.25cifar10:0.4-instance | Epoch [ 64/ 75] Iter[351/969]	  loss: 0.25cifar10:0.4-instance | Epoch [ 64/ 75] Iter[401/969]	  loss: 0.23cifar10:0.4-instance | Epoch [ 64/ 75] Iter[451/969]	  loss: 0.35cifar10:0.4-instance | Epoch [ 64/ 75] Iter[501/969]	  loss: 0.25cifar10:0.4-instance | Epoch [ 64/ 75] Iter[551/969]	  loss: 0.21cifar10:0.4-instance | Epoch [ 64/ 75] Iter[601/969]	  loss: 0.45cifar10:0.4-instance | Epoch [ 64/ 75] Iter[651/969]	  loss: 0.24cifar10:0.4-instance | Epoch [ 64/ 75] Iter[701/969]	  loss: 0.24cifar10:0.4-instance | Epoch [ 64/ 75] Iter[751/969]	  loss: 0.16cifar10:0.4-instance | Epoch [ 64/ 75] Iter[801/969]	  loss: 0.17cifar10:0.4-instance | Epoch [ 64/ 75] Iter[851/969]	  loss: 0.28cifar10:0.4-instance | Epoch [ 64/ 75] Iter[901/969]	  loss: 0.24cifar10:0.4-instance | Epoch [ 64/ 75] Iter[951/969]	  loss: 0.41
| Test Epoch 64	 Accuracy: 88.95% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 65 | Accuracy on train set: 60.60% 
labeled data has a size of 31069, f-score: 0.942483
cifar10:0.4-instance | Epoch [ 65/ 75] Iter[  1/971]	  loss: 0.22cifar10:0.4-instance | Epoch [ 65/ 75] Iter[ 51/971]	  loss: 0.22cifar10:0.4-instance | Epoch [ 65/ 75] Iter[101/971]	  loss: 0.28cifar10:0.4-instance | Epoch [ 65/ 75] Iter[151/971]	  loss: 0.16cifar10:0.4-instance | Epoch [ 65/ 75] Iter[201/971]	  loss: 0.27cifar10:0.4-instance | Epoch [ 65/ 75] Iter[251/971]	  loss: 0.24cifar10:0.4-instance | Epoch [ 65/ 75] Iter[301/971]	  loss: 0.32cifar10:0.4-instance | Epoch [ 65/ 75] Iter[351/971]	  loss: 0.31cifar10:0.4-instance | Epoch [ 65/ 75] Iter[401/971]	  loss: 0.43cifar10:0.4-instance | Epoch [ 65/ 75] Iter[451/971]	  loss: 0.30cifar10:0.4-instance | Epoch [ 65/ 75] Iter[501/971]	  loss: 0.23cifar10:0.4-instance | Epoch [ 65/ 75] Iter[551/971]	  loss: 0.19cifar10:0.4-instance | Epoch [ 65/ 75] Iter[601/971]	  loss: 0.22cifar10:0.4-instance | Epoch [ 65/ 75] Iter[651/971]	  loss: 0.27cifar10:0.4-instance | Epoch [ 65/ 75] Iter[701/971]	  loss: 0.23cifar10:0.4-instance | Epoch [ 65/ 75] Iter[751/971]	  loss: 0.21cifar10:0.4-instance | Epoch [ 65/ 75] Iter[801/971]	  loss: 0.17cifar10:0.4-instance | Epoch [ 65/ 75] Iter[851/971]	  loss: 0.19cifar10:0.4-instance | Epoch [ 65/ 75] Iter[901/971]	  loss: 0.22cifar10:0.4-instance | Epoch [ 65/ 75] Iter[951/971]	  loss: 0.34
| Test Epoch 65	 Accuracy: 89.68% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 66 | Accuracy on train set: 60.96% 
labeled data has a size of 31149, f-score: 0.941732
cifar10:0.4-instance | Epoch [ 66/ 75] Iter[  1/974]	  loss: 0.24cifar10:0.4-instance | Epoch [ 66/ 75] Iter[ 51/974]	  loss: 0.17cifar10:0.4-instance | Epoch [ 66/ 75] Iter[101/974]	  loss: 0.27cifar10:0.4-instance | Epoch [ 66/ 75] Iter[151/974]	  loss: 0.24cifar10:0.4-instance | Epoch [ 66/ 75] Iter[201/974]	  loss: 0.24cifar10:0.4-instance | Epoch [ 66/ 75] Iter[251/974]	  loss: 0.37cifar10:0.4-instance | Epoch [ 66/ 75] Iter[301/974]	  loss: 0.18cifar10:0.4-instance | Epoch [ 66/ 75] Iter[351/974]	  loss: 0.18cifar10:0.4-instance | Epoch [ 66/ 75] Iter[401/974]	  loss: 0.17cifar10:0.4-instance | Epoch [ 66/ 75] Iter[451/974]	  loss: 0.27cifar10:0.4-instance | Epoch [ 66/ 75] Iter[501/974]	  loss: 0.28cifar10:0.4-instance | Epoch [ 66/ 75] Iter[551/974]	  loss: 0.23cifar10:0.4-instance | Epoch [ 66/ 75] Iter[601/974]	  loss: 0.21cifar10:0.4-instance | Epoch [ 66/ 75] Iter[651/974]	  loss: 0.21cifar10:0.4-instance | Epoch [ 66/ 75] Iter[701/974]	  loss: 0.20cifar10:0.4-instance | Epoch [ 66/ 75] Iter[751/974]	  loss: 0.18cifar10:0.4-instance | Epoch [ 66/ 75] Iter[801/974]	  loss: 0.27cifar10:0.4-instance | Epoch [ 66/ 75] Iter[851/974]	  loss: 0.15cifar10:0.4-instance | Epoch [ 66/ 75] Iter[901/974]	  loss: 0.32cifar10:0.4-instance | Epoch [ 66/ 75] Iter[951/974]	  loss: 0.19
| Test Epoch 66	 Accuracy: 88.99% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 67 | Accuracy on train set: 61.35% 
labeled data has a size of 31253, f-score: 0.939398
cifar10:0.4-instance | Epoch [ 67/ 75] Iter[  1/977]	  loss: 0.24cifar10:0.4-instance | Epoch [ 67/ 75] Iter[ 51/977]	  loss: 0.23cifar10:0.4-instance | Epoch [ 67/ 75] Iter[101/977]	  loss: 0.23cifar10:0.4-instance | Epoch [ 67/ 75] Iter[151/977]	  loss: 0.26cifar10:0.4-instance | Epoch [ 67/ 75] Iter[201/977]	  loss: 0.22cifar10:0.4-instance | Epoch [ 67/ 75] Iter[251/977]	  loss: 0.30cifar10:0.4-instance | Epoch [ 67/ 75] Iter[301/977]	  loss: 0.24cifar10:0.4-instance | Epoch [ 67/ 75] Iter[351/977]	  loss: 0.31cifar10:0.4-instance | Epoch [ 67/ 75] Iter[401/977]	  loss: 0.32cifar10:0.4-instance | Epoch [ 67/ 75] Iter[451/977]	  loss: 0.19cifar10:0.4-instance | Epoch [ 67/ 75] Iter[501/977]	  loss: 0.16cifar10:0.4-instance | Epoch [ 67/ 75] Iter[551/977]	  loss: 0.26cifar10:0.4-instance | Epoch [ 67/ 75] Iter[601/977]	  loss: 0.22cifar10:0.4-instance | Epoch [ 67/ 75] Iter[651/977]	  loss: 0.25cifar10:0.4-instance | Epoch [ 67/ 75] Iter[701/977]	  loss: 0.22cifar10:0.4-instance | Epoch [ 67/ 75] Iter[751/977]	  loss: 0.16cifar10:0.4-instance | Epoch [ 67/ 75] Iter[801/977]	  loss: 0.15cifar10:0.4-instance | Epoch [ 67/ 75] Iter[851/977]	  loss: 0.16cifar10:0.4-instance | Epoch [ 67/ 75] Iter[901/977]	  loss: 0.23cifar10:0.4-instance | Epoch [ 67/ 75] Iter[951/977]	  loss: 0.38
| Test Epoch 67	 Accuracy: 88.87% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 68 | Accuracy on train set: 61.50% 
labeled data has a size of 31351, f-score: 0.937291
cifar10:0.4-instance | Epoch [ 68/ 75] Iter[  1/980]	  loss: 0.29cifar10:0.4-instance | Epoch [ 68/ 75] Iter[ 51/980]	  loss: 0.15cifar10:0.4-instance | Epoch [ 68/ 75] Iter[101/980]	  loss: 0.24cifar10:0.4-instance | Epoch [ 68/ 75] Iter[151/980]	  loss: 0.22cifar10:0.4-instance | Epoch [ 68/ 75] Iter[201/980]	  loss: 0.20cifar10:0.4-instance | Epoch [ 68/ 75] Iter[251/980]	  loss: 0.17cifar10:0.4-instance | Epoch [ 68/ 75] Iter[301/980]	  loss: 0.23cifar10:0.4-instance | Epoch [ 68/ 75] Iter[351/980]	  loss: 0.28cifar10:0.4-instance | Epoch [ 68/ 75] Iter[401/980]	  loss: 0.18cifar10:0.4-instance | Epoch [ 68/ 75] Iter[451/980]	  loss: 0.19cifar10:0.4-instance | Epoch [ 68/ 75] Iter[501/980]	  loss: 0.23cifar10:0.4-instance | Epoch [ 68/ 75] Iter[551/980]	  loss: 0.19cifar10:0.4-instance | Epoch [ 68/ 75] Iter[601/980]	  loss: 0.23cifar10:0.4-instance | Epoch [ 68/ 75] Iter[651/980]	  loss: 0.16cifar10:0.4-instance | Epoch [ 68/ 75] Iter[701/980]	  loss: 0.20cifar10:0.4-instance | Epoch [ 68/ 75] Iter[751/980]	  loss: 0.24cifar10:0.4-instance | Epoch [ 68/ 75] Iter[801/980]	  loss: 0.30cifar10:0.4-instance | Epoch [ 68/ 75] Iter[851/980]	  loss: 0.34cifar10:0.4-instance | Epoch [ 68/ 75] Iter[901/980]	  loss: 0.26cifar10:0.4-instance | Epoch [ 68/ 75] Iter[951/980]	  loss: 0.17
| Test Epoch 68	 Accuracy: 88.63% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 69 | Accuracy on train set: 61.68% 
labeled data has a size of 31426, f-score: 0.935467
cifar10:0.4-instance | Epoch [ 69/ 75] Iter[  1/983]	  loss: 0.30cifar10:0.4-instance | Epoch [ 69/ 75] Iter[ 51/983]	  loss: 0.22cifar10:0.4-instance | Epoch [ 69/ 75] Iter[101/983]	  loss: 0.16cifar10:0.4-instance | Epoch [ 69/ 75] Iter[151/983]	  loss: 0.18cifar10:0.4-instance | Epoch [ 69/ 75] Iter[201/983]	  loss: 0.28cifar10:0.4-instance | Epoch [ 69/ 75] Iter[251/983]	  loss: 0.16cifar10:0.4-instance | Epoch [ 69/ 75] Iter[301/983]	  loss: 0.16cifar10:0.4-instance | Epoch [ 69/ 75] Iter[351/983]	  loss: 0.18cifar10:0.4-instance | Epoch [ 69/ 75] Iter[401/983]	  loss: 0.17cifar10:0.4-instance | Epoch [ 69/ 75] Iter[451/983]	  loss: 0.24cifar10:0.4-instance | Epoch [ 69/ 75] Iter[501/983]	  loss: 0.36cifar10:0.4-instance | Epoch [ 69/ 75] Iter[551/983]	  loss: 0.15cifar10:0.4-instance | Epoch [ 69/ 75] Iter[601/983]	  loss: 0.19cifar10:0.4-instance | Epoch [ 69/ 75] Iter[651/983]	  loss: 0.19cifar10:0.4-instance | Epoch [ 69/ 75] Iter[701/983]	  loss: 0.27cifar10:0.4-instance | Epoch [ 69/ 75] Iter[751/983]	  loss: 0.35cifar10:0.4-instance | Epoch [ 69/ 75] Iter[801/983]	  loss: 0.21cifar10:0.4-instance | Epoch [ 69/ 75] Iter[851/983]	  loss: 0.31cifar10:0.4-instance | Epoch [ 69/ 75] Iter[901/983]	  loss: 0.42cifar10:0.4-instance | Epoch [ 69/ 75] Iter[951/983]	  loss: 0.25
| Test Epoch 69	 Accuracy: 88.59% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 70 | Accuracy on train set: 61.89% 
labeled data has a size of 31464, f-score: 0.934878
cifar10:0.4-instance | Epoch [ 70/ 75] Iter[  1/984]	  loss: 0.16cifar10:0.4-instance | Epoch [ 70/ 75] Iter[ 51/984]	  loss: 0.17cifar10:0.4-instance | Epoch [ 70/ 75] Iter[101/984]	  loss: 0.22cifar10:0.4-instance | Epoch [ 70/ 75] Iter[151/984]	  loss: 0.19cifar10:0.4-instance | Epoch [ 70/ 75] Iter[201/984]	  loss: 0.21cifar10:0.4-instance | Epoch [ 70/ 75] Iter[251/984]	  loss: 0.26cifar10:0.4-instance | Epoch [ 70/ 75] Iter[301/984]	  loss: 0.21cifar10:0.4-instance | Epoch [ 70/ 75] Iter[351/984]	  loss: 0.24cifar10:0.4-instance | Epoch [ 70/ 75] Iter[401/984]	  loss: 0.18cifar10:0.4-instance | Epoch [ 70/ 75] Iter[451/984]	  loss: 0.24cifar10:0.4-instance | Epoch [ 70/ 75] Iter[501/984]	  loss: 0.26cifar10:0.4-instance | Epoch [ 70/ 75] Iter[551/984]	  loss: 0.25cifar10:0.4-instance | Epoch [ 70/ 75] Iter[601/984]	  loss: 0.18cifar10:0.4-instance | Epoch [ 70/ 75] Iter[651/984]	  loss: 0.28cifar10:0.4-instance | Epoch [ 70/ 75] Iter[701/984]	  loss: 0.18cifar10:0.4-instance | Epoch [ 70/ 75] Iter[751/984]	  loss: 0.19cifar10:0.4-instance | Epoch [ 70/ 75] Iter[801/984]	  loss: 0.17cifar10:0.4-instance | Epoch [ 70/ 75] Iter[851/984]	  loss: 0.31cifar10:0.4-instance | Epoch [ 70/ 75] Iter[901/984]	  loss: 0.22cifar10:0.4-instance | Epoch [ 70/ 75] Iter[951/984]	  loss: 0.23
| Test Epoch 70	 Accuracy: 88.54% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 71 | Accuracy on train set: 61.87% 
labeled data has a size of 31521, f-score: 0.933536
cifar10:0.4-instance | Epoch [ 71/ 75] Iter[  1/986]	  loss: 0.25cifar10:0.4-instance | Epoch [ 71/ 75] Iter[ 51/986]	  loss: 0.34cifar10:0.4-instance | Epoch [ 71/ 75] Iter[101/986]	  loss: 0.22cifar10:0.4-instance | Epoch [ 71/ 75] Iter[151/986]	  loss: 0.22cifar10:0.4-instance | Epoch [ 71/ 75] Iter[201/986]	  loss: 0.22cifar10:0.4-instance | Epoch [ 71/ 75] Iter[251/986]	  loss: 0.27cifar10:0.4-instance | Epoch [ 71/ 75] Iter[301/986]	  loss: 0.17cifar10:0.4-instance | Epoch [ 71/ 75] Iter[351/986]	  loss: 0.45cifar10:0.4-instance | Epoch [ 71/ 75] Iter[401/986]	  loss: 0.22cifar10:0.4-instance | Epoch [ 71/ 75] Iter[451/986]	  loss: 0.18cifar10:0.4-instance | Epoch [ 71/ 75] Iter[501/986]	  loss: 0.16cifar10:0.4-instance | Epoch [ 71/ 75] Iter[551/986]	  loss: 0.25cifar10:0.4-instance | Epoch [ 71/ 75] Iter[601/986]	  loss: 0.19cifar10:0.4-instance | Epoch [ 71/ 75] Iter[651/986]	  loss: 0.24cifar10:0.4-instance | Epoch [ 71/ 75] Iter[701/986]	  loss: 0.24cifar10:0.4-instance | Epoch [ 71/ 75] Iter[751/986]	  loss: 0.17cifar10:0.4-instance | Epoch [ 71/ 75] Iter[801/986]	  loss: 0.20cifar10:0.4-instance | Epoch [ 71/ 75] Iter[851/986]	  loss: 0.27cifar10:0.4-instance | Epoch [ 71/ 75] Iter[901/986]	  loss: 0.16cifar10:0.4-instance | Epoch [ 71/ 75] Iter[951/986]	  loss: 0.16
| Test Epoch 71	 Accuracy: 88.04% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 72 | Accuracy on train set: 62.11% 
labeled data has a size of 31589, f-score: 0.932128
cifar10:0.4-instance | Epoch [ 72/ 75] Iter[  1/988]	  loss: 0.19cifar10:0.4-instance | Epoch [ 72/ 75] Iter[ 51/988]	  loss: 0.19cifar10:0.4-instance | Epoch [ 72/ 75] Iter[101/988]	  loss: 0.28cifar10:0.4-instance | Epoch [ 72/ 75] Iter[151/988]	  loss: 0.24cifar10:0.4-instance | Epoch [ 72/ 75] Iter[201/988]	  loss: 0.17cifar10:0.4-instance | Epoch [ 72/ 75] Iter[251/988]	  loss: 0.17cifar10:0.4-instance | Epoch [ 72/ 75] Iter[301/988]	  loss: 0.33cifar10:0.4-instance | Epoch [ 72/ 75] Iter[351/988]	  loss: 0.19cifar10:0.4-instance | Epoch [ 72/ 75] Iter[401/988]	  loss: 0.19cifar10:0.4-instance | Epoch [ 72/ 75] Iter[451/988]	  loss: 0.18cifar10:0.4-instance | Epoch [ 72/ 75] Iter[501/988]	  loss: 0.18cifar10:0.4-instance | Epoch [ 72/ 75] Iter[551/988]	  loss: 0.20cifar10:0.4-instance | Epoch [ 72/ 75] Iter[601/988]	  loss: 0.21cifar10:0.4-instance | Epoch [ 72/ 75] Iter[651/988]	  loss: 0.17cifar10:0.4-instance | Epoch [ 72/ 75] Iter[701/988]	  loss: 0.19cifar10:0.4-instance | Epoch [ 72/ 75] Iter[751/988]	  loss: 0.17cifar10:0.4-instance | Epoch [ 72/ 75] Iter[801/988]	  loss: 0.17cifar10:0.4-instance | Epoch [ 72/ 75] Iter[851/988]	  loss: 0.20cifar10:0.4-instance | Epoch [ 72/ 75] Iter[901/988]	  loss: 0.18cifar10:0.4-instance | Epoch [ 72/ 75] Iter[951/988]	  loss: 0.24
| Test Epoch 72	 Accuracy: 88.30% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 73 | Accuracy on train set: 62.32% 
labeled data has a size of 31631, f-score: 0.931302
cifar10:0.4-instance | Epoch [ 73/ 75] Iter[  1/989]	  loss: 0.25cifar10:0.4-instance | Epoch [ 73/ 75] Iter[ 51/989]	  loss: 0.23cifar10:0.4-instance | Epoch [ 73/ 75] Iter[101/989]	  loss: 0.19cifar10:0.4-instance | Epoch [ 73/ 75] Iter[151/989]	  loss: 0.18cifar10:0.4-instance | Epoch [ 73/ 75] Iter[201/989]	  loss: 0.15cifar10:0.4-instance | Epoch [ 73/ 75] Iter[251/989]	  loss: 0.21cifar10:0.4-instance | Epoch [ 73/ 75] Iter[301/989]	  loss: 0.15cifar10:0.4-instance | Epoch [ 73/ 75] Iter[351/989]	  loss: 0.19cifar10:0.4-instance | Epoch [ 73/ 75] Iter[401/989]	  loss: 0.18cifar10:0.4-instance | Epoch [ 73/ 75] Iter[451/989]	  loss: 0.40cifar10:0.4-instance | Epoch [ 73/ 75] Iter[501/989]	  loss: 0.18cifar10:0.4-instance | Epoch [ 73/ 75] Iter[551/989]	  loss: 0.19cifar10:0.4-instance | Epoch [ 73/ 75] Iter[601/989]	  loss: 0.25cifar10:0.4-instance | Epoch [ 73/ 75] Iter[651/989]	  loss: 0.30cifar10:0.4-instance | Epoch [ 73/ 75] Iter[701/989]	  loss: 0.15cifar10:0.4-instance | Epoch [ 73/ 75] Iter[751/989]	  loss: 0.35cifar10:0.4-instance | Epoch [ 73/ 75] Iter[801/989]	  loss: 0.16cifar10:0.4-instance | Epoch [ 73/ 75] Iter[851/989]	  loss: 0.17cifar10:0.4-instance | Epoch [ 73/ 75] Iter[901/989]	  loss: 0.26cifar10:0.4-instance | Epoch [ 73/ 75] Iter[951/989]	  loss: 0.20
| Test Epoch 73	 Accuracy: 88.62% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 74 | Accuracy on train set: 62.46% 
labeled data has a size of 31718, f-score: 0.929851
cifar10:0.4-instance | Epoch [ 74/ 75] Iter[  1/992]	  loss: 0.17cifar10:0.4-instance | Epoch [ 74/ 75] Iter[ 51/992]	  loss: 0.18cifar10:0.4-instance | Epoch [ 74/ 75] Iter[101/992]	  loss: 0.19cifar10:0.4-instance | Epoch [ 74/ 75] Iter[151/992]	  loss: 0.19cifar10:0.4-instance | Epoch [ 74/ 75] Iter[201/992]	  loss: 0.18cifar10:0.4-instance | Epoch [ 74/ 75] Iter[251/992]	  loss: 0.17cifar10:0.4-instance | Epoch [ 74/ 75] Iter[301/992]	  loss: 0.15cifar10:0.4-instance | Epoch [ 74/ 75] Iter[351/992]	  loss: 0.31cifar10:0.4-instance | Epoch [ 74/ 75] Iter[401/992]	  loss: 0.34cifar10:0.4-instance | Epoch [ 74/ 75] Iter[451/992]	  loss: 0.25cifar10:0.4-instance | Epoch [ 74/ 75] Iter[501/992]	  loss: 0.18cifar10:0.4-instance | Epoch [ 74/ 75] Iter[551/992]	  loss: 0.36cifar10:0.4-instance | Epoch [ 74/ 75] Iter[601/992]	  loss: 0.22cifar10:0.4-instance | Epoch [ 74/ 75] Iter[651/992]	  loss: 0.15cifar10:0.4-instance | Epoch [ 74/ 75] Iter[701/992]	  loss: 0.46cifar10:0.4-instance | Epoch [ 74/ 75] Iter[751/992]	  loss: 0.21cifar10:0.4-instance | Epoch [ 74/ 75] Iter[801/992]	  loss: 0.23cifar10:0.4-instance | Epoch [ 74/ 75] Iter[851/992]	  loss: 0.16cifar10:0.4-instance | Epoch [ 74/ 75] Iter[901/992]	  loss: 0.32cifar10:0.4-instance | Epoch [ 74/ 75] Iter[951/992]	  loss: 0.16
| Test Epoch 74	 Accuracy: 87.64% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 75 | Accuracy on train set: 62.67% 
labeled data has a size of 31807, f-score: 0.927343
cifar10:0.4-instance | Epoch [ 75/ 75] Iter[  1/994]	  loss: 0.25cifar10:0.4-instance | Epoch [ 75/ 75] Iter[ 51/994]	  loss: 0.16cifar10:0.4-instance | Epoch [ 75/ 75] Iter[101/994]	  loss: 0.20cifar10:0.4-instance | Epoch [ 75/ 75] Iter[151/994]	  loss: 0.19cifar10:0.4-instance | Epoch [ 75/ 75] Iter[201/994]	  loss: 0.17cifar10:0.4-instance | Epoch [ 75/ 75] Iter[251/994]	  loss: 0.17cifar10:0.4-instance | Epoch [ 75/ 75] Iter[301/994]	  loss: 0.18cifar10:0.4-instance | Epoch [ 75/ 75] Iter[351/994]	  loss: 0.20cifar10:0.4-instance | Epoch [ 75/ 75] Iter[401/994]	  loss: 0.17cifar10:0.4-instance | Epoch [ 75/ 75] Iter[451/994]	  loss: 0.19cifar10:0.4-instance | Epoch [ 75/ 75] Iter[501/994]	  loss: 0.18cifar10:0.4-instance | Epoch [ 75/ 75] Iter[551/994]	  loss: 0.19cifar10:0.4-instance | Epoch [ 75/ 75] Iter[601/994]	  loss: 0.15cifar10:0.4-instance | Epoch [ 75/ 75] Iter[651/994]	  loss: 0.20cifar10:0.4-instance | Epoch [ 75/ 75] Iter[701/994]	  loss: 0.19cifar10:0.4-instance | Epoch [ 75/ 75] Iter[751/994]	  loss: 0.25cifar10:0.4-instance | Epoch [ 75/ 75] Iter[801/994]	  loss: 0.31cifar10:0.4-instance | Epoch [ 75/ 75] Iter[851/994]	  loss: 0.20cifar10:0.4-instance | Epoch [ 75/ 75] Iter[901/994]	  loss: 0.20cifar10:0.4-instance | Epoch [ 75/ 75] Iter[951/994]	  loss: 0.25
| Test Epoch 75	 Accuracy: 87.59% 



best test Acc:  89.68
