Namespace(T=0.2, batch_size=32, data_path='./dataset2/cifar10', dataset='cifar10', fig_7=0, fluctuation_ablation=0, gpuid=0, k=3, lr=0.02, model='resnet18', noise_mode='instance', num_class=10, num_epochs=75, r=0.2, save_sel_sam=0, seed_model=5, seed_noise=1, semi='no', warm_up=10, wdecay=0.0005, without_Lcr=0, without_R=0)
============ Initialize data
============ Actual clean samples number:  39820
============ use resnet18 
============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 0 | Accuracy on train set: 7.55% 
cifar10:0.2-instance | Epoch [  0/ 75] Iter[  1/391]	 CE-loss: 2.4246cifar10:0.2-instance | Epoch [  0/ 75] Iter[ 51/391]	 CE-loss: 2.0113cifar10:0.2-instance | Epoch [  0/ 75] Iter[101/391]	 CE-loss: 1.9345cifar10:0.2-instance | Epoch [  0/ 75] Iter[151/391]	 CE-loss: 1.9210cifar10:0.2-instance | Epoch [  0/ 75] Iter[201/391]	 CE-loss: 1.7434cifar10:0.2-instance | Epoch [  0/ 75] Iter[251/391]	 CE-loss: 1.7873cifar10:0.2-instance | Epoch [  0/ 75] Iter[301/391]	 CE-loss: 1.5646cifar10:0.2-instance | Epoch [  0/ 75] Iter[351/391]	 CE-loss: 1.7239
| Test Epoch 0	 Accuracy: 47.94% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 1 | Accuracy on train set: 40.57% 
cifar10:0.2-instance | Epoch [  1/ 75] Iter[  1/391]	 CE-loss: 1.5667cifar10:0.2-instance | Epoch [  1/ 75] Iter[ 51/391]	 CE-loss: 1.5757cifar10:0.2-instance | Epoch [  1/ 75] Iter[101/391]	 CE-loss: 1.5490cifar10:0.2-instance | Epoch [  1/ 75] Iter[151/391]	 CE-loss: 1.5659cifar10:0.2-instance | Epoch [  1/ 75] Iter[201/391]	 CE-loss: 1.5974cifar10:0.2-instance | Epoch [  1/ 75] Iter[251/391]	 CE-loss: 1.3417cifar10:0.2-instance | Epoch [  1/ 75] Iter[301/391]	 CE-loss: 1.4062cifar10:0.2-instance | Epoch [  1/ 75] Iter[351/391]	 CE-loss: 1.4562
| Test Epoch 1	 Accuracy: 59.02% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 2 | Accuracy on train set: 49.31% 
cifar10:0.2-instance | Epoch [  2/ 75] Iter[  1/391]	 CE-loss: 1.2547cifar10:0.2-instance | Epoch [  2/ 75] Iter[ 51/391]	 CE-loss: 1.3849cifar10:0.2-instance | Epoch [  2/ 75] Iter[101/391]	 CE-loss: 1.3185cifar10:0.2-instance | Epoch [  2/ 75] Iter[151/391]	 CE-loss: 1.2883cifar10:0.2-instance | Epoch [  2/ 75] Iter[201/391]	 CE-loss: 1.4849cifar10:0.2-instance | Epoch [  2/ 75] Iter[251/391]	 CE-loss: 1.1634cifar10:0.2-instance | Epoch [  2/ 75] Iter[301/391]	 CE-loss: 1.3053cifar10:0.2-instance | Epoch [  2/ 75] Iter[351/391]	 CE-loss: 1.1694
| Test Epoch 2	 Accuracy: 63.35% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 3 | Accuracy on train set: 52.61% 
cifar10:0.2-instance | Epoch [  3/ 75] Iter[  1/391]	 CE-loss: 1.2085cifar10:0.2-instance | Epoch [  3/ 75] Iter[ 51/391]	 CE-loss: 1.3357cifar10:0.2-instance | Epoch [  3/ 75] Iter[101/391]	 CE-loss: 1.1171cifar10:0.2-instance | Epoch [  3/ 75] Iter[151/391]	 CE-loss: 1.1507cifar10:0.2-instance | Epoch [  3/ 75] Iter[201/391]	 CE-loss: 1.1643cifar10:0.2-instance | Epoch [  3/ 75] Iter[251/391]	 CE-loss: 1.1888cifar10:0.2-instance | Epoch [  3/ 75] Iter[301/391]	 CE-loss: 1.2110cifar10:0.2-instance | Epoch [  3/ 75] Iter[351/391]	 CE-loss: 1.1371
| Test Epoch 3	 Accuracy: 62.64% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 4 | Accuracy on train set: 54.53% 
cifar10:0.2-instance | Epoch [  4/ 75] Iter[  1/391]	 CE-loss: 1.3431cifar10:0.2-instance | Epoch [  4/ 75] Iter[ 51/391]	 CE-loss: 1.4272cifar10:0.2-instance | Epoch [  4/ 75] Iter[101/391]	 CE-loss: 1.1192cifar10:0.2-instance | Epoch [  4/ 75] Iter[151/391]	 CE-loss: 1.2648cifar10:0.2-instance | Epoch [  4/ 75] Iter[201/391]	 CE-loss: 1.1440cifar10:0.2-instance | Epoch [  4/ 75] Iter[251/391]	 CE-loss: 1.0035cifar10:0.2-instance | Epoch [  4/ 75] Iter[301/391]	 CE-loss: 1.1550cifar10:0.2-instance | Epoch [  4/ 75] Iter[351/391]	 CE-loss: 1.2126
| Test Epoch 4	 Accuracy: 76.03% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 5 | Accuracy on train set: 62.72% 
cifar10:0.2-instance | Epoch [  5/ 75] Iter[  1/391]	 CE-loss: 1.1372cifar10:0.2-instance | Epoch [  5/ 75] Iter[ 51/391]	 CE-loss: 1.1466cifar10:0.2-instance | Epoch [  5/ 75] Iter[101/391]	 CE-loss: 1.1779cifar10:0.2-instance | Epoch [  5/ 75] Iter[151/391]	 CE-loss: 1.1984cifar10:0.2-instance | Epoch [  5/ 75] Iter[201/391]	 CE-loss: 0.9806cifar10:0.2-instance | Epoch [  5/ 75] Iter[251/391]	 CE-loss: 1.1475cifar10:0.2-instance | Epoch [  5/ 75] Iter[301/391]	 CE-loss: 1.3098cifar10:0.2-instance | Epoch [  5/ 75] Iter[351/391]	 CE-loss: 1.1425
| Test Epoch 5	 Accuracy: 78.87% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 6 | Accuracy on train set: 65.36% 
cifar10:0.2-instance | Epoch [  6/ 75] Iter[  1/391]	 CE-loss: 1.1477cifar10:0.2-instance | Epoch [  6/ 75] Iter[ 51/391]	 CE-loss: 1.0207cifar10:0.2-instance | Epoch [  6/ 75] Iter[101/391]	 CE-loss: 1.1524cifar10:0.2-instance | Epoch [  6/ 75] Iter[151/391]	 CE-loss: 1.2056cifar10:0.2-instance | Epoch [  6/ 75] Iter[201/391]	 CE-loss: 1.0169cifar10:0.2-instance | Epoch [  6/ 75] Iter[251/391]	 CE-loss: 1.1201cifar10:0.2-instance | Epoch [  6/ 75] Iter[301/391]	 CE-loss: 1.0595cifar10:0.2-instance | Epoch [  6/ 75] Iter[351/391]	 CE-loss: 0.9447
| Test Epoch 6	 Accuracy: 78.18% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 7 | Accuracy on train set: 65.16% 
cifar10:0.2-instance | Epoch [  7/ 75] Iter[  1/391]	 CE-loss: 1.1402cifar10:0.2-instance | Epoch [  7/ 75] Iter[ 51/391]	 CE-loss: 1.0061cifar10:0.2-instance | Epoch [  7/ 75] Iter[101/391]	 CE-loss: 1.0552cifar10:0.2-instance | Epoch [  7/ 75] Iter[151/391]	 CE-loss: 1.0151cifar10:0.2-instance | Epoch [  7/ 75] Iter[201/391]	 CE-loss: 0.9610cifar10:0.2-instance | Epoch [  7/ 75] Iter[251/391]	 CE-loss: 0.9182cifar10:0.2-instance | Epoch [  7/ 75] Iter[301/391]	 CE-loss: 1.1601cifar10:0.2-instance | Epoch [  7/ 75] Iter[351/391]	 CE-loss: 1.0327
| Test Epoch 7	 Accuracy: 78.46% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 8 | Accuracy on train set: 65.43% 
cifar10:0.2-instance | Epoch [  8/ 75] Iter[  1/391]	 CE-loss: 0.8463cifar10:0.2-instance | Epoch [  8/ 75] Iter[ 51/391]	 CE-loss: 0.9323cifar10:0.2-instance | Epoch [  8/ 75] Iter[101/391]	 CE-loss: 0.9624cifar10:0.2-instance | Epoch [  8/ 75] Iter[151/391]	 CE-loss: 0.8890cifar10:0.2-instance | Epoch [  8/ 75] Iter[201/391]	 CE-loss: 1.0744cifar10:0.2-instance | Epoch [  8/ 75] Iter[251/391]	 CE-loss: 1.0711cifar10:0.2-instance | Epoch [  8/ 75] Iter[301/391]	 CE-loss: 1.0574cifar10:0.2-instance | Epoch [  8/ 75] Iter[351/391]	 CE-loss: 0.8189
| Test Epoch 8	 Accuracy: 81.66% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 9 | Accuracy on train set: 68.28% 
cifar10:0.2-instance | Epoch [  9/ 75] Iter[  1/391]	 CE-loss: 0.8941cifar10:0.2-instance | Epoch [  9/ 75] Iter[ 51/391]	 CE-loss: 0.9351cifar10:0.2-instance | Epoch [  9/ 75] Iter[101/391]	 CE-loss: 0.9963cifar10:0.2-instance | Epoch [  9/ 75] Iter[151/391]	 CE-loss: 1.0869cifar10:0.2-instance | Epoch [  9/ 75] Iter[201/391]	 CE-loss: 0.9090cifar10:0.2-instance | Epoch [  9/ 75] Iter[251/391]	 CE-loss: 1.0742cifar10:0.2-instance | Epoch [  9/ 75] Iter[301/391]	 CE-loss: 0.8184cifar10:0.2-instance | Epoch [  9/ 75] Iter[351/391]	 CE-loss: 0.9821
| Test Epoch 9	 Accuracy: 80.61% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 10 | Accuracy on train set: 67.87% 
labeled data has a size of 38394, f-score: 0.973043
cifar10:0.2-instance | Epoch [ 10/ 75] Iter[  1/1200]	  loss: 0.60cifar10:0.2-instance | Epoch [ 10/ 75] Iter[ 51/1200]	  loss: 1.02cifar10:0.2-instance | Epoch [ 10/ 75] Iter[101/1200]	  loss: 0.50cifar10:0.2-instance | Epoch [ 10/ 75] Iter[151/1200]	  loss: 0.75cifar10:0.2-instance | Epoch [ 10/ 75] Iter[201/1200]	  loss: 0.78cifar10:0.2-instance | Epoch [ 10/ 75] Iter[251/1200]	  loss: 0.72cifar10:0.2-instance | Epoch [ 10/ 75] Iter[301/1200]	  loss: 0.56cifar10:0.2-instance | Epoch [ 10/ 75] Iter[351/1200]	  loss: 0.92cifar10:0.2-instance | Epoch [ 10/ 75] Iter[401/1200]	  loss: 0.69cifar10:0.2-instance | Epoch [ 10/ 75] Iter[451/1200]	  loss: 0.91cifar10:0.2-instance | Epoch [ 10/ 75] Iter[501/1200]	  loss: 0.84cifar10:0.2-instance | Epoch [ 10/ 75] Iter[551/1200]	  loss: 0.67cifar10:0.2-instance | Epoch [ 10/ 75] Iter[601/1200]	  loss: 0.74cifar10:0.2-instance | Epoch [ 10/ 75] Iter[651/1200]	  loss: 0.72cifar10:0.2-instance | Epoch [ 10/ 75] Iter[701/1200]	  loss: 0.85cifar10:0.2-instance | Epoch [ 10/ 75] Iter[751/1200]	  loss: 0.56cifar10:0.2-instance | Epoch [ 10/ 75] Iter[801/1200]	  loss: 0.53cifar10:0.2-instance | Epoch [ 10/ 75] Iter[851/1200]	  loss: 0.71cifar10:0.2-instance | Epoch [ 10/ 75] Iter[901/1200]	  loss: 0.83cifar10:0.2-instance | Epoch [ 10/ 75] Iter[951/1200]	  loss: 0.65cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1001/1200]	  loss: 0.68cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1051/1200]	  loss: 0.70cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1101/1200]	  loss: 0.72cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1151/1200]	  loss: 0.62
| Test Epoch 10	 Accuracy: 77.66% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 11 | Accuracy on train set: 63.48% 
labeled data has a size of 38121, f-score: 0.975788
cifar10:0.2-instance | Epoch [ 11/ 75] Iter[  1/1192]	  loss: 0.59cifar10:0.2-instance | Epoch [ 11/ 75] Iter[ 51/1192]	  loss: 0.65cifar10:0.2-instance | Epoch [ 11/ 75] Iter[101/1192]	  loss: 0.39cifar10:0.2-instance | Epoch [ 11/ 75] Iter[151/1192]	  loss: 0.59cifar10:0.2-instance | Epoch [ 11/ 75] Iter[201/1192]	  loss: 0.69cifar10:0.2-instance | Epoch [ 11/ 75] Iter[251/1192]	  loss: 0.51cifar10:0.2-instance | Epoch [ 11/ 75] Iter[301/1192]	  loss: 0.39cifar10:0.2-instance | Epoch [ 11/ 75] Iter[351/1192]	  loss: 0.65cifar10:0.2-instance | Epoch [ 11/ 75] Iter[401/1192]	  loss: 0.62cifar10:0.2-instance | Epoch [ 11/ 75] Iter[451/1192]	  loss: 0.49cifar10:0.2-instance | Epoch [ 11/ 75] Iter[501/1192]	  loss: 0.58cifar10:0.2-instance | Epoch [ 11/ 75] Iter[551/1192]	  loss: 0.55cifar10:0.2-instance | Epoch [ 11/ 75] Iter[601/1192]	  loss: 0.49cifar10:0.2-instance | Epoch [ 11/ 75] Iter[651/1192]	  loss: 0.45cifar10:0.2-instance | Epoch [ 11/ 75] Iter[701/1192]	  loss: 0.57cifar10:0.2-instance | Epoch [ 11/ 75] Iter[751/1192]	  loss: 1.01cifar10:0.2-instance | Epoch [ 11/ 75] Iter[801/1192]	  loss: 0.50cifar10:0.2-instance | Epoch [ 11/ 75] Iter[851/1192]	  loss: 0.69cifar10:0.2-instance | Epoch [ 11/ 75] Iter[901/1192]	  loss: 0.57cifar10:0.2-instance | Epoch [ 11/ 75] Iter[951/1192]	  loss: 0.64cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1001/1192]	  loss: 0.60cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1051/1192]	  loss: 0.45cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1101/1192]	  loss: 0.42cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1151/1192]	  loss: 0.47
| Test Epoch 11	 Accuracy: 80.92% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 12 | Accuracy on train set: 66.78% 
labeled data has a size of 37807, f-score: 0.976380
cifar10:0.2-instance | Epoch [ 12/ 75] Iter[  1/1182]	  loss: 0.47cifar10:0.2-instance | Epoch [ 12/ 75] Iter[ 51/1182]	  loss: 0.56cifar10:0.2-instance | Epoch [ 12/ 75] Iter[101/1182]	  loss: 0.67cifar10:0.2-instance | Epoch [ 12/ 75] Iter[151/1182]	  loss: 0.50cifar10:0.2-instance | Epoch [ 12/ 75] Iter[201/1182]	  loss: 1.04cifar10:0.2-instance | Epoch [ 12/ 75] Iter[251/1182]	  loss: 0.59cifar10:0.2-instance | Epoch [ 12/ 75] Iter[301/1182]	  loss: 0.65cifar10:0.2-instance | Epoch [ 12/ 75] Iter[351/1182]	  loss: 0.55cifar10:0.2-instance | Epoch [ 12/ 75] Iter[401/1182]	  loss: 0.31cifar10:0.2-instance | Epoch [ 12/ 75] Iter[451/1182]	  loss: 0.43cifar10:0.2-instance | Epoch [ 12/ 75] Iter[501/1182]	  loss: 0.80cifar10:0.2-instance | Epoch [ 12/ 75] Iter[551/1182]	  loss: 0.42cifar10:0.2-instance | Epoch [ 12/ 75] Iter[601/1182]	  loss: 0.54cifar10:0.2-instance | Epoch [ 12/ 75] Iter[651/1182]	  loss: 0.35cifar10:0.2-instance | Epoch [ 12/ 75] Iter[701/1182]	  loss: 0.61cifar10:0.2-instance | Epoch [ 12/ 75] Iter[751/1182]	  loss: 0.52cifar10:0.2-instance | Epoch [ 12/ 75] Iter[801/1182]	  loss: 0.30cifar10:0.2-instance | Epoch [ 12/ 75] Iter[851/1182]	  loss: 0.55cifar10:0.2-instance | Epoch [ 12/ 75] Iter[901/1182]	  loss: 0.69cifar10:0.2-instance | Epoch [ 12/ 75] Iter[951/1182]	  loss: 0.48cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1001/1182]	  loss: 0.62cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1051/1182]	  loss: 0.64cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1101/1182]	  loss: 0.46cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1151/1182]	  loss: 0.35
| Test Epoch 12	 Accuracy: 80.73% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 13 | Accuracy on train set: 66.75% 
labeled data has a size of 37667, f-score: 0.979106
cifar10:0.2-instance | Epoch [ 13/ 75] Iter[  1/1178]	  loss: 0.38cifar10:0.2-instance | Epoch [ 13/ 75] Iter[ 51/1178]	  loss: 0.59cifar10:0.2-instance | Epoch [ 13/ 75] Iter[101/1178]	  loss: 0.83cifar10:0.2-instance | Epoch [ 13/ 75] Iter[151/1178]	  loss: 0.36cifar10:0.2-instance | Epoch [ 13/ 75] Iter[201/1178]	  loss: 0.46cifar10:0.2-instance | Epoch [ 13/ 75] Iter[251/1178]	  loss: 0.40cifar10:0.2-instance | Epoch [ 13/ 75] Iter[301/1178]	  loss: 0.55cifar10:0.2-instance | Epoch [ 13/ 75] Iter[351/1178]	  loss: 0.59cifar10:0.2-instance | Epoch [ 13/ 75] Iter[401/1178]	  loss: 0.30cifar10:0.2-instance | Epoch [ 13/ 75] Iter[451/1178]	  loss: 0.47cifar10:0.2-instance | Epoch [ 13/ 75] Iter[501/1178]	  loss: 0.84cifar10:0.2-instance | Epoch [ 13/ 75] Iter[551/1178]	  loss: 0.58cifar10:0.2-instance | Epoch [ 13/ 75] Iter[601/1178]	  loss: 0.52cifar10:0.2-instance | Epoch [ 13/ 75] Iter[651/1178]	  loss: 0.34cifar10:0.2-instance | Epoch [ 13/ 75] Iter[701/1178]	  loss: 0.40cifar10:0.2-instance | Epoch [ 13/ 75] Iter[751/1178]	  loss: 0.34cifar10:0.2-instance | Epoch [ 13/ 75] Iter[801/1178]	  loss: 0.40cifar10:0.2-instance | Epoch [ 13/ 75] Iter[851/1178]	  loss: 0.38cifar10:0.2-instance | Epoch [ 13/ 75] Iter[901/1178]	  loss: 0.53cifar10:0.2-instance | Epoch [ 13/ 75] Iter[951/1178]	  loss: 0.42cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1001/1178]	  loss: 0.39cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1051/1178]	  loss: 0.47cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1101/1178]	  loss: 0.69cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1151/1178]	  loss: 0.40
| Test Epoch 13	 Accuracy: 81.53% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 14 | Accuracy on train set: 67.27% 
labeled data has a size of 37836, f-score: 0.979834
cifar10:0.2-instance | Epoch [ 14/ 75] Iter[  1/1183]	  loss: 0.48cifar10:0.2-instance | Epoch [ 14/ 75] Iter[ 51/1183]	  loss: 0.41cifar10:0.2-instance | Epoch [ 14/ 75] Iter[101/1183]	  loss: 0.51cifar10:0.2-instance | Epoch [ 14/ 75] Iter[151/1183]	  loss: 0.57cifar10:0.2-instance | Epoch [ 14/ 75] Iter[201/1183]	  loss: 0.29cifar10:0.2-instance | Epoch [ 14/ 75] Iter[251/1183]	  loss: 0.42cifar10:0.2-instance | Epoch [ 14/ 75] Iter[301/1183]	  loss: 0.46cifar10:0.2-instance | Epoch [ 14/ 75] Iter[351/1183]	  loss: 0.40cifar10:0.2-instance | Epoch [ 14/ 75] Iter[401/1183]	  loss: 0.60cifar10:0.2-instance | Epoch [ 14/ 75] Iter[451/1183]	  loss: 0.39cifar10:0.2-instance | Epoch [ 14/ 75] Iter[501/1183]	  loss: 0.30cifar10:0.2-instance | Epoch [ 14/ 75] Iter[551/1183]	  loss: 0.38cifar10:0.2-instance | Epoch [ 14/ 75] Iter[601/1183]	  loss: 0.54cifar10:0.2-instance | Epoch [ 14/ 75] Iter[651/1183]	  loss: 0.72cifar10:0.2-instance | Epoch [ 14/ 75] Iter[701/1183]	  loss: 0.68cifar10:0.2-instance | Epoch [ 14/ 75] Iter[751/1183]	  loss: 0.61cifar10:0.2-instance | Epoch [ 14/ 75] Iter[801/1183]	  loss: 0.43cifar10:0.2-instance | Epoch [ 14/ 75] Iter[851/1183]	  loss: 0.35cifar10:0.2-instance | Epoch [ 14/ 75] Iter[901/1183]	  loss: 0.34cifar10:0.2-instance | Epoch [ 14/ 75] Iter[951/1183]	  loss: 0.35cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1001/1183]	  loss: 0.31cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1051/1183]	  loss: 0.65cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1101/1183]	  loss: 0.44cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1151/1183]	  loss: 0.58
| Test Epoch 14	 Accuracy: 84.18% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 15 | Accuracy on train set: 69.60% 
labeled data has a size of 38016, f-score: 0.981034
cifar10:0.2-instance | Epoch [ 15/ 75] Iter[  1/1189]	  loss: 0.46cifar10:0.2-instance | Epoch [ 15/ 75] Iter[ 51/1189]	  loss: 0.48cifar10:0.2-instance | Epoch [ 15/ 75] Iter[101/1189]	  loss: 0.26cifar10:0.2-instance | Epoch [ 15/ 75] Iter[151/1189]	  loss: 0.29cifar10:0.2-instance | Epoch [ 15/ 75] Iter[201/1189]	  loss: 0.33cifar10:0.2-instance | Epoch [ 15/ 75] Iter[251/1189]	  loss: 0.53cifar10:0.2-instance | Epoch [ 15/ 75] Iter[301/1189]	  loss: 0.46cifar10:0.2-instance | Epoch [ 15/ 75] Iter[351/1189]	  loss: 0.55cifar10:0.2-instance | Epoch [ 15/ 75] Iter[401/1189]	  loss: 0.37cifar10:0.2-instance | Epoch [ 15/ 75] Iter[451/1189]	  loss: 0.29cifar10:0.2-instance | Epoch [ 15/ 75] Iter[501/1189]	  loss: 0.57cifar10:0.2-instance | Epoch [ 15/ 75] Iter[551/1189]	  loss: 0.31cifar10:0.2-instance | Epoch [ 15/ 75] Iter[601/1189]	  loss: 0.29cifar10:0.2-instance | Epoch [ 15/ 75] Iter[651/1189]	  loss: 0.55cifar10:0.2-instance | Epoch [ 15/ 75] Iter[701/1189]	  loss: 0.52cifar10:0.2-instance | Epoch [ 15/ 75] Iter[751/1189]	  loss: 0.45cifar10:0.2-instance | Epoch [ 15/ 75] Iter[801/1189]	  loss: 0.58cifar10:0.2-instance | Epoch [ 15/ 75] Iter[851/1189]	  loss: 0.36cifar10:0.2-instance | Epoch [ 15/ 75] Iter[901/1189]	  loss: 0.35cifar10:0.2-instance | Epoch [ 15/ 75] Iter[951/1189]	  loss: 0.40cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1001/1189]	  loss: 0.38cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1051/1189]	  loss: 0.41cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1101/1189]	  loss: 0.39cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1151/1189]	  loss: 0.30
| Test Epoch 15	 Accuracy: 82.32% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 16 | Accuracy on train set: 68.08% 
labeled data has a size of 37755, f-score: 0.983049
cifar10:0.2-instance | Epoch [ 16/ 75] Iter[  1/1180]	  loss: 0.40cifar10:0.2-instance | Epoch [ 16/ 75] Iter[ 51/1180]	  loss: 0.29cifar10:0.2-instance | Epoch [ 16/ 75] Iter[101/1180]	  loss: 0.51cifar10:0.2-instance | Epoch [ 16/ 75] Iter[151/1180]	  loss: 0.38cifar10:0.2-instance | Epoch [ 16/ 75] Iter[201/1180]	  loss: 0.43cifar10:0.2-instance | Epoch [ 16/ 75] Iter[251/1180]	  loss: 0.40cifar10:0.2-instance | Epoch [ 16/ 75] Iter[301/1180]	  loss: 0.35cifar10:0.2-instance | Epoch [ 16/ 75] Iter[351/1180]	  loss: 0.35cifar10:0.2-instance | Epoch [ 16/ 75] Iter[401/1180]	  loss: 0.35cifar10:0.2-instance | Epoch [ 16/ 75] Iter[451/1180]	  loss: 0.62cifar10:0.2-instance | Epoch [ 16/ 75] Iter[501/1180]	  loss: 0.53cifar10:0.2-instance | Epoch [ 16/ 75] Iter[551/1180]	  loss: 0.48cifar10:0.2-instance | Epoch [ 16/ 75] Iter[601/1180]	  loss: 0.38cifar10:0.2-instance | Epoch [ 16/ 75] Iter[651/1180]	  loss: 0.44cifar10:0.2-instance | Epoch [ 16/ 75] Iter[701/1180]	  loss: 0.27cifar10:0.2-instance | Epoch [ 16/ 75] Iter[751/1180]	  loss: 0.30cifar10:0.2-instance | Epoch [ 16/ 75] Iter[801/1180]	  loss: 0.23cifar10:0.2-instance | Epoch [ 16/ 75] Iter[851/1180]	  loss: 0.40cifar10:0.2-instance | Epoch [ 16/ 75] Iter[901/1180]	  loss: 0.50cifar10:0.2-instance | Epoch [ 16/ 75] Iter[951/1180]	  loss: 0.47cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1001/1180]	  loss: 0.55cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1051/1180]	  loss: 0.55cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1101/1180]	  loss: 0.37cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1151/1180]	  loss: 0.45
| Test Epoch 16	 Accuracy: 82.27% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 17 | Accuracy on train set: 68.29% 
labeled data has a size of 37645, f-score: 0.985390
cifar10:0.2-instance | Epoch [ 17/ 75] Iter[  1/1177]	  loss: 0.41cifar10:0.2-instance | Epoch [ 17/ 75] Iter[ 51/1177]	  loss: 0.67cifar10:0.2-instance | Epoch [ 17/ 75] Iter[101/1177]	  loss: 0.35cifar10:0.2-instance | Epoch [ 17/ 75] Iter[151/1177]	  loss: 0.45cifar10:0.2-instance | Epoch [ 17/ 75] Iter[201/1177]	  loss: 0.51cifar10:0.2-instance | Epoch [ 17/ 75] Iter[251/1177]	  loss: 0.41cifar10:0.2-instance | Epoch [ 17/ 75] Iter[301/1177]	  loss: 0.39cifar10:0.2-instance | Epoch [ 17/ 75] Iter[351/1177]	  loss: 0.40cifar10:0.2-instance | Epoch [ 17/ 75] Iter[401/1177]	  loss: 0.24cifar10:0.2-instance | Epoch [ 17/ 75] Iter[451/1177]	  loss: 0.54cifar10:0.2-instance | Epoch [ 17/ 75] Iter[501/1177]	  loss: 0.46cifar10:0.2-instance | Epoch [ 17/ 75] Iter[551/1177]	  loss: 0.38cifar10:0.2-instance | Epoch [ 17/ 75] Iter[601/1177]	  loss: 0.29cifar10:0.2-instance | Epoch [ 17/ 75] Iter[651/1177]	  loss: 0.94cifar10:0.2-instance | Epoch [ 17/ 75] Iter[701/1177]	  loss: 0.48cifar10:0.2-instance | Epoch [ 17/ 75] Iter[751/1177]	  loss: 0.44cifar10:0.2-instance | Epoch [ 17/ 75] Iter[801/1177]	  loss: 0.28cifar10:0.2-instance | Epoch [ 17/ 75] Iter[851/1177]	  loss: 0.46cifar10:0.2-instance | Epoch [ 17/ 75] Iter[901/1177]	  loss: 0.43cifar10:0.2-instance | Epoch [ 17/ 75] Iter[951/1177]	  loss: 0.52cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1001/1177]	  loss: 0.61cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1051/1177]	  loss: 0.49cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1101/1177]	  loss: 0.48cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1151/1177]	  loss: 0.29
| Test Epoch 17	 Accuracy: 81.89% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 18 | Accuracy on train set: 68.40% 
labeled data has a size of 38042, f-score: 0.983729
cifar10:0.2-instance | Epoch [ 18/ 75] Iter[  1/1189]	  loss: 0.52cifar10:0.2-instance | Epoch [ 18/ 75] Iter[ 51/1189]	  loss: 0.42cifar10:0.2-instance | Epoch [ 18/ 75] Iter[101/1189]	  loss: 0.57cifar10:0.2-instance | Epoch [ 18/ 75] Iter[151/1189]	  loss: 0.47cifar10:0.2-instance | Epoch [ 18/ 75] Iter[201/1189]	  loss: 0.60cifar10:0.2-instance | Epoch [ 18/ 75] Iter[251/1189]	  loss: 0.34cifar10:0.2-instance | Epoch [ 18/ 75] Iter[301/1189]	  loss: 0.30cifar10:0.2-instance | Epoch [ 18/ 75] Iter[351/1189]	  loss: 0.34cifar10:0.2-instance | Epoch [ 18/ 75] Iter[401/1189]	  loss: 0.47cifar10:0.2-instance | Epoch [ 18/ 75] Iter[451/1189]	  loss: 0.52cifar10:0.2-instance | Epoch [ 18/ 75] Iter[501/1189]	  loss: 0.39cifar10:0.2-instance | Epoch [ 18/ 75] Iter[551/1189]	  loss: 0.34cifar10:0.2-instance | Epoch [ 18/ 75] Iter[601/1189]	  loss: 0.37cifar10:0.2-instance | Epoch [ 18/ 75] Iter[651/1189]	  loss: 0.28cifar10:0.2-instance | Epoch [ 18/ 75] Iter[701/1189]	  loss: 0.38cifar10:0.2-instance | Epoch [ 18/ 75] Iter[751/1189]	  loss: 0.27cifar10:0.2-instance | Epoch [ 18/ 75] Iter[801/1189]	  loss: 0.74cifar10:0.2-instance | Epoch [ 18/ 75] Iter[851/1189]	  loss: 0.45cifar10:0.2-instance | Epoch [ 18/ 75] Iter[901/1189]	  loss: 0.31cifar10:0.2-instance | Epoch [ 18/ 75] Iter[951/1189]	  loss: 0.35cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1001/1189]	  loss: 0.60cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1051/1189]	  loss: 0.53cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1101/1189]	  loss: 0.55cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1151/1189]	  loss: 0.47
| Test Epoch 18	 Accuracy: 83.47% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 19 | Accuracy on train set: 69.61% 
labeled data has a size of 38253, f-score: 0.983452
cifar10:0.2-instance | Epoch [ 19/ 75] Iter[  1/1196]	  loss: 0.57cifar10:0.2-instance | Epoch [ 19/ 75] Iter[ 51/1196]	  loss: 0.53cifar10:0.2-instance | Epoch [ 19/ 75] Iter[101/1196]	  loss: 0.28cifar10:0.2-instance | Epoch [ 19/ 75] Iter[151/1196]	  loss: 0.46cifar10:0.2-instance | Epoch [ 19/ 75] Iter[201/1196]	  loss: 0.41cifar10:0.2-instance | Epoch [ 19/ 75] Iter[251/1196]	  loss: 0.38cifar10:0.2-instance | Epoch [ 19/ 75] Iter[301/1196]	  loss: 0.36cifar10:0.2-instance | Epoch [ 19/ 75] Iter[351/1196]	  loss: 0.43cifar10:0.2-instance | Epoch [ 19/ 75] Iter[401/1196]	  loss: 0.42cifar10:0.2-instance | Epoch [ 19/ 75] Iter[451/1196]	  loss: 0.38cifar10:0.2-instance | Epoch [ 19/ 75] Iter[501/1196]	  loss: 0.34cifar10:0.2-instance | Epoch [ 19/ 75] Iter[551/1196]	  loss: 0.54cifar10:0.2-instance | Epoch [ 19/ 75] Iter[601/1196]	  loss: 0.56cifar10:0.2-instance | Epoch [ 19/ 75] Iter[651/1196]	  loss: 0.41cifar10:0.2-instance | Epoch [ 19/ 75] Iter[701/1196]	  loss: 0.40cifar10:0.2-instance | Epoch [ 19/ 75] Iter[751/1196]	  loss: 0.42cifar10:0.2-instance | Epoch [ 19/ 75] Iter[801/1196]	  loss: 0.47cifar10:0.2-instance | Epoch [ 19/ 75] Iter[851/1196]	  loss: 0.62cifar10:0.2-instance | Epoch [ 19/ 75] Iter[901/1196]	  loss: 0.35cifar10:0.2-instance | Epoch [ 19/ 75] Iter[951/1196]	  loss: 0.55cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1001/1196]	  loss: 0.28cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1051/1196]	  loss: 0.33cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1101/1196]	  loss: 0.48cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1151/1196]	  loss: 0.40
| Test Epoch 19	 Accuracy: 81.87% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 20 | Accuracy on train set: 68.17% 
labeled data has a size of 38458, f-score: 0.982448
cifar10:0.2-instance | Epoch [ 20/ 75] Iter[  1/1202]	  loss: 0.30cifar10:0.2-instance | Epoch [ 20/ 75] Iter[ 51/1202]	  loss: 0.49cifar10:0.2-instance | Epoch [ 20/ 75] Iter[101/1202]	  loss: 0.23cifar10:0.2-instance | Epoch [ 20/ 75] Iter[151/1202]	  loss: 0.32cifar10:0.2-instance | Epoch [ 20/ 75] Iter[201/1202]	  loss: 0.77cifar10:0.2-instance | Epoch [ 20/ 75] Iter[251/1202]	  loss: 0.56cifar10:0.2-instance | Epoch [ 20/ 75] Iter[301/1202]	  loss: 0.50cifar10:0.2-instance | Epoch [ 20/ 75] Iter[351/1202]	  loss: 0.37cifar10:0.2-instance | Epoch [ 20/ 75] Iter[401/1202]	  loss: 0.60cifar10:0.2-instance | Epoch [ 20/ 75] Iter[451/1202]	  loss: 0.20cifar10:0.2-instance | Epoch [ 20/ 75] Iter[501/1202]	  loss: 0.44cifar10:0.2-instance | Epoch [ 20/ 75] Iter[551/1202]	  loss: 0.32cifar10:0.2-instance | Epoch [ 20/ 75] Iter[601/1202]	  loss: 0.33cifar10:0.2-instance | Epoch [ 20/ 75] Iter[651/1202]	  loss: 0.44cifar10:0.2-instance | Epoch [ 20/ 75] Iter[701/1202]	  loss: 0.61cifar10:0.2-instance | Epoch [ 20/ 75] Iter[751/1202]	  loss: 0.53cifar10:0.2-instance | Epoch [ 20/ 75] Iter[801/1202]	  loss: 0.43cifar10:0.2-instance | Epoch [ 20/ 75] Iter[851/1202]	  loss: 0.31cifar10:0.2-instance | Epoch [ 20/ 75] Iter[901/1202]	  loss: 0.38cifar10:0.2-instance | Epoch [ 20/ 75] Iter[951/1202]	  loss: 0.40cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1001/1202]	  loss: 0.67cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1051/1202]	  loss: 0.35cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1101/1202]	  loss: 0.46cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1151/1202]	  loss: 0.31cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1201/1202]	  loss: 0.43
| Test Epoch 20	 Accuracy: 83.35% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 21 | Accuracy on train set: 69.77% 
labeled data has a size of 38495, f-score: 0.983141
cifar10:0.2-instance | Epoch [ 21/ 75] Iter[  1/1203]	  loss: 0.43cifar10:0.2-instance | Epoch [ 21/ 75] Iter[ 51/1203]	  loss: 0.30cifar10:0.2-instance | Epoch [ 21/ 75] Iter[101/1203]	  loss: 0.66cifar10:0.2-instance | Epoch [ 21/ 75] Iter[151/1203]	  loss: 0.53cifar10:0.2-instance | Epoch [ 21/ 75] Iter[201/1203]	  loss: 0.52cifar10:0.2-instance | Epoch [ 21/ 75] Iter[251/1203]	  loss: 0.41cifar10:0.2-instance | Epoch [ 21/ 75] Iter[301/1203]	  loss: 0.41cifar10:0.2-instance | Epoch [ 21/ 75] Iter[351/1203]	  loss: 0.71cifar10:0.2-instance | Epoch [ 21/ 75] Iter[401/1203]	  loss: 0.52cifar10:0.2-instance | Epoch [ 21/ 75] Iter[451/1203]	  loss: 0.44cifar10:0.2-instance | Epoch [ 21/ 75] Iter[501/1203]	  loss: 0.43cifar10:0.2-instance | Epoch [ 21/ 75] Iter[551/1203]	  loss: 0.63cifar10:0.2-instance | Epoch [ 21/ 75] Iter[601/1203]	  loss: 0.32cifar10:0.2-instance | Epoch [ 21/ 75] Iter[651/1203]	  loss: 0.28cifar10:0.2-instance | Epoch [ 21/ 75] Iter[701/1203]	  loss: 0.60cifar10:0.2-instance | Epoch [ 21/ 75] Iter[751/1203]	  loss: 0.21cifar10:0.2-instance | Epoch [ 21/ 75] Iter[801/1203]	  loss: 0.48cifar10:0.2-instance | Epoch [ 21/ 75] Iter[851/1203]	  loss: 0.36cifar10:0.2-instance | Epoch [ 21/ 75] Iter[901/1203]	  loss: 0.48cifar10:0.2-instance | Epoch [ 21/ 75] Iter[951/1203]	  loss: 0.48cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1001/1203]	  loss: 0.57cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1051/1203]	  loss: 0.57cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1101/1203]	  loss: 0.53cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1151/1203]	  loss: 0.45cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1201/1203]	  loss: 0.75
| Test Epoch 21	 Accuracy: 81.76% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 22 | Accuracy on train set: 68.59% 
labeled data has a size of 38233, f-score: 0.981979
cifar10:0.2-instance | Epoch [ 22/ 75] Iter[  1/1195]	  loss: 0.47cifar10:0.2-instance | Epoch [ 22/ 75] Iter[ 51/1195]	  loss: 0.57cifar10:0.2-instance | Epoch [ 22/ 75] Iter[101/1195]	  loss: 0.44cifar10:0.2-instance | Epoch [ 22/ 75] Iter[151/1195]	  loss: 0.39cifar10:0.2-instance | Epoch [ 22/ 75] Iter[201/1195]	  loss: 0.35cifar10:0.2-instance | Epoch [ 22/ 75] Iter[251/1195]	  loss: 0.84cifar10:0.2-instance | Epoch [ 22/ 75] Iter[301/1195]	  loss: 0.64cifar10:0.2-instance | Epoch [ 22/ 75] Iter[351/1195]	  loss: 0.58cifar10:0.2-instance | Epoch [ 22/ 75] Iter[401/1195]	  loss: 0.27cifar10:0.2-instance | Epoch [ 22/ 75] Iter[451/1195]	  loss: 0.47cifar10:0.2-instance | Epoch [ 22/ 75] Iter[501/1195]	  loss: 0.27cifar10:0.2-instance | Epoch [ 22/ 75] Iter[551/1195]	  loss: 0.36cifar10:0.2-instance | Epoch [ 22/ 75] Iter[601/1195]	  loss: 0.56cifar10:0.2-instance | Epoch [ 22/ 75] Iter[651/1195]	  loss: 0.56cifar10:0.2-instance | Epoch [ 22/ 75] Iter[701/1195]	  loss: 0.38cifar10:0.2-instance | Epoch [ 22/ 75] Iter[751/1195]	  loss: 0.49cifar10:0.2-instance | Epoch [ 22/ 75] Iter[801/1195]	  loss: 0.52cifar10:0.2-instance | Epoch [ 22/ 75] Iter[851/1195]	  loss: 0.30cifar10:0.2-instance | Epoch [ 22/ 75] Iter[901/1195]	  loss: 0.29cifar10:0.2-instance | Epoch [ 22/ 75] Iter[951/1195]	  loss: 0.41cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1001/1195]	  loss: 0.51cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1051/1195]	  loss: 0.32cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1101/1195]	  loss: 0.31cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1151/1195]	  loss: 0.42
| Test Epoch 22	 Accuracy: 83.99% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 23 | Accuracy on train set: 70.12% 
labeled data has a size of 38462, f-score: 0.981176
cifar10:0.2-instance | Epoch [ 23/ 75] Iter[  1/1202]	  loss: 0.35cifar10:0.2-instance | Epoch [ 23/ 75] Iter[ 51/1202]	  loss: 0.32cifar10:0.2-instance | Epoch [ 23/ 75] Iter[101/1202]	  loss: 0.29cifar10:0.2-instance | Epoch [ 23/ 75] Iter[151/1202]	  loss: 0.39cifar10:0.2-instance | Epoch [ 23/ 75] Iter[201/1202]	  loss: 0.57cifar10:0.2-instance | Epoch [ 23/ 75] Iter[251/1202]	  loss: 0.55cifar10:0.2-instance | Epoch [ 23/ 75] Iter[301/1202]	  loss: 0.33cifar10:0.2-instance | Epoch [ 23/ 75] Iter[351/1202]	  loss: 0.40cifar10:0.2-instance | Epoch [ 23/ 75] Iter[401/1202]	  loss: 0.58cifar10:0.2-instance | Epoch [ 23/ 75] Iter[451/1202]	  loss: 0.67cifar10:0.2-instance | Epoch [ 23/ 75] Iter[501/1202]	  loss: 0.38cifar10:0.2-instance | Epoch [ 23/ 75] Iter[551/1202]	  loss: 0.54cifar10:0.2-instance | Epoch [ 23/ 75] Iter[601/1202]	  loss: 0.45cifar10:0.2-instance | Epoch [ 23/ 75] Iter[651/1202]	  loss: 0.40cifar10:0.2-instance | Epoch [ 23/ 75] Iter[701/1202]	  loss: 0.31cifar10:0.2-instance | Epoch [ 23/ 75] Iter[751/1202]	  loss: 0.34cifar10:0.2-instance | Epoch [ 23/ 75] Iter[801/1202]	  loss: 0.67cifar10:0.2-instance | Epoch [ 23/ 75] Iter[851/1202]	  loss: 0.37cifar10:0.2-instance | Epoch [ 23/ 75] Iter[901/1202]	  loss: 0.51cifar10:0.2-instance | Epoch [ 23/ 75] Iter[951/1202]	  loss: 0.39cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1001/1202]	  loss: 0.23cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1051/1202]	  loss: 0.30cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1101/1202]	  loss: 0.67cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1151/1202]	  loss: 0.33cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1201/1202]	  loss: 0.46
| Test Epoch 23	 Accuracy: 81.93% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 24 | Accuracy on train set: 68.51% 
labeled data has a size of 38608, f-score: 0.979849
cifar10:0.2-instance | Epoch [ 24/ 75] Iter[  1/1207]	  loss: 0.64cifar10:0.2-instance | Epoch [ 24/ 75] Iter[ 51/1207]	  loss: 0.33cifar10:0.2-instance | Epoch [ 24/ 75] Iter[101/1207]	  loss: 0.29cifar10:0.2-instance | Epoch [ 24/ 75] Iter[151/1207]	  loss: 0.58cifar10:0.2-instance | Epoch [ 24/ 75] Iter[201/1207]	  loss: 0.22cifar10:0.2-instance | Epoch [ 24/ 75] Iter[251/1207]	  loss: 0.30cifar10:0.2-instance | Epoch [ 24/ 75] Iter[301/1207]	  loss: 0.46cifar10:0.2-instance | Epoch [ 24/ 75] Iter[351/1207]	  loss: 0.73cifar10:0.2-instance | Epoch [ 24/ 75] Iter[401/1207]	  loss: 0.73cifar10:0.2-instance | Epoch [ 24/ 75] Iter[451/1207]	  loss: 0.59cifar10:0.2-instance | Epoch [ 24/ 75] Iter[501/1207]	  loss: 0.37cifar10:0.2-instance | Epoch [ 24/ 75] Iter[551/1207]	  loss: 0.38cifar10:0.2-instance | Epoch [ 24/ 75] Iter[601/1207]	  loss: 0.45cifar10:0.2-instance | Epoch [ 24/ 75] Iter[651/1207]	  loss: 0.27cifar10:0.2-instance | Epoch [ 24/ 75] Iter[701/1207]	  loss: 0.33cifar10:0.2-instance | Epoch [ 24/ 75] Iter[751/1207]	  loss: 0.47cifar10:0.2-instance | Epoch [ 24/ 75] Iter[801/1207]	  loss: 0.21cifar10:0.2-instance | Epoch [ 24/ 75] Iter[851/1207]	  loss: 0.44cifar10:0.2-instance | Epoch [ 24/ 75] Iter[901/1207]	  loss: 0.21cifar10:0.2-instance | Epoch [ 24/ 75] Iter[951/1207]	  loss: 0.40cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1001/1207]	  loss: 0.54cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1051/1207]	  loss: 0.22cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1101/1207]	  loss: 0.53cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1151/1207]	  loss: 0.42cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1201/1207]	  loss: 0.26
| Test Epoch 24	 Accuracy: 82.06% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 25 | Accuracy on train set: 68.85% 
labeled data has a size of 38676, f-score: 0.980375
cifar10:0.2-instance | Epoch [ 25/ 75] Iter[  1/1209]	  loss: 0.48cifar10:0.2-instance | Epoch [ 25/ 75] Iter[ 51/1209]	  loss: 0.29cifar10:0.2-instance | Epoch [ 25/ 75] Iter[101/1209]	  loss: 0.37cifar10:0.2-instance | Epoch [ 25/ 75] Iter[151/1209]	  loss: 0.47cifar10:0.2-instance | Epoch [ 25/ 75] Iter[201/1209]	  loss: 0.43cifar10:0.2-instance | Epoch [ 25/ 75] Iter[251/1209]	  loss: 0.36cifar10:0.2-instance | Epoch [ 25/ 75] Iter[301/1209]	  loss: 0.47cifar10:0.2-instance | Epoch [ 25/ 75] Iter[351/1209]	  loss: 0.28cifar10:0.2-instance | Epoch [ 25/ 75] Iter[401/1209]	  loss: 0.68cifar10:0.2-instance | Epoch [ 25/ 75] Iter[451/1209]	  loss: 0.35cifar10:0.2-instance | Epoch [ 25/ 75] Iter[501/1209]	  loss: 0.46cifar10:0.2-instance | Epoch [ 25/ 75] Iter[551/1209]	  loss: 0.47cifar10:0.2-instance | Epoch [ 25/ 75] Iter[601/1209]	  loss: 0.69cifar10:0.2-instance | Epoch [ 25/ 75] Iter[651/1209]	  loss: 0.34cifar10:0.2-instance | Epoch [ 25/ 75] Iter[701/1209]	  loss: 0.58cifar10:0.2-instance | Epoch [ 25/ 75] Iter[751/1209]	  loss: 0.46cifar10:0.2-instance | Epoch [ 25/ 75] Iter[801/1209]	  loss: 0.28cifar10:0.2-instance | Epoch [ 25/ 75] Iter[851/1209]	  loss: 0.59cifar10:0.2-instance | Epoch [ 25/ 75] Iter[901/1209]	  loss: 0.26cifar10:0.2-instance | Epoch [ 25/ 75] Iter[951/1209]	  loss: 0.29cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1001/1209]	  loss: 0.57cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1051/1209]	  loss: 0.52cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1101/1209]	  loss: 0.44cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1151/1209]	  loss: 0.28cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1201/1209]	  loss: 0.24
| Test Epoch 25	 Accuracy: 85.45% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 26 | Accuracy on train set: 71.36% 
labeled data has a size of 38627, f-score: 0.981774
cifar10:0.2-instance | Epoch [ 26/ 75] Iter[  1/1208]	  loss: 0.33cifar10:0.2-instance | Epoch [ 26/ 75] Iter[ 51/1208]	  loss: 0.38cifar10:0.2-instance | Epoch [ 26/ 75] Iter[101/1208]	  loss: 0.49cifar10:0.2-instance | Epoch [ 26/ 75] Iter[151/1208]	  loss: 0.65cifar10:0.2-instance | Epoch [ 26/ 75] Iter[201/1208]	  loss: 0.70cifar10:0.2-instance | Epoch [ 26/ 75] Iter[251/1208]	  loss: 0.34cifar10:0.2-instance | Epoch [ 26/ 75] Iter[301/1208]	  loss: 0.27cifar10:0.2-instance | Epoch [ 26/ 75] Iter[351/1208]	  loss: 0.60cifar10:0.2-instance | Epoch [ 26/ 75] Iter[401/1208]	  loss: 0.47cifar10:0.2-instance | Epoch [ 26/ 75] Iter[451/1208]	  loss: 0.53cifar10:0.2-instance | Epoch [ 26/ 75] Iter[501/1208]	  loss: 0.43cifar10:0.2-instance | Epoch [ 26/ 75] Iter[551/1208]	  loss: 0.41cifar10:0.2-instance | Epoch [ 26/ 75] Iter[601/1208]	  loss: 0.39cifar10:0.2-instance | Epoch [ 26/ 75] Iter[651/1208]	  loss: 0.28cifar10:0.2-instance | Epoch [ 26/ 75] Iter[701/1208]	  loss: 0.47cifar10:0.2-instance | Epoch [ 26/ 75] Iter[751/1208]	  loss: 0.36cifar10:0.2-instance | Epoch [ 26/ 75] Iter[801/1208]	  loss: 0.31cifar10:0.2-instance | Epoch [ 26/ 75] Iter[851/1208]	  loss: 0.49cifar10:0.2-instance | Epoch [ 26/ 75] Iter[901/1208]	  loss: 0.52cifar10:0.2-instance | Epoch [ 26/ 75] Iter[951/1208]	  loss: 0.55cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1001/1208]	  loss: 0.37cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1051/1208]	  loss: 0.22cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1101/1208]	  loss: 0.40cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1151/1208]	  loss: 0.52cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1201/1208]	  loss: 0.51
| Test Epoch 26	 Accuracy: 82.98% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 27 | Accuracy on train set: 69.53% 
labeled data has a size of 38578, f-score: 0.982036
cifar10:0.2-instance | Epoch [ 27/ 75] Iter[  1/1206]	  loss: 0.51cifar10:0.2-instance | Epoch [ 27/ 75] Iter[ 51/1206]	  loss: 0.75cifar10:0.2-instance | Epoch [ 27/ 75] Iter[101/1206]	  loss: 0.31cifar10:0.2-instance | Epoch [ 27/ 75] Iter[151/1206]	  loss: 0.45cifar10:0.2-instance | Epoch [ 27/ 75] Iter[201/1206]	  loss: 0.23cifar10:0.2-instance | Epoch [ 27/ 75] Iter[251/1206]	  loss: 0.23cifar10:0.2-instance | Epoch [ 27/ 75] Iter[301/1206]	  loss: 0.45cifar10:0.2-instance | Epoch [ 27/ 75] Iter[351/1206]	  loss: 0.46cifar10:0.2-instance | Epoch [ 27/ 75] Iter[401/1206]	  loss: 0.33cifar10:0.2-instance | Epoch [ 27/ 75] Iter[451/1206]	  loss: 0.39cifar10:0.2-instance | Epoch [ 27/ 75] Iter[501/1206]	  loss: 0.44cifar10:0.2-instance | Epoch [ 27/ 75] Iter[551/1206]	  loss: 0.36cifar10:0.2-instance | Epoch [ 27/ 75] Iter[601/1206]	  loss: 0.37cifar10:0.2-instance | Epoch [ 27/ 75] Iter[651/1206]	  loss: 0.34cifar10:0.2-instance | Epoch [ 27/ 75] Iter[701/1206]	  loss: 0.52cifar10:0.2-instance | Epoch [ 27/ 75] Iter[751/1206]	  loss: 0.46cifar10:0.2-instance | Epoch [ 27/ 75] Iter[801/1206]	  loss: 0.27cifar10:0.2-instance | Epoch [ 27/ 75] Iter[851/1206]	  loss: 0.43cifar10:0.2-instance | Epoch [ 27/ 75] Iter[901/1206]	  loss: 0.49cifar10:0.2-instance | Epoch [ 27/ 75] Iter[951/1206]	  loss: 0.37cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1001/1206]	  loss: 0.40cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1051/1206]	  loss: 0.52cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1101/1206]	  loss: 0.37cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1151/1206]	  loss: 0.38cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1201/1206]	  loss: 0.54
| Test Epoch 27	 Accuracy: 84.18% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 28 | Accuracy on train set: 70.47% 
labeled data has a size of 38749, f-score: 0.981109
cifar10:0.2-instance | Epoch [ 28/ 75] Iter[  1/1211]	  loss: 0.35cifar10:0.2-instance | Epoch [ 28/ 75] Iter[ 51/1211]	  loss: 0.44cifar10:0.2-instance | Epoch [ 28/ 75] Iter[101/1211]	  loss: 0.35cifar10:0.2-instance | Epoch [ 28/ 75] Iter[151/1211]	  loss: 0.58cifar10:0.2-instance | Epoch [ 28/ 75] Iter[201/1211]	  loss: 0.58cifar10:0.2-instance | Epoch [ 28/ 75] Iter[251/1211]	  loss: 0.48cifar10:0.2-instance | Epoch [ 28/ 75] Iter[301/1211]	  loss: 0.28cifar10:0.2-instance | Epoch [ 28/ 75] Iter[351/1211]	  loss: 0.57cifar10:0.2-instance | Epoch [ 28/ 75] Iter[401/1211]	  loss: 0.41cifar10:0.2-instance | Epoch [ 28/ 75] Iter[451/1211]	  loss: 0.38cifar10:0.2-instance | Epoch [ 28/ 75] Iter[501/1211]	  loss: 0.52cifar10:0.2-instance | Epoch [ 28/ 75] Iter[551/1211]	  loss: 0.40cifar10:0.2-instance | Epoch [ 28/ 75] Iter[601/1211]	  loss: 0.48cifar10:0.2-instance | Epoch [ 28/ 75] Iter[651/1211]	  loss: 0.37cifar10:0.2-instance | Epoch [ 28/ 75] Iter[701/1211]	  loss: 0.77cifar10:0.2-instance | Epoch [ 28/ 75] Iter[751/1211]	  loss: 0.44cifar10:0.2-instance | Epoch [ 28/ 75] Iter[801/1211]	  loss: 0.36cifar10:0.2-instance | Epoch [ 28/ 75] Iter[851/1211]	  loss: 0.38cifar10:0.2-instance | Epoch [ 28/ 75] Iter[901/1211]	  loss: 0.43cifar10:0.2-instance | Epoch [ 28/ 75] Iter[951/1211]	  loss: 0.39cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1001/1211]	  loss: 0.26cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1051/1211]	  loss: 0.60cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1101/1211]	  loss: 0.36cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1151/1211]	  loss: 0.48cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1201/1211]	  loss: 0.48
| Test Epoch 28	 Accuracy: 85.03% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 29 | Accuracy on train set: 71.07% 
labeled data has a size of 38736, f-score: 0.980716
cifar10:0.2-instance | Epoch [ 29/ 75] Iter[  1/1211]	  loss: 0.48cifar10:0.2-instance | Epoch [ 29/ 75] Iter[ 51/1211]	  loss: 0.33cifar10:0.2-instance | Epoch [ 29/ 75] Iter[101/1211]	  loss: 0.29cifar10:0.2-instance | Epoch [ 29/ 75] Iter[151/1211]	  loss: 0.47cifar10:0.2-instance | Epoch [ 29/ 75] Iter[201/1211]	  loss: 0.42cifar10:0.2-instance | Epoch [ 29/ 75] Iter[251/1211]	  loss: 0.43cifar10:0.2-instance | Epoch [ 29/ 75] Iter[301/1211]	  loss: 0.35cifar10:0.2-instance | Epoch [ 29/ 75] Iter[351/1211]	  loss: 0.54cifar10:0.2-instance | Epoch [ 29/ 75] Iter[401/1211]	  loss: 0.32cifar10:0.2-instance | Epoch [ 29/ 75] Iter[451/1211]	  loss: 0.35cifar10:0.2-instance | Epoch [ 29/ 75] Iter[501/1211]	  loss: 0.29cifar10:0.2-instance | Epoch [ 29/ 75] Iter[551/1211]	  loss: 0.25cifar10:0.2-instance | Epoch [ 29/ 75] Iter[601/1211]	  loss: 0.39cifar10:0.2-instance | Epoch [ 29/ 75] Iter[651/1211]	  loss: 0.68cifar10:0.2-instance | Epoch [ 29/ 75] Iter[701/1211]	  loss: 0.53cifar10:0.2-instance | Epoch [ 29/ 75] Iter[751/1211]	  loss: 0.37cifar10:0.2-instance | Epoch [ 29/ 75] Iter[801/1211]	  loss: 0.23cifar10:0.2-instance | Epoch [ 29/ 75] Iter[851/1211]	  loss: 0.70cifar10:0.2-instance | Epoch [ 29/ 75] Iter[901/1211]	  loss: 0.20cifar10:0.2-instance | Epoch [ 29/ 75] Iter[951/1211]	  loss: 0.48cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1001/1211]	  loss: 0.32cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1051/1211]	  loss: 0.35cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1101/1211]	  loss: 0.40cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1151/1211]	  loss: 0.51cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1201/1211]	  loss: 0.33
| Test Epoch 29	 Accuracy: 84.91% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 30 | Accuracy on train set: 71.47% 
labeled data has a size of 38837, f-score: 0.982671
cifar10:0.2-instance | Epoch [ 30/ 75] Iter[  1/1214]	  loss: 0.32cifar10:0.2-instance | Epoch [ 30/ 75] Iter[ 51/1214]	  loss: 0.50cifar10:0.2-instance | Epoch [ 30/ 75] Iter[101/1214]	  loss: 0.43cifar10:0.2-instance | Epoch [ 30/ 75] Iter[151/1214]	  loss: 0.42cifar10:0.2-instance | Epoch [ 30/ 75] Iter[201/1214]	  loss: 0.47cifar10:0.2-instance | Epoch [ 30/ 75] Iter[251/1214]	  loss: 0.41cifar10:0.2-instance | Epoch [ 30/ 75] Iter[301/1214]	  loss: 0.43cifar10:0.2-instance | Epoch [ 30/ 75] Iter[351/1214]	  loss: 0.78cifar10:0.2-instance | Epoch [ 30/ 75] Iter[401/1214]	  loss: 0.37cifar10:0.2-instance | Epoch [ 30/ 75] Iter[451/1214]	  loss: 0.44cifar10:0.2-instance | Epoch [ 30/ 75] Iter[501/1214]	  loss: 0.30cifar10:0.2-instance | Epoch [ 30/ 75] Iter[551/1214]	  loss: 0.36cifar10:0.2-instance | Epoch [ 30/ 75] Iter[601/1214]	  loss: 0.28cifar10:0.2-instance | Epoch [ 30/ 75] Iter[651/1214]	  loss: 0.28cifar10:0.2-instance | Epoch [ 30/ 75] Iter[701/1214]	  loss: 0.48cifar10:0.2-instance | Epoch [ 30/ 75] Iter[751/1214]	  loss: 0.34cifar10:0.2-instance | Epoch [ 30/ 75] Iter[801/1214]	  loss: 0.34cifar10:0.2-instance | Epoch [ 30/ 75] Iter[851/1214]	  loss: 0.53cifar10:0.2-instance | Epoch [ 30/ 75] Iter[901/1214]	  loss: 0.39cifar10:0.2-instance | Epoch [ 30/ 75] Iter[951/1214]	  loss: 0.41cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1001/1214]	  loss: 0.47cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1051/1214]	  loss: 0.26cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1101/1214]	  loss: 0.38cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1151/1214]	  loss: 0.76cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1201/1214]	  loss: 0.54
| Test Epoch 30	 Accuracy: 85.06% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 31 | Accuracy on train set: 71.15% 
labeled data has a size of 38771, f-score: 0.984034
cifar10:0.2-instance | Epoch [ 31/ 75] Iter[  1/1212]	  loss: 0.20cifar10:0.2-instance | Epoch [ 31/ 75] Iter[ 51/1212]	  loss: 0.61cifar10:0.2-instance | Epoch [ 31/ 75] Iter[101/1212]	  loss: 0.44cifar10:0.2-instance | Epoch [ 31/ 75] Iter[151/1212]	  loss: 0.26cifar10:0.2-instance | Epoch [ 31/ 75] Iter[201/1212]	  loss: 0.37cifar10:0.2-instance | Epoch [ 31/ 75] Iter[251/1212]	  loss: 0.55cifar10:0.2-instance | Epoch [ 31/ 75] Iter[301/1212]	  loss: 0.55cifar10:0.2-instance | Epoch [ 31/ 75] Iter[351/1212]	  loss: 0.23cifar10:0.2-instance | Epoch [ 31/ 75] Iter[401/1212]	  loss: 0.56cifar10:0.2-instance | Epoch [ 31/ 75] Iter[451/1212]	  loss: 0.50cifar10:0.2-instance | Epoch [ 31/ 75] Iter[501/1212]	  loss: 0.52cifar10:0.2-instance | Epoch [ 31/ 75] Iter[551/1212]	  loss: 0.46cifar10:0.2-instance | Epoch [ 31/ 75] Iter[601/1212]	  loss: 0.52cifar10:0.2-instance | Epoch [ 31/ 75] Iter[651/1212]	  loss: 0.37cifar10:0.2-instance | Epoch [ 31/ 75] Iter[701/1212]	  loss: 0.47cifar10:0.2-instance | Epoch [ 31/ 75] Iter[751/1212]	  loss: 0.44cifar10:0.2-instance | Epoch [ 31/ 75] Iter[801/1212]	  loss: 0.46cifar10:0.2-instance | Epoch [ 31/ 75] Iter[851/1212]	  loss: 0.38cifar10:0.2-instance | Epoch [ 31/ 75] Iter[901/1212]	  loss: 0.28cifar10:0.2-instance | Epoch [ 31/ 75] Iter[951/1212]	  loss: 0.35cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1001/1212]	  loss: 0.41cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1051/1212]	  loss: 0.36cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1101/1212]	  loss: 0.41cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1151/1212]	  loss: 0.34cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1201/1212]	  loss: 0.43
| Test Epoch 31	 Accuracy: 84.69% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 32 | Accuracy on train set: 71.26% 
labeled data has a size of 38924, f-score: 0.982016
cifar10:0.2-instance | Epoch [ 32/ 75] Iter[  1/1217]	  loss: 0.35cifar10:0.2-instance | Epoch [ 32/ 75] Iter[ 51/1217]	  loss: 0.43cifar10:0.2-instance | Epoch [ 32/ 75] Iter[101/1217]	  loss: 0.49cifar10:0.2-instance | Epoch [ 32/ 75] Iter[151/1217]	  loss: 0.70cifar10:0.2-instance | Epoch [ 32/ 75] Iter[201/1217]	  loss: 0.28cifar10:0.2-instance | Epoch [ 32/ 75] Iter[251/1217]	  loss: 0.53cifar10:0.2-instance | Epoch [ 32/ 75] Iter[301/1217]	  loss: 0.49cifar10:0.2-instance | Epoch [ 32/ 75] Iter[351/1217]	  loss: 0.58cifar10:0.2-instance | Epoch [ 32/ 75] Iter[401/1217]	  loss: 0.40cifar10:0.2-instance | Epoch [ 32/ 75] Iter[451/1217]	  loss: 0.41cifar10:0.2-instance | Epoch [ 32/ 75] Iter[501/1217]	  loss: 0.20cifar10:0.2-instance | Epoch [ 32/ 75] Iter[551/1217]	  loss: 0.35cifar10:0.2-instance | Epoch [ 32/ 75] Iter[601/1217]	  loss: 0.32cifar10:0.2-instance | Epoch [ 32/ 75] Iter[651/1217]	  loss: 0.51cifar10:0.2-instance | Epoch [ 32/ 75] Iter[701/1217]	  loss: 0.45cifar10:0.2-instance | Epoch [ 32/ 75] Iter[751/1217]	  loss: 0.72cifar10:0.2-instance | Epoch [ 32/ 75] Iter[801/1217]	  loss: 0.63cifar10:0.2-instance | Epoch [ 32/ 75] Iter[851/1217]	  loss: 0.43cifar10:0.2-instance | Epoch [ 32/ 75] Iter[901/1217]	  loss: 0.44cifar10:0.2-instance | Epoch [ 32/ 75] Iter[951/1217]	  loss: 0.55cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1001/1217]	  loss: 0.59cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1051/1217]	  loss: 0.25cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1101/1217]	  loss: 0.25cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1151/1217]	  loss: 0.73cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1201/1217]	  loss: 0.27
| Test Epoch 32	 Accuracy: 85.28% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 33 | Accuracy on train set: 71.62% 
labeled data has a size of 39003, f-score: 0.981412
cifar10:0.2-instance | Epoch [ 33/ 75] Iter[  1/1219]	  loss: 0.45cifar10:0.2-instance | Epoch [ 33/ 75] Iter[ 51/1219]	  loss: 0.28cifar10:0.2-instance | Epoch [ 33/ 75] Iter[101/1219]	  loss: 0.26cifar10:0.2-instance | Epoch [ 33/ 75] Iter[151/1219]	  loss: 0.38cifar10:0.2-instance | Epoch [ 33/ 75] Iter[201/1219]	  loss: 0.40cifar10:0.2-instance | Epoch [ 33/ 75] Iter[251/1219]	  loss: 0.43cifar10:0.2-instance | Epoch [ 33/ 75] Iter[301/1219]	  loss: 0.48cifar10:0.2-instance | Epoch [ 33/ 75] Iter[351/1219]	  loss: 0.29cifar10:0.2-instance | Epoch [ 33/ 75] Iter[401/1219]	  loss: 0.29cifar10:0.2-instance | Epoch [ 33/ 75] Iter[451/1219]	  loss: 0.46cifar10:0.2-instance | Epoch [ 33/ 75] Iter[501/1219]	  loss: 0.57cifar10:0.2-instance | Epoch [ 33/ 75] Iter[551/1219]	  loss: 0.55cifar10:0.2-instance | Epoch [ 33/ 75] Iter[601/1219]	  loss: 0.44cifar10:0.2-instance | Epoch [ 33/ 75] Iter[651/1219]	  loss: 0.37cifar10:0.2-instance | Epoch [ 33/ 75] Iter[701/1219]	  loss: 0.36cifar10:0.2-instance | Epoch [ 33/ 75] Iter[751/1219]	  loss: 0.25cifar10:0.2-instance | Epoch [ 33/ 75] Iter[801/1219]	  loss: 0.46cifar10:0.2-instance | Epoch [ 33/ 75] Iter[851/1219]	  loss: 0.46cifar10:0.2-instance | Epoch [ 33/ 75] Iter[901/1219]	  loss: 0.49cifar10:0.2-instance | Epoch [ 33/ 75] Iter[951/1219]	  loss: 0.45cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1001/1219]	  loss: 0.72cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1051/1219]	  loss: 0.58cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1101/1219]	  loss: 0.47cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1151/1219]	  loss: 0.27cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1201/1219]	  loss: 0.54
| Test Epoch 33	 Accuracy: 83.77% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 34 | Accuracy on train set: 70.18% 
labeled data has a size of 39052, f-score: 0.982152
cifar10:0.2-instance | Epoch [ 34/ 75] Iter[  1/1221]	  loss: 0.37cifar10:0.2-instance | Epoch [ 34/ 75] Iter[ 51/1221]	  loss: 0.39cifar10:0.2-instance | Epoch [ 34/ 75] Iter[101/1221]	  loss: 0.52cifar10:0.2-instance | Epoch [ 34/ 75] Iter[151/1221]	  loss: 0.48cifar10:0.2-instance | Epoch [ 34/ 75] Iter[201/1221]	  loss: 0.60cifar10:0.2-instance | Epoch [ 34/ 75] Iter[251/1221]	  loss: 0.34cifar10:0.2-instance | Epoch [ 34/ 75] Iter[301/1221]	  loss: 0.24cifar10:0.2-instance | Epoch [ 34/ 75] Iter[351/1221]	  loss: 0.28cifar10:0.2-instance | Epoch [ 34/ 75] Iter[401/1221]	  loss: 0.36cifar10:0.2-instance | Epoch [ 34/ 75] Iter[451/1221]	  loss: 0.73cifar10:0.2-instance | Epoch [ 34/ 75] Iter[501/1221]	  loss: 0.54cifar10:0.2-instance | Epoch [ 34/ 75] Iter[551/1221]	  loss: 0.47cifar10:0.2-instance | Epoch [ 34/ 75] Iter[601/1221]	  loss: 0.42cifar10:0.2-instance | Epoch [ 34/ 75] Iter[651/1221]	  loss: 0.44cifar10:0.2-instance | Epoch [ 34/ 75] Iter[701/1221]	  loss: 0.25cifar10:0.2-instance | Epoch [ 34/ 75] Iter[751/1221]	  loss: 0.50cifar10:0.2-instance | Epoch [ 34/ 75] Iter[801/1221]	  loss: 0.63cifar10:0.2-instance | Epoch [ 34/ 75] Iter[851/1221]	  loss: 0.65cifar10:0.2-instance | Epoch [ 34/ 75] Iter[901/1221]	  loss: 0.33cifar10:0.2-instance | Epoch [ 34/ 75] Iter[951/1221]	  loss: 0.55cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1001/1221]	  loss: 0.57cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1051/1221]	  loss: 0.28cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1101/1221]	  loss: 0.29cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1151/1221]	  loss: 0.44cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1201/1221]	  loss: 0.38
| Test Epoch 34	 Accuracy: 84.68% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 35 | Accuracy on train set: 71.67% 
labeled data has a size of 39006, f-score: 0.983259
cifar10:0.2-instance | Epoch [ 35/ 75] Iter[  1/1219]	  loss: 0.30cifar10:0.2-instance | Epoch [ 35/ 75] Iter[ 51/1219]	  loss: 0.74cifar10:0.2-instance | Epoch [ 35/ 75] Iter[101/1219]	  loss: 0.29cifar10:0.2-instance | Epoch [ 35/ 75] Iter[151/1219]	  loss: 0.31cifar10:0.2-instance | Epoch [ 35/ 75] Iter[201/1219]	  loss: 0.44cifar10:0.2-instance | Epoch [ 35/ 75] Iter[251/1219]	  loss: 0.49cifar10:0.2-instance | Epoch [ 35/ 75] Iter[301/1219]	  loss: 0.40cifar10:0.2-instance | Epoch [ 35/ 75] Iter[351/1219]	  loss: 0.33cifar10:0.2-instance | Epoch [ 35/ 75] Iter[401/1219]	  loss: 0.40cifar10:0.2-instance | Epoch [ 35/ 75] Iter[451/1219]	  loss: 0.61cifar10:0.2-instance | Epoch [ 35/ 75] Iter[501/1219]	  loss: 0.34cifar10:0.2-instance | Epoch [ 35/ 75] Iter[551/1219]	  loss: 0.53cifar10:0.2-instance | Epoch [ 35/ 75] Iter[601/1219]	  loss: 0.43cifar10:0.2-instance | Epoch [ 35/ 75] Iter[651/1219]	  loss: 0.49cifar10:0.2-instance | Epoch [ 35/ 75] Iter[701/1219]	  loss: 0.52cifar10:0.2-instance | Epoch [ 35/ 75] Iter[751/1219]	  loss: 0.48cifar10:0.2-instance | Epoch [ 35/ 75] Iter[801/1219]	  loss: 0.22cifar10:0.2-instance | Epoch [ 35/ 75] Iter[851/1219]	  loss: 0.47cifar10:0.2-instance | Epoch [ 35/ 75] Iter[901/1219]	  loss: 0.48cifar10:0.2-instance | Epoch [ 35/ 75] Iter[951/1219]	  loss: 0.55cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1001/1219]	  loss: 0.36cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1051/1219]	  loss: 0.32cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1101/1219]	  loss: 0.36cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1151/1219]	  loss: 0.46cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1201/1219]	  loss: 0.50
| Test Epoch 35	 Accuracy: 86.39% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 36 | Accuracy on train set: 72.72% 
labeled data has a size of 39031, f-score: 0.984141
cifar10:0.2-instance | Epoch [ 36/ 75] Iter[  1/1220]	  loss: 0.29cifar10:0.2-instance | Epoch [ 36/ 75] Iter[ 51/1220]	  loss: 0.56cifar10:0.2-instance | Epoch [ 36/ 75] Iter[101/1220]	  loss: 0.45cifar10:0.2-instance | Epoch [ 36/ 75] Iter[151/1220]	  loss: 0.36cifar10:0.2-instance | Epoch [ 36/ 75] Iter[201/1220]	  loss: 0.39cifar10:0.2-instance | Epoch [ 36/ 75] Iter[251/1220]	  loss: 0.47cifar10:0.2-instance | Epoch [ 36/ 75] Iter[301/1220]	  loss: 0.44cifar10:0.2-instance | Epoch [ 36/ 75] Iter[351/1220]	  loss: 0.47cifar10:0.2-instance | Epoch [ 36/ 75] Iter[401/1220]	  loss: 0.55cifar10:0.2-instance | Epoch [ 36/ 75] Iter[451/1220]	  loss: 0.34cifar10:0.2-instance | Epoch [ 36/ 75] Iter[501/1220]	  loss: 0.43cifar10:0.2-instance | Epoch [ 36/ 75] Iter[551/1220]	  loss: 0.42cifar10:0.2-instance | Epoch [ 36/ 75] Iter[601/1220]	  loss: 0.65cifar10:0.2-instance | Epoch [ 36/ 75] Iter[651/1220]	  loss: 0.35cifar10:0.2-instance | Epoch [ 36/ 75] Iter[701/1220]	  loss: 0.55cifar10:0.2-instance | Epoch [ 36/ 75] Iter[751/1220]	  loss: 0.49cifar10:0.2-instance | Epoch [ 36/ 75] Iter[801/1220]	  loss: 0.44cifar10:0.2-instance | Epoch [ 36/ 75] Iter[851/1220]	  loss: 0.54cifar10:0.2-instance | Epoch [ 36/ 75] Iter[901/1220]	  loss: 0.47cifar10:0.2-instance | Epoch [ 36/ 75] Iter[951/1220]	  loss: 0.42cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1001/1220]	  loss: 0.41cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1051/1220]	  loss: 0.49cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1101/1220]	  loss: 0.44cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1151/1220]	  loss: 0.54cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1201/1220]	  loss: 0.55
| Test Epoch 36	 Accuracy: 84.30% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 37 | Accuracy on train set: 70.76% 
labeled data has a size of 39026, f-score: 0.983268
cifar10:0.2-instance | Epoch [ 37/ 75] Iter[  1/1220]	  loss: 0.32cifar10:0.2-instance | Epoch [ 37/ 75] Iter[ 51/1220]	  loss: 0.21cifar10:0.2-instance | Epoch [ 37/ 75] Iter[101/1220]	  loss: 0.39cifar10:0.2-instance | Epoch [ 37/ 75] Iter[151/1220]	  loss: 0.30cifar10:0.2-instance | Epoch [ 37/ 75] Iter[201/1220]	  loss: 0.50cifar10:0.2-instance | Epoch [ 37/ 75] Iter[251/1220]	  loss: 0.57cifar10:0.2-instance | Epoch [ 37/ 75] Iter[301/1220]	  loss: 0.25cifar10:0.2-instance | Epoch [ 37/ 75] Iter[351/1220]	  loss: 0.51cifar10:0.2-instance | Epoch [ 37/ 75] Iter[401/1220]	  loss: 0.40cifar10:0.2-instance | Epoch [ 37/ 75] Iter[451/1220]	  loss: 0.37cifar10:0.2-instance | Epoch [ 37/ 75] Iter[501/1220]	  loss: 0.26cifar10:0.2-instance | Epoch [ 37/ 75] Iter[551/1220]	  loss: 0.41cifar10:0.2-instance | Epoch [ 37/ 75] Iter[601/1220]	  loss: 0.36cifar10:0.2-instance | Epoch [ 37/ 75] Iter[651/1220]	  loss: 0.52cifar10:0.2-instance | Epoch [ 37/ 75] Iter[701/1220]	  loss: 0.48cifar10:0.2-instance | Epoch [ 37/ 75] Iter[751/1220]	  loss: 0.30cifar10:0.2-instance | Epoch [ 37/ 75] Iter[801/1220]	  loss: 0.36cifar10:0.2-instance | Epoch [ 37/ 75] Iter[851/1220]	  loss: 0.41cifar10:0.2-instance | Epoch [ 37/ 75] Iter[901/1220]	  loss: 0.28cifar10:0.2-instance | Epoch [ 37/ 75] Iter[951/1220]	  loss: 0.65cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1001/1220]	  loss: 0.64cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1051/1220]	  loss: 0.28cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1101/1220]	  loss: 0.37cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1151/1220]	  loss: 0.42cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1201/1220]	  loss: 0.25
| Test Epoch 37	 Accuracy: 86.57% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 38 | Accuracy on train set: 72.56% 
labeled data has a size of 39012, f-score: 0.984184
cifar10:0.2-instance | Epoch [ 38/ 75] Iter[  1/1220]	  loss: 0.40cifar10:0.2-instance | Epoch [ 38/ 75] Iter[ 51/1220]	  loss: 0.35cifar10:0.2-instance | Epoch [ 38/ 75] Iter[101/1220]	  loss: 0.34cifar10:0.2-instance | Epoch [ 38/ 75] Iter[151/1220]	  loss: 0.62cifar10:0.2-instance | Epoch [ 38/ 75] Iter[201/1220]	  loss: 0.42cifar10:0.2-instance | Epoch [ 38/ 75] Iter[251/1220]	  loss: 0.25cifar10:0.2-instance | Epoch [ 38/ 75] Iter[301/1220]	  loss: 0.35cifar10:0.2-instance | Epoch [ 38/ 75] Iter[351/1220]	  loss: 0.37cifar10:0.2-instance | Epoch [ 38/ 75] Iter[401/1220]	  loss: 0.42cifar10:0.2-instance | Epoch [ 38/ 75] Iter[451/1220]	  loss: 0.24cifar10:0.2-instance | Epoch [ 38/ 75] Iter[501/1220]	  loss: 0.34cifar10:0.2-instance | Epoch [ 38/ 75] Iter[551/1220]	  loss: 0.60cifar10:0.2-instance | Epoch [ 38/ 75] Iter[601/1220]	  loss: 0.43cifar10:0.2-instance | Epoch [ 38/ 75] Iter[651/1220]	  loss: 0.42cifar10:0.2-instance | Epoch [ 38/ 75] Iter[701/1220]	  loss: 0.62cifar10:0.2-instance | Epoch [ 38/ 75] Iter[751/1220]	  loss: 0.39cifar10:0.2-instance | Epoch [ 38/ 75] Iter[801/1220]	  loss: 0.32cifar10:0.2-instance | Epoch [ 38/ 75] Iter[851/1220]	  loss: 0.21cifar10:0.2-instance | Epoch [ 38/ 75] Iter[901/1220]	  loss: 0.58cifar10:0.2-instance | Epoch [ 38/ 75] Iter[951/1220]	  loss: 0.46cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1001/1220]	  loss: 0.47cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1051/1220]	  loss: 0.60cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1101/1220]	  loss: 0.35cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1151/1220]	  loss: 0.43cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1201/1220]	  loss: 0.26
| Test Epoch 38	 Accuracy: 85.26% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 39 | Accuracy on train set: 71.56% 
labeled data has a size of 39081, f-score: 0.984289
cifar10:0.2-instance | Epoch [ 39/ 75] Iter[  1/1222]	  loss: 0.45cifar10:0.2-instance | Epoch [ 39/ 75] Iter[ 51/1222]	  loss: 0.61cifar10:0.2-instance | Epoch [ 39/ 75] Iter[101/1222]	  loss: 0.29cifar10:0.2-instance | Epoch [ 39/ 75] Iter[151/1222]	  loss: 0.32cifar10:0.2-instance | Epoch [ 39/ 75] Iter[201/1222]	  loss: 0.39cifar10:0.2-instance | Epoch [ 39/ 75] Iter[251/1222]	  loss: 0.33cifar10:0.2-instance | Epoch [ 39/ 75] Iter[301/1222]	  loss: 0.42cifar10:0.2-instance | Epoch [ 39/ 75] Iter[351/1222]	  loss: 0.70cifar10:0.2-instance | Epoch [ 39/ 75] Iter[401/1222]	  loss: 0.31cifar10:0.2-instance | Epoch [ 39/ 75] Iter[451/1222]	  loss: 0.36cifar10:0.2-instance | Epoch [ 39/ 75] Iter[501/1222]	  loss: 0.54cifar10:0.2-instance | Epoch [ 39/ 75] Iter[551/1222]	  loss: 0.41cifar10:0.2-instance | Epoch [ 39/ 75] Iter[601/1222]	  loss: 0.34cifar10:0.2-instance | Epoch [ 39/ 75] Iter[651/1222]	  loss: 0.17cifar10:0.2-instance | Epoch [ 39/ 75] Iter[701/1222]	  loss: 0.30cifar10:0.2-instance | Epoch [ 39/ 75] Iter[751/1222]	  loss: 0.27cifar10:0.2-instance | Epoch [ 39/ 75] Iter[801/1222]	  loss: 0.26cifar10:0.2-instance | Epoch [ 39/ 75] Iter[851/1222]	  loss: 0.30cifar10:0.2-instance | Epoch [ 39/ 75] Iter[901/1222]	  loss: 0.33cifar10:0.2-instance | Epoch [ 39/ 75] Iter[951/1222]	  loss: 0.32cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1001/1222]	  loss: 0.25cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1051/1222]	  loss: 0.44cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1101/1222]	  loss: 0.54cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1151/1222]	  loss: 0.49cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1201/1222]	  loss: 0.24
| Test Epoch 39	 Accuracy: 86.03% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 40 | Accuracy on train set: 71.97% 
labeled data has a size of 39084, f-score: 0.985186
cifar10:0.2-instance | Epoch [ 40/ 75] Iter[  1/1222]	  loss: 0.27cifar10:0.2-instance | Epoch [ 40/ 75] Iter[ 51/1222]	  loss: 0.31cifar10:0.2-instance | Epoch [ 40/ 75] Iter[101/1222]	  loss: 0.21cifar10:0.2-instance | Epoch [ 40/ 75] Iter[151/1222]	  loss: 0.32cifar10:0.2-instance | Epoch [ 40/ 75] Iter[201/1222]	  loss: 0.34cifar10:0.2-instance | Epoch [ 40/ 75] Iter[251/1222]	  loss: 0.37cifar10:0.2-instance | Epoch [ 40/ 75] Iter[301/1222]	  loss: 0.28cifar10:0.2-instance | Epoch [ 40/ 75] Iter[351/1222]	  loss: 0.33cifar10:0.2-instance | Epoch [ 40/ 75] Iter[401/1222]	  loss: 0.52cifar10:0.2-instance | Epoch [ 40/ 75] Iter[451/1222]	  loss: 0.28cifar10:0.2-instance | Epoch [ 40/ 75] Iter[501/1222]	  loss: 0.70cifar10:0.2-instance | Epoch [ 40/ 75] Iter[551/1222]	  loss: 0.39cifar10:0.2-instance | Epoch [ 40/ 75] Iter[601/1222]	  loss: 0.21cifar10:0.2-instance | Epoch [ 40/ 75] Iter[651/1222]	  loss: 0.30cifar10:0.2-instance | Epoch [ 40/ 75] Iter[701/1222]	  loss: 0.25cifar10:0.2-instance | Epoch [ 40/ 75] Iter[751/1222]	  loss: 0.72cifar10:0.2-instance | Epoch [ 40/ 75] Iter[801/1222]	  loss: 0.36cifar10:0.2-instance | Epoch [ 40/ 75] Iter[851/1222]	  loss: 0.70cifar10:0.2-instance | Epoch [ 40/ 75] Iter[901/1222]	  loss: 0.47cifar10:0.2-instance | Epoch [ 40/ 75] Iter[951/1222]	  loss: 0.29cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1001/1222]	  loss: 0.41cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1051/1222]	  loss: 0.33cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1101/1222]	  loss: 0.23cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1151/1222]	  loss: 0.26cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1201/1222]	  loss: 0.35
| Test Epoch 40	 Accuracy: 84.65% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 41 | Accuracy on train set: 71.24% 
labeled data has a size of 39166, f-score: 0.982995
cifar10:0.2-instance | Epoch [ 41/ 75] Iter[  1/1224]	  loss: 0.42cifar10:0.2-instance | Epoch [ 41/ 75] Iter[ 51/1224]	  loss: 0.31cifar10:0.2-instance | Epoch [ 41/ 75] Iter[101/1224]	  loss: 0.32cifar10:0.2-instance | Epoch [ 41/ 75] Iter[151/1224]	  loss: 0.46cifar10:0.2-instance | Epoch [ 41/ 75] Iter[201/1224]	  loss: 0.33cifar10:0.2-instance | Epoch [ 41/ 75] Iter[251/1224]	  loss: 0.53cifar10:0.2-instance | Epoch [ 41/ 75] Iter[301/1224]	  loss: 0.51cifar10:0.2-instance | Epoch [ 41/ 75] Iter[351/1224]	  loss: 0.53cifar10:0.2-instance | Epoch [ 41/ 75] Iter[401/1224]	  loss: 0.43cifar10:0.2-instance | Epoch [ 41/ 75] Iter[451/1224]	  loss: 0.31cifar10:0.2-instance | Epoch [ 41/ 75] Iter[501/1224]	  loss: 0.49cifar10:0.2-instance | Epoch [ 41/ 75] Iter[551/1224]	  loss: 0.37cifar10:0.2-instance | Epoch [ 41/ 75] Iter[601/1224]	  loss: 0.34cifar10:0.2-instance | Epoch [ 41/ 75] Iter[651/1224]	  loss: 0.31cifar10:0.2-instance | Epoch [ 41/ 75] Iter[701/1224]	  loss: 0.29cifar10:0.2-instance | Epoch [ 41/ 75] Iter[751/1224]	  loss: 0.65cifar10:0.2-instance | Epoch [ 41/ 75] Iter[801/1224]	  loss: 0.66cifar10:0.2-instance | Epoch [ 41/ 75] Iter[851/1224]	  loss: 0.34cifar10:0.2-instance | Epoch [ 41/ 75] Iter[901/1224]	  loss: 0.46cifar10:0.2-instance | Epoch [ 41/ 75] Iter[951/1224]	  loss: 0.25cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1001/1224]	  loss: 0.37cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1051/1224]	  loss: 0.47cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1101/1224]	  loss: 0.46cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1151/1224]	  loss: 0.58cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1201/1224]	  loss: 0.38
| Test Epoch 41	 Accuracy: 83.91% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 42 | Accuracy on train set: 70.53% 
labeled data has a size of 39179, f-score: 0.982542
cifar10:0.2-instance | Epoch [ 42/ 75] Iter[  1/1225]	  loss: 0.32cifar10:0.2-instance | Epoch [ 42/ 75] Iter[ 51/1225]	  loss: 0.49cifar10:0.2-instance | Epoch [ 42/ 75] Iter[101/1225]	  loss: 0.33cifar10:0.2-instance | Epoch [ 42/ 75] Iter[151/1225]	  loss: 0.52cifar10:0.2-instance | Epoch [ 42/ 75] Iter[201/1225]	  loss: 0.39cifar10:0.2-instance | Epoch [ 42/ 75] Iter[251/1225]	  loss: 0.28cifar10:0.2-instance | Epoch [ 42/ 75] Iter[301/1225]	  loss: 0.50cifar10:0.2-instance | Epoch [ 42/ 75] Iter[351/1225]	  loss: 0.30cifar10:0.2-instance | Epoch [ 42/ 75] Iter[401/1225]	  loss: 0.51cifar10:0.2-instance | Epoch [ 42/ 75] Iter[451/1225]	  loss: 0.37cifar10:0.2-instance | Epoch [ 42/ 75] Iter[501/1225]	  loss: 0.43cifar10:0.2-instance | Epoch [ 42/ 75] Iter[551/1225]	  loss: 0.36cifar10:0.2-instance | Epoch [ 42/ 75] Iter[601/1225]	  loss: 0.36cifar10:0.2-instance | Epoch [ 42/ 75] Iter[651/1225]	  loss: 0.38cifar10:0.2-instance | Epoch [ 42/ 75] Iter[701/1225]	  loss: 0.46cifar10:0.2-instance | Epoch [ 42/ 75] Iter[751/1225]	  loss: 0.38cifar10:0.2-instance | Epoch [ 42/ 75] Iter[801/1225]	  loss: 0.59cifar10:0.2-instance | Epoch [ 42/ 75] Iter[851/1225]	  loss: 0.31cifar10:0.2-instance | Epoch [ 42/ 75] Iter[901/1225]	  loss: 0.53cifar10:0.2-instance | Epoch [ 42/ 75] Iter[951/1225]	  loss: 0.29cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1001/1225]	  loss: 0.23cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1051/1225]	  loss: 0.21cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1101/1225]	  loss: 0.37cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1151/1225]	  loss: 0.36cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1201/1225]	  loss: 0.32
| Test Epoch 42	 Accuracy: 85.83% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 43 | Accuracy on train set: 72.76% 
labeled data has a size of 39071, f-score: 0.982621
cifar10:0.2-instance | Epoch [ 43/ 75] Iter[  1/1221]	  loss: 0.34cifar10:0.2-instance | Epoch [ 43/ 75] Iter[ 51/1221]	  loss: 0.43cifar10:0.2-instance | Epoch [ 43/ 75] Iter[101/1221]	  loss: 0.31cifar10:0.2-instance | Epoch [ 43/ 75] Iter[151/1221]	  loss: 0.43cifar10:0.2-instance | Epoch [ 43/ 75] Iter[201/1221]	  loss: 0.32cifar10:0.2-instance | Epoch [ 43/ 75] Iter[251/1221]	  loss: 0.62cifar10:0.2-instance | Epoch [ 43/ 75] Iter[301/1221]	  loss: 0.20cifar10:0.2-instance | Epoch [ 43/ 75] Iter[351/1221]	  loss: 0.35cifar10:0.2-instance | Epoch [ 43/ 75] Iter[401/1221]	  loss: 0.43cifar10:0.2-instance | Epoch [ 43/ 75] Iter[451/1221]	  loss: 0.32cifar10:0.2-instance | Epoch [ 43/ 75] Iter[501/1221]	  loss: 0.50cifar10:0.2-instance | Epoch [ 43/ 75] Iter[551/1221]	  loss: 0.30cifar10:0.2-instance | Epoch [ 43/ 75] Iter[601/1221]	  loss: 0.55cifar10:0.2-instance | Epoch [ 43/ 75] Iter[651/1221]	  loss: 0.37cifar10:0.2-instance | Epoch [ 43/ 75] Iter[701/1221]	  loss: 0.42cifar10:0.2-instance | Epoch [ 43/ 75] Iter[751/1221]	  loss: 0.29cifar10:0.2-instance | Epoch [ 43/ 75] Iter[801/1221]	  loss: 0.55cifar10:0.2-instance | Epoch [ 43/ 75] Iter[851/1221]	  loss: 0.60cifar10:0.2-instance | Epoch [ 43/ 75] Iter[901/1221]	  loss: 0.24cifar10:0.2-instance | Epoch [ 43/ 75] Iter[951/1221]	  loss: 0.31cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1001/1221]	  loss: 0.34cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1051/1221]	  loss: 0.31cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1101/1221]	  loss: 0.37cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1151/1221]	  loss: 0.35cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1201/1221]	  loss: 0.45
| Test Epoch 43	 Accuracy: 86.70% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 44 | Accuracy on train set: 72.79% 
labeled data has a size of 39016, f-score: 0.984212
cifar10:0.2-instance | Epoch [ 44/ 75] Iter[  1/1220]	  loss: 0.24cifar10:0.2-instance | Epoch [ 44/ 75] Iter[ 51/1220]	  loss: 0.22cifar10:0.2-instance | Epoch [ 44/ 75] Iter[101/1220]	  loss: 0.23cifar10:0.2-instance | Epoch [ 44/ 75] Iter[151/1220]	  loss: 0.41cifar10:0.2-instance | Epoch [ 44/ 75] Iter[201/1220]	  loss: 0.44cifar10:0.2-instance | Epoch [ 44/ 75] Iter[251/1220]	  loss: 0.26cifar10:0.2-instance | Epoch [ 44/ 75] Iter[301/1220]	  loss: 0.68cifar10:0.2-instance | Epoch [ 44/ 75] Iter[351/1220]	  loss: 0.34cifar10:0.2-instance | Epoch [ 44/ 75] Iter[401/1220]	  loss: 0.43cifar10:0.2-instance | Epoch [ 44/ 75] Iter[451/1220]	  loss: 0.52cifar10:0.2-instance | Epoch [ 44/ 75] Iter[501/1220]	  loss: 0.22cifar10:0.2-instance | Epoch [ 44/ 75] Iter[551/1220]	  loss: 0.46cifar10:0.2-instance | Epoch [ 44/ 75] Iter[601/1220]	  loss: 0.32cifar10:0.2-instance | Epoch [ 44/ 75] Iter[651/1220]	  loss: 0.35cifar10:0.2-instance | Epoch [ 44/ 75] Iter[701/1220]	  loss: 0.36cifar10:0.2-instance | Epoch [ 44/ 75] Iter[751/1220]	  loss: 0.33cifar10:0.2-instance | Epoch [ 44/ 75] Iter[801/1220]	  loss: 0.28cifar10:0.2-instance | Epoch [ 44/ 75] Iter[851/1220]	  loss: 0.37cifar10:0.2-instance | Epoch [ 44/ 75] Iter[901/1220]	  loss: 0.59cifar10:0.2-instance | Epoch [ 44/ 75] Iter[951/1220]	  loss: 0.44cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1001/1220]	  loss: 0.30cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1051/1220]	  loss: 0.40cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1101/1220]	  loss: 0.42cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1151/1220]	  loss: 0.40cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1201/1220]	  loss: 0.45
| Test Epoch 44	 Accuracy: 83.91% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 45 | Accuracy on train set: 71.15% 
labeled data has a size of 39068, f-score: 0.984335
cifar10:0.2-instance | Epoch [ 45/ 75] Iter[  1/1221]	  loss: 0.59cifar10:0.2-instance | Epoch [ 45/ 75] Iter[ 51/1221]	  loss: 0.41cifar10:0.2-instance | Epoch [ 45/ 75] Iter[101/1221]	  loss: 0.33cifar10:0.2-instance | Epoch [ 45/ 75] Iter[151/1221]	  loss: 0.42cifar10:0.2-instance | Epoch [ 45/ 75] Iter[201/1221]	  loss: 0.39cifar10:0.2-instance | Epoch [ 45/ 75] Iter[251/1221]	  loss: 0.21cifar10:0.2-instance | Epoch [ 45/ 75] Iter[301/1221]	  loss: 0.26cifar10:0.2-instance | Epoch [ 45/ 75] Iter[351/1221]	  loss: 0.37cifar10:0.2-instance | Epoch [ 45/ 75] Iter[401/1221]	  loss: 0.46cifar10:0.2-instance | Epoch [ 45/ 75] Iter[451/1221]	  loss: 0.52cifar10:0.2-instance | Epoch [ 45/ 75] Iter[501/1221]	  loss: 0.29cifar10:0.2-instance | Epoch [ 45/ 75] Iter[551/1221]	  loss: 0.47cifar10:0.2-instance | Epoch [ 45/ 75] Iter[601/1221]	  loss: 0.43cifar10:0.2-instance | Epoch [ 45/ 75] Iter[651/1221]	  loss: 0.22cifar10:0.2-instance | Epoch [ 45/ 75] Iter[701/1221]	  loss: 0.38cifar10:0.2-instance | Epoch [ 45/ 75] Iter[751/1221]	  loss: 0.29cifar10:0.2-instance | Epoch [ 45/ 75] Iter[801/1221]	  loss: 0.32cifar10:0.2-instance | Epoch [ 45/ 75] Iter[851/1221]	  loss: 0.40cifar10:0.2-instance | Epoch [ 45/ 75] Iter[901/1221]	  loss: 0.26cifar10:0.2-instance | Epoch [ 45/ 75] Iter[951/1221]	  loss: 0.35cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1001/1221]	  loss: 0.55cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1051/1221]	  loss: 0.29cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1101/1221]	  loss: 0.41cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1151/1221]	  loss: 0.35cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1201/1221]	  loss: 0.71
| Test Epoch 45	 Accuracy: 85.69% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 46 | Accuracy on train set: 72.11% 
labeled data has a size of 39111, f-score: 0.984122
cifar10:0.2-instance | Epoch [ 46/ 75] Iter[  1/1223]	  loss: 0.34cifar10:0.2-instance | Epoch [ 46/ 75] Iter[ 51/1223]	  loss: 0.68cifar10:0.2-instance | Epoch [ 46/ 75] Iter[101/1223]	  loss: 0.54cifar10:0.2-instance | Epoch [ 46/ 75] Iter[151/1223]	  loss: 0.38cifar10:0.2-instance | Epoch [ 46/ 75] Iter[201/1223]	  loss: 0.47cifar10:0.2-instance | Epoch [ 46/ 75] Iter[251/1223]	  loss: 0.75cifar10:0.2-instance | Epoch [ 46/ 75] Iter[301/1223]	  loss: 0.65cifar10:0.2-instance | Epoch [ 46/ 75] Iter[351/1223]	  loss: 0.29cifar10:0.2-instance | Epoch [ 46/ 75] Iter[401/1223]	  loss: 0.41cifar10:0.2-instance | Epoch [ 46/ 75] Iter[451/1223]	  loss: 0.25cifar10:0.2-instance | Epoch [ 46/ 75] Iter[501/1223]	  loss: 0.28cifar10:0.2-instance | Epoch [ 46/ 75] Iter[551/1223]	  loss: 0.46cifar10:0.2-instance | Epoch [ 46/ 75] Iter[601/1223]	  loss: 0.42cifar10:0.2-instance | Epoch [ 46/ 75] Iter[651/1223]	  loss: 0.26cifar10:0.2-instance | Epoch [ 46/ 75] Iter[701/1223]	  loss: 0.42cifar10:0.2-instance | Epoch [ 46/ 75] Iter[751/1223]	  loss: 0.54cifar10:0.2-instance | Epoch [ 46/ 75] Iter[801/1223]	  loss: 0.41cifar10:0.2-instance | Epoch [ 46/ 75] Iter[851/1223]	  loss: 0.41cifar10:0.2-instance | Epoch [ 46/ 75] Iter[901/1223]	  loss: 0.52cifar10:0.2-instance | Epoch [ 46/ 75] Iter[951/1223]	  loss: 0.52cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1001/1223]	  loss: 0.27cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1051/1223]	  loss: 0.41cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1101/1223]	  loss: 0.41cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1151/1223]	  loss: 0.41cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1201/1223]	  loss: 0.23
| Test Epoch 46	 Accuracy: 85.48% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 47 | Accuracy on train set: 72.13% 
labeled data has a size of 39112, f-score: 0.983202
cifar10:0.2-instance | Epoch [ 47/ 75] Iter[  1/1223]	  loss: 0.31cifar10:0.2-instance | Epoch [ 47/ 75] Iter[ 51/1223]	  loss: 0.43cifar10:0.2-instance | Epoch [ 47/ 75] Iter[101/1223]	  loss: 0.67cifar10:0.2-instance | Epoch [ 47/ 75] Iter[151/1223]	  loss: 0.68cifar10:0.2-instance | Epoch [ 47/ 75] Iter[201/1223]	  loss: 0.48cifar10:0.2-instance | Epoch [ 47/ 75] Iter[251/1223]	  loss: 0.42cifar10:0.2-instance | Epoch [ 47/ 75] Iter[301/1223]	  loss: 0.43cifar10:0.2-instance | Epoch [ 47/ 75] Iter[351/1223]	  loss: 0.53cifar10:0.2-instance | Epoch [ 47/ 75] Iter[401/1223]	  loss: 0.45cifar10:0.2-instance | Epoch [ 47/ 75] Iter[451/1223]	  loss: 0.55cifar10:0.2-instance | Epoch [ 47/ 75] Iter[501/1223]	  loss: 0.35cifar10:0.2-instance | Epoch [ 47/ 75] Iter[551/1223]	  loss: 0.46cifar10:0.2-instance | Epoch [ 47/ 75] Iter[601/1223]	  loss: 0.37cifar10:0.2-instance | Epoch [ 47/ 75] Iter[651/1223]	  loss: 0.34cifar10:0.2-instance | Epoch [ 47/ 75] Iter[701/1223]	  loss: 0.42cifar10:0.2-instance | Epoch [ 47/ 75] Iter[751/1223]	  loss: 0.29cifar10:0.2-instance | Epoch [ 47/ 75] Iter[801/1223]	  loss: 0.30cifar10:0.2-instance | Epoch [ 47/ 75] Iter[851/1223]	  loss: 0.28cifar10:0.2-instance | Epoch [ 47/ 75] Iter[901/1223]	  loss: 0.57cifar10:0.2-instance | Epoch [ 47/ 75] Iter[951/1223]	  loss: 0.42cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1001/1223]	  loss: 0.56cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1051/1223]	  loss: 0.34cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1101/1223]	  loss: 0.46cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1151/1223]	  loss: 0.31cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1201/1223]	  loss: 0.28
| Test Epoch 47	 Accuracy: 85.85% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 48 | Accuracy on train set: 72.33% 
labeled data has a size of 39071, f-score: 0.983389
cifar10:0.2-instance | Epoch [ 48/ 75] Iter[  1/1221]	  loss: 0.45cifar10:0.2-instance | Epoch [ 48/ 75] Iter[ 51/1221]	  loss: 0.38cifar10:0.2-instance | Epoch [ 48/ 75] Iter[101/1221]	  loss: 0.56cifar10:0.2-instance | Epoch [ 48/ 75] Iter[151/1221]	  loss: 0.51cifar10:0.2-instance | Epoch [ 48/ 75] Iter[201/1221]	  loss: 0.32cifar10:0.2-instance | Epoch [ 48/ 75] Iter[251/1221]	  loss: 0.33cifar10:0.2-instance | Epoch [ 48/ 75] Iter[301/1221]	  loss: 0.34cifar10:0.2-instance | Epoch [ 48/ 75] Iter[351/1221]	  loss: 0.54cifar10:0.2-instance | Epoch [ 48/ 75] Iter[401/1221]	  loss: 0.45cifar10:0.2-instance | Epoch [ 48/ 75] Iter[451/1221]	  loss: 0.70cifar10:0.2-instance | Epoch [ 48/ 75] Iter[501/1221]	  loss: 0.59cifar10:0.2-instance | Epoch [ 48/ 75] Iter[551/1221]	  loss: 0.63cifar10:0.2-instance | Epoch [ 48/ 75] Iter[601/1221]	  loss: 0.28cifar10:0.2-instance | Epoch [ 48/ 75] Iter[651/1221]	  loss: 0.50cifar10:0.2-instance | Epoch [ 48/ 75] Iter[701/1221]	  loss: 0.45cifar10:0.2-instance | Epoch [ 48/ 75] Iter[751/1221]	  loss: 0.38cifar10:0.2-instance | Epoch [ 48/ 75] Iter[801/1221]	  loss: 0.41cifar10:0.2-instance | Epoch [ 48/ 75] Iter[851/1221]	  loss: 0.34cifar10:0.2-instance | Epoch [ 48/ 75] Iter[901/1221]	  loss: 0.28cifar10:0.2-instance | Epoch [ 48/ 75] Iter[951/1221]	  loss: 0.33cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1001/1221]	  loss: 0.68cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1051/1221]	  loss: 0.29cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1101/1221]	  loss: 0.21cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1151/1221]	  loss: 0.50cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1201/1221]	  loss: 0.40
| Test Epoch 48	 Accuracy: 86.77% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 49 | Accuracy on train set: 72.73% 
labeled data has a size of 39199, f-score: 0.981811
cifar10:0.2-instance | Epoch [ 49/ 75] Iter[  1/1225]	  loss: 0.19cifar10:0.2-instance | Epoch [ 49/ 75] Iter[ 51/1225]	  loss: 0.41cifar10:0.2-instance | Epoch [ 49/ 75] Iter[101/1225]	  loss: 0.46cifar10:0.2-instance | Epoch [ 49/ 75] Iter[151/1225]	  loss: 0.32cifar10:0.2-instance | Epoch [ 49/ 75] Iter[201/1225]	  loss: 0.42cifar10:0.2-instance | Epoch [ 49/ 75] Iter[251/1225]	  loss: 0.38cifar10:0.2-instance | Epoch [ 49/ 75] Iter[301/1225]	  loss: 0.58cifar10:0.2-instance | Epoch [ 49/ 75] Iter[351/1225]	  loss: 0.43cifar10:0.2-instance | Epoch [ 49/ 75] Iter[401/1225]	  loss: 0.52cifar10:0.2-instance | Epoch [ 49/ 75] Iter[451/1225]	  loss: 0.51cifar10:0.2-instance | Epoch [ 49/ 75] Iter[501/1225]	  loss: 0.56cifar10:0.2-instance | Epoch [ 49/ 75] Iter[551/1225]	  loss: 0.39cifar10:0.2-instance | Epoch [ 49/ 75] Iter[601/1225]	  loss: 0.37cifar10:0.2-instance | Epoch [ 49/ 75] Iter[651/1225]	  loss: 0.34cifar10:0.2-instance | Epoch [ 49/ 75] Iter[701/1225]	  loss: 0.32cifar10:0.2-instance | Epoch [ 49/ 75] Iter[751/1225]	  loss: 0.25cifar10:0.2-instance | Epoch [ 49/ 75] Iter[801/1225]	  loss: 0.37cifar10:0.2-instance | Epoch [ 49/ 75] Iter[851/1225]	  loss: 0.49cifar10:0.2-instance | Epoch [ 49/ 75] Iter[901/1225]	  loss: 0.32cifar10:0.2-instance | Epoch [ 49/ 75] Iter[951/1225]	  loss: 0.47cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1001/1225]	  loss: 0.37cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1051/1225]	  loss: 0.73cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1101/1225]	  loss: 0.38cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1151/1225]	  loss: 0.39cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1201/1225]	  loss: 0.39
| Test Epoch 49	 Accuracy: 85.37% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 50 | Accuracy on train set: 72.18% 
labeled data has a size of 39286, f-score: 0.981673
cifar10:0.2-instance | Epoch [ 50/ 75] Iter[  1/1228]	  loss: 0.24cifar10:0.2-instance | Epoch [ 50/ 75] Iter[ 51/1228]	  loss: 0.32cifar10:0.2-instance | Epoch [ 50/ 75] Iter[101/1228]	  loss: 0.49cifar10:0.2-instance | Epoch [ 50/ 75] Iter[151/1228]	  loss: 0.59cifar10:0.2-instance | Epoch [ 50/ 75] Iter[201/1228]	  loss: 0.52cifar10:0.2-instance | Epoch [ 50/ 75] Iter[251/1228]	  loss: 0.36cifar10:0.2-instance | Epoch [ 50/ 75] Iter[301/1228]	  loss: 0.39cifar10:0.2-instance | Epoch [ 50/ 75] Iter[351/1228]	  loss: 0.27cifar10:0.2-instance | Epoch [ 50/ 75] Iter[401/1228]	  loss: 0.36cifar10:0.2-instance | Epoch [ 50/ 75] Iter[451/1228]	  loss: 0.27cifar10:0.2-instance | Epoch [ 50/ 75] Iter[501/1228]	  loss: 0.57cifar10:0.2-instance | Epoch [ 50/ 75] Iter[551/1228]	  loss: 0.32cifar10:0.2-instance | Epoch [ 50/ 75] Iter[601/1228]	  loss: 0.44cifar10:0.2-instance | Epoch [ 50/ 75] Iter[651/1228]	  loss: 0.49cifar10:0.2-instance | Epoch [ 50/ 75] Iter[701/1228]	  loss: 0.47cifar10:0.2-instance | Epoch [ 50/ 75] Iter[751/1228]	  loss: 0.45cifar10:0.2-instance | Epoch [ 50/ 75] Iter[801/1228]	  loss: 0.31cifar10:0.2-instance | Epoch [ 50/ 75] Iter[851/1228]	  loss: 0.40cifar10:0.2-instance | Epoch [ 50/ 75] Iter[901/1228]	  loss: 0.33cifar10:0.2-instance | Epoch [ 50/ 75] Iter[951/1228]	  loss: 0.24cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1001/1228]	  loss: 0.31cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1051/1228]	  loss: 0.53cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1101/1228]	  loss: 0.39cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1151/1228]	  loss: 0.53cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1201/1228]	  loss: 0.54
| Test Epoch 50	 Accuracy: 86.02% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 51 | Accuracy on train set: 72.51% 
labeled data has a size of 39334, f-score: 0.981339
cifar10:0.2-instance | Epoch [ 51/ 75] Iter[  1/1230]	  loss: 0.23cifar10:0.2-instance | Epoch [ 51/ 75] Iter[ 51/1230]	  loss: 0.36cifar10:0.2-instance | Epoch [ 51/ 75] Iter[101/1230]	  loss: 0.47cifar10:0.2-instance | Epoch [ 51/ 75] Iter[151/1230]	  loss: 0.54cifar10:0.2-instance | Epoch [ 51/ 75] Iter[201/1230]	  loss: 0.37cifar10:0.2-instance | Epoch [ 51/ 75] Iter[251/1230]	  loss: 0.51cifar10:0.2-instance | Epoch [ 51/ 75] Iter[301/1230]	  loss: 0.28cifar10:0.2-instance | Epoch [ 51/ 75] Iter[351/1230]	  loss: 0.45cifar10:0.2-instance | Epoch [ 51/ 75] Iter[401/1230]	  loss: 0.31cifar10:0.2-instance | Epoch [ 51/ 75] Iter[451/1230]	  loss: 0.52cifar10:0.2-instance | Epoch [ 51/ 75] Iter[501/1230]	  loss: 0.63cifar10:0.2-instance | Epoch [ 51/ 75] Iter[551/1230]	  loss: 0.40cifar10:0.2-instance | Epoch [ 51/ 75] Iter[601/1230]	  loss: 0.48cifar10:0.2-instance | Epoch [ 51/ 75] Iter[651/1230]	  loss: 0.40cifar10:0.2-instance | Epoch [ 51/ 75] Iter[701/1230]	  loss: 0.42cifar10:0.2-instance | Epoch [ 51/ 75] Iter[751/1230]	  loss: 0.33cifar10:0.2-instance | Epoch [ 51/ 75] Iter[801/1230]	  loss: 0.44cifar10:0.2-instance | Epoch [ 51/ 75] Iter[851/1230]	  loss: 0.46cifar10:0.2-instance | Epoch [ 51/ 75] Iter[901/1230]	  loss: 0.34cifar10:0.2-instance | Epoch [ 51/ 75] Iter[951/1230]	  loss: 0.40cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1001/1230]	  loss: 0.32cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1051/1230]	  loss: 0.37cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1101/1230]	  loss: 0.62cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1151/1230]	  loss: 0.42cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1201/1230]	  loss: 0.26
| Test Epoch 51	 Accuracy: 85.28% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 52 | Accuracy on train set: 71.94% 
labeled data has a size of 39320, f-score: 0.981078
cifar10:0.2-instance | Epoch [ 52/ 75] Iter[  1/1229]	  loss: 0.42cifar10:0.2-instance | Epoch [ 52/ 75] Iter[ 51/1229]	  loss: 0.41cifar10:0.2-instance | Epoch [ 52/ 75] Iter[101/1229]	  loss: 0.30cifar10:0.2-instance | Epoch [ 52/ 75] Iter[151/1229]	  loss: 0.49cifar10:0.2-instance | Epoch [ 52/ 75] Iter[201/1229]	  loss: 0.44cifar10:0.2-instance | Epoch [ 52/ 75] Iter[251/1229]	  loss: 0.49cifar10:0.2-instance | Epoch [ 52/ 75] Iter[301/1229]	  loss: 0.46cifar10:0.2-instance | Epoch [ 52/ 75] Iter[351/1229]	  loss: 0.21cifar10:0.2-instance | Epoch [ 52/ 75] Iter[401/1229]	  loss: 0.45cifar10:0.2-instance | Epoch [ 52/ 75] Iter[451/1229]	  loss: 0.44cifar10:0.2-instance | Epoch [ 52/ 75] Iter[501/1229]	  loss: 0.27cifar10:0.2-instance | Epoch [ 52/ 75] Iter[551/1229]	  loss: 0.30cifar10:0.2-instance | Epoch [ 52/ 75] Iter[601/1229]	  loss: 0.35cifar10:0.2-instance | Epoch [ 52/ 75] Iter[651/1229]	  loss: 0.37cifar10:0.2-instance | Epoch [ 52/ 75] Iter[701/1229]	  loss: 0.44cifar10:0.2-instance | Epoch [ 52/ 75] Iter[751/1229]	  loss: 0.43cifar10:0.2-instance | Epoch [ 52/ 75] Iter[801/1229]	  loss: 0.36cifar10:0.2-instance | Epoch [ 52/ 75] Iter[851/1229]	  loss: 0.53cifar10:0.2-instance | Epoch [ 52/ 75] Iter[901/1229]	  loss: 0.46cifar10:0.2-instance | Epoch [ 52/ 75] Iter[951/1229]	  loss: 0.31cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1001/1229]	  loss: 0.19cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1051/1229]	  loss: 0.59cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1101/1229]	  loss: 0.44cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1151/1229]	  loss: 0.30cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1201/1229]	  loss: 0.39
| Test Epoch 52	 Accuracy: 84.82% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 53 | Accuracy on train set: 71.87% 
labeled data has a size of 39236, f-score: 0.981573
cifar10:0.2-instance | Epoch [ 53/ 75] Iter[  1/1227]	  loss: 0.39cifar10:0.2-instance | Epoch [ 53/ 75] Iter[ 51/1227]	  loss: 0.46cifar10:0.2-instance | Epoch [ 53/ 75] Iter[101/1227]	  loss: 0.32cifar10:0.2-instance | Epoch [ 53/ 75] Iter[151/1227]	  loss: 0.54cifar10:0.2-instance | Epoch [ 53/ 75] Iter[201/1227]	  loss: 0.47cifar10:0.2-instance | Epoch [ 53/ 75] Iter[251/1227]	  loss: 0.36cifar10:0.2-instance | Epoch [ 53/ 75] Iter[301/1227]	  loss: 0.25cifar10:0.2-instance | Epoch [ 53/ 75] Iter[351/1227]	  loss: 0.63cifar10:0.2-instance | Epoch [ 53/ 75] Iter[401/1227]	  loss: 0.64cifar10:0.2-instance | Epoch [ 53/ 75] Iter[451/1227]	  loss: 0.29cifar10:0.2-instance | Epoch [ 53/ 75] Iter[501/1227]	  loss: 0.32cifar10:0.2-instance | Epoch [ 53/ 75] Iter[551/1227]	  loss: 0.33cifar10:0.2-instance | Epoch [ 53/ 75] Iter[601/1227]	  loss: 0.34cifar10:0.2-instance | Epoch [ 53/ 75] Iter[651/1227]	  loss: 0.36cifar10:0.2-instance | Epoch [ 53/ 75] Iter[701/1227]	  loss: 0.57cifar10:0.2-instance | Epoch [ 53/ 75] Iter[751/1227]	  loss: 0.33cifar10:0.2-instance | Epoch [ 53/ 75] Iter[801/1227]	  loss: 0.45cifar10:0.2-instance | Epoch [ 53/ 75] Iter[851/1227]	  loss: 0.45cifar10:0.2-instance | Epoch [ 53/ 75] Iter[901/1227]	  loss: 0.32cifar10:0.2-instance | Epoch [ 53/ 75] Iter[951/1227]	  loss: 0.43cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1001/1227]	  loss: 0.55cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1051/1227]	  loss: 0.48cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1101/1227]	  loss: 0.64cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1151/1227]	  loss: 0.29cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1201/1227]	  loss: 0.27
| Test Epoch 53	 Accuracy: 85.55% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 54 | Accuracy on train set: 72.14% 
labeled data has a size of 39131, f-score: 0.981038
cifar10:0.2-instance | Epoch [ 54/ 75] Iter[  1/1223]	  loss: 0.65cifar10:0.2-instance | Epoch [ 54/ 75] Iter[ 51/1223]	  loss: 0.49cifar10:0.2-instance | Epoch [ 54/ 75] Iter[101/1223]	  loss: 0.34cifar10:0.2-instance | Epoch [ 54/ 75] Iter[151/1223]	  loss: 0.49cifar10:0.2-instance | Epoch [ 54/ 75] Iter[201/1223]	  loss: 0.28cifar10:0.2-instance | Epoch [ 54/ 75] Iter[251/1223]	  loss: 0.54cifar10:0.2-instance | Epoch [ 54/ 75] Iter[301/1223]	  loss: 0.42cifar10:0.2-instance | Epoch [ 54/ 75] Iter[351/1223]	  loss: 0.52cifar10:0.2-instance | Epoch [ 54/ 75] Iter[401/1223]	  loss: 0.51cifar10:0.2-instance | Epoch [ 54/ 75] Iter[451/1223]	  loss: 0.27cifar10:0.2-instance | Epoch [ 54/ 75] Iter[501/1223]	  loss: 0.32cifar10:0.2-instance | Epoch [ 54/ 75] Iter[551/1223]	  loss: 0.47cifar10:0.2-instance | Epoch [ 54/ 75] Iter[601/1223]	  loss: 0.40cifar10:0.2-instance | Epoch [ 54/ 75] Iter[651/1223]	  loss: 0.38cifar10:0.2-instance | Epoch [ 54/ 75] Iter[701/1223]	  loss: 0.46cifar10:0.2-instance | Epoch [ 54/ 75] Iter[751/1223]	  loss: 0.50cifar10:0.2-instance | Epoch [ 54/ 75] Iter[801/1223]	  loss: 0.69cifar10:0.2-instance | Epoch [ 54/ 75] Iter[851/1223]	  loss: 0.52cifar10:0.2-instance | Epoch [ 54/ 75] Iter[901/1223]	  loss: 0.29cifar10:0.2-instance | Epoch [ 54/ 75] Iter[951/1223]	  loss: 0.65cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1001/1223]	  loss: 0.56cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1051/1223]	  loss: 0.54cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1101/1223]	  loss: 0.50cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1151/1223]	  loss: 0.33cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1201/1223]	  loss: 0.38
| Test Epoch 54	 Accuracy: 86.58% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 55 | Accuracy on train set: 73.03% 
labeled data has a size of 39226, f-score: 0.981211
cifar10:0.2-instance | Epoch [ 55/ 75] Iter[  1/1226]	  loss: 0.36cifar10:0.2-instance | Epoch [ 55/ 75] Iter[ 51/1226]	  loss: 0.37cifar10:0.2-instance | Epoch [ 55/ 75] Iter[101/1226]	  loss: 0.43cifar10:0.2-instance | Epoch [ 55/ 75] Iter[151/1226]	  loss: 0.28cifar10:0.2-instance | Epoch [ 55/ 75] Iter[201/1226]	  loss: 0.34cifar10:0.2-instance | Epoch [ 55/ 75] Iter[251/1226]	  loss: 0.36cifar10:0.2-instance | Epoch [ 55/ 75] Iter[301/1226]	  loss: 0.38cifar10:0.2-instance | Epoch [ 55/ 75] Iter[351/1226]	  loss: 0.36cifar10:0.2-instance | Epoch [ 55/ 75] Iter[401/1226]	  loss: 0.21cifar10:0.2-instance | Epoch [ 55/ 75] Iter[451/1226]	  loss: 0.27cifar10:0.2-instance | Epoch [ 55/ 75] Iter[501/1226]	  loss: 0.39cifar10:0.2-instance | Epoch [ 55/ 75] Iter[551/1226]	  loss: 0.36cifar10:0.2-instance | Epoch [ 55/ 75] Iter[601/1226]	  loss: 0.29cifar10:0.2-instance | Epoch [ 55/ 75] Iter[651/1226]	  loss: 0.62cifar10:0.2-instance | Epoch [ 55/ 75] Iter[701/1226]	  loss: 0.45cifar10:0.2-instance | Epoch [ 55/ 75] Iter[751/1226]	  loss: 0.18cifar10:0.2-instance | Epoch [ 55/ 75] Iter[801/1226]	  loss: 0.40cifar10:0.2-instance | Epoch [ 55/ 75] Iter[851/1226]	  loss: 0.22cifar10:0.2-instance | Epoch [ 55/ 75] Iter[901/1226]	  loss: 0.33cifar10:0.2-instance | Epoch [ 55/ 75] Iter[951/1226]	  loss: 0.37cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1001/1226]	  loss: 0.50cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1051/1226]	  loss: 0.40cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1101/1226]	  loss: 0.51cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1151/1226]	  loss: 0.56cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1201/1226]	  loss: 0.39
| Test Epoch 55	 Accuracy: 84.76% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 56 | Accuracy on train set: 71.21% 
labeled data has a size of 39249, f-score: 0.981452
cifar10:0.2-instance | Epoch [ 56/ 75] Iter[  1/1227]	  loss: 0.36cifar10:0.2-instance | Epoch [ 56/ 75] Iter[ 51/1227]	  loss: 0.26cifar10:0.2-instance | Epoch [ 56/ 75] Iter[101/1227]	  loss: 0.40cifar10:0.2-instance | Epoch [ 56/ 75] Iter[151/1227]	  loss: 0.40cifar10:0.2-instance | Epoch [ 56/ 75] Iter[201/1227]	  loss: 0.36cifar10:0.2-instance | Epoch [ 56/ 75] Iter[251/1227]	  loss: 0.49cifar10:0.2-instance | Epoch [ 56/ 75] Iter[301/1227]	  loss: 0.45cifar10:0.2-instance | Epoch [ 56/ 75] Iter[351/1227]	  loss: 0.72cifar10:0.2-instance | Epoch [ 56/ 75] Iter[401/1227]	  loss: 0.44cifar10:0.2-instance | Epoch [ 56/ 75] Iter[451/1227]	  loss: 0.35cifar10:0.2-instance | Epoch [ 56/ 75] Iter[501/1227]	  loss: 0.35cifar10:0.2-instance | Epoch [ 56/ 75] Iter[551/1227]	  loss: 0.45cifar10:0.2-instance | Epoch [ 56/ 75] Iter[601/1227]	  loss: 0.44cifar10:0.2-instance | Epoch [ 56/ 75] Iter[651/1227]	  loss: 0.48cifar10:0.2-instance | Epoch [ 56/ 75] Iter[701/1227]	  loss: 0.59cifar10:0.2-instance | Epoch [ 56/ 75] Iter[751/1227]	  loss: 0.48cifar10:0.2-instance | Epoch [ 56/ 75] Iter[801/1227]	  loss: 0.42cifar10:0.2-instance | Epoch [ 56/ 75] Iter[851/1227]	  loss: 0.32cifar10:0.2-instance | Epoch [ 56/ 75] Iter[901/1227]	  loss: 0.50cifar10:0.2-instance | Epoch [ 56/ 75] Iter[951/1227]	  loss: 0.82cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1001/1227]	  loss: 0.56cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1051/1227]	  loss: 0.28cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1101/1227]	  loss: 0.70cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1151/1227]	  loss: 0.44cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1201/1227]	  loss: 0.48
| Test Epoch 56	 Accuracy: 83.91% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 57 | Accuracy on train set: 71.02% 
labeled data has a size of 39238, f-score: 0.982339
cifar10:0.2-instance | Epoch [ 57/ 75] Iter[  1/1227]	  loss: 0.30cifar10:0.2-instance | Epoch [ 57/ 75] Iter[ 51/1227]	  loss: 0.39cifar10:0.2-instance | Epoch [ 57/ 75] Iter[101/1227]	  loss: 0.40cifar10:0.2-instance | Epoch [ 57/ 75] Iter[151/1227]	  loss: 0.42cifar10:0.2-instance | Epoch [ 57/ 75] Iter[201/1227]	  loss: 0.44cifar10:0.2-instance | Epoch [ 57/ 75] Iter[251/1227]	  loss: 0.36cifar10:0.2-instance | Epoch [ 57/ 75] Iter[301/1227]	  loss: 0.61cifar10:0.2-instance | Epoch [ 57/ 75] Iter[351/1227]	  loss: 0.40cifar10:0.2-instance | Epoch [ 57/ 75] Iter[401/1227]	  loss: 0.49cifar10:0.2-instance | Epoch [ 57/ 75] Iter[451/1227]	  loss: 0.68cifar10:0.2-instance | Epoch [ 57/ 75] Iter[501/1227]	  loss: 0.38cifar10:0.2-instance | Epoch [ 57/ 75] Iter[551/1227]	  loss: 0.49cifar10:0.2-instance | Epoch [ 57/ 75] Iter[601/1227]	  loss: 0.27cifar10:0.2-instance | Epoch [ 57/ 75] Iter[651/1227]	  loss: 0.32cifar10:0.2-instance | Epoch [ 57/ 75] Iter[701/1227]	  loss: 0.45cifar10:0.2-instance | Epoch [ 57/ 75] Iter[751/1227]	  loss: 0.31cifar10:0.2-instance | Epoch [ 57/ 75] Iter[801/1227]	  loss: 0.41cifar10:0.2-instance | Epoch [ 57/ 75] Iter[851/1227]	  loss: 0.35cifar10:0.2-instance | Epoch [ 57/ 75] Iter[901/1227]	  loss: 0.53cifar10:0.2-instance | Epoch [ 57/ 75] Iter[951/1227]	  loss: 0.39cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1001/1227]	  loss: 0.33cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1051/1227]	  loss: 0.39cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1101/1227]	  loss: 0.45cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1151/1227]	  loss: 0.30cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1201/1227]	  loss: 0.48
| Test Epoch 57	 Accuracy: 85.87% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 58 | Accuracy on train set: 72.81% 
labeled data has a size of 39359, f-score: 0.981961
cifar10:0.2-instance | Epoch [ 58/ 75] Iter[  1/1230]	  loss: 0.37cifar10:0.2-instance | Epoch [ 58/ 75] Iter[ 51/1230]	  loss: 0.41cifar10:0.2-instance | Epoch [ 58/ 75] Iter[101/1230]	  loss: 0.36cifar10:0.2-instance | Epoch [ 58/ 75] Iter[151/1230]	  loss: 0.24cifar10:0.2-instance | Epoch [ 58/ 75] Iter[201/1230]	  loss: 0.22cifar10:0.2-instance | Epoch [ 58/ 75] Iter[251/1230]	  loss: 0.77cifar10:0.2-instance | Epoch [ 58/ 75] Iter[301/1230]	  loss: 0.37cifar10:0.2-instance | Epoch [ 58/ 75] Iter[351/1230]	  loss: 0.25cifar10:0.2-instance | Epoch [ 58/ 75] Iter[401/1230]	  loss: 0.36cifar10:0.2-instance | Epoch [ 58/ 75] Iter[451/1230]	  loss: 0.38cifar10:0.2-instance | Epoch [ 58/ 75] Iter[501/1230]	  loss: 0.40cifar10:0.2-instance | Epoch [ 58/ 75] Iter[551/1230]	  loss: 0.55cifar10:0.2-instance | Epoch [ 58/ 75] Iter[601/1230]	  loss: 0.66cifar10:0.2-instance | Epoch [ 58/ 75] Iter[651/1230]	  loss: 0.29cifar10:0.2-instance | Epoch [ 58/ 75] Iter[701/1230]	  loss: 0.20cifar10:0.2-instance | Epoch [ 58/ 75] Iter[751/1230]	  loss: 0.36cifar10:0.2-instance | Epoch [ 58/ 75] Iter[801/1230]	  loss: 0.47cifar10:0.2-instance | Epoch [ 58/ 75] Iter[851/1230]	  loss: 0.36cifar10:0.2-instance | Epoch [ 58/ 75] Iter[901/1230]	  loss: 0.30cifar10:0.2-instance | Epoch [ 58/ 75] Iter[951/1230]	  loss: 0.36cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1001/1230]	  loss: 0.24cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1051/1230]	  loss: 0.32cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1101/1230]	  loss: 0.41cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1151/1230]	  loss: 0.52cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1201/1230]	  loss: 0.40
| Test Epoch 58	 Accuracy: 86.34% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 59 | Accuracy on train set: 72.82% 
labeled data has a size of 39288, f-score: 0.982463
cifar10:0.2-instance | Epoch [ 59/ 75] Iter[  1/1228]	  loss: 0.37cifar10:0.2-instance | Epoch [ 59/ 75] Iter[ 51/1228]	  loss: 0.40cifar10:0.2-instance | Epoch [ 59/ 75] Iter[101/1228]	  loss: 0.37cifar10:0.2-instance | Epoch [ 59/ 75] Iter[151/1228]	  loss: 0.63cifar10:0.2-instance | Epoch [ 59/ 75] Iter[201/1228]	  loss: 0.35cifar10:0.2-instance | Epoch [ 59/ 75] Iter[251/1228]	  loss: 0.52cifar10:0.2-instance | Epoch [ 59/ 75] Iter[301/1228]	  loss: 0.30cifar10:0.2-instance | Epoch [ 59/ 75] Iter[351/1228]	  loss: 0.48cifar10:0.2-instance | Epoch [ 59/ 75] Iter[401/1228]	  loss: 0.41cifar10:0.2-instance | Epoch [ 59/ 75] Iter[451/1228]	  loss: 0.33cifar10:0.2-instance | Epoch [ 59/ 75] Iter[501/1228]	  loss: 0.39cifar10:0.2-instance | Epoch [ 59/ 75] Iter[551/1228]	  loss: 0.47cifar10:0.2-instance | Epoch [ 59/ 75] Iter[601/1228]	  loss: 0.28cifar10:0.2-instance | Epoch [ 59/ 75] Iter[651/1228]	  loss: 0.31cifar10:0.2-instance | Epoch [ 59/ 75] Iter[701/1228]	  loss: 0.34cifar10:0.2-instance | Epoch [ 59/ 75] Iter[751/1228]	  loss: 0.20cifar10:0.2-instance | Epoch [ 59/ 75] Iter[801/1228]	  loss: 0.49cifar10:0.2-instance | Epoch [ 59/ 75] Iter[851/1228]	  loss: 0.29cifar10:0.2-instance | Epoch [ 59/ 75] Iter[901/1228]	  loss: 0.30cifar10:0.2-instance | Epoch [ 59/ 75] Iter[951/1228]	  loss: 0.34cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1001/1228]	  loss: 0.62cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1051/1228]	  loss: 0.75cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1101/1228]	  loss: 0.37cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1151/1228]	  loss: 0.48cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1201/1228]	  loss: 0.53
| Test Epoch 59	 Accuracy: 86.37% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 60 | Accuracy on train set: 72.87% 
labeled data has a size of 39277, f-score: 0.983807
cifar10:0.2-instance | Epoch [ 60/ 75] Iter[  1/1228]	  loss: 0.41cifar10:0.2-instance | Epoch [ 60/ 75] Iter[ 51/1228]	  loss: 0.27cifar10:0.2-instance | Epoch [ 60/ 75] Iter[101/1228]	  loss: 0.36cifar10:0.2-instance | Epoch [ 60/ 75] Iter[151/1228]	  loss: 0.41cifar10:0.2-instance | Epoch [ 60/ 75] Iter[201/1228]	  loss: 0.28cifar10:0.2-instance | Epoch [ 60/ 75] Iter[251/1228]	  loss: 0.30cifar10:0.2-instance | Epoch [ 60/ 75] Iter[301/1228]	  loss: 0.18cifar10:0.2-instance | Epoch [ 60/ 75] Iter[351/1228]	  loss: 0.23cifar10:0.2-instance | Epoch [ 60/ 75] Iter[401/1228]	  loss: 0.26cifar10:0.2-instance | Epoch [ 60/ 75] Iter[451/1228]	  loss: 0.25cifar10:0.2-instance | Epoch [ 60/ 75] Iter[501/1228]	  loss: 0.23cifar10:0.2-instance | Epoch [ 60/ 75] Iter[551/1228]	  loss: 0.34cifar10:0.2-instance | Epoch [ 60/ 75] Iter[601/1228]	  loss: 0.20cifar10:0.2-instance | Epoch [ 60/ 75] Iter[651/1228]	  loss: 0.44cifar10:0.2-instance | Epoch [ 60/ 75] Iter[701/1228]	  loss: 0.22cifar10:0.2-instance | Epoch [ 60/ 75] Iter[751/1228]	  loss: 0.44cifar10:0.2-instance | Epoch [ 60/ 75] Iter[801/1228]	  loss: 0.24cifar10:0.2-instance | Epoch [ 60/ 75] Iter[851/1228]	  loss: 0.32cifar10:0.2-instance | Epoch [ 60/ 75] Iter[901/1228]	  loss: 0.22cifar10:0.2-instance | Epoch [ 60/ 75] Iter[951/1228]	  loss: 0.18cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1001/1228]	  loss: 0.27cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1051/1228]	  loss: 0.42cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1101/1228]	  loss: 0.29cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1151/1228]	  loss: 0.27cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1201/1228]	  loss: 0.37
| Test Epoch 60	 Accuracy: 91.08% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 61 | Accuracy on train set: 77.04% 
labeled data has a size of 39327, f-score: 0.985659
cifar10:0.2-instance | Epoch [ 61/ 75] Iter[  1/1229]	  loss: 0.21cifar10:0.2-instance | Epoch [ 61/ 75] Iter[ 51/1229]	  loss: 0.20cifar10:0.2-instance | Epoch [ 61/ 75] Iter[101/1229]	  loss: 0.18cifar10:0.2-instance | Epoch [ 61/ 75] Iter[151/1229]	  loss: 0.19cifar10:0.2-instance | Epoch [ 61/ 75] Iter[201/1229]	  loss: 0.35cifar10:0.2-instance | Epoch [ 61/ 75] Iter[251/1229]	  loss: 0.19cifar10:0.2-instance | Epoch [ 61/ 75] Iter[301/1229]	  loss: 0.28cifar10:0.2-instance | Epoch [ 61/ 75] Iter[351/1229]	  loss: 0.28cifar10:0.2-instance | Epoch [ 61/ 75] Iter[401/1229]	  loss: 0.32cifar10:0.2-instance | Epoch [ 61/ 75] Iter[451/1229]	  loss: 0.29cifar10:0.2-instance | Epoch [ 61/ 75] Iter[501/1229]	  loss: 0.49cifar10:0.2-instance | Epoch [ 61/ 75] Iter[551/1229]	  loss: 0.34cifar10:0.2-instance | Epoch [ 61/ 75] Iter[601/1229]	  loss: 0.17cifar10:0.2-instance | Epoch [ 61/ 75] Iter[651/1229]	  loss: 0.18cifar10:0.2-instance | Epoch [ 61/ 75] Iter[701/1229]	  loss: 0.22cifar10:0.2-instance | Epoch [ 61/ 75] Iter[751/1229]	  loss: 0.19cifar10:0.2-instance | Epoch [ 61/ 75] Iter[801/1229]	  loss: 0.30cifar10:0.2-instance | Epoch [ 61/ 75] Iter[851/1229]	  loss: 0.20cifar10:0.2-instance | Epoch [ 61/ 75] Iter[901/1229]	  loss: 0.22cifar10:0.2-instance | Epoch [ 61/ 75] Iter[951/1229]	  loss: 0.16cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1001/1229]	  loss: 0.16cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1051/1229]	  loss: 0.25cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1101/1229]	  loss: 0.32cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1151/1229]	  loss: 0.17cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1201/1229]	  loss: 0.21
| Test Epoch 61	 Accuracy: 91.53% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 62 | Accuracy on train set: 77.47% 
labeled data has a size of 39378, f-score: 0.986465
cifar10:0.2-instance | Epoch [ 62/ 75] Iter[  1/1231]	  loss: 0.23cifar10:0.2-instance | Epoch [ 62/ 75] Iter[ 51/1231]	  loss: 0.26cifar10:0.2-instance | Epoch [ 62/ 75] Iter[101/1231]	  loss: 0.20cifar10:0.2-instance | Epoch [ 62/ 75] Iter[151/1231]	  loss: 0.20cifar10:0.2-instance | Epoch [ 62/ 75] Iter[201/1231]	  loss: 0.21cifar10:0.2-instance | Epoch [ 62/ 75] Iter[251/1231]	  loss: 0.26cifar10:0.2-instance | Epoch [ 62/ 75] Iter[301/1231]	  loss: 0.19cifar10:0.2-instance | Epoch [ 62/ 75] Iter[351/1231]	  loss: 0.15cifar10:0.2-instance | Epoch [ 62/ 75] Iter[401/1231]	  loss: 0.20cifar10:0.2-instance | Epoch [ 62/ 75] Iter[451/1231]	  loss: 0.27cifar10:0.2-instance | Epoch [ 62/ 75] Iter[501/1231]	  loss: 0.22cifar10:0.2-instance | Epoch [ 62/ 75] Iter[551/1231]	  loss: 0.33cifar10:0.2-instance | Epoch [ 62/ 75] Iter[601/1231]	  loss: 0.27cifar10:0.2-instance | Epoch [ 62/ 75] Iter[651/1231]	  loss: 0.26cifar10:0.2-instance | Epoch [ 62/ 75] Iter[701/1231]	  loss: 0.22cifar10:0.2-instance | Epoch [ 62/ 75] Iter[751/1231]	  loss: 0.22cifar10:0.2-instance | Epoch [ 62/ 75] Iter[801/1231]	  loss: 0.19cifar10:0.2-instance | Epoch [ 62/ 75] Iter[851/1231]	  loss: 0.21cifar10:0.2-instance | Epoch [ 62/ 75] Iter[901/1231]	  loss: 0.19cifar10:0.2-instance | Epoch [ 62/ 75] Iter[951/1231]	  loss: 0.34cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1001/1231]	  loss: 0.20cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1051/1231]	  loss: 0.27cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1101/1231]	  loss: 0.23cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1151/1231]	  loss: 0.20cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1201/1231]	  loss: 0.42
| Test Epoch 62	 Accuracy: 91.48% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 63 | Accuracy on train set: 77.67% 
labeled data has a size of 39446, f-score: 0.986260
cifar10:0.2-instance | Epoch [ 63/ 75] Iter[  1/1233]	  loss: 0.22cifar10:0.2-instance | Epoch [ 63/ 75] Iter[ 51/1233]	  loss: 0.22cifar10:0.2-instance | Epoch [ 63/ 75] Iter[101/1233]	  loss: 0.16cifar10:0.2-instance | Epoch [ 63/ 75] Iter[151/1233]	  loss: 0.19cifar10:0.2-instance | Epoch [ 63/ 75] Iter[201/1233]	  loss: 0.20cifar10:0.2-instance | Epoch [ 63/ 75] Iter[251/1233]	  loss: 0.18cifar10:0.2-instance | Epoch [ 63/ 75] Iter[301/1233]	  loss: 0.17cifar10:0.2-instance | Epoch [ 63/ 75] Iter[351/1233]	  loss: 0.20cifar10:0.2-instance | Epoch [ 63/ 75] Iter[401/1233]	  loss: 0.18cifar10:0.2-instance | Epoch [ 63/ 75] Iter[451/1233]	  loss: 0.16cifar10:0.2-instance | Epoch [ 63/ 75] Iter[501/1233]	  loss: 0.16cifar10:0.2-instance | Epoch [ 63/ 75] Iter[551/1233]	  loss: 0.17cifar10:0.2-instance | Epoch [ 63/ 75] Iter[601/1233]	  loss: 0.24cifar10:0.2-instance | Epoch [ 63/ 75] Iter[651/1233]	  loss: 0.16cifar10:0.2-instance | Epoch [ 63/ 75] Iter[701/1233]	  loss: 0.16cifar10:0.2-instance | Epoch [ 63/ 75] Iter[751/1233]	  loss: 0.17cifar10:0.2-instance | Epoch [ 63/ 75] Iter[801/1233]	  loss: 0.24cifar10:0.2-instance | Epoch [ 63/ 75] Iter[851/1233]	  loss: 0.23cifar10:0.2-instance | Epoch [ 63/ 75] Iter[901/1233]	  loss: 0.34cifar10:0.2-instance | Epoch [ 63/ 75] Iter[951/1233]	  loss: 0.26cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1001/1233]	  loss: 0.16cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1051/1233]	  loss: 0.15cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1101/1233]	  loss: 0.23cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1151/1233]	  loss: 0.17cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1201/1233]	  loss: 0.17
| Test Epoch 63	 Accuracy: 92.19% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 64 | Accuracy on train set: 78.03% 
labeled data has a size of 39523, f-score: 0.985882
cifar10:0.2-instance | Epoch [ 64/ 75] Iter[  1/1236]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[ 51/1236]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[101/1236]	  loss: 0.44cifar10:0.2-instance | Epoch [ 64/ 75] Iter[151/1236]	  loss: 0.20cifar10:0.2-instance | Epoch [ 64/ 75] Iter[201/1236]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[251/1236]	  loss: 0.19cifar10:0.2-instance | Epoch [ 64/ 75] Iter[301/1236]	  loss: 0.17cifar10:0.2-instance | Epoch [ 64/ 75] Iter[351/1236]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[401/1236]	  loss: 0.18cifar10:0.2-instance | Epoch [ 64/ 75] Iter[451/1236]	  loss: 0.34cifar10:0.2-instance | Epoch [ 64/ 75] Iter[501/1236]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[551/1236]	  loss: 0.22cifar10:0.2-instance | Epoch [ 64/ 75] Iter[601/1236]	  loss: 0.18cifar10:0.2-instance | Epoch [ 64/ 75] Iter[651/1236]	  loss: 0.33cifar10:0.2-instance | Epoch [ 64/ 75] Iter[701/1236]	  loss: 0.20cifar10:0.2-instance | Epoch [ 64/ 75] Iter[751/1236]	  loss: 0.27cifar10:0.2-instance | Epoch [ 64/ 75] Iter[801/1236]	  loss: 0.17cifar10:0.2-instance | Epoch [ 64/ 75] Iter[851/1236]	  loss: 0.15cifar10:0.2-instance | Epoch [ 64/ 75] Iter[901/1236]	  loss: 0.15cifar10:0.2-instance | Epoch [ 64/ 75] Iter[951/1236]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1001/1236]	  loss: 0.19cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1051/1236]	  loss: 0.18cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1101/1236]	  loss: 0.29cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1151/1236]	  loss: 0.21cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1201/1236]	  loss: 0.25
| Test Epoch 64	 Accuracy: 92.07% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 65 | Accuracy on train set: 78.20% 
labeled data has a size of 39588, f-score: 0.985299
cifar10:0.2-instance | Epoch [ 65/ 75] Iter[  1/1238]	  loss: 0.18cifar10:0.2-instance | Epoch [ 65/ 75] Iter[ 51/1238]	  loss: 0.17cifar10:0.2-instance | Epoch [ 65/ 75] Iter[101/1238]	  loss: 0.22cifar10:0.2-instance | Epoch [ 65/ 75] Iter[151/1238]	  loss: 0.23cifar10:0.2-instance | Epoch [ 65/ 75] Iter[201/1238]	  loss: 0.16cifar10:0.2-instance | Epoch [ 65/ 75] Iter[251/1238]	  loss: 0.18cifar10:0.2-instance | Epoch [ 65/ 75] Iter[301/1238]	  loss: 0.22cifar10:0.2-instance | Epoch [ 65/ 75] Iter[351/1238]	  loss: 0.25cifar10:0.2-instance | Epoch [ 65/ 75] Iter[401/1238]	  loss: 0.16cifar10:0.2-instance | Epoch [ 65/ 75] Iter[451/1238]	  loss: 0.16cifar10:0.2-instance | Epoch [ 65/ 75] Iter[501/1238]	  loss: 0.20cifar10:0.2-instance | Epoch [ 65/ 75] Iter[551/1238]	  loss: 0.28cifar10:0.2-instance | Epoch [ 65/ 75] Iter[601/1238]	  loss: 0.18cifar10:0.2-instance | Epoch [ 65/ 75] Iter[651/1238]	  loss: 0.15cifar10:0.2-instance | Epoch [ 65/ 75] Iter[701/1238]	  loss: 0.28cifar10:0.2-instance | Epoch [ 65/ 75] Iter[751/1238]	  loss: 0.15cifar10:0.2-instance | Epoch [ 65/ 75] Iter[801/1238]	  loss: 0.19cifar10:0.2-instance | Epoch [ 65/ 75] Iter[851/1238]	  loss: 0.19cifar10:0.2-instance | Epoch [ 65/ 75] Iter[901/1238]	  loss: 0.33cifar10:0.2-instance | Epoch [ 65/ 75] Iter[951/1238]	  loss: 0.16cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1001/1238]	  loss: 0.15cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1051/1238]	  loss: 0.16cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1101/1238]	  loss: 0.24cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1151/1238]	  loss: 0.20cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1201/1238]	  loss: 0.18
| Test Epoch 65	 Accuracy: 91.90% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 66 | Accuracy on train set: 78.42% 
labeled data has a size of 39677, f-score: 0.984727
cifar10:0.2-instance | Epoch [ 66/ 75] Iter[  1/1240]	  loss: 0.16cifar10:0.2-instance | Epoch [ 66/ 75] Iter[ 51/1240]	  loss: 0.37cifar10:0.2-instance | Epoch [ 66/ 75] Iter[101/1240]	  loss: 0.23cifar10:0.2-instance | Epoch [ 66/ 75] Iter[151/1240]	  loss: 0.18cifar10:0.2-instance | Epoch [ 66/ 75] Iter[201/1240]	  loss: 0.16cifar10:0.2-instance | Epoch [ 66/ 75] Iter[251/1240]	  loss: 0.23cifar10:0.2-instance | Epoch [ 66/ 75] Iter[301/1240]	  loss: 0.27cifar10:0.2-instance | Epoch [ 66/ 75] Iter[351/1240]	  loss: 0.22cifar10:0.2-instance | Epoch [ 66/ 75] Iter[401/1240]	  loss: 0.16cifar10:0.2-instance | Epoch [ 66/ 75] Iter[451/1240]	  loss: 0.22cifar10:0.2-instance | Epoch [ 66/ 75] Iter[501/1240]	  loss: 0.17cifar10:0.2-instance | Epoch [ 66/ 75] Iter[551/1240]	  loss: 0.23cifar10:0.2-instance | Epoch [ 66/ 75] Iter[601/1240]	  loss: 0.28cifar10:0.2-instance | Epoch [ 66/ 75] Iter[651/1240]	  loss: 0.16cifar10:0.2-instance | Epoch [ 66/ 75] Iter[701/1240]	  loss: 0.22cifar10:0.2-instance | Epoch [ 66/ 75] Iter[751/1240]	  loss: 0.18cifar10:0.2-instance | Epoch [ 66/ 75] Iter[801/1240]	  loss: 0.17cifar10:0.2-instance | Epoch [ 66/ 75] Iter[851/1240]	  loss: 0.19cifar10:0.2-instance | Epoch [ 66/ 75] Iter[901/1240]	  loss: 0.16cifar10:0.2-instance | Epoch [ 66/ 75] Iter[951/1240]	  loss: 0.19cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1001/1240]	  loss: 0.23cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1051/1240]	  loss: 0.22cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1101/1240]	  loss: 0.25cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1151/1240]	  loss: 0.19cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1201/1240]	  loss: 0.17
| Test Epoch 66	 Accuracy: 91.91% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 67 | Accuracy on train set: 78.60% 
labeled data has a size of 39720, f-score: 0.984491
cifar10:0.2-instance | Epoch [ 67/ 75] Iter[  1/1242]	  loss: 0.17cifar10:0.2-instance | Epoch [ 67/ 75] Iter[ 51/1242]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[101/1242]	  loss: 0.15cifar10:0.2-instance | Epoch [ 67/ 75] Iter[151/1242]	  loss: 0.20cifar10:0.2-instance | Epoch [ 67/ 75] Iter[201/1242]	  loss: 0.26cifar10:0.2-instance | Epoch [ 67/ 75] Iter[251/1242]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[301/1242]	  loss: 0.22cifar10:0.2-instance | Epoch [ 67/ 75] Iter[351/1242]	  loss: 0.22cifar10:0.2-instance | Epoch [ 67/ 75] Iter[401/1242]	  loss: 0.15cifar10:0.2-instance | Epoch [ 67/ 75] Iter[451/1242]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[501/1242]	  loss: 0.32cifar10:0.2-instance | Epoch [ 67/ 75] Iter[551/1242]	  loss: 0.15cifar10:0.2-instance | Epoch [ 67/ 75] Iter[601/1242]	  loss: 0.15cifar10:0.2-instance | Epoch [ 67/ 75] Iter[651/1242]	  loss: 0.23cifar10:0.2-instance | Epoch [ 67/ 75] Iter[701/1242]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[751/1242]	  loss: 0.18cifar10:0.2-instance | Epoch [ 67/ 75] Iter[801/1242]	  loss: 0.27cifar10:0.2-instance | Epoch [ 67/ 75] Iter[851/1242]	  loss: 0.22cifar10:0.2-instance | Epoch [ 67/ 75] Iter[901/1242]	  loss: 0.18cifar10:0.2-instance | Epoch [ 67/ 75] Iter[951/1242]	  loss: 0.20cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1001/1242]	  loss: 0.20cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1051/1242]	  loss: 0.17cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1101/1242]	  loss: 0.17cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1151/1242]	  loss: 0.33cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1201/1242]	  loss: 0.17
| Test Epoch 67	 Accuracy: 91.84% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 68 | Accuracy on train set: 78.70% 
labeled data has a size of 39756, f-score: 0.984153
cifar10:0.2-instance | Epoch [ 68/ 75] Iter[  1/1243]	  loss: 0.21cifar10:0.2-instance | Epoch [ 68/ 75] Iter[ 51/1243]	  loss: 0.31cifar10:0.2-instance | Epoch [ 68/ 75] Iter[101/1243]	  loss: 0.18cifar10:0.2-instance | Epoch [ 68/ 75] Iter[151/1243]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[201/1243]	  loss: 0.17cifar10:0.2-instance | Epoch [ 68/ 75] Iter[251/1243]	  loss: 0.21cifar10:0.2-instance | Epoch [ 68/ 75] Iter[301/1243]	  loss: 0.25cifar10:0.2-instance | Epoch [ 68/ 75] Iter[351/1243]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[401/1243]	  loss: 0.16cifar10:0.2-instance | Epoch [ 68/ 75] Iter[451/1243]	  loss: 0.24cifar10:0.2-instance | Epoch [ 68/ 75] Iter[501/1243]	  loss: 0.17cifar10:0.2-instance | Epoch [ 68/ 75] Iter[551/1243]	  loss: 0.16cifar10:0.2-instance | Epoch [ 68/ 75] Iter[601/1243]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[651/1243]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[701/1243]	  loss: 0.17cifar10:0.2-instance | Epoch [ 68/ 75] Iter[751/1243]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[801/1243]	  loss: 0.22cifar10:0.2-instance | Epoch [ 68/ 75] Iter[851/1243]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[901/1243]	  loss: 0.25cifar10:0.2-instance | Epoch [ 68/ 75] Iter[951/1243]	  loss: 0.27cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1001/1243]	  loss: 0.21cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1051/1243]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1101/1243]	  loss: 0.23cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1151/1243]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1201/1243]	  loss: 0.18
| Test Epoch 68	 Accuracy: 91.91% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 69 | Accuracy on train set: 78.80% 
labeled data has a size of 39806, f-score: 0.983847
cifar10:0.2-instance | Epoch [ 69/ 75] Iter[  1/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[ 51/1244]	  loss: 0.23cifar10:0.2-instance | Epoch [ 69/ 75] Iter[101/1244]	  loss: 0.21cifar10:0.2-instance | Epoch [ 69/ 75] Iter[151/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[201/1244]	  loss: 0.17cifar10:0.2-instance | Epoch [ 69/ 75] Iter[251/1244]	  loss: 0.17cifar10:0.2-instance | Epoch [ 69/ 75] Iter[301/1244]	  loss: 0.18cifar10:0.2-instance | Epoch [ 69/ 75] Iter[351/1244]	  loss: 0.18cifar10:0.2-instance | Epoch [ 69/ 75] Iter[401/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[451/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[501/1244]	  loss: 0.18cifar10:0.2-instance | Epoch [ 69/ 75] Iter[551/1244]	  loss: 0.19cifar10:0.2-instance | Epoch [ 69/ 75] Iter[601/1244]	  loss: 0.17cifar10:0.2-instance | Epoch [ 69/ 75] Iter[651/1244]	  loss: 0.16cifar10:0.2-instance | Epoch [ 69/ 75] Iter[701/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[751/1244]	  loss: 0.17cifar10:0.2-instance | Epoch [ 69/ 75] Iter[801/1244]	  loss: 0.20cifar10:0.2-instance | Epoch [ 69/ 75] Iter[851/1244]	  loss: 0.17cifar10:0.2-instance | Epoch [ 69/ 75] Iter[901/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[951/1244]	  loss: 0.16cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1001/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1051/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1101/1244]	  loss: 0.34cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1151/1244]	  loss: 0.21cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1201/1244]	  loss: 0.22
| Test Epoch 69	 Accuracy: 91.93% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 70 | Accuracy on train set: 78.93% 
labeled data has a size of 39846, f-score: 0.983286
cifar10:0.2-instance | Epoch [ 70/ 75] Iter[  1/1246]	  loss: 0.17cifar10:0.2-instance | Epoch [ 70/ 75] Iter[ 51/1246]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[101/1246]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[151/1246]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[201/1246]	  loss: 0.17cifar10:0.2-instance | Epoch [ 70/ 75] Iter[251/1246]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[301/1246]	  loss: 0.18cifar10:0.2-instance | Epoch [ 70/ 75] Iter[351/1246]	  loss: 0.17cifar10:0.2-instance | Epoch [ 70/ 75] Iter[401/1246]	  loss: 0.30cifar10:0.2-instance | Epoch [ 70/ 75] Iter[451/1246]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[501/1246]	  loss: 0.39cifar10:0.2-instance | Epoch [ 70/ 75] Iter[551/1246]	  loss: 0.18cifar10:0.2-instance | Epoch [ 70/ 75] Iter[601/1246]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[651/1246]	  loss: 0.19cifar10:0.2-instance | Epoch [ 70/ 75] Iter[701/1246]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[751/1246]	  loss: 0.20cifar10:0.2-instance | Epoch [ 70/ 75] Iter[801/1246]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[851/1246]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[901/1246]	  loss: 0.21cifar10:0.2-instance | Epoch [ 70/ 75] Iter[951/1246]	  loss: 0.17cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1001/1246]	  loss: 0.23cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1051/1246]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1101/1246]	  loss: 0.31cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1151/1246]	  loss: 0.17cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1201/1246]	  loss: 0.15
| Test Epoch 70	 Accuracy: 91.84% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 71 | Accuracy on train set: 79.02% 
labeled data has a size of 39880, f-score: 0.982999
cifar10:0.2-instance | Epoch [ 71/ 75] Iter[  1/1247]	  loss: 0.17cifar10:0.2-instance | Epoch [ 71/ 75] Iter[ 51/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[101/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[151/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[201/1247]	  loss: 0.17cifar10:0.2-instance | Epoch [ 71/ 75] Iter[251/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[301/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[351/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[401/1247]	  loss: 0.21cifar10:0.2-instance | Epoch [ 71/ 75] Iter[451/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[501/1247]	  loss: 0.17cifar10:0.2-instance | Epoch [ 71/ 75] Iter[551/1247]	  loss: 0.17cifar10:0.2-instance | Epoch [ 71/ 75] Iter[601/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[651/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[701/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[751/1247]	  loss: 0.23cifar10:0.2-instance | Epoch [ 71/ 75] Iter[801/1247]	  loss: 0.19cifar10:0.2-instance | Epoch [ 71/ 75] Iter[851/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[901/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[951/1247]	  loss: 0.24cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1001/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1051/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1101/1247]	  loss: 0.21cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1151/1247]	  loss: 0.17cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1201/1247]	  loss: 0.24
| Test Epoch 71	 Accuracy: 91.94% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 72 | Accuracy on train set: 79.21% 
labeled data has a size of 39933, f-score: 0.982696
cifar10:0.2-instance | Epoch [ 72/ 75] Iter[  1/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[ 51/1248]	  loss: 0.20cifar10:0.2-instance | Epoch [ 72/ 75] Iter[101/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[151/1248]	  loss: 0.19cifar10:0.2-instance | Epoch [ 72/ 75] Iter[201/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[251/1248]	  loss: 0.17cifar10:0.2-instance | Epoch [ 72/ 75] Iter[301/1248]	  loss: 0.18cifar10:0.2-instance | Epoch [ 72/ 75] Iter[351/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[401/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[451/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[501/1248]	  loss: 0.20cifar10:0.2-instance | Epoch [ 72/ 75] Iter[551/1248]	  loss: 0.25cifar10:0.2-instance | Epoch [ 72/ 75] Iter[601/1248]	  loss: 0.19cifar10:0.2-instance | Epoch [ 72/ 75] Iter[651/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[701/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[751/1248]	  loss: 0.20cifar10:0.2-instance | Epoch [ 72/ 75] Iter[801/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[851/1248]	  loss: 0.21cifar10:0.2-instance | Epoch [ 72/ 75] Iter[901/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[951/1248]	  loss: 0.18cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1001/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1051/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1101/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1151/1248]	  loss: 0.29cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1201/1248]	  loss: 0.16
| Test Epoch 72	 Accuracy: 91.64% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 73 | Accuracy on train set: 79.33% 
labeled data has a size of 39964, f-score: 0.982384
cifar10:0.2-instance | Epoch [ 73/ 75] Iter[  1/1249]	  loss: 0.17cifar10:0.2-instance | Epoch [ 73/ 75] Iter[ 51/1249]	  loss: 0.28cifar10:0.2-instance | Epoch [ 73/ 75] Iter[101/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[151/1249]	  loss: 0.29cifar10:0.2-instance | Epoch [ 73/ 75] Iter[201/1249]	  loss: 0.20cifar10:0.2-instance | Epoch [ 73/ 75] Iter[251/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[301/1249]	  loss: 0.21cifar10:0.2-instance | Epoch [ 73/ 75] Iter[351/1249]	  loss: 0.19cifar10:0.2-instance | Epoch [ 73/ 75] Iter[401/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[451/1249]	  loss: 0.22cifar10:0.2-instance | Epoch [ 73/ 75] Iter[501/1249]	  loss: 0.29cifar10:0.2-instance | Epoch [ 73/ 75] Iter[551/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[601/1249]	  loss: 0.20cifar10:0.2-instance | Epoch [ 73/ 75] Iter[651/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[701/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[751/1249]	  loss: 0.19cifar10:0.2-instance | Epoch [ 73/ 75] Iter[801/1249]	  loss: 0.34cifar10:0.2-instance | Epoch [ 73/ 75] Iter[851/1249]	  loss: 0.17cifar10:0.2-instance | Epoch [ 73/ 75] Iter[901/1249]	  loss: 0.25cifar10:0.2-instance | Epoch [ 73/ 75] Iter[951/1249]	  loss: 0.17cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1001/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1051/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1101/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1151/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1201/1249]	  loss: 0.16
| Test Epoch 73	 Accuracy: 91.96% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 74 | Accuracy on train set: 79.33% 
labeled data has a size of 39986, f-score: 0.982394
cifar10:0.2-instance | Epoch [ 74/ 75] Iter[  1/1250]	  loss: 0.18cifar10:0.2-instance | Epoch [ 74/ 75] Iter[ 51/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[101/1250]	  loss: 0.38cifar10:0.2-instance | Epoch [ 74/ 75] Iter[151/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[201/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[251/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[301/1250]	  loss: 0.18cifar10:0.2-instance | Epoch [ 74/ 75] Iter[351/1250]	  loss: 0.24cifar10:0.2-instance | Epoch [ 74/ 75] Iter[401/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[451/1250]	  loss: 0.17cifar10:0.2-instance | Epoch [ 74/ 75] Iter[501/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[551/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[601/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[651/1250]	  loss: 0.19cifar10:0.2-instance | Epoch [ 74/ 75] Iter[701/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[751/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[801/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[851/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[901/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[951/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1001/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1051/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1101/1250]	  loss: 0.21cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1151/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1201/1250]	  loss: 0.22
| Test Epoch 74	 Accuracy: 91.79% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 75 | Accuracy on train set: 79.42% 
labeled data has a size of 40021, f-score: 0.982034
cifar10:0.2-instance | Epoch [ 75/ 75] Iter[  1/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[ 51/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[101/1251]	  loss: 0.21cifar10:0.2-instance | Epoch [ 75/ 75] Iter[151/1251]	  loss: 0.17cifar10:0.2-instance | Epoch [ 75/ 75] Iter[201/1251]	  loss: 0.20cifar10:0.2-instance | Epoch [ 75/ 75] Iter[251/1251]	  loss: 0.26cifar10:0.2-instance | Epoch [ 75/ 75] Iter[301/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[351/1251]	  loss: 0.18cifar10:0.2-instance | Epoch [ 75/ 75] Iter[401/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[451/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[501/1251]	  loss: 0.18cifar10:0.2-instance | Epoch [ 75/ 75] Iter[551/1251]	  loss: 0.22cifar10:0.2-instance | Epoch [ 75/ 75] Iter[601/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[651/1251]	  loss: 0.17cifar10:0.2-instance | Epoch [ 75/ 75] Iter[701/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[751/1251]	  loss: 0.17cifar10:0.2-instance | Epoch [ 75/ 75] Iter[801/1251]	  loss: 0.17cifar10:0.2-instance | Epoch [ 75/ 75] Iter[851/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[901/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[951/1251]	  loss: 0.34cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1001/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1051/1251]	  loss: 0.20cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1101/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1151/1251]	  loss: 0.19cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1201/1251]	  loss: 0.19cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1251/1251]	  loss: 0.15
| Test Epoch 75	 Accuracy: 91.73% 



best test Acc:  92.19
