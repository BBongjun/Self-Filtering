Namespace(T=0.2, batch_size=32, data_path='./dataset2/cifar10', dataset='cifar10', fig_7=0, fluctuation_ablation=0, gpuid=0, k=3, lr=0.02, model='resnet18', noise_mode='instance', num_class=10, num_epochs=75, r=0.2, save_sel_sam=0, seed_model=3, seed_noise=1, semi='no', warm_up=10, wdecay=0.0005, without_Lcr=0, without_R=0)
============ Initialize data
============ Actual clean samples number:  39820
============ use resnet18 
============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 0 | Accuracy on train set: 7.55% 
cifar10:0.2-instance | Epoch [  0/ 75] Iter[  1/391]	 CE-loss: 2.4246cifar10:0.2-instance | Epoch [  0/ 75] Iter[ 51/391]	 CE-loss: 2.0423cifar10:0.2-instance | Epoch [  0/ 75] Iter[101/391]	 CE-loss: 1.9230cifar10:0.2-instance | Epoch [  0/ 75] Iter[151/391]	 CE-loss: 1.9235cifar10:0.2-instance | Epoch [  0/ 75] Iter[201/391]	 CE-loss: 1.8428cifar10:0.2-instance | Epoch [  0/ 75] Iter[251/391]	 CE-loss: 1.8125cifar10:0.2-instance | Epoch [  0/ 75] Iter[301/391]	 CE-loss: 1.5394cifar10:0.2-instance | Epoch [  0/ 75] Iter[351/391]	 CE-loss: 1.7131
| Test Epoch 0	 Accuracy: 46.50% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 1 | Accuracy on train set: 40.78% 
cifar10:0.2-instance | Epoch [  1/ 75] Iter[  1/391]	 CE-loss: 1.5435cifar10:0.2-instance | Epoch [  1/ 75] Iter[ 51/391]	 CE-loss: 1.5166cifar10:0.2-instance | Epoch [  1/ 75] Iter[101/391]	 CE-loss: 1.5592cifar10:0.2-instance | Epoch [  1/ 75] Iter[151/391]	 CE-loss: 1.5736cifar10:0.2-instance | Epoch [  1/ 75] Iter[201/391]	 CE-loss: 1.5808cifar10:0.2-instance | Epoch [  1/ 75] Iter[251/391]	 CE-loss: 1.3443cifar10:0.2-instance | Epoch [  1/ 75] Iter[301/391]	 CE-loss: 1.4136cifar10:0.2-instance | Epoch [  1/ 75] Iter[351/391]	 CE-loss: 1.4983
| Test Epoch 1	 Accuracy: 55.49% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 2 | Accuracy on train set: 46.51% 
cifar10:0.2-instance | Epoch [  2/ 75] Iter[  1/391]	 CE-loss: 1.2760cifar10:0.2-instance | Epoch [  2/ 75] Iter[ 51/391]	 CE-loss: 1.3362cifar10:0.2-instance | Epoch [  2/ 75] Iter[101/391]	 CE-loss: 1.3261cifar10:0.2-instance | Epoch [  2/ 75] Iter[151/391]	 CE-loss: 1.2862cifar10:0.2-instance | Epoch [  2/ 75] Iter[201/391]	 CE-loss: 1.5209cifar10:0.2-instance | Epoch [  2/ 75] Iter[251/391]	 CE-loss: 1.1762cifar10:0.2-instance | Epoch [  2/ 75] Iter[301/391]	 CE-loss: 1.2965cifar10:0.2-instance | Epoch [  2/ 75] Iter[351/391]	 CE-loss: 1.2220
| Test Epoch 2	 Accuracy: 66.41% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 3 | Accuracy on train set: 55.02% 
cifar10:0.2-instance | Epoch [  3/ 75] Iter[  1/391]	 CE-loss: 1.2036cifar10:0.2-instance | Epoch [  3/ 75] Iter[ 51/391]	 CE-loss: 1.3357cifar10:0.2-instance | Epoch [  3/ 75] Iter[101/391]	 CE-loss: 1.1645cifar10:0.2-instance | Epoch [  3/ 75] Iter[151/391]	 CE-loss: 1.1455cifar10:0.2-instance | Epoch [  3/ 75] Iter[201/391]	 CE-loss: 1.2151cifar10:0.2-instance | Epoch [  3/ 75] Iter[251/391]	 CE-loss: 1.2274cifar10:0.2-instance | Epoch [  3/ 75] Iter[301/391]	 CE-loss: 1.1906cifar10:0.2-instance | Epoch [  3/ 75] Iter[351/391]	 CE-loss: 1.1294
| Test Epoch 3	 Accuracy: 63.07% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 4 | Accuracy on train set: 54.87% 
cifar10:0.2-instance | Epoch [  4/ 75] Iter[  1/391]	 CE-loss: 1.2690cifar10:0.2-instance | Epoch [  4/ 75] Iter[ 51/391]	 CE-loss: 1.3729cifar10:0.2-instance | Epoch [  4/ 75] Iter[101/391]	 CE-loss: 1.0496cifar10:0.2-instance | Epoch [  4/ 75] Iter[151/391]	 CE-loss: 1.2142cifar10:0.2-instance | Epoch [  4/ 75] Iter[201/391]	 CE-loss: 1.1569cifar10:0.2-instance | Epoch [  4/ 75] Iter[251/391]	 CE-loss: 0.9914cifar10:0.2-instance | Epoch [  4/ 75] Iter[301/391]	 CE-loss: 1.1187cifar10:0.2-instance | Epoch [  4/ 75] Iter[351/391]	 CE-loss: 1.2677
| Test Epoch 4	 Accuracy: 75.77% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 5 | Accuracy on train set: 62.96% 
cifar10:0.2-instance | Epoch [  5/ 75] Iter[  1/391]	 CE-loss: 1.1761cifar10:0.2-instance | Epoch [  5/ 75] Iter[ 51/391]	 CE-loss: 1.1338cifar10:0.2-instance | Epoch [  5/ 75] Iter[101/391]	 CE-loss: 1.1364cifar10:0.2-instance | Epoch [  5/ 75] Iter[151/391]	 CE-loss: 1.1335cifar10:0.2-instance | Epoch [  5/ 75] Iter[201/391]	 CE-loss: 0.9975cifar10:0.2-instance | Epoch [  5/ 75] Iter[251/391]	 CE-loss: 1.1111cifar10:0.2-instance | Epoch [  5/ 75] Iter[301/391]	 CE-loss: 1.2835cifar10:0.2-instance | Epoch [  5/ 75] Iter[351/391]	 CE-loss: 1.0884
| Test Epoch 5	 Accuracy: 78.39% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 6 | Accuracy on train set: 65.35% 
cifar10:0.2-instance | Epoch [  6/ 75] Iter[  1/391]	 CE-loss: 1.1365cifar10:0.2-instance | Epoch [  6/ 75] Iter[ 51/391]	 CE-loss: 1.0320cifar10:0.2-instance | Epoch [  6/ 75] Iter[101/391]	 CE-loss: 1.0738cifar10:0.2-instance | Epoch [  6/ 75] Iter[151/391]	 CE-loss: 1.2384cifar10:0.2-instance | Epoch [  6/ 75] Iter[201/391]	 CE-loss: 0.9839cifar10:0.2-instance | Epoch [  6/ 75] Iter[251/391]	 CE-loss: 1.0864cifar10:0.2-instance | Epoch [  6/ 75] Iter[301/391]	 CE-loss: 1.0308cifar10:0.2-instance | Epoch [  6/ 75] Iter[351/391]	 CE-loss: 0.9291
| Test Epoch 6	 Accuracy: 75.11% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 7 | Accuracy on train set: 62.90% 
cifar10:0.2-instance | Epoch [  7/ 75] Iter[  1/391]	 CE-loss: 1.1405cifar10:0.2-instance | Epoch [  7/ 75] Iter[ 51/391]	 CE-loss: 1.0316cifar10:0.2-instance | Epoch [  7/ 75] Iter[101/391]	 CE-loss: 1.0568cifar10:0.2-instance | Epoch [  7/ 75] Iter[151/391]	 CE-loss: 1.0345cifar10:0.2-instance | Epoch [  7/ 75] Iter[201/391]	 CE-loss: 0.9960cifar10:0.2-instance | Epoch [  7/ 75] Iter[251/391]	 CE-loss: 0.9342cifar10:0.2-instance | Epoch [  7/ 75] Iter[301/391]	 CE-loss: 1.1606cifar10:0.2-instance | Epoch [  7/ 75] Iter[351/391]	 CE-loss: 1.0370
| Test Epoch 7	 Accuracy: 77.93% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 8 | Accuracy on train set: 65.26% 
cifar10:0.2-instance | Epoch [  8/ 75] Iter[  1/391]	 CE-loss: 0.8641cifar10:0.2-instance | Epoch [  8/ 75] Iter[ 51/391]	 CE-loss: 0.9070cifar10:0.2-instance | Epoch [  8/ 75] Iter[101/391]	 CE-loss: 0.9434cifar10:0.2-instance | Epoch [  8/ 75] Iter[151/391]	 CE-loss: 0.9508cifar10:0.2-instance | Epoch [  8/ 75] Iter[201/391]	 CE-loss: 1.0741cifar10:0.2-instance | Epoch [  8/ 75] Iter[251/391]	 CE-loss: 1.0547cifar10:0.2-instance | Epoch [  8/ 75] Iter[301/391]	 CE-loss: 1.0892cifar10:0.2-instance | Epoch [  8/ 75] Iter[351/391]	 CE-loss: 0.8449
| Test Epoch 8	 Accuracy: 81.02% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 9 | Accuracy on train set: 67.24% 
cifar10:0.2-instance | Epoch [  9/ 75] Iter[  1/391]	 CE-loss: 0.9114cifar10:0.2-instance | Epoch [  9/ 75] Iter[ 51/391]	 CE-loss: 0.9477cifar10:0.2-instance | Epoch [  9/ 75] Iter[101/391]	 CE-loss: 1.0017cifar10:0.2-instance | Epoch [  9/ 75] Iter[151/391]	 CE-loss: 1.0767cifar10:0.2-instance | Epoch [  9/ 75] Iter[201/391]	 CE-loss: 0.9286cifar10:0.2-instance | Epoch [  9/ 75] Iter[251/391]	 CE-loss: 1.1054cifar10:0.2-instance | Epoch [  9/ 75] Iter[301/391]	 CE-loss: 0.8270cifar10:0.2-instance | Epoch [  9/ 75] Iter[351/391]	 CE-loss: 0.9641
| Test Epoch 9	 Accuracy: 81.45% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 10 | Accuracy on train set: 68.55% 
labeled data has a size of 38506, f-score: 0.970394
cifar10:0.2-instance | Epoch [ 10/ 75] Iter[  1/1204]	  loss: 0.67cifar10:0.2-instance | Epoch [ 10/ 75] Iter[ 51/1204]	  loss: 0.94cifar10:0.2-instance | Epoch [ 10/ 75] Iter[101/1204]	  loss: 1.21cifar10:0.2-instance | Epoch [ 10/ 75] Iter[151/1204]	  loss: 1.08cifar10:0.2-instance | Epoch [ 10/ 75] Iter[201/1204]	  loss: 1.12cifar10:0.2-instance | Epoch [ 10/ 75] Iter[251/1204]	  loss: 0.83cifar10:0.2-instance | Epoch [ 10/ 75] Iter[301/1204]	  loss: 0.81cifar10:0.2-instance | Epoch [ 10/ 75] Iter[351/1204]	  loss: 0.74cifar10:0.2-instance | Epoch [ 10/ 75] Iter[401/1204]	  loss: 0.52cifar10:0.2-instance | Epoch [ 10/ 75] Iter[451/1204]	  loss: 0.87cifar10:0.2-instance | Epoch [ 10/ 75] Iter[501/1204]	  loss: 0.80cifar10:0.2-instance | Epoch [ 10/ 75] Iter[551/1204]	  loss: 0.54cifar10:0.2-instance | Epoch [ 10/ 75] Iter[601/1204]	  loss: 0.89cifar10:0.2-instance | Epoch [ 10/ 75] Iter[651/1204]	  loss: 0.59cifar10:0.2-instance | Epoch [ 10/ 75] Iter[701/1204]	  loss: 0.69cifar10:0.2-instance | Epoch [ 10/ 75] Iter[751/1204]	  loss: 0.73cifar10:0.2-instance | Epoch [ 10/ 75] Iter[801/1204]	  loss: 0.65cifar10:0.2-instance | Epoch [ 10/ 75] Iter[851/1204]	  loss: 0.53cifar10:0.2-instance | Epoch [ 10/ 75] Iter[901/1204]	  loss: 0.79cifar10:0.2-instance | Epoch [ 10/ 75] Iter[951/1204]	  loss: 0.78cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1001/1204]	  loss: 0.80cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1051/1204]	  loss: 0.83cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1101/1204]	  loss: 0.83cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1151/1204]	  loss: 0.67cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1201/1204]	  loss: 0.41
| Test Epoch 10	 Accuracy: 76.93% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 11 | Accuracy on train set: 63.48% 
labeled data has a size of 38330, f-score: 0.975580
cifar10:0.2-instance | Epoch [ 11/ 75] Iter[  1/1198]	  loss: 0.40cifar10:0.2-instance | Epoch [ 11/ 75] Iter[ 51/1198]	  loss: 0.55cifar10:0.2-instance | Epoch [ 11/ 75] Iter[101/1198]	  loss: 0.84cifar10:0.2-instance | Epoch [ 11/ 75] Iter[151/1198]	  loss: 0.77cifar10:0.2-instance | Epoch [ 11/ 75] Iter[201/1198]	  loss: 0.71cifar10:0.2-instance | Epoch [ 11/ 75] Iter[251/1198]	  loss: 0.57cifar10:0.2-instance | Epoch [ 11/ 75] Iter[301/1198]	  loss: 0.42cifar10:0.2-instance | Epoch [ 11/ 75] Iter[351/1198]	  loss: 0.64cifar10:0.2-instance | Epoch [ 11/ 75] Iter[401/1198]	  loss: 0.53cifar10:0.2-instance | Epoch [ 11/ 75] Iter[451/1198]	  loss: 0.70cifar10:0.2-instance | Epoch [ 11/ 75] Iter[501/1198]	  loss: 0.67cifar10:0.2-instance | Epoch [ 11/ 75] Iter[551/1198]	  loss: 0.68cifar10:0.2-instance | Epoch [ 11/ 75] Iter[601/1198]	  loss: 0.41cifar10:0.2-instance | Epoch [ 11/ 75] Iter[651/1198]	  loss: 0.74cifar10:0.2-instance | Epoch [ 11/ 75] Iter[701/1198]	  loss: 0.85cifar10:0.2-instance | Epoch [ 11/ 75] Iter[751/1198]	  loss: 0.62cifar10:0.2-instance | Epoch [ 11/ 75] Iter[801/1198]	  loss: 0.81cifar10:0.2-instance | Epoch [ 11/ 75] Iter[851/1198]	  loss: 0.61cifar10:0.2-instance | Epoch [ 11/ 75] Iter[901/1198]	  loss: 0.93cifar10:0.2-instance | Epoch [ 11/ 75] Iter[951/1198]	  loss: 0.40cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1001/1198]	  loss: 0.50cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1051/1198]	  loss: 0.55cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1101/1198]	  loss: 0.53cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1151/1198]	  loss: 0.44
| Test Epoch 11	 Accuracy: 78.27% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 12 | Accuracy on train set: 65.16% 
labeled data has a size of 38146, f-score: 0.974676
cifar10:0.2-instance | Epoch [ 12/ 75] Iter[  1/1193]	  loss: 0.47cifar10:0.2-instance | Epoch [ 12/ 75] Iter[ 51/1193]	  loss: 0.69cifar10:0.2-instance | Epoch [ 12/ 75] Iter[101/1193]	  loss: 0.79cifar10:0.2-instance | Epoch [ 12/ 75] Iter[151/1193]	  loss: 0.37cifar10:0.2-instance | Epoch [ 12/ 75] Iter[201/1193]	  loss: 0.44cifar10:0.2-instance | Epoch [ 12/ 75] Iter[251/1193]	  loss: 0.93cifar10:0.2-instance | Epoch [ 12/ 75] Iter[301/1193]	  loss: 0.55cifar10:0.2-instance | Epoch [ 12/ 75] Iter[351/1193]	  loss: 0.55cifar10:0.2-instance | Epoch [ 12/ 75] Iter[401/1193]	  loss: 0.52cifar10:0.2-instance | Epoch [ 12/ 75] Iter[451/1193]	  loss: 0.45cifar10:0.2-instance | Epoch [ 12/ 75] Iter[501/1193]	  loss: 0.51cifar10:0.2-instance | Epoch [ 12/ 75] Iter[551/1193]	  loss: 0.57cifar10:0.2-instance | Epoch [ 12/ 75] Iter[601/1193]	  loss: 0.72cifar10:0.2-instance | Epoch [ 12/ 75] Iter[651/1193]	  loss: 0.54cifar10:0.2-instance | Epoch [ 12/ 75] Iter[701/1193]	  loss: 0.43cifar10:0.2-instance | Epoch [ 12/ 75] Iter[751/1193]	  loss: 0.49cifar10:0.2-instance | Epoch [ 12/ 75] Iter[801/1193]	  loss: 0.64cifar10:0.2-instance | Epoch [ 12/ 75] Iter[851/1193]	  loss: 0.76cifar10:0.2-instance | Epoch [ 12/ 75] Iter[901/1193]	  loss: 0.75cifar10:0.2-instance | Epoch [ 12/ 75] Iter[951/1193]	  loss: 0.58cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1001/1193]	  loss: 0.31cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1051/1193]	  loss: 0.73cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1101/1193]	  loss: 0.53cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1151/1193]	  loss: 0.51
| Test Epoch 12	 Accuracy: 79.34% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 13 | Accuracy on train set: 65.55% 
labeled data has a size of 37556, f-score: 0.978432
cifar10:0.2-instance | Epoch [ 13/ 75] Iter[  1/1174]	  loss: 0.47cifar10:0.2-instance | Epoch [ 13/ 75] Iter[ 51/1174]	  loss: 0.59cifar10:0.2-instance | Epoch [ 13/ 75] Iter[101/1174]	  loss: 0.63cifar10:0.2-instance | Epoch [ 13/ 75] Iter[151/1174]	  loss: 0.54cifar10:0.2-instance | Epoch [ 13/ 75] Iter[201/1174]	  loss: 0.41cifar10:0.2-instance | Epoch [ 13/ 75] Iter[251/1174]	  loss: 0.39cifar10:0.2-instance | Epoch [ 13/ 75] Iter[301/1174]	  loss: 0.54cifar10:0.2-instance | Epoch [ 13/ 75] Iter[351/1174]	  loss: 0.35cifar10:0.2-instance | Epoch [ 13/ 75] Iter[401/1174]	  loss: 0.65cifar10:0.2-instance | Epoch [ 13/ 75] Iter[451/1174]	  loss: 0.49cifar10:0.2-instance | Epoch [ 13/ 75] Iter[501/1174]	  loss: 0.56cifar10:0.2-instance | Epoch [ 13/ 75] Iter[551/1174]	  loss: 0.42cifar10:0.2-instance | Epoch [ 13/ 75] Iter[601/1174]	  loss: 0.40cifar10:0.2-instance | Epoch [ 13/ 75] Iter[651/1174]	  loss: 0.63cifar10:0.2-instance | Epoch [ 13/ 75] Iter[701/1174]	  loss: 0.57cifar10:0.2-instance | Epoch [ 13/ 75] Iter[751/1174]	  loss: 0.52cifar10:0.2-instance | Epoch [ 13/ 75] Iter[801/1174]	  loss: 0.62cifar10:0.2-instance | Epoch [ 13/ 75] Iter[851/1174]	  loss: 0.49cifar10:0.2-instance | Epoch [ 13/ 75] Iter[901/1174]	  loss: 0.45cifar10:0.2-instance | Epoch [ 13/ 75] Iter[951/1174]	  loss: 0.54cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1001/1174]	  loss: 0.53cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1051/1174]	  loss: 0.52cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1101/1174]	  loss: 0.46cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1151/1174]	  loss: 0.35
| Test Epoch 13	 Accuracy: 82.79% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 14 | Accuracy on train set: 68.37% 
labeled data has a size of 37756, f-score: 0.977063
cifar10:0.2-instance | Epoch [ 14/ 75] Iter[  1/1180]	  loss: 0.27cifar10:0.2-instance | Epoch [ 14/ 75] Iter[ 51/1180]	  loss: 0.33cifar10:0.2-instance | Epoch [ 14/ 75] Iter[101/1180]	  loss: 0.39cifar10:0.2-instance | Epoch [ 14/ 75] Iter[151/1180]	  loss: 0.44cifar10:0.2-instance | Epoch [ 14/ 75] Iter[201/1180]	  loss: 0.55cifar10:0.2-instance | Epoch [ 14/ 75] Iter[251/1180]	  loss: 0.49cifar10:0.2-instance | Epoch [ 14/ 75] Iter[301/1180]	  loss: 0.35cifar10:0.2-instance | Epoch [ 14/ 75] Iter[351/1180]	  loss: 0.28cifar10:0.2-instance | Epoch [ 14/ 75] Iter[401/1180]	  loss: 0.48cifar10:0.2-instance | Epoch [ 14/ 75] Iter[451/1180]	  loss: 0.56cifar10:0.2-instance | Epoch [ 14/ 75] Iter[501/1180]	  loss: 0.53cifar10:0.2-instance | Epoch [ 14/ 75] Iter[551/1180]	  loss: 0.57cifar10:0.2-instance | Epoch [ 14/ 75] Iter[601/1180]	  loss: 0.32cifar10:0.2-instance | Epoch [ 14/ 75] Iter[651/1180]	  loss: 0.56cifar10:0.2-instance | Epoch [ 14/ 75] Iter[701/1180]	  loss: 0.33cifar10:0.2-instance | Epoch [ 14/ 75] Iter[751/1180]	  loss: 0.31cifar10:0.2-instance | Epoch [ 14/ 75] Iter[801/1180]	  loss: 0.40cifar10:0.2-instance | Epoch [ 14/ 75] Iter[851/1180]	  loss: 0.45cifar10:0.2-instance | Epoch [ 14/ 75] Iter[901/1180]	  loss: 0.51cifar10:0.2-instance | Epoch [ 14/ 75] Iter[951/1180]	  loss: 0.35cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1001/1180]	  loss: 0.43cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1051/1180]	  loss: 0.69cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1101/1180]	  loss: 0.41cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1151/1180]	  loss: 0.57
| Test Epoch 14	 Accuracy: 81.55% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 15 | Accuracy on train set: 68.10% 
labeled data has a size of 37834, f-score: 0.980150
cifar10:0.2-instance | Epoch [ 15/ 75] Iter[  1/1183]	  loss: 0.47cifar10:0.2-instance | Epoch [ 15/ 75] Iter[ 51/1183]	  loss: 0.42cifar10:0.2-instance | Epoch [ 15/ 75] Iter[101/1183]	  loss: 0.65cifar10:0.2-instance | Epoch [ 15/ 75] Iter[151/1183]	  loss: 0.40cifar10:0.2-instance | Epoch [ 15/ 75] Iter[201/1183]	  loss: 0.33cifar10:0.2-instance | Epoch [ 15/ 75] Iter[251/1183]	  loss: 0.32cifar10:0.2-instance | Epoch [ 15/ 75] Iter[301/1183]	  loss: 0.42cifar10:0.2-instance | Epoch [ 15/ 75] Iter[351/1183]	  loss: 0.34cifar10:0.2-instance | Epoch [ 15/ 75] Iter[401/1183]	  loss: 0.54cifar10:0.2-instance | Epoch [ 15/ 75] Iter[451/1183]	  loss: 0.74cifar10:0.2-instance | Epoch [ 15/ 75] Iter[501/1183]	  loss: 0.47cifar10:0.2-instance | Epoch [ 15/ 75] Iter[551/1183]	  loss: 0.52cifar10:0.2-instance | Epoch [ 15/ 75] Iter[601/1183]	  loss: 0.53cifar10:0.2-instance | Epoch [ 15/ 75] Iter[651/1183]	  loss: 0.49cifar10:0.2-instance | Epoch [ 15/ 75] Iter[701/1183]	  loss: 0.36cifar10:0.2-instance | Epoch [ 15/ 75] Iter[751/1183]	  loss: 0.51cifar10:0.2-instance | Epoch [ 15/ 75] Iter[801/1183]	  loss: 0.84cifar10:0.2-instance | Epoch [ 15/ 75] Iter[851/1183]	  loss: 0.44cifar10:0.2-instance | Epoch [ 15/ 75] Iter[901/1183]	  loss: 0.46cifar10:0.2-instance | Epoch [ 15/ 75] Iter[951/1183]	  loss: 0.30cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1001/1183]	  loss: 0.40cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1051/1183]	  loss: 0.51cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1101/1183]	  loss: 0.22cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1151/1183]	  loss: 0.71
| Test Epoch 15	 Accuracy: 83.33% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 16 | Accuracy on train set: 69.20% 
labeled data has a size of 38103, f-score: 0.981078
cifar10:0.2-instance | Epoch [ 16/ 75] Iter[  1/1191]	  loss: 0.31cifar10:0.2-instance | Epoch [ 16/ 75] Iter[ 51/1191]	  loss: 0.53cifar10:0.2-instance | Epoch [ 16/ 75] Iter[101/1191]	  loss: 0.55cifar10:0.2-instance | Epoch [ 16/ 75] Iter[151/1191]	  loss: 0.43cifar10:0.2-instance | Epoch [ 16/ 75] Iter[201/1191]	  loss: 0.35cifar10:0.2-instance | Epoch [ 16/ 75] Iter[251/1191]	  loss: 0.35cifar10:0.2-instance | Epoch [ 16/ 75] Iter[301/1191]	  loss: 0.32cifar10:0.2-instance | Epoch [ 16/ 75] Iter[351/1191]	  loss: 0.59cifar10:0.2-instance | Epoch [ 16/ 75] Iter[401/1191]	  loss: 0.38cifar10:0.2-instance | Epoch [ 16/ 75] Iter[451/1191]	  loss: 0.57cifar10:0.2-instance | Epoch [ 16/ 75] Iter[501/1191]	  loss: 0.69cifar10:0.2-instance | Epoch [ 16/ 75] Iter[551/1191]	  loss: 0.59cifar10:0.2-instance | Epoch [ 16/ 75] Iter[601/1191]	  loss: 0.86cifar10:0.2-instance | Epoch [ 16/ 75] Iter[651/1191]	  loss: 0.34cifar10:0.2-instance | Epoch [ 16/ 75] Iter[701/1191]	  loss: 0.30cifar10:0.2-instance | Epoch [ 16/ 75] Iter[751/1191]	  loss: 0.38cifar10:0.2-instance | Epoch [ 16/ 75] Iter[801/1191]	  loss: 0.55cifar10:0.2-instance | Epoch [ 16/ 75] Iter[851/1191]	  loss: 0.49cifar10:0.2-instance | Epoch [ 16/ 75] Iter[901/1191]	  loss: 0.52cifar10:0.2-instance | Epoch [ 16/ 75] Iter[951/1191]	  loss: 0.24cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1001/1191]	  loss: 0.48cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1051/1191]	  loss: 0.54cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1101/1191]	  loss: 0.28cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1151/1191]	  loss: 0.35
| Test Epoch 16	 Accuracy: 82.81% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 17 | Accuracy on train set: 69.24% 
labeled data has a size of 38212, f-score: 0.979797
cifar10:0.2-instance | Epoch [ 17/ 75] Iter[  1/1195]	  loss: 0.27cifar10:0.2-instance | Epoch [ 17/ 75] Iter[ 51/1195]	  loss: 0.42cifar10:0.2-instance | Epoch [ 17/ 75] Iter[101/1195]	  loss: 0.35cifar10:0.2-instance | Epoch [ 17/ 75] Iter[151/1195]	  loss: 0.37cifar10:0.2-instance | Epoch [ 17/ 75] Iter[201/1195]	  loss: 0.73cifar10:0.2-instance | Epoch [ 17/ 75] Iter[251/1195]	  loss: 0.53cifar10:0.2-instance | Epoch [ 17/ 75] Iter[301/1195]	  loss: 0.26cifar10:0.2-instance | Epoch [ 17/ 75] Iter[351/1195]	  loss: 0.45cifar10:0.2-instance | Epoch [ 17/ 75] Iter[401/1195]	  loss: 0.59cifar10:0.2-instance | Epoch [ 17/ 75] Iter[451/1195]	  loss: 0.55cifar10:0.2-instance | Epoch [ 17/ 75] Iter[501/1195]	  loss: 0.36cifar10:0.2-instance | Epoch [ 17/ 75] Iter[551/1195]	  loss: 0.70cifar10:0.2-instance | Epoch [ 17/ 75] Iter[601/1195]	  loss: 0.58cifar10:0.2-instance | Epoch [ 17/ 75] Iter[651/1195]	  loss: 0.40cifar10:0.2-instance | Epoch [ 17/ 75] Iter[701/1195]	  loss: 0.51cifar10:0.2-instance | Epoch [ 17/ 75] Iter[751/1195]	  loss: 0.49cifar10:0.2-instance | Epoch [ 17/ 75] Iter[801/1195]	  loss: 0.46cifar10:0.2-instance | Epoch [ 17/ 75] Iter[851/1195]	  loss: 0.34cifar10:0.2-instance | Epoch [ 17/ 75] Iter[901/1195]	  loss: 0.29cifar10:0.2-instance | Epoch [ 17/ 75] Iter[951/1195]	  loss: 0.51cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1001/1195]	  loss: 0.59cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1051/1195]	  loss: 0.40cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1101/1195]	  loss: 0.40cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1151/1195]	  loss: 0.42
| Test Epoch 17	 Accuracy: 82.86% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 18 | Accuracy on train set: 68.92% 
labeled data has a size of 38312, f-score: 0.981285
cifar10:0.2-instance | Epoch [ 18/ 75] Iter[  1/1198]	  loss: 0.52cifar10:0.2-instance | Epoch [ 18/ 75] Iter[ 51/1198]	  loss: 0.44cifar10:0.2-instance | Epoch [ 18/ 75] Iter[101/1198]	  loss: 0.37cifar10:0.2-instance | Epoch [ 18/ 75] Iter[151/1198]	  loss: 0.81cifar10:0.2-instance | Epoch [ 18/ 75] Iter[201/1198]	  loss: 0.39cifar10:0.2-instance | Epoch [ 18/ 75] Iter[251/1198]	  loss: 0.28cifar10:0.2-instance | Epoch [ 18/ 75] Iter[301/1198]	  loss: 0.44cifar10:0.2-instance | Epoch [ 18/ 75] Iter[351/1198]	  loss: 0.34cifar10:0.2-instance | Epoch [ 18/ 75] Iter[401/1198]	  loss: 0.76cifar10:0.2-instance | Epoch [ 18/ 75] Iter[451/1198]	  loss: 0.83cifar10:0.2-instance | Epoch [ 18/ 75] Iter[501/1198]	  loss: 0.44cifar10:0.2-instance | Epoch [ 18/ 75] Iter[551/1198]	  loss: 0.47cifar10:0.2-instance | Epoch [ 18/ 75] Iter[601/1198]	  loss: 0.35cifar10:0.2-instance | Epoch [ 18/ 75] Iter[651/1198]	  loss: 0.45cifar10:0.2-instance | Epoch [ 18/ 75] Iter[701/1198]	  loss: 0.37cifar10:0.2-instance | Epoch [ 18/ 75] Iter[751/1198]	  loss: 0.39cifar10:0.2-instance | Epoch [ 18/ 75] Iter[801/1198]	  loss: 0.48cifar10:0.2-instance | Epoch [ 18/ 75] Iter[851/1198]	  loss: 0.37cifar10:0.2-instance | Epoch [ 18/ 75] Iter[901/1198]	  loss: 0.50cifar10:0.2-instance | Epoch [ 18/ 75] Iter[951/1198]	  loss: 0.39cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1001/1198]	  loss: 0.50cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1051/1198]	  loss: 0.41cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1101/1198]	  loss: 0.59cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1151/1198]	  loss: 0.30
| Test Epoch 18	 Accuracy: 82.23% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 19 | Accuracy on train set: 68.64% 
labeled data has a size of 38415, f-score: 0.980554
cifar10:0.2-instance | Epoch [ 19/ 75] Iter[  1/1201]	  loss: 0.48cifar10:0.2-instance | Epoch [ 19/ 75] Iter[ 51/1201]	  loss: 0.37cifar10:0.2-instance | Epoch [ 19/ 75] Iter[101/1201]	  loss: 0.52cifar10:0.2-instance | Epoch [ 19/ 75] Iter[151/1201]	  loss: 0.39cifar10:0.2-instance | Epoch [ 19/ 75] Iter[201/1201]	  loss: 0.37cifar10:0.2-instance | Epoch [ 19/ 75] Iter[251/1201]	  loss: 0.33cifar10:0.2-instance | Epoch [ 19/ 75] Iter[301/1201]	  loss: 0.51cifar10:0.2-instance | Epoch [ 19/ 75] Iter[351/1201]	  loss: 0.53cifar10:0.2-instance | Epoch [ 19/ 75] Iter[401/1201]	  loss: 0.42cifar10:0.2-instance | Epoch [ 19/ 75] Iter[451/1201]	  loss: 0.36cifar10:0.2-instance | Epoch [ 19/ 75] Iter[501/1201]	  loss: 0.25cifar10:0.2-instance | Epoch [ 19/ 75] Iter[551/1201]	  loss: 0.68cifar10:0.2-instance | Epoch [ 19/ 75] Iter[601/1201]	  loss: 0.31cifar10:0.2-instance | Epoch [ 19/ 75] Iter[651/1201]	  loss: 0.34cifar10:0.2-instance | Epoch [ 19/ 75] Iter[701/1201]	  loss: 0.47cifar10:0.2-instance | Epoch [ 19/ 75] Iter[751/1201]	  loss: 0.35cifar10:0.2-instance | Epoch [ 19/ 75] Iter[801/1201]	  loss: 0.39cifar10:0.2-instance | Epoch [ 19/ 75] Iter[851/1201]	  loss: 0.62cifar10:0.2-instance | Epoch [ 19/ 75] Iter[901/1201]	  loss: 0.57cifar10:0.2-instance | Epoch [ 19/ 75] Iter[951/1201]	  loss: 0.62cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1001/1201]	  loss: 0.64cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1051/1201]	  loss: 0.54cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1101/1201]	  loss: 0.38cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1151/1201]	  loss: 0.56cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1201/1201]	  loss: 0.53
| Test Epoch 19	 Accuracy: 84.52% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 20 | Accuracy on train set: 70.19% 
labeled data has a size of 38368, f-score: 0.983189
cifar10:0.2-instance | Epoch [ 20/ 75] Iter[  1/1200]	  loss: 0.35cifar10:0.2-instance | Epoch [ 20/ 75] Iter[ 51/1200]	  loss: 0.27cifar10:0.2-instance | Epoch [ 20/ 75] Iter[101/1200]	  loss: 0.40cifar10:0.2-instance | Epoch [ 20/ 75] Iter[151/1200]	  loss: 0.29cifar10:0.2-instance | Epoch [ 20/ 75] Iter[201/1200]	  loss: 0.48cifar10:0.2-instance | Epoch [ 20/ 75] Iter[251/1200]	  loss: 0.27cifar10:0.2-instance | Epoch [ 20/ 75] Iter[301/1200]	  loss: 0.28cifar10:0.2-instance | Epoch [ 20/ 75] Iter[351/1200]	  loss: 0.46cifar10:0.2-instance | Epoch [ 20/ 75] Iter[401/1200]	  loss: 0.59cifar10:0.2-instance | Epoch [ 20/ 75] Iter[451/1200]	  loss: 0.37cifar10:0.2-instance | Epoch [ 20/ 75] Iter[501/1200]	  loss: 0.50cifar10:0.2-instance | Epoch [ 20/ 75] Iter[551/1200]	  loss: 0.31cifar10:0.2-instance | Epoch [ 20/ 75] Iter[601/1200]	  loss: 0.47cifar10:0.2-instance | Epoch [ 20/ 75] Iter[651/1200]	  loss: 0.26cifar10:0.2-instance | Epoch [ 20/ 75] Iter[701/1200]	  loss: 0.35cifar10:0.2-instance | Epoch [ 20/ 75] Iter[751/1200]	  loss: 0.55cifar10:0.2-instance | Epoch [ 20/ 75] Iter[801/1200]	  loss: 0.43cifar10:0.2-instance | Epoch [ 20/ 75] Iter[851/1200]	  loss: 0.64cifar10:0.2-instance | Epoch [ 20/ 75] Iter[901/1200]	  loss: 0.43cifar10:0.2-instance | Epoch [ 20/ 75] Iter[951/1200]	  loss: 0.58cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1001/1200]	  loss: 0.42cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1051/1200]	  loss: 0.66cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1101/1200]	  loss: 0.48cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1151/1200]	  loss: 0.51
| Test Epoch 20	 Accuracy: 82.36% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 21 | Accuracy on train set: 68.65% 
labeled data has a size of 38356, f-score: 0.983158
cifar10:0.2-instance | Epoch [ 21/ 75] Iter[  1/1199]	  loss: 0.44cifar10:0.2-instance | Epoch [ 21/ 75] Iter[ 51/1199]	  loss: 0.39cifar10:0.2-instance | Epoch [ 21/ 75] Iter[101/1199]	  loss: 0.44cifar10:0.2-instance | Epoch [ 21/ 75] Iter[151/1199]	  loss: 0.29cifar10:0.2-instance | Epoch [ 21/ 75] Iter[201/1199]	  loss: 0.53cifar10:0.2-instance | Epoch [ 21/ 75] Iter[251/1199]	  loss: 0.41cifar10:0.2-instance | Epoch [ 21/ 75] Iter[301/1199]	  loss: 0.36cifar10:0.2-instance | Epoch [ 21/ 75] Iter[351/1199]	  loss: 0.54cifar10:0.2-instance | Epoch [ 21/ 75] Iter[401/1199]	  loss: 0.40cifar10:0.2-instance | Epoch [ 21/ 75] Iter[451/1199]	  loss: 0.49cifar10:0.2-instance | Epoch [ 21/ 75] Iter[501/1199]	  loss: 0.41cifar10:0.2-instance | Epoch [ 21/ 75] Iter[551/1199]	  loss: 0.48cifar10:0.2-instance | Epoch [ 21/ 75] Iter[601/1199]	  loss: 0.53cifar10:0.2-instance | Epoch [ 21/ 75] Iter[651/1199]	  loss: 0.55cifar10:0.2-instance | Epoch [ 21/ 75] Iter[701/1199]	  loss: 0.51cifar10:0.2-instance | Epoch [ 21/ 75] Iter[751/1199]	  loss: 0.52cifar10:0.2-instance | Epoch [ 21/ 75] Iter[801/1199]	  loss: 0.51cifar10:0.2-instance | Epoch [ 21/ 75] Iter[851/1199]	  loss: 0.38cifar10:0.2-instance | Epoch [ 21/ 75] Iter[901/1199]	  loss: 0.32cifar10:0.2-instance | Epoch [ 21/ 75] Iter[951/1199]	  loss: 0.42cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1001/1199]	  loss: 0.50cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1051/1199]	  loss: 0.49cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1101/1199]	  loss: 0.39cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1151/1199]	  loss: 0.48
| Test Epoch 21	 Accuracy: 82.46% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 22 | Accuracy on train set: 69.32% 
labeled data has a size of 38397, f-score: 0.983306
cifar10:0.2-instance | Epoch [ 22/ 75] Iter[  1/1200]	  loss: 0.35cifar10:0.2-instance | Epoch [ 22/ 75] Iter[ 51/1200]	  loss: 0.64cifar10:0.2-instance | Epoch [ 22/ 75] Iter[101/1200]	  loss: 0.39cifar10:0.2-instance | Epoch [ 22/ 75] Iter[151/1200]	  loss: 0.44cifar10:0.2-instance | Epoch [ 22/ 75] Iter[201/1200]	  loss: 0.24cifar10:0.2-instance | Epoch [ 22/ 75] Iter[251/1200]	  loss: 0.31cifar10:0.2-instance | Epoch [ 22/ 75] Iter[301/1200]	  loss: 0.25cifar10:0.2-instance | Epoch [ 22/ 75] Iter[351/1200]	  loss: 0.27cifar10:0.2-instance | Epoch [ 22/ 75] Iter[401/1200]	  loss: 0.48cifar10:0.2-instance | Epoch [ 22/ 75] Iter[451/1200]	  loss: 0.36cifar10:0.2-instance | Epoch [ 22/ 75] Iter[501/1200]	  loss: 0.41cifar10:0.2-instance | Epoch [ 22/ 75] Iter[551/1200]	  loss: 0.41cifar10:0.2-instance | Epoch [ 22/ 75] Iter[601/1200]	  loss: 0.37cifar10:0.2-instance | Epoch [ 22/ 75] Iter[651/1200]	  loss: 0.58cifar10:0.2-instance | Epoch [ 22/ 75] Iter[701/1200]	  loss: 0.58cifar10:0.2-instance | Epoch [ 22/ 75] Iter[751/1200]	  loss: 0.44cifar10:0.2-instance | Epoch [ 22/ 75] Iter[801/1200]	  loss: 0.47cifar10:0.2-instance | Epoch [ 22/ 75] Iter[851/1200]	  loss: 0.48cifar10:0.2-instance | Epoch [ 22/ 75] Iter[901/1200]	  loss: 0.42cifar10:0.2-instance | Epoch [ 22/ 75] Iter[951/1200]	  loss: 0.34cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1001/1200]	  loss: 0.41cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1051/1200]	  loss: 0.49cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1101/1200]	  loss: 0.38cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1151/1200]	  loss: 0.30
| Test Epoch 22	 Accuracy: 82.22% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 23 | Accuracy on train set: 68.44% 
labeled data has a size of 38099, f-score: 0.983963
cifar10:0.2-instance | Epoch [ 23/ 75] Iter[  1/1191]	  loss: 0.55cifar10:0.2-instance | Epoch [ 23/ 75] Iter[ 51/1191]	  loss: 0.43cifar10:0.2-instance | Epoch [ 23/ 75] Iter[101/1191]	  loss: 0.48cifar10:0.2-instance | Epoch [ 23/ 75] Iter[151/1191]	  loss: 0.31cifar10:0.2-instance | Epoch [ 23/ 75] Iter[201/1191]	  loss: 0.48cifar10:0.2-instance | Epoch [ 23/ 75] Iter[251/1191]	  loss: 0.49cifar10:0.2-instance | Epoch [ 23/ 75] Iter[301/1191]	  loss: 0.70cifar10:0.2-instance | Epoch [ 23/ 75] Iter[351/1191]	  loss: 0.43cifar10:0.2-instance | Epoch [ 23/ 75] Iter[401/1191]	  loss: 0.32cifar10:0.2-instance | Epoch [ 23/ 75] Iter[451/1191]	  loss: 0.48cifar10:0.2-instance | Epoch [ 23/ 75] Iter[501/1191]	  loss: 0.34cifar10:0.2-instance | Epoch [ 23/ 75] Iter[551/1191]	  loss: 0.44cifar10:0.2-instance | Epoch [ 23/ 75] Iter[601/1191]	  loss: 0.40cifar10:0.2-instance | Epoch [ 23/ 75] Iter[651/1191]	  loss: 0.32cifar10:0.2-instance | Epoch [ 23/ 75] Iter[701/1191]	  loss: 0.54cifar10:0.2-instance | Epoch [ 23/ 75] Iter[751/1191]	  loss: 0.78cifar10:0.2-instance | Epoch [ 23/ 75] Iter[801/1191]	  loss: 0.24cifar10:0.2-instance | Epoch [ 23/ 75] Iter[851/1191]	  loss: 0.72cifar10:0.2-instance | Epoch [ 23/ 75] Iter[901/1191]	  loss: 0.36cifar10:0.2-instance | Epoch [ 23/ 75] Iter[951/1191]	  loss: 0.49cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1001/1191]	  loss: 0.30cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1051/1191]	  loss: 0.42cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1101/1191]	  loss: 0.44cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1151/1191]	  loss: 0.47
| Test Epoch 23	 Accuracy: 85.04% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 24 | Accuracy on train set: 71.73% 
labeled data has a size of 38502, f-score: 0.981871
cifar10:0.2-instance | Epoch [ 24/ 75] Iter[  1/1204]	  loss: 0.38cifar10:0.2-instance | Epoch [ 24/ 75] Iter[ 51/1204]	  loss: 0.45cifar10:0.2-instance | Epoch [ 24/ 75] Iter[101/1204]	  loss: 0.27cifar10:0.2-instance | Epoch [ 24/ 75] Iter[151/1204]	  loss: 0.58cifar10:0.2-instance | Epoch [ 24/ 75] Iter[201/1204]	  loss: 0.43cifar10:0.2-instance | Epoch [ 24/ 75] Iter[251/1204]	  loss: 0.32cifar10:0.2-instance | Epoch [ 24/ 75] Iter[301/1204]	  loss: 0.24cifar10:0.2-instance | Epoch [ 24/ 75] Iter[351/1204]	  loss: 0.28cifar10:0.2-instance | Epoch [ 24/ 75] Iter[401/1204]	  loss: 0.35cifar10:0.2-instance | Epoch [ 24/ 75] Iter[451/1204]	  loss: 0.37cifar10:0.2-instance | Epoch [ 24/ 75] Iter[501/1204]	  loss: 0.27cifar10:0.2-instance | Epoch [ 24/ 75] Iter[551/1204]	  loss: 0.47cifar10:0.2-instance | Epoch [ 24/ 75] Iter[601/1204]	  loss: 0.28cifar10:0.2-instance | Epoch [ 24/ 75] Iter[651/1204]	  loss: 0.39cifar10:0.2-instance | Epoch [ 24/ 75] Iter[701/1204]	  loss: 0.42cifar10:0.2-instance | Epoch [ 24/ 75] Iter[751/1204]	  loss: 0.46cifar10:0.2-instance | Epoch [ 24/ 75] Iter[801/1204]	  loss: 0.42cifar10:0.2-instance | Epoch [ 24/ 75] Iter[851/1204]	  loss: 0.43cifar10:0.2-instance | Epoch [ 24/ 75] Iter[901/1204]	  loss: 0.50cifar10:0.2-instance | Epoch [ 24/ 75] Iter[951/1204]	  loss: 0.34cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1001/1204]	  loss: 0.45cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1051/1204]	  loss: 0.40cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1101/1204]	  loss: 0.33cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1151/1204]	  loss: 0.34cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1201/1204]	  loss: 0.58
| Test Epoch 24	 Accuracy: 83.71% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 25 | Accuracy on train set: 70.34% 
labeled data has a size of 38792, f-score: 0.980692
cifar10:0.2-instance | Epoch [ 25/ 75] Iter[  1/1213]	  loss: 0.37cifar10:0.2-instance | Epoch [ 25/ 75] Iter[ 51/1213]	  loss: 0.55cifar10:0.2-instance | Epoch [ 25/ 75] Iter[101/1213]	  loss: 0.55cifar10:0.2-instance | Epoch [ 25/ 75] Iter[151/1213]	  loss: 0.36cifar10:0.2-instance | Epoch [ 25/ 75] Iter[201/1213]	  loss: 0.38cifar10:0.2-instance | Epoch [ 25/ 75] Iter[251/1213]	  loss: 0.53cifar10:0.2-instance | Epoch [ 25/ 75] Iter[301/1213]	  loss: 0.58cifar10:0.2-instance | Epoch [ 25/ 75] Iter[351/1213]	  loss: 0.29cifar10:0.2-instance | Epoch [ 25/ 75] Iter[401/1213]	  loss: 0.47cifar10:0.2-instance | Epoch [ 25/ 75] Iter[451/1213]	  loss: 0.53cifar10:0.2-instance | Epoch [ 25/ 75] Iter[501/1213]	  loss: 0.46cifar10:0.2-instance | Epoch [ 25/ 75] Iter[551/1213]	  loss: 0.34cifar10:0.2-instance | Epoch [ 25/ 75] Iter[601/1213]	  loss: 0.64cifar10:0.2-instance | Epoch [ 25/ 75] Iter[651/1213]	  loss: 0.62cifar10:0.2-instance | Epoch [ 25/ 75] Iter[701/1213]	  loss: 0.36cifar10:0.2-instance | Epoch [ 25/ 75] Iter[751/1213]	  loss: 0.33cifar10:0.2-instance | Epoch [ 25/ 75] Iter[801/1213]	  loss: 0.28cifar10:0.2-instance | Epoch [ 25/ 75] Iter[851/1213]	  loss: 0.30cifar10:0.2-instance | Epoch [ 25/ 75] Iter[901/1213]	  loss: 0.32cifar10:0.2-instance | Epoch [ 25/ 75] Iter[951/1213]	  loss: 0.45cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1001/1213]	  loss: 0.39cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1051/1213]	  loss: 0.41cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1101/1213]	  loss: 0.50cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1151/1213]	  loss: 0.41cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1201/1213]	  loss: 0.52
| Test Epoch 25	 Accuracy: 83.95% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 26 | Accuracy on train set: 70.58% 
labeled data has a size of 38822, f-score: 0.980681
cifar10:0.2-instance | Epoch [ 26/ 75] Iter[  1/1214]	  loss: 0.32cifar10:0.2-instance | Epoch [ 26/ 75] Iter[ 51/1214]	  loss: 0.34cifar10:0.2-instance | Epoch [ 26/ 75] Iter[101/1214]	  loss: 0.36cifar10:0.2-instance | Epoch [ 26/ 75] Iter[151/1214]	  loss: 0.56cifar10:0.2-instance | Epoch [ 26/ 75] Iter[201/1214]	  loss: 0.48cifar10:0.2-instance | Epoch [ 26/ 75] Iter[251/1214]	  loss: 0.43cifar10:0.2-instance | Epoch [ 26/ 75] Iter[301/1214]	  loss: 0.44cifar10:0.2-instance | Epoch [ 26/ 75] Iter[351/1214]	  loss: 0.46cifar10:0.2-instance | Epoch [ 26/ 75] Iter[401/1214]	  loss: 0.46cifar10:0.2-instance | Epoch [ 26/ 75] Iter[451/1214]	  loss: 0.45cifar10:0.2-instance | Epoch [ 26/ 75] Iter[501/1214]	  loss: 0.85cifar10:0.2-instance | Epoch [ 26/ 75] Iter[551/1214]	  loss: 0.38cifar10:0.2-instance | Epoch [ 26/ 75] Iter[601/1214]	  loss: 0.35cifar10:0.2-instance | Epoch [ 26/ 75] Iter[651/1214]	  loss: 0.43cifar10:0.2-instance | Epoch [ 26/ 75] Iter[701/1214]	  loss: 0.34cifar10:0.2-instance | Epoch [ 26/ 75] Iter[751/1214]	  loss: 0.47cifar10:0.2-instance | Epoch [ 26/ 75] Iter[801/1214]	  loss: 0.27cifar10:0.2-instance | Epoch [ 26/ 75] Iter[851/1214]	  loss: 0.41cifar10:0.2-instance | Epoch [ 26/ 75] Iter[901/1214]	  loss: 0.33cifar10:0.2-instance | Epoch [ 26/ 75] Iter[951/1214]	  loss: 0.45cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1001/1214]	  loss: 0.32cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1051/1214]	  loss: 0.57cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1101/1214]	  loss: 0.42cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1151/1214]	  loss: 0.24cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1201/1214]	  loss: 0.50
| Test Epoch 26	 Accuracy: 85.44% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 27 | Accuracy on train set: 71.50% 
labeled data has a size of 38832, f-score: 0.981124
cifar10:0.2-instance | Epoch [ 27/ 75] Iter[  1/1214]	  loss: 0.37cifar10:0.2-instance | Epoch [ 27/ 75] Iter[ 51/1214]	  loss: 0.28cifar10:0.2-instance | Epoch [ 27/ 75] Iter[101/1214]	  loss: 0.37cifar10:0.2-instance | Epoch [ 27/ 75] Iter[151/1214]	  loss: 0.46cifar10:0.2-instance | Epoch [ 27/ 75] Iter[201/1214]	  loss: 0.46cifar10:0.2-instance | Epoch [ 27/ 75] Iter[251/1214]	  loss: 0.52cifar10:0.2-instance | Epoch [ 27/ 75] Iter[301/1214]	  loss: 0.34cifar10:0.2-instance | Epoch [ 27/ 75] Iter[351/1214]	  loss: 0.39cifar10:0.2-instance | Epoch [ 27/ 75] Iter[401/1214]	  loss: 0.40cifar10:0.2-instance | Epoch [ 27/ 75] Iter[451/1214]	  loss: 0.68cifar10:0.2-instance | Epoch [ 27/ 75] Iter[501/1214]	  loss: 0.47cifar10:0.2-instance | Epoch [ 27/ 75] Iter[551/1214]	  loss: 0.28cifar10:0.2-instance | Epoch [ 27/ 75] Iter[601/1214]	  loss: 0.39cifar10:0.2-instance | Epoch [ 27/ 75] Iter[651/1214]	  loss: 0.36cifar10:0.2-instance | Epoch [ 27/ 75] Iter[701/1214]	  loss: 0.60cifar10:0.2-instance | Epoch [ 27/ 75] Iter[751/1214]	  loss: 0.55cifar10:0.2-instance | Epoch [ 27/ 75] Iter[801/1214]	  loss: 0.57cifar10:0.2-instance | Epoch [ 27/ 75] Iter[851/1214]	  loss: 0.42cifar10:0.2-instance | Epoch [ 27/ 75] Iter[901/1214]	  loss: 0.32cifar10:0.2-instance | Epoch [ 27/ 75] Iter[951/1214]	  loss: 0.72cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1001/1214]	  loss: 0.38cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1051/1214]	  loss: 0.37cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1101/1214]	  loss: 0.36cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1151/1214]	  loss: 0.55cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1201/1214]	  loss: 0.43
| Test Epoch 27	 Accuracy: 84.67% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 28 | Accuracy on train set: 71.12% 
labeled data has a size of 38614, f-score: 0.982649
cifar10:0.2-instance | Epoch [ 28/ 75] Iter[  1/1207]	  loss: 0.39cifar10:0.2-instance | Epoch [ 28/ 75] Iter[ 51/1207]	  loss: 0.43cifar10:0.2-instance | Epoch [ 28/ 75] Iter[101/1207]	  loss: 0.39cifar10:0.2-instance | Epoch [ 28/ 75] Iter[151/1207]	  loss: 0.34cifar10:0.2-instance | Epoch [ 28/ 75] Iter[201/1207]	  loss: 0.27cifar10:0.2-instance | Epoch [ 28/ 75] Iter[251/1207]	  loss: 0.38cifar10:0.2-instance | Epoch [ 28/ 75] Iter[301/1207]	  loss: 0.54cifar10:0.2-instance | Epoch [ 28/ 75] Iter[351/1207]	  loss: 0.53cifar10:0.2-instance | Epoch [ 28/ 75] Iter[401/1207]	  loss: 0.53cifar10:0.2-instance | Epoch [ 28/ 75] Iter[451/1207]	  loss: 0.61cifar10:0.2-instance | Epoch [ 28/ 75] Iter[501/1207]	  loss: 0.30cifar10:0.2-instance | Epoch [ 28/ 75] Iter[551/1207]	  loss: 0.45cifar10:0.2-instance | Epoch [ 28/ 75] Iter[601/1207]	  loss: 0.43cifar10:0.2-instance | Epoch [ 28/ 75] Iter[651/1207]	  loss: 0.36cifar10:0.2-instance | Epoch [ 28/ 75] Iter[701/1207]	  loss: 0.36cifar10:0.2-instance | Epoch [ 28/ 75] Iter[751/1207]	  loss: 0.49cifar10:0.2-instance | Epoch [ 28/ 75] Iter[801/1207]	  loss: 0.36cifar10:0.2-instance | Epoch [ 28/ 75] Iter[851/1207]	  loss: 0.28cifar10:0.2-instance | Epoch [ 28/ 75] Iter[901/1207]	  loss: 0.37cifar10:0.2-instance | Epoch [ 28/ 75] Iter[951/1207]	  loss: 0.41cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1001/1207]	  loss: 0.36cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1051/1207]	  loss: 0.51cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1101/1207]	  loss: 0.43cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1151/1207]	  loss: 0.25cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1201/1207]	  loss: 0.34
| Test Epoch 28	 Accuracy: 84.41% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 29 | Accuracy on train set: 70.95% 
labeled data has a size of 38798, f-score: 0.981984
cifar10:0.2-instance | Epoch [ 29/ 75] Iter[  1/1213]	  loss: 0.27cifar10:0.2-instance | Epoch [ 29/ 75] Iter[ 51/1213]	  loss: 0.28cifar10:0.2-instance | Epoch [ 29/ 75] Iter[101/1213]	  loss: 0.29cifar10:0.2-instance | Epoch [ 29/ 75] Iter[151/1213]	  loss: 0.44cifar10:0.2-instance | Epoch [ 29/ 75] Iter[201/1213]	  loss: 0.34cifar10:0.2-instance | Epoch [ 29/ 75] Iter[251/1213]	  loss: 0.21cifar10:0.2-instance | Epoch [ 29/ 75] Iter[301/1213]	  loss: 0.41cifar10:0.2-instance | Epoch [ 29/ 75] Iter[351/1213]	  loss: 0.34cifar10:0.2-instance | Epoch [ 29/ 75] Iter[401/1213]	  loss: 0.35cifar10:0.2-instance | Epoch [ 29/ 75] Iter[451/1213]	  loss: 0.36cifar10:0.2-instance | Epoch [ 29/ 75] Iter[501/1213]	  loss: 0.44cifar10:0.2-instance | Epoch [ 29/ 75] Iter[551/1213]	  loss: 0.43cifar10:0.2-instance | Epoch [ 29/ 75] Iter[601/1213]	  loss: 0.60cifar10:0.2-instance | Epoch [ 29/ 75] Iter[651/1213]	  loss: 0.57cifar10:0.2-instance | Epoch [ 29/ 75] Iter[701/1213]	  loss: 0.52cifar10:0.2-instance | Epoch [ 29/ 75] Iter[751/1213]	  loss: 0.49cifar10:0.2-instance | Epoch [ 29/ 75] Iter[801/1213]	  loss: 0.32cifar10:0.2-instance | Epoch [ 29/ 75] Iter[851/1213]	  loss: 0.56cifar10:0.2-instance | Epoch [ 29/ 75] Iter[901/1213]	  loss: 0.59cifar10:0.2-instance | Epoch [ 29/ 75] Iter[951/1213]	  loss: 0.43cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1001/1213]	  loss: 0.28cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1051/1213]	  loss: 0.35cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1101/1213]	  loss: 0.37cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1151/1213]	  loss: 0.35cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1201/1213]	  loss: 0.30
| Test Epoch 29	 Accuracy: 85.86% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 30 | Accuracy on train set: 71.47% 
labeled data has a size of 38971, f-score: 0.982474
cifar10:0.2-instance | Epoch [ 30/ 75] Iter[  1/1218]	  loss: 0.42cifar10:0.2-instance | Epoch [ 30/ 75] Iter[ 51/1218]	  loss: 0.54cifar10:0.2-instance | Epoch [ 30/ 75] Iter[101/1218]	  loss: 0.22cifar10:0.2-instance | Epoch [ 30/ 75] Iter[151/1218]	  loss: 0.48cifar10:0.2-instance | Epoch [ 30/ 75] Iter[201/1218]	  loss: 0.49cifar10:0.2-instance | Epoch [ 30/ 75] Iter[251/1218]	  loss: 0.34cifar10:0.2-instance | Epoch [ 30/ 75] Iter[301/1218]	  loss: 0.41cifar10:0.2-instance | Epoch [ 30/ 75] Iter[351/1218]	  loss: 0.41cifar10:0.2-instance | Epoch [ 30/ 75] Iter[401/1218]	  loss: 0.30cifar10:0.2-instance | Epoch [ 30/ 75] Iter[451/1218]	  loss: 0.45cifar10:0.2-instance | Epoch [ 30/ 75] Iter[501/1218]	  loss: 0.49cifar10:0.2-instance | Epoch [ 30/ 75] Iter[551/1218]	  loss: 0.58cifar10:0.2-instance | Epoch [ 30/ 75] Iter[601/1218]	  loss: 0.44cifar10:0.2-instance | Epoch [ 30/ 75] Iter[651/1218]	  loss: 0.34cifar10:0.2-instance | Epoch [ 30/ 75] Iter[701/1218]	  loss: 0.48cifar10:0.2-instance | Epoch [ 30/ 75] Iter[751/1218]	  loss: 0.32cifar10:0.2-instance | Epoch [ 30/ 75] Iter[801/1218]	  loss: 0.42cifar10:0.2-instance | Epoch [ 30/ 75] Iter[851/1218]	  loss: 0.64cifar10:0.2-instance | Epoch [ 30/ 75] Iter[901/1218]	  loss: 0.45cifar10:0.2-instance | Epoch [ 30/ 75] Iter[951/1218]	  loss: 0.48cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1001/1218]	  loss: 0.27cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1051/1218]	  loss: 0.43cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1101/1218]	  loss: 0.65cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1151/1218]	  loss: 0.33cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1201/1218]	  loss: 0.62
| Test Epoch 30	 Accuracy: 85.10% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 31 | Accuracy on train set: 71.53% 
labeled data has a size of 38974, f-score: 0.982963
cifar10:0.2-instance | Epoch [ 31/ 75] Iter[  1/1218]	  loss: 0.26cifar10:0.2-instance | Epoch [ 31/ 75] Iter[ 51/1218]	  loss: 0.53cifar10:0.2-instance | Epoch [ 31/ 75] Iter[101/1218]	  loss: 0.61cifar10:0.2-instance | Epoch [ 31/ 75] Iter[151/1218]	  loss: 0.28cifar10:0.2-instance | Epoch [ 31/ 75] Iter[201/1218]	  loss: 0.45cifar10:0.2-instance | Epoch [ 31/ 75] Iter[251/1218]	  loss: 0.34cifar10:0.2-instance | Epoch [ 31/ 75] Iter[301/1218]	  loss: 0.44cifar10:0.2-instance | Epoch [ 31/ 75] Iter[351/1218]	  loss: 0.34cifar10:0.2-instance | Epoch [ 31/ 75] Iter[401/1218]	  loss: 0.48cifar10:0.2-instance | Epoch [ 31/ 75] Iter[451/1218]	  loss: 0.44cifar10:0.2-instance | Epoch [ 31/ 75] Iter[501/1218]	  loss: 0.68cifar10:0.2-instance | Epoch [ 31/ 75] Iter[551/1218]	  loss: 0.26cifar10:0.2-instance | Epoch [ 31/ 75] Iter[601/1218]	  loss: 0.32cifar10:0.2-instance | Epoch [ 31/ 75] Iter[651/1218]	  loss: 0.38cifar10:0.2-instance | Epoch [ 31/ 75] Iter[701/1218]	  loss: 0.45cifar10:0.2-instance | Epoch [ 31/ 75] Iter[751/1218]	  loss: 0.57cifar10:0.2-instance | Epoch [ 31/ 75] Iter[801/1218]	  loss: 0.38cifar10:0.2-instance | Epoch [ 31/ 75] Iter[851/1218]	  loss: 0.57cifar10:0.2-instance | Epoch [ 31/ 75] Iter[901/1218]	  loss: 0.46cifar10:0.2-instance | Epoch [ 31/ 75] Iter[951/1218]	  loss: 0.62cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1001/1218]	  loss: 0.56cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1051/1218]	  loss: 0.44cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1101/1218]	  loss: 0.86cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1151/1218]	  loss: 0.74cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1201/1218]	  loss: 0.47
| Test Epoch 31	 Accuracy: 84.72% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 32 | Accuracy on train set: 71.12% 
labeled data has a size of 38964, f-score: 0.983677
cifar10:0.2-instance | Epoch [ 32/ 75] Iter[  1/1218]	  loss: 0.33cifar10:0.2-instance | Epoch [ 32/ 75] Iter[ 51/1218]	  loss: 0.44cifar10:0.2-instance | Epoch [ 32/ 75] Iter[101/1218]	  loss: 0.24cifar10:0.2-instance | Epoch [ 32/ 75] Iter[151/1218]	  loss: 0.36cifar10:0.2-instance | Epoch [ 32/ 75] Iter[201/1218]	  loss: 0.84cifar10:0.2-instance | Epoch [ 32/ 75] Iter[251/1218]	  loss: 0.20cifar10:0.2-instance | Epoch [ 32/ 75] Iter[301/1218]	  loss: 0.35cifar10:0.2-instance | Epoch [ 32/ 75] Iter[351/1218]	  loss: 0.44cifar10:0.2-instance | Epoch [ 32/ 75] Iter[401/1218]	  loss: 0.40cifar10:0.2-instance | Epoch [ 32/ 75] Iter[451/1218]	  loss: 0.63cifar10:0.2-instance | Epoch [ 32/ 75] Iter[501/1218]	  loss: 0.34cifar10:0.2-instance | Epoch [ 32/ 75] Iter[551/1218]	  loss: 0.40cifar10:0.2-instance | Epoch [ 32/ 75] Iter[601/1218]	  loss: 0.37cifar10:0.2-instance | Epoch [ 32/ 75] Iter[651/1218]	  loss: 0.41cifar10:0.2-instance | Epoch [ 32/ 75] Iter[701/1218]	  loss: 0.49cifar10:0.2-instance | Epoch [ 32/ 75] Iter[751/1218]	  loss: 0.56cifar10:0.2-instance | Epoch [ 32/ 75] Iter[801/1218]	  loss: 0.39cifar10:0.2-instance | Epoch [ 32/ 75] Iter[851/1218]	  loss: 0.37cifar10:0.2-instance | Epoch [ 32/ 75] Iter[901/1218]	  loss: 0.44cifar10:0.2-instance | Epoch [ 32/ 75] Iter[951/1218]	  loss: 0.50cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1001/1218]	  loss: 0.51cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1051/1218]	  loss: 0.29cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1101/1218]	  loss: 0.32cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1151/1218]	  loss: 0.43cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1201/1218]	  loss: 0.49
| Test Epoch 32	 Accuracy: 85.97% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 33 | Accuracy on train set: 72.15% 
labeled data has a size of 38932, f-score: 0.983433
cifar10:0.2-instance | Epoch [ 33/ 75] Iter[  1/1217]	  loss: 0.28cifar10:0.2-instance | Epoch [ 33/ 75] Iter[ 51/1217]	  loss: 0.19cifar10:0.2-instance | Epoch [ 33/ 75] Iter[101/1217]	  loss: 0.35cifar10:0.2-instance | Epoch [ 33/ 75] Iter[151/1217]	  loss: 0.39cifar10:0.2-instance | Epoch [ 33/ 75] Iter[201/1217]	  loss: 0.54cifar10:0.2-instance | Epoch [ 33/ 75] Iter[251/1217]	  loss: 0.35cifar10:0.2-instance | Epoch [ 33/ 75] Iter[301/1217]	  loss: 0.39cifar10:0.2-instance | Epoch [ 33/ 75] Iter[351/1217]	  loss: 0.22cifar10:0.2-instance | Epoch [ 33/ 75] Iter[401/1217]	  loss: 0.47cifar10:0.2-instance | Epoch [ 33/ 75] Iter[451/1217]	  loss: 0.62cifar10:0.2-instance | Epoch [ 33/ 75] Iter[501/1217]	  loss: 0.47cifar10:0.2-instance | Epoch [ 33/ 75] Iter[551/1217]	  loss: 0.54cifar10:0.2-instance | Epoch [ 33/ 75] Iter[601/1217]	  loss: 0.42cifar10:0.2-instance | Epoch [ 33/ 75] Iter[651/1217]	  loss: 0.34cifar10:0.2-instance | Epoch [ 33/ 75] Iter[701/1217]	  loss: 0.27cifar10:0.2-instance | Epoch [ 33/ 75] Iter[751/1217]	  loss: 0.40cifar10:0.2-instance | Epoch [ 33/ 75] Iter[801/1217]	  loss: 0.33cifar10:0.2-instance | Epoch [ 33/ 75] Iter[851/1217]	  loss: 0.35cifar10:0.2-instance | Epoch [ 33/ 75] Iter[901/1217]	  loss: 0.48cifar10:0.2-instance | Epoch [ 33/ 75] Iter[951/1217]	  loss: 0.57cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1001/1217]	  loss: 0.48cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1051/1217]	  loss: 0.31cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1101/1217]	  loss: 0.57cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1151/1217]	  loss: 0.32cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1201/1217]	  loss: 0.40
| Test Epoch 33	 Accuracy: 85.21% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 34 | Accuracy on train set: 71.67% 
labeled data has a size of 38969, f-score: 0.983885
cifar10:0.2-instance | Epoch [ 34/ 75] Iter[  1/1218]	  loss: 0.31cifar10:0.2-instance | Epoch [ 34/ 75] Iter[ 51/1218]	  loss: 0.36cifar10:0.2-instance | Epoch [ 34/ 75] Iter[101/1218]	  loss: 0.39cifar10:0.2-instance | Epoch [ 34/ 75] Iter[151/1218]	  loss: 0.40cifar10:0.2-instance | Epoch [ 34/ 75] Iter[201/1218]	  loss: 0.35cifar10:0.2-instance | Epoch [ 34/ 75] Iter[251/1218]	  loss: 0.36cifar10:0.2-instance | Epoch [ 34/ 75] Iter[301/1218]	  loss: 0.55cifar10:0.2-instance | Epoch [ 34/ 75] Iter[351/1218]	  loss: 0.45cifar10:0.2-instance | Epoch [ 34/ 75] Iter[401/1218]	  loss: 0.38cifar10:0.2-instance | Epoch [ 34/ 75] Iter[451/1218]	  loss: 0.38cifar10:0.2-instance | Epoch [ 34/ 75] Iter[501/1218]	  loss: 0.32cifar10:0.2-instance | Epoch [ 34/ 75] Iter[551/1218]	  loss: 0.56cifar10:0.2-instance | Epoch [ 34/ 75] Iter[601/1218]	  loss: 0.61cifar10:0.2-instance | Epoch [ 34/ 75] Iter[651/1218]	  loss: 0.46cifar10:0.2-instance | Epoch [ 34/ 75] Iter[701/1218]	  loss: 0.28cifar10:0.2-instance | Epoch [ 34/ 75] Iter[751/1218]	  loss: 0.48cifar10:0.2-instance | Epoch [ 34/ 75] Iter[801/1218]	  loss: 0.22cifar10:0.2-instance | Epoch [ 34/ 75] Iter[851/1218]	  loss: 0.45cifar10:0.2-instance | Epoch [ 34/ 75] Iter[901/1218]	  loss: 0.46cifar10:0.2-instance | Epoch [ 34/ 75] Iter[951/1218]	  loss: 0.44cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1001/1218]	  loss: 0.44cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1051/1218]	  loss: 0.47cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1101/1218]	  loss: 0.45cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1151/1218]	  loss: 0.29cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1201/1218]	  loss: 0.28
| Test Epoch 34	 Accuracy: 85.84% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 35 | Accuracy on train set: 71.84% 
labeled data has a size of 38973, f-score: 0.984040
cifar10:0.2-instance | Epoch [ 35/ 75] Iter[  1/1218]	  loss: 0.26cifar10:0.2-instance | Epoch [ 35/ 75] Iter[ 51/1218]	  loss: 0.51cifar10:0.2-instance | Epoch [ 35/ 75] Iter[101/1218]	  loss: 0.45cifar10:0.2-instance | Epoch [ 35/ 75] Iter[151/1218]	  loss: 0.59cifar10:0.2-instance | Epoch [ 35/ 75] Iter[201/1218]	  loss: 0.61cifar10:0.2-instance | Epoch [ 35/ 75] Iter[251/1218]	  loss: 0.29cifar10:0.2-instance | Epoch [ 35/ 75] Iter[301/1218]	  loss: 0.36cifar10:0.2-instance | Epoch [ 35/ 75] Iter[351/1218]	  loss: 0.49cifar10:0.2-instance | Epoch [ 35/ 75] Iter[401/1218]	  loss: 0.51cifar10:0.2-instance | Epoch [ 35/ 75] Iter[451/1218]	  loss: 0.21cifar10:0.2-instance | Epoch [ 35/ 75] Iter[501/1218]	  loss: 0.26cifar10:0.2-instance | Epoch [ 35/ 75] Iter[551/1218]	  loss: 0.43cifar10:0.2-instance | Epoch [ 35/ 75] Iter[601/1218]	  loss: 0.34cifar10:0.2-instance | Epoch [ 35/ 75] Iter[651/1218]	  loss: 0.40cifar10:0.2-instance | Epoch [ 35/ 75] Iter[701/1218]	  loss: 0.47cifar10:0.2-instance | Epoch [ 35/ 75] Iter[751/1218]	  loss: 0.43cifar10:0.2-instance | Epoch [ 35/ 75] Iter[801/1218]	  loss: 0.47cifar10:0.2-instance | Epoch [ 35/ 75] Iter[851/1218]	  loss: 0.23cifar10:0.2-instance | Epoch [ 35/ 75] Iter[901/1218]	  loss: 0.40cifar10:0.2-instance | Epoch [ 35/ 75] Iter[951/1218]	  loss: 0.48cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1001/1218]	  loss: 0.39cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1051/1218]	  loss: 0.40cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1101/1218]	  loss: 0.40cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1151/1218]	  loss: 0.46cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1201/1218]	  loss: 0.60
| Test Epoch 35	 Accuracy: 82.19% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 36 | Accuracy on train set: 69.25% 
labeled data has a size of 38906, f-score: 0.983961
cifar10:0.2-instance | Epoch [ 36/ 75] Iter[  1/1216]	  loss: 0.31cifar10:0.2-instance | Epoch [ 36/ 75] Iter[ 51/1216]	  loss: 0.65cifar10:0.2-instance | Epoch [ 36/ 75] Iter[101/1216]	  loss: 0.61cifar10:0.2-instance | Epoch [ 36/ 75] Iter[151/1216]	  loss: 0.47cifar10:0.2-instance | Epoch [ 36/ 75] Iter[201/1216]	  loss: 0.53cifar10:0.2-instance | Epoch [ 36/ 75] Iter[251/1216]	  loss: 0.34cifar10:0.2-instance | Epoch [ 36/ 75] Iter[301/1216]	  loss: 0.56cifar10:0.2-instance | Epoch [ 36/ 75] Iter[351/1216]	  loss: 0.81cifar10:0.2-instance | Epoch [ 36/ 75] Iter[401/1216]	  loss: 0.32cifar10:0.2-instance | Epoch [ 36/ 75] Iter[451/1216]	  loss: 0.27cifar10:0.2-instance | Epoch [ 36/ 75] Iter[501/1216]	  loss: 0.36cifar10:0.2-instance | Epoch [ 36/ 75] Iter[551/1216]	  loss: 0.32cifar10:0.2-instance | Epoch [ 36/ 75] Iter[601/1216]	  loss: 0.30cifar10:0.2-instance | Epoch [ 36/ 75] Iter[651/1216]	  loss: 0.59cifar10:0.2-instance | Epoch [ 36/ 75] Iter[701/1216]	  loss: 0.46cifar10:0.2-instance | Epoch [ 36/ 75] Iter[751/1216]	  loss: 0.63cifar10:0.2-instance | Epoch [ 36/ 75] Iter[801/1216]	  loss: 0.23cifar10:0.2-instance | Epoch [ 36/ 75] Iter[851/1216]	  loss: 0.34cifar10:0.2-instance | Epoch [ 36/ 75] Iter[901/1216]	  loss: 0.19cifar10:0.2-instance | Epoch [ 36/ 75] Iter[951/1216]	  loss: 0.54cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1001/1216]	  loss: 0.35cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1051/1216]	  loss: 0.26cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1101/1216]	  loss: 0.42cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1151/1216]	  loss: 0.36cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1201/1216]	  loss: 0.35
| Test Epoch 36	 Accuracy: 83.55% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 37 | Accuracy on train set: 70.01% 
labeled data has a size of 38921, f-score: 0.984302
cifar10:0.2-instance | Epoch [ 37/ 75] Iter[  1/1217]	  loss: 0.45cifar10:0.2-instance | Epoch [ 37/ 75] Iter[ 51/1217]	  loss: 0.43cifar10:0.2-instance | Epoch [ 37/ 75] Iter[101/1217]	  loss: 0.60cifar10:0.2-instance | Epoch [ 37/ 75] Iter[151/1217]	  loss: 0.39cifar10:0.2-instance | Epoch [ 37/ 75] Iter[201/1217]	  loss: 0.32cifar10:0.2-instance | Epoch [ 37/ 75] Iter[251/1217]	  loss: 0.24cifar10:0.2-instance | Epoch [ 37/ 75] Iter[301/1217]	  loss: 0.47cifar10:0.2-instance | Epoch [ 37/ 75] Iter[351/1217]	  loss: 0.61cifar10:0.2-instance | Epoch [ 37/ 75] Iter[401/1217]	  loss: 0.39cifar10:0.2-instance | Epoch [ 37/ 75] Iter[451/1217]	  loss: 0.35cifar10:0.2-instance | Epoch [ 37/ 75] Iter[501/1217]	  loss: 0.24cifar10:0.2-instance | Epoch [ 37/ 75] Iter[551/1217]	  loss: 0.32cifar10:0.2-instance | Epoch [ 37/ 75] Iter[601/1217]	  loss: 0.54cifar10:0.2-instance | Epoch [ 37/ 75] Iter[651/1217]	  loss: 0.50cifar10:0.2-instance | Epoch [ 37/ 75] Iter[701/1217]	  loss: 0.33cifar10:0.2-instance | Epoch [ 37/ 75] Iter[751/1217]	  loss: 0.55cifar10:0.2-instance | Epoch [ 37/ 75] Iter[801/1217]	  loss: 0.63cifar10:0.2-instance | Epoch [ 37/ 75] Iter[851/1217]	  loss: 0.43cifar10:0.2-instance | Epoch [ 37/ 75] Iter[901/1217]	  loss: 0.78cifar10:0.2-instance | Epoch [ 37/ 75] Iter[951/1217]	  loss: 0.50cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1001/1217]	  loss: 0.71cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1051/1217]	  loss: 0.29cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1101/1217]	  loss: 0.25cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1151/1217]	  loss: 0.39cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1201/1217]	  loss: 0.53
| Test Epoch 37	 Accuracy: 82.28% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 38 | Accuracy on train set: 68.86% 
labeled data has a size of 39005, f-score: 0.983233
cifar10:0.2-instance | Epoch [ 38/ 75] Iter[  1/1219]	  loss: 0.40cifar10:0.2-instance | Epoch [ 38/ 75] Iter[ 51/1219]	  loss: 0.43cifar10:0.2-instance | Epoch [ 38/ 75] Iter[101/1219]	  loss: 0.32cifar10:0.2-instance | Epoch [ 38/ 75] Iter[151/1219]	  loss: 0.51cifar10:0.2-instance | Epoch [ 38/ 75] Iter[201/1219]	  loss: 0.43cifar10:0.2-instance | Epoch [ 38/ 75] Iter[251/1219]	  loss: 0.43cifar10:0.2-instance | Epoch [ 38/ 75] Iter[301/1219]	  loss: 0.54cifar10:0.2-instance | Epoch [ 38/ 75] Iter[351/1219]	  loss: 0.33cifar10:0.2-instance | Epoch [ 38/ 75] Iter[401/1219]	  loss: 0.36cifar10:0.2-instance | Epoch [ 38/ 75] Iter[451/1219]	  loss: 0.35cifar10:0.2-instance | Epoch [ 38/ 75] Iter[501/1219]	  loss: 0.46cifar10:0.2-instance | Epoch [ 38/ 75] Iter[551/1219]	  loss: 0.30cifar10:0.2-instance | Epoch [ 38/ 75] Iter[601/1219]	  loss: 0.24cifar10:0.2-instance | Epoch [ 38/ 75] Iter[651/1219]	  loss: 0.41cifar10:0.2-instance | Epoch [ 38/ 75] Iter[701/1219]	  loss: 0.30cifar10:0.2-instance | Epoch [ 38/ 75] Iter[751/1219]	  loss: 0.64cifar10:0.2-instance | Epoch [ 38/ 75] Iter[801/1219]	  loss: 0.33cifar10:0.2-instance | Epoch [ 38/ 75] Iter[851/1219]	  loss: 0.34cifar10:0.2-instance | Epoch [ 38/ 75] Iter[901/1219]	  loss: 0.48cifar10:0.2-instance | Epoch [ 38/ 75] Iter[951/1219]	  loss: 0.38cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1001/1219]	  loss: 0.43cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1051/1219]	  loss: 0.42cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1101/1219]	  loss: 0.20cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1151/1219]	  loss: 0.31cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1201/1219]	  loss: 0.59
| Test Epoch 38	 Accuracy: 85.19% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 39 | Accuracy on train set: 71.84% 
labeled data has a size of 39023, f-score: 0.982395
cifar10:0.2-instance | Epoch [ 39/ 75] Iter[  1/1220]	  loss: 0.39cifar10:0.2-instance | Epoch [ 39/ 75] Iter[ 51/1220]	  loss: 0.42cifar10:0.2-instance | Epoch [ 39/ 75] Iter[101/1220]	  loss: 0.29cifar10:0.2-instance | Epoch [ 39/ 75] Iter[151/1220]	  loss: 0.48cifar10:0.2-instance | Epoch [ 39/ 75] Iter[201/1220]	  loss: 0.53cifar10:0.2-instance | Epoch [ 39/ 75] Iter[251/1220]	  loss: 0.54cifar10:0.2-instance | Epoch [ 39/ 75] Iter[301/1220]	  loss: 0.25cifar10:0.2-instance | Epoch [ 39/ 75] Iter[351/1220]	  loss: 0.68cifar10:0.2-instance | Epoch [ 39/ 75] Iter[401/1220]	  loss: 0.40cifar10:0.2-instance | Epoch [ 39/ 75] Iter[451/1220]	  loss: 0.30cifar10:0.2-instance | Epoch [ 39/ 75] Iter[501/1220]	  loss: 0.50cifar10:0.2-instance | Epoch [ 39/ 75] Iter[551/1220]	  loss: 0.44cifar10:0.2-instance | Epoch [ 39/ 75] Iter[601/1220]	  loss: 0.31cifar10:0.2-instance | Epoch [ 39/ 75] Iter[651/1220]	  loss: 0.35cifar10:0.2-instance | Epoch [ 39/ 75] Iter[701/1220]	  loss: 0.41cifar10:0.2-instance | Epoch [ 39/ 75] Iter[751/1220]	  loss: 0.43cifar10:0.2-instance | Epoch [ 39/ 75] Iter[801/1220]	  loss: 0.30cifar10:0.2-instance | Epoch [ 39/ 75] Iter[851/1220]	  loss: 0.32cifar10:0.2-instance | Epoch [ 39/ 75] Iter[901/1220]	  loss: 0.45cifar10:0.2-instance | Epoch [ 39/ 75] Iter[951/1220]	  loss: 0.31cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1001/1220]	  loss: 0.54cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1051/1220]	  loss: 0.36cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1101/1220]	  loss: 0.52cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1151/1220]	  loss: 0.41cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1201/1220]	  loss: 0.46
| Test Epoch 39	 Accuracy: 84.21% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 40 | Accuracy on train set: 70.96% 
labeled data has a size of 39130, f-score: 0.982520
cifar10:0.2-instance | Epoch [ 40/ 75] Iter[  1/1223]	  loss: 0.62cifar10:0.2-instance | Epoch [ 40/ 75] Iter[ 51/1223]	  loss: 0.53cifar10:0.2-instance | Epoch [ 40/ 75] Iter[101/1223]	  loss: 0.40cifar10:0.2-instance | Epoch [ 40/ 75] Iter[151/1223]	  loss: 0.38cifar10:0.2-instance | Epoch [ 40/ 75] Iter[201/1223]	  loss: 0.62cifar10:0.2-instance | Epoch [ 40/ 75] Iter[251/1223]	  loss: 0.50cifar10:0.2-instance | Epoch [ 40/ 75] Iter[301/1223]	  loss: 0.37cifar10:0.2-instance | Epoch [ 40/ 75] Iter[351/1223]	  loss: 0.49cifar10:0.2-instance | Epoch [ 40/ 75] Iter[401/1223]	  loss: 0.42cifar10:0.2-instance | Epoch [ 40/ 75] Iter[451/1223]	  loss: 0.27cifar10:0.2-instance | Epoch [ 40/ 75] Iter[501/1223]	  loss: 0.55cifar10:0.2-instance | Epoch [ 40/ 75] Iter[551/1223]	  loss: 0.35cifar10:0.2-instance | Epoch [ 40/ 75] Iter[601/1223]	  loss: 0.38cifar10:0.2-instance | Epoch [ 40/ 75] Iter[651/1223]	  loss: 0.34cifar10:0.2-instance | Epoch [ 40/ 75] Iter[701/1223]	  loss: 0.46cifar10:0.2-instance | Epoch [ 40/ 75] Iter[751/1223]	  loss: 0.47cifar10:0.2-instance | Epoch [ 40/ 75] Iter[801/1223]	  loss: 0.58cifar10:0.2-instance | Epoch [ 40/ 75] Iter[851/1223]	  loss: 0.23cifar10:0.2-instance | Epoch [ 40/ 75] Iter[901/1223]	  loss: 0.63cifar10:0.2-instance | Epoch [ 40/ 75] Iter[951/1223]	  loss: 0.31cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1001/1223]	  loss: 0.45cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1051/1223]	  loss: 0.31cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1101/1223]	  loss: 0.46cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1151/1223]	  loss: 0.57cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1201/1223]	  loss: 0.39
| Test Epoch 40	 Accuracy: 83.90% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 41 | Accuracy on train set: 70.63% 
labeled data has a size of 39182, f-score: 0.982262
cifar10:0.2-instance | Epoch [ 41/ 75] Iter[  1/1225]	  loss: 0.38cifar10:0.2-instance | Epoch [ 41/ 75] Iter[ 51/1225]	  loss: 0.34cifar10:0.2-instance | Epoch [ 41/ 75] Iter[101/1225]	  loss: 0.60cifar10:0.2-instance | Epoch [ 41/ 75] Iter[151/1225]	  loss: 0.36cifar10:0.2-instance | Epoch [ 41/ 75] Iter[201/1225]	  loss: 0.25cifar10:0.2-instance | Epoch [ 41/ 75] Iter[251/1225]	  loss: 0.53cifar10:0.2-instance | Epoch [ 41/ 75] Iter[301/1225]	  loss: 0.25cifar10:0.2-instance | Epoch [ 41/ 75] Iter[351/1225]	  loss: 0.37cifar10:0.2-instance | Epoch [ 41/ 75] Iter[401/1225]	  loss: 0.42cifar10:0.2-instance | Epoch [ 41/ 75] Iter[451/1225]	  loss: 0.59cifar10:0.2-instance | Epoch [ 41/ 75] Iter[501/1225]	  loss: 0.23cifar10:0.2-instance | Epoch [ 41/ 75] Iter[551/1225]	  loss: 0.28cifar10:0.2-instance | Epoch [ 41/ 75] Iter[601/1225]	  loss: 0.48cifar10:0.2-instance | Epoch [ 41/ 75] Iter[651/1225]	  loss: 0.87cifar10:0.2-instance | Epoch [ 41/ 75] Iter[701/1225]	  loss: 0.50cifar10:0.2-instance | Epoch [ 41/ 75] Iter[751/1225]	  loss: 0.64cifar10:0.2-instance | Epoch [ 41/ 75] Iter[801/1225]	  loss: 0.50cifar10:0.2-instance | Epoch [ 41/ 75] Iter[851/1225]	  loss: 0.37cifar10:0.2-instance | Epoch [ 41/ 75] Iter[901/1225]	  loss: 0.76cifar10:0.2-instance | Epoch [ 41/ 75] Iter[951/1225]	  loss: 0.27cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1001/1225]	  loss: 0.22cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1051/1225]	  loss: 0.58cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1101/1225]	  loss: 0.47cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1151/1225]	  loss: 0.31cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1201/1225]	  loss: 0.36
| Test Epoch 41	 Accuracy: 83.57% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 42 | Accuracy on train set: 70.76% 
labeled data has a size of 39000, f-score: 0.982410
cifar10:0.2-instance | Epoch [ 42/ 75] Iter[  1/1219]	  loss: 0.33cifar10:0.2-instance | Epoch [ 42/ 75] Iter[ 51/1219]	  loss: 0.40cifar10:0.2-instance | Epoch [ 42/ 75] Iter[101/1219]	  loss: 0.43cifar10:0.2-instance | Epoch [ 42/ 75] Iter[151/1219]	  loss: 0.30cifar10:0.2-instance | Epoch [ 42/ 75] Iter[201/1219]	  loss: 0.29cifar10:0.2-instance | Epoch [ 42/ 75] Iter[251/1219]	  loss: 0.45cifar10:0.2-instance | Epoch [ 42/ 75] Iter[301/1219]	  loss: 0.23cifar10:0.2-instance | Epoch [ 42/ 75] Iter[351/1219]	  loss: 0.39cifar10:0.2-instance | Epoch [ 42/ 75] Iter[401/1219]	  loss: 0.39cifar10:0.2-instance | Epoch [ 42/ 75] Iter[451/1219]	  loss: 0.37cifar10:0.2-instance | Epoch [ 42/ 75] Iter[501/1219]	  loss: 0.42cifar10:0.2-instance | Epoch [ 42/ 75] Iter[551/1219]	  loss: 0.58cifar10:0.2-instance | Epoch [ 42/ 75] Iter[601/1219]	  loss: 0.58cifar10:0.2-instance | Epoch [ 42/ 75] Iter[651/1219]	  loss: 0.55cifar10:0.2-instance | Epoch [ 42/ 75] Iter[701/1219]	  loss: 0.32cifar10:0.2-instance | Epoch [ 42/ 75] Iter[751/1219]	  loss: 0.44cifar10:0.2-instance | Epoch [ 42/ 75] Iter[801/1219]	  loss: 0.53cifar10:0.2-instance | Epoch [ 42/ 75] Iter[851/1219]	  loss: 0.41cifar10:0.2-instance | Epoch [ 42/ 75] Iter[901/1219]	  loss: 0.45cifar10:0.2-instance | Epoch [ 42/ 75] Iter[951/1219]	  loss: 0.51cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1001/1219]	  loss: 0.31cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1051/1219]	  loss: 0.40cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1101/1219]	  loss: 0.39cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1151/1219]	  loss: 0.49cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1201/1219]	  loss: 0.29
| Test Epoch 42	 Accuracy: 85.34% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 43 | Accuracy on train set: 71.83% 
labeled data has a size of 39048, f-score: 0.981305
cifar10:0.2-instance | Epoch [ 43/ 75] Iter[  1/1221]	  loss: 0.25cifar10:0.2-instance | Epoch [ 43/ 75] Iter[ 51/1221]	  loss: 0.40cifar10:0.2-instance | Epoch [ 43/ 75] Iter[101/1221]	  loss: 0.41cifar10:0.2-instance | Epoch [ 43/ 75] Iter[151/1221]	  loss: 0.56cifar10:0.2-instance | Epoch [ 43/ 75] Iter[201/1221]	  loss: 0.40cifar10:0.2-instance | Epoch [ 43/ 75] Iter[251/1221]	  loss: 0.43cifar10:0.2-instance | Epoch [ 43/ 75] Iter[301/1221]	  loss: 0.25cifar10:0.2-instance | Epoch [ 43/ 75] Iter[351/1221]	  loss: 0.39cifar10:0.2-instance | Epoch [ 43/ 75] Iter[401/1221]	  loss: 0.44cifar10:0.2-instance | Epoch [ 43/ 75] Iter[451/1221]	  loss: 0.36cifar10:0.2-instance | Epoch [ 43/ 75] Iter[501/1221]	  loss: 0.27cifar10:0.2-instance | Epoch [ 43/ 75] Iter[551/1221]	  loss: 0.35cifar10:0.2-instance | Epoch [ 43/ 75] Iter[601/1221]	  loss: 0.30cifar10:0.2-instance | Epoch [ 43/ 75] Iter[651/1221]	  loss: 0.28cifar10:0.2-instance | Epoch [ 43/ 75] Iter[701/1221]	  loss: 0.29cifar10:0.2-instance | Epoch [ 43/ 75] Iter[751/1221]	  loss: 0.30cifar10:0.2-instance | Epoch [ 43/ 75] Iter[801/1221]	  loss: 0.25cifar10:0.2-instance | Epoch [ 43/ 75] Iter[851/1221]	  loss: 0.40cifar10:0.2-instance | Epoch [ 43/ 75] Iter[901/1221]	  loss: 0.47cifar10:0.2-instance | Epoch [ 43/ 75] Iter[951/1221]	  loss: 0.24cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1001/1221]	  loss: 0.26cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1051/1221]	  loss: 0.33cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1101/1221]	  loss: 0.49cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1151/1221]	  loss: 0.32cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1201/1221]	  loss: 0.35
| Test Epoch 43	 Accuracy: 83.48% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 44 | Accuracy on train set: 70.07% 
labeled data has a size of 39128, f-score: 0.982953
cifar10:0.2-instance | Epoch [ 44/ 75] Iter[  1/1223]	  loss: 0.37cifar10:0.2-instance | Epoch [ 44/ 75] Iter[ 51/1223]	  loss: 0.39cifar10:0.2-instance | Epoch [ 44/ 75] Iter[101/1223]	  loss: 0.29cifar10:0.2-instance | Epoch [ 44/ 75] Iter[151/1223]	  loss: 0.57cifar10:0.2-instance | Epoch [ 44/ 75] Iter[201/1223]	  loss: 0.28cifar10:0.2-instance | Epoch [ 44/ 75] Iter[251/1223]	  loss: 0.36cifar10:0.2-instance | Epoch [ 44/ 75] Iter[301/1223]	  loss: 0.36cifar10:0.2-instance | Epoch [ 44/ 75] Iter[351/1223]	  loss: 0.46cifar10:0.2-instance | Epoch [ 44/ 75] Iter[401/1223]	  loss: 0.42cifar10:0.2-instance | Epoch [ 44/ 75] Iter[451/1223]	  loss: 0.38cifar10:0.2-instance | Epoch [ 44/ 75] Iter[501/1223]	  loss: 0.30cifar10:0.2-instance | Epoch [ 44/ 75] Iter[551/1223]	  loss: 0.25cifar10:0.2-instance | Epoch [ 44/ 75] Iter[601/1223]	  loss: 0.51cifar10:0.2-instance | Epoch [ 44/ 75] Iter[651/1223]	  loss: 0.34cifar10:0.2-instance | Epoch [ 44/ 75] Iter[701/1223]	  loss: 0.37cifar10:0.2-instance | Epoch [ 44/ 75] Iter[751/1223]	  loss: 0.38cifar10:0.2-instance | Epoch [ 44/ 75] Iter[801/1223]	  loss: 0.52cifar10:0.2-instance | Epoch [ 44/ 75] Iter[851/1223]	  loss: 0.41cifar10:0.2-instance | Epoch [ 44/ 75] Iter[901/1223]	  loss: 0.41cifar10:0.2-instance | Epoch [ 44/ 75] Iter[951/1223]	  loss: 0.39cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1001/1223]	  loss: 0.56cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1051/1223]	  loss: 0.37cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1101/1223]	  loss: 0.39cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1151/1223]	  loss: 0.54cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1201/1223]	  loss: 0.33
| Test Epoch 44	 Accuracy: 86.37% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 45 | Accuracy on train set: 72.82% 
labeled data has a size of 39182, f-score: 0.983462
cifar10:0.2-instance | Epoch [ 45/ 75] Iter[  1/1225]	  loss: 0.36cifar10:0.2-instance | Epoch [ 45/ 75] Iter[ 51/1225]	  loss: 0.25cifar10:0.2-instance | Epoch [ 45/ 75] Iter[101/1225]	  loss: 0.45cifar10:0.2-instance | Epoch [ 45/ 75] Iter[151/1225]	  loss: 0.48cifar10:0.2-instance | Epoch [ 45/ 75] Iter[201/1225]	  loss: 0.45cifar10:0.2-instance | Epoch [ 45/ 75] Iter[251/1225]	  loss: 0.30cifar10:0.2-instance | Epoch [ 45/ 75] Iter[301/1225]	  loss: 0.46cifar10:0.2-instance | Epoch [ 45/ 75] Iter[351/1225]	  loss: 0.56cifar10:0.2-instance | Epoch [ 45/ 75] Iter[401/1225]	  loss: 0.47cifar10:0.2-instance | Epoch [ 45/ 75] Iter[451/1225]	  loss: 0.23cifar10:0.2-instance | Epoch [ 45/ 75] Iter[501/1225]	  loss: 0.34cifar10:0.2-instance | Epoch [ 45/ 75] Iter[551/1225]	  loss: 0.42cifar10:0.2-instance | Epoch [ 45/ 75] Iter[601/1225]	  loss: 0.56cifar10:0.2-instance | Epoch [ 45/ 75] Iter[651/1225]	  loss: 0.46cifar10:0.2-instance | Epoch [ 45/ 75] Iter[701/1225]	  loss: 0.38cifar10:0.2-instance | Epoch [ 45/ 75] Iter[751/1225]	  loss: 0.57cifar10:0.2-instance | Epoch [ 45/ 75] Iter[801/1225]	  loss: 0.46cifar10:0.2-instance | Epoch [ 45/ 75] Iter[851/1225]	  loss: 0.43cifar10:0.2-instance | Epoch [ 45/ 75] Iter[901/1225]	  loss: 0.38cifar10:0.2-instance | Epoch [ 45/ 75] Iter[951/1225]	  loss: 0.22cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1001/1225]	  loss: 0.39cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1051/1225]	  loss: 0.42cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1101/1225]	  loss: 0.35cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1151/1225]	  loss: 0.34cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1201/1225]	  loss: 0.24
| Test Epoch 45	 Accuracy: 85.42% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 46 | Accuracy on train set: 71.93% 
labeled data has a size of 39204, f-score: 0.983828
cifar10:0.2-instance | Epoch [ 46/ 75] Iter[  1/1226]	  loss: 0.44cifar10:0.2-instance | Epoch [ 46/ 75] Iter[ 51/1226]	  loss: 0.27cifar10:0.2-instance | Epoch [ 46/ 75] Iter[101/1226]	  loss: 0.49cifar10:0.2-instance | Epoch [ 46/ 75] Iter[151/1226]	  loss: 0.37cifar10:0.2-instance | Epoch [ 46/ 75] Iter[201/1226]	  loss: 0.65cifar10:0.2-instance | Epoch [ 46/ 75] Iter[251/1226]	  loss: 0.45cifar10:0.2-instance | Epoch [ 46/ 75] Iter[301/1226]	  loss: 0.28cifar10:0.2-instance | Epoch [ 46/ 75] Iter[351/1226]	  loss: 0.42cifar10:0.2-instance | Epoch [ 46/ 75] Iter[401/1226]	  loss: 0.30cifar10:0.2-instance | Epoch [ 46/ 75] Iter[451/1226]	  loss: 0.43cifar10:0.2-instance | Epoch [ 46/ 75] Iter[501/1226]	  loss: 0.59cifar10:0.2-instance | Epoch [ 46/ 75] Iter[551/1226]	  loss: 0.42cifar10:0.2-instance | Epoch [ 46/ 75] Iter[601/1226]	  loss: 0.31cifar10:0.2-instance | Epoch [ 46/ 75] Iter[651/1226]	  loss: 0.44cifar10:0.2-instance | Epoch [ 46/ 75] Iter[701/1226]	  loss: 0.37cifar10:0.2-instance | Epoch [ 46/ 75] Iter[751/1226]	  loss: 0.25cifar10:0.2-instance | Epoch [ 46/ 75] Iter[801/1226]	  loss: 0.64cifar10:0.2-instance | Epoch [ 46/ 75] Iter[851/1226]	  loss: 0.39cifar10:0.2-instance | Epoch [ 46/ 75] Iter[901/1226]	  loss: 0.36cifar10:0.2-instance | Epoch [ 46/ 75] Iter[951/1226]	  loss: 0.39cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1001/1226]	  loss: 0.93cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1051/1226]	  loss: 0.64cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1101/1226]	  loss: 0.58cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1151/1226]	  loss: 0.83cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1201/1226]	  loss: 0.34
| Test Epoch 46	 Accuracy: 86.34% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 47 | Accuracy on train set: 72.41% 
labeled data has a size of 39262, f-score: 0.984183
cifar10:0.2-instance | Epoch [ 47/ 75] Iter[  1/1227]	  loss: 0.25cifar10:0.2-instance | Epoch [ 47/ 75] Iter[ 51/1227]	  loss: 0.44cifar10:0.2-instance | Epoch [ 47/ 75] Iter[101/1227]	  loss: 0.31cifar10:0.2-instance | Epoch [ 47/ 75] Iter[151/1227]	  loss: 0.28cifar10:0.2-instance | Epoch [ 47/ 75] Iter[201/1227]	  loss: 0.44cifar10:0.2-instance | Epoch [ 47/ 75] Iter[251/1227]	  loss: 0.33cifar10:0.2-instance | Epoch [ 47/ 75] Iter[301/1227]	  loss: 0.38cifar10:0.2-instance | Epoch [ 47/ 75] Iter[351/1227]	  loss: 0.46cifar10:0.2-instance | Epoch [ 47/ 75] Iter[401/1227]	  loss: 0.22cifar10:0.2-instance | Epoch [ 47/ 75] Iter[451/1227]	  loss: 0.62cifar10:0.2-instance | Epoch [ 47/ 75] Iter[501/1227]	  loss: 0.29cifar10:0.2-instance | Epoch [ 47/ 75] Iter[551/1227]	  loss: 0.40cifar10:0.2-instance | Epoch [ 47/ 75] Iter[601/1227]	  loss: 0.46cifar10:0.2-instance | Epoch [ 47/ 75] Iter[651/1227]	  loss: 0.32cifar10:0.2-instance | Epoch [ 47/ 75] Iter[701/1227]	  loss: 0.51cifar10:0.2-instance | Epoch [ 47/ 75] Iter[751/1227]	  loss: 0.43cifar10:0.2-instance | Epoch [ 47/ 75] Iter[801/1227]	  loss: 0.40cifar10:0.2-instance | Epoch [ 47/ 75] Iter[851/1227]	  loss: 0.70cifar10:0.2-instance | Epoch [ 47/ 75] Iter[901/1227]	  loss: 0.34cifar10:0.2-instance | Epoch [ 47/ 75] Iter[951/1227]	  loss: 0.40cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1001/1227]	  loss: 0.43cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1051/1227]	  loss: 0.42cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1101/1227]	  loss: 0.24cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1151/1227]	  loss: 0.26cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1201/1227]	  loss: 0.39
| Test Epoch 47	 Accuracy: 86.83% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 48 | Accuracy on train set: 73.29% 
labeled data has a size of 39228, f-score: 0.985087
cifar10:0.2-instance | Epoch [ 48/ 75] Iter[  1/1226]	  loss: 0.22cifar10:0.2-instance | Epoch [ 48/ 75] Iter[ 51/1226]	  loss: 0.35cifar10:0.2-instance | Epoch [ 48/ 75] Iter[101/1226]	  loss: 0.36cifar10:0.2-instance | Epoch [ 48/ 75] Iter[151/1226]	  loss: 0.28cifar10:0.2-instance | Epoch [ 48/ 75] Iter[201/1226]	  loss: 0.50cifar10:0.2-instance | Epoch [ 48/ 75] Iter[251/1226]	  loss: 0.32cifar10:0.2-instance | Epoch [ 48/ 75] Iter[301/1226]	  loss: 0.39cifar10:0.2-instance | Epoch [ 48/ 75] Iter[351/1226]	  loss: 0.45cifar10:0.2-instance | Epoch [ 48/ 75] Iter[401/1226]	  loss: 0.39cifar10:0.2-instance | Epoch [ 48/ 75] Iter[451/1226]	  loss: 0.28cifar10:0.2-instance | Epoch [ 48/ 75] Iter[501/1226]	  loss: 0.28cifar10:0.2-instance | Epoch [ 48/ 75] Iter[551/1226]	  loss: 0.46cifar10:0.2-instance | Epoch [ 48/ 75] Iter[601/1226]	  loss: 0.46cifar10:0.2-instance | Epoch [ 48/ 75] Iter[651/1226]	  loss: 0.32cifar10:0.2-instance | Epoch [ 48/ 75] Iter[701/1226]	  loss: 0.50cifar10:0.2-instance | Epoch [ 48/ 75] Iter[751/1226]	  loss: 0.26cifar10:0.2-instance | Epoch [ 48/ 75] Iter[801/1226]	  loss: 0.31cifar10:0.2-instance | Epoch [ 48/ 75] Iter[851/1226]	  loss: 0.34cifar10:0.2-instance | Epoch [ 48/ 75] Iter[901/1226]	  loss: 0.31cifar10:0.2-instance | Epoch [ 48/ 75] Iter[951/1226]	  loss: 0.37cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1001/1226]	  loss: 0.30cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1051/1226]	  loss: 0.24cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1101/1226]	  loss: 0.27cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1151/1226]	  loss: 0.33cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1201/1226]	  loss: 0.52
| Test Epoch 48	 Accuracy: 84.99% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 49 | Accuracy on train set: 71.72% 
labeled data has a size of 39274, f-score: 0.984086
cifar10:0.2-instance | Epoch [ 49/ 75] Iter[  1/1228]	  loss: 0.53cifar10:0.2-instance | Epoch [ 49/ 75] Iter[ 51/1228]	  loss: 0.62cifar10:0.2-instance | Epoch [ 49/ 75] Iter[101/1228]	  loss: 0.42cifar10:0.2-instance | Epoch [ 49/ 75] Iter[151/1228]	  loss: 0.41cifar10:0.2-instance | Epoch [ 49/ 75] Iter[201/1228]	  loss: 0.28cifar10:0.2-instance | Epoch [ 49/ 75] Iter[251/1228]	  loss: 0.27cifar10:0.2-instance | Epoch [ 49/ 75] Iter[301/1228]	  loss: 0.44cifar10:0.2-instance | Epoch [ 49/ 75] Iter[351/1228]	  loss: 0.43cifar10:0.2-instance | Epoch [ 49/ 75] Iter[401/1228]	  loss: 0.34cifar10:0.2-instance | Epoch [ 49/ 75] Iter[451/1228]	  loss: 0.48cifar10:0.2-instance | Epoch [ 49/ 75] Iter[501/1228]	  loss: 0.81cifar10:0.2-instance | Epoch [ 49/ 75] Iter[551/1228]	  loss: 0.33cifar10:0.2-instance | Epoch [ 49/ 75] Iter[601/1228]	  loss: 0.35cifar10:0.2-instance | Epoch [ 49/ 75] Iter[651/1228]	  loss: 0.34cifar10:0.2-instance | Epoch [ 49/ 75] Iter[701/1228]	  loss: 0.26cifar10:0.2-instance | Epoch [ 49/ 75] Iter[751/1228]	  loss: 0.30cifar10:0.2-instance | Epoch [ 49/ 75] Iter[801/1228]	  loss: 0.45cifar10:0.2-instance | Epoch [ 49/ 75] Iter[851/1228]	  loss: 0.61cifar10:0.2-instance | Epoch [ 49/ 75] Iter[901/1228]	  loss: 0.37cifar10:0.2-instance | Epoch [ 49/ 75] Iter[951/1228]	  loss: 0.39cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1001/1228]	  loss: 0.25cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1051/1228]	  loss: 0.35cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1101/1228]	  loss: 0.34cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1151/1228]	  loss: 0.70cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1201/1228]	  loss: 0.42
| Test Epoch 49	 Accuracy: 86.46% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 50 | Accuracy on train set: 73.03% 
labeled data has a size of 39284, f-score: 0.983327
cifar10:0.2-instance | Epoch [ 50/ 75] Iter[  1/1228]	  loss: 0.31cifar10:0.2-instance | Epoch [ 50/ 75] Iter[ 51/1228]	  loss: 0.40cifar10:0.2-instance | Epoch [ 50/ 75] Iter[101/1228]	  loss: 0.35cifar10:0.2-instance | Epoch [ 50/ 75] Iter[151/1228]	  loss: 0.70cifar10:0.2-instance | Epoch [ 50/ 75] Iter[201/1228]	  loss: 0.31cifar10:0.2-instance | Epoch [ 50/ 75] Iter[251/1228]	  loss: 0.36cifar10:0.2-instance | Epoch [ 50/ 75] Iter[301/1228]	  loss: 0.46cifar10:0.2-instance | Epoch [ 50/ 75] Iter[351/1228]	  loss: 0.27cifar10:0.2-instance | Epoch [ 50/ 75] Iter[401/1228]	  loss: 0.26cifar10:0.2-instance | Epoch [ 50/ 75] Iter[451/1228]	  loss: 0.22cifar10:0.2-instance | Epoch [ 50/ 75] Iter[501/1228]	  loss: 0.30cifar10:0.2-instance | Epoch [ 50/ 75] Iter[551/1228]	  loss: 0.21cifar10:0.2-instance | Epoch [ 50/ 75] Iter[601/1228]	  loss: 0.89cifar10:0.2-instance | Epoch [ 50/ 75] Iter[651/1228]	  loss: 0.72cifar10:0.2-instance | Epoch [ 50/ 75] Iter[701/1228]	  loss: 0.34cifar10:0.2-instance | Epoch [ 50/ 75] Iter[751/1228]	  loss: 0.53cifar10:0.2-instance | Epoch [ 50/ 75] Iter[801/1228]	  loss: 0.24cifar10:0.2-instance | Epoch [ 50/ 75] Iter[851/1228]	  loss: 0.41cifar10:0.2-instance | Epoch [ 50/ 75] Iter[901/1228]	  loss: 0.39cifar10:0.2-instance | Epoch [ 50/ 75] Iter[951/1228]	  loss: 0.29cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1001/1228]	  loss: 0.40cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1051/1228]	  loss: 0.57cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1101/1228]	  loss: 0.26cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1151/1228]	  loss: 0.44cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1201/1228]	  loss: 0.29
| Test Epoch 50	 Accuracy: 85.50% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 51 | Accuracy on train set: 72.27% 
labeled data has a size of 39335, f-score: 0.981111
cifar10:0.2-instance | Epoch [ 51/ 75] Iter[  1/1230]	  loss: 0.55cifar10:0.2-instance | Epoch [ 51/ 75] Iter[ 51/1230]	  loss: 0.63cifar10:0.2-instance | Epoch [ 51/ 75] Iter[101/1230]	  loss: 0.53cifar10:0.2-instance | Epoch [ 51/ 75] Iter[151/1230]	  loss: 0.37cifar10:0.2-instance | Epoch [ 51/ 75] Iter[201/1230]	  loss: 0.25cifar10:0.2-instance | Epoch [ 51/ 75] Iter[251/1230]	  loss: 0.24cifar10:0.2-instance | Epoch [ 51/ 75] Iter[301/1230]	  loss: 0.29cifar10:0.2-instance | Epoch [ 51/ 75] Iter[351/1230]	  loss: 0.23cifar10:0.2-instance | Epoch [ 51/ 75] Iter[401/1230]	  loss: 0.36cifar10:0.2-instance | Epoch [ 51/ 75] Iter[451/1230]	  loss: 0.38cifar10:0.2-instance | Epoch [ 51/ 75] Iter[501/1230]	  loss: 0.65cifar10:0.2-instance | Epoch [ 51/ 75] Iter[551/1230]	  loss: 0.49cifar10:0.2-instance | Epoch [ 51/ 75] Iter[601/1230]	  loss: 0.24cifar10:0.2-instance | Epoch [ 51/ 75] Iter[651/1230]	  loss: 0.41cifar10:0.2-instance | Epoch [ 51/ 75] Iter[701/1230]	  loss: 0.48cifar10:0.2-instance | Epoch [ 51/ 75] Iter[751/1230]	  loss: 0.35cifar10:0.2-instance | Epoch [ 51/ 75] Iter[801/1230]	  loss: 0.23cifar10:0.2-instance | Epoch [ 51/ 75] Iter[851/1230]	  loss: 0.27cifar10:0.2-instance | Epoch [ 51/ 75] Iter[901/1230]	  loss: 0.24cifar10:0.2-instance | Epoch [ 51/ 75] Iter[951/1230]	  loss: 0.41cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1001/1230]	  loss: 0.35cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1051/1230]	  loss: 0.59cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1101/1230]	  loss: 0.40cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1151/1230]	  loss: 0.54cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1201/1230]	  loss: 0.44
| Test Epoch 51	 Accuracy: 86.49% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 52 | Accuracy on train set: 73.02% 
labeled data has a size of 39368, f-score: 0.982092
cifar10:0.2-instance | Epoch [ 52/ 75] Iter[  1/1231]	  loss: 0.34cifar10:0.2-instance | Epoch [ 52/ 75] Iter[ 51/1231]	  loss: 0.29cifar10:0.2-instance | Epoch [ 52/ 75] Iter[101/1231]	  loss: 0.36cifar10:0.2-instance | Epoch [ 52/ 75] Iter[151/1231]	  loss: 0.28cifar10:0.2-instance | Epoch [ 52/ 75] Iter[201/1231]	  loss: 0.55cifar10:0.2-instance | Epoch [ 52/ 75] Iter[251/1231]	  loss: 0.70cifar10:0.2-instance | Epoch [ 52/ 75] Iter[301/1231]	  loss: 0.23cifar10:0.2-instance | Epoch [ 52/ 75] Iter[351/1231]	  loss: 0.42cifar10:0.2-instance | Epoch [ 52/ 75] Iter[401/1231]	  loss: 0.44cifar10:0.2-instance | Epoch [ 52/ 75] Iter[451/1231]	  loss: 0.54cifar10:0.2-instance | Epoch [ 52/ 75] Iter[501/1231]	  loss: 0.35cifar10:0.2-instance | Epoch [ 52/ 75] Iter[551/1231]	  loss: 0.29cifar10:0.2-instance | Epoch [ 52/ 75] Iter[601/1231]	  loss: 0.54cifar10:0.2-instance | Epoch [ 52/ 75] Iter[651/1231]	  loss: 0.34cifar10:0.2-instance | Epoch [ 52/ 75] Iter[701/1231]	  loss: 0.45cifar10:0.2-instance | Epoch [ 52/ 75] Iter[751/1231]	  loss: 0.61cifar10:0.2-instance | Epoch [ 52/ 75] Iter[801/1231]	  loss: 0.28cifar10:0.2-instance | Epoch [ 52/ 75] Iter[851/1231]	  loss: 0.32cifar10:0.2-instance | Epoch [ 52/ 75] Iter[901/1231]	  loss: 0.43cifar10:0.2-instance | Epoch [ 52/ 75] Iter[951/1231]	  loss: 0.34cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1001/1231]	  loss: 0.57cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1051/1231]	  loss: 0.55cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1101/1231]	  loss: 0.53cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1151/1231]	  loss: 0.50cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1201/1231]	  loss: 0.41
| Test Epoch 52	 Accuracy: 83.09% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 53 | Accuracy on train set: 70.14% 
labeled data has a size of 39302, f-score: 0.980332
cifar10:0.2-instance | Epoch [ 53/ 75] Iter[  1/1229]	  loss: 0.34cifar10:0.2-instance | Epoch [ 53/ 75] Iter[ 51/1229]	  loss: 0.44cifar10:0.2-instance | Epoch [ 53/ 75] Iter[101/1229]	  loss: 0.29cifar10:0.2-instance | Epoch [ 53/ 75] Iter[151/1229]	  loss: 0.35cifar10:0.2-instance | Epoch [ 53/ 75] Iter[201/1229]	  loss: 0.42cifar10:0.2-instance | Epoch [ 53/ 75] Iter[251/1229]	  loss: 0.40cifar10:0.2-instance | Epoch [ 53/ 75] Iter[301/1229]	  loss: 0.47cifar10:0.2-instance | Epoch [ 53/ 75] Iter[351/1229]	  loss: 0.60cifar10:0.2-instance | Epoch [ 53/ 75] Iter[401/1229]	  loss: 0.58cifar10:0.2-instance | Epoch [ 53/ 75] Iter[451/1229]	  loss: 0.40cifar10:0.2-instance | Epoch [ 53/ 75] Iter[501/1229]	  loss: 0.32cifar10:0.2-instance | Epoch [ 53/ 75] Iter[551/1229]	  loss: 0.53cifar10:0.2-instance | Epoch [ 53/ 75] Iter[601/1229]	  loss: 0.46cifar10:0.2-instance | Epoch [ 53/ 75] Iter[651/1229]	  loss: 0.50cifar10:0.2-instance | Epoch [ 53/ 75] Iter[701/1229]	  loss: 0.68cifar10:0.2-instance | Epoch [ 53/ 75] Iter[751/1229]	  loss: 0.56cifar10:0.2-instance | Epoch [ 53/ 75] Iter[801/1229]	  loss: 0.42cifar10:0.2-instance | Epoch [ 53/ 75] Iter[851/1229]	  loss: 0.35cifar10:0.2-instance | Epoch [ 53/ 75] Iter[901/1229]	  loss: 0.32cifar10:0.2-instance | Epoch [ 53/ 75] Iter[951/1229]	  loss: 0.43cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1001/1229]	  loss: 0.56cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1051/1229]	  loss: 0.26cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1101/1229]	  loss: 0.58cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1151/1229]	  loss: 0.50cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1201/1229]	  loss: 0.36
| Test Epoch 53	 Accuracy: 85.96% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 54 | Accuracy on train set: 72.33% 
labeled data has a size of 39263, f-score: 0.980873
cifar10:0.2-instance | Epoch [ 54/ 75] Iter[  1/1227]	  loss: 0.33cifar10:0.2-instance | Epoch [ 54/ 75] Iter[ 51/1227]	  loss: 0.27cifar10:0.2-instance | Epoch [ 54/ 75] Iter[101/1227]	  loss: 0.44cifar10:0.2-instance | Epoch [ 54/ 75] Iter[151/1227]	  loss: 0.37cifar10:0.2-instance | Epoch [ 54/ 75] Iter[201/1227]	  loss: 0.35cifar10:0.2-instance | Epoch [ 54/ 75] Iter[251/1227]	  loss: 0.67cifar10:0.2-instance | Epoch [ 54/ 75] Iter[301/1227]	  loss: 0.24cifar10:0.2-instance | Epoch [ 54/ 75] Iter[351/1227]	  loss: 0.29cifar10:0.2-instance | Epoch [ 54/ 75] Iter[401/1227]	  loss: 0.49cifar10:0.2-instance | Epoch [ 54/ 75] Iter[451/1227]	  loss: 0.32cifar10:0.2-instance | Epoch [ 54/ 75] Iter[501/1227]	  loss: 0.48cifar10:0.2-instance | Epoch [ 54/ 75] Iter[551/1227]	  loss: 0.33cifar10:0.2-instance | Epoch [ 54/ 75] Iter[601/1227]	  loss: 0.79cifar10:0.2-instance | Epoch [ 54/ 75] Iter[651/1227]	  loss: 0.55cifar10:0.2-instance | Epoch [ 54/ 75] Iter[701/1227]	  loss: 0.32cifar10:0.2-instance | Epoch [ 54/ 75] Iter[751/1227]	  loss: 0.30cifar10:0.2-instance | Epoch [ 54/ 75] Iter[801/1227]	  loss: 0.52cifar10:0.2-instance | Epoch [ 54/ 75] Iter[851/1227]	  loss: 0.37cifar10:0.2-instance | Epoch [ 54/ 75] Iter[901/1227]	  loss: 0.42cifar10:0.2-instance | Epoch [ 54/ 75] Iter[951/1227]	  loss: 0.30cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1001/1227]	  loss: 0.48cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1051/1227]	  loss: 0.36cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1101/1227]	  loss: 0.32cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1151/1227]	  loss: 0.31cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1201/1227]	  loss: 0.38
| Test Epoch 54	 Accuracy: 86.76% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 55 | Accuracy on train set: 72.75% 
labeled data has a size of 39252, f-score: 0.980918
cifar10:0.2-instance | Epoch [ 55/ 75] Iter[  1/1227]	  loss: 0.48cifar10:0.2-instance | Epoch [ 55/ 75] Iter[ 51/1227]	  loss: 0.20cifar10:0.2-instance | Epoch [ 55/ 75] Iter[101/1227]	  loss: 0.47cifar10:0.2-instance | Epoch [ 55/ 75] Iter[151/1227]	  loss: 0.46cifar10:0.2-instance | Epoch [ 55/ 75] Iter[201/1227]	  loss: 0.25cifar10:0.2-instance | Epoch [ 55/ 75] Iter[251/1227]	  loss: 0.53cifar10:0.2-instance | Epoch [ 55/ 75] Iter[301/1227]	  loss: 0.29cifar10:0.2-instance | Epoch [ 55/ 75] Iter[351/1227]	  loss: 0.49cifar10:0.2-instance | Epoch [ 55/ 75] Iter[401/1227]	  loss: 0.40cifar10:0.2-instance | Epoch [ 55/ 75] Iter[451/1227]	  loss: 0.35cifar10:0.2-instance | Epoch [ 55/ 75] Iter[501/1227]	  loss: 0.37cifar10:0.2-instance | Epoch [ 55/ 75] Iter[551/1227]	  loss: 0.31cifar10:0.2-instance | Epoch [ 55/ 75] Iter[601/1227]	  loss: 0.35cifar10:0.2-instance | Epoch [ 55/ 75] Iter[651/1227]	  loss: 0.37cifar10:0.2-instance | Epoch [ 55/ 75] Iter[701/1227]	  loss: 0.29cifar10:0.2-instance | Epoch [ 55/ 75] Iter[751/1227]	  loss: 0.39cifar10:0.2-instance | Epoch [ 55/ 75] Iter[801/1227]	  loss: 0.48cifar10:0.2-instance | Epoch [ 55/ 75] Iter[851/1227]	  loss: 0.33cifar10:0.2-instance | Epoch [ 55/ 75] Iter[901/1227]	  loss: 0.33cifar10:0.2-instance | Epoch [ 55/ 75] Iter[951/1227]	  loss: 0.29cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1001/1227]	  loss: 0.42cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1051/1227]	  loss: 0.38cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1101/1227]	  loss: 0.49cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1151/1227]	  loss: 0.51cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1201/1227]	  loss: 0.43
| Test Epoch 55	 Accuracy: 87.26% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 56 | Accuracy on train set: 73.05% 
labeled data has a size of 39365, f-score: 0.982396
cifar10:0.2-instance | Epoch [ 56/ 75] Iter[  1/1231]	  loss: 0.28cifar10:0.2-instance | Epoch [ 56/ 75] Iter[ 51/1231]	  loss: 0.29cifar10:0.2-instance | Epoch [ 56/ 75] Iter[101/1231]	  loss: 0.59cifar10:0.2-instance | Epoch [ 56/ 75] Iter[151/1231]	  loss: 0.28cifar10:0.2-instance | Epoch [ 56/ 75] Iter[201/1231]	  loss: 0.22cifar10:0.2-instance | Epoch [ 56/ 75] Iter[251/1231]	  loss: 0.37cifar10:0.2-instance | Epoch [ 56/ 75] Iter[301/1231]	  loss: 0.27cifar10:0.2-instance | Epoch [ 56/ 75] Iter[351/1231]	  loss: 0.29cifar10:0.2-instance | Epoch [ 56/ 75] Iter[401/1231]	  loss: 0.35cifar10:0.2-instance | Epoch [ 56/ 75] Iter[451/1231]	  loss: 0.39cifar10:0.2-instance | Epoch [ 56/ 75] Iter[501/1231]	  loss: 0.49cifar10:0.2-instance | Epoch [ 56/ 75] Iter[551/1231]	  loss: 0.38cifar10:0.2-instance | Epoch [ 56/ 75] Iter[601/1231]	  loss: 0.23cifar10:0.2-instance | Epoch [ 56/ 75] Iter[651/1231]	  loss: 0.66cifar10:0.2-instance | Epoch [ 56/ 75] Iter[701/1231]	  loss: 0.31cifar10:0.2-instance | Epoch [ 56/ 75] Iter[751/1231]	  loss: 0.45cifar10:0.2-instance | Epoch [ 56/ 75] Iter[801/1231]	  loss: 0.48cifar10:0.2-instance | Epoch [ 56/ 75] Iter[851/1231]	  loss: 0.30cifar10:0.2-instance | Epoch [ 56/ 75] Iter[901/1231]	  loss: 0.34cifar10:0.2-instance | Epoch [ 56/ 75] Iter[951/1231]	  loss: 0.44cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1001/1231]	  loss: 0.33cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1051/1231]	  loss: 0.23cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1101/1231]	  loss: 0.42cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1151/1231]	  loss: 0.26cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1201/1231]	  loss: 0.47
| Test Epoch 56	 Accuracy: 84.68% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 57 | Accuracy on train set: 71.58% 
labeled data has a size of 39302, f-score: 0.982596
cifar10:0.2-instance | Epoch [ 57/ 75] Iter[  1/1229]	  loss: 0.29cifar10:0.2-instance | Epoch [ 57/ 75] Iter[ 51/1229]	  loss: 0.33cifar10:0.2-instance | Epoch [ 57/ 75] Iter[101/1229]	  loss: 0.34cifar10:0.2-instance | Epoch [ 57/ 75] Iter[151/1229]	  loss: 0.25cifar10:0.2-instance | Epoch [ 57/ 75] Iter[201/1229]	  loss: 0.34cifar10:0.2-instance | Epoch [ 57/ 75] Iter[251/1229]	  loss: 0.31cifar10:0.2-instance | Epoch [ 57/ 75] Iter[301/1229]	  loss: 0.23cifar10:0.2-instance | Epoch [ 57/ 75] Iter[351/1229]	  loss: 0.38cifar10:0.2-instance | Epoch [ 57/ 75] Iter[401/1229]	  loss: 0.54cifar10:0.2-instance | Epoch [ 57/ 75] Iter[451/1229]	  loss: 0.44cifar10:0.2-instance | Epoch [ 57/ 75] Iter[501/1229]	  loss: 0.37cifar10:0.2-instance | Epoch [ 57/ 75] Iter[551/1229]	  loss: 0.30cifar10:0.2-instance | Epoch [ 57/ 75] Iter[601/1229]	  loss: 0.74cifar10:0.2-instance | Epoch [ 57/ 75] Iter[651/1229]	  loss: 0.46cifar10:0.2-instance | Epoch [ 57/ 75] Iter[701/1229]	  loss: 0.63cifar10:0.2-instance | Epoch [ 57/ 75] Iter[751/1229]	  loss: 0.27cifar10:0.2-instance | Epoch [ 57/ 75] Iter[801/1229]	  loss: 0.37cifar10:0.2-instance | Epoch [ 57/ 75] Iter[851/1229]	  loss: 0.41cifar10:0.2-instance | Epoch [ 57/ 75] Iter[901/1229]	  loss: 0.36cifar10:0.2-instance | Epoch [ 57/ 75] Iter[951/1229]	  loss: 0.29cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1001/1229]	  loss: 0.45cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1051/1229]	  loss: 0.73cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1101/1229]	  loss: 0.43cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1151/1229]	  loss: 0.33cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1201/1229]	  loss: 0.32
| Test Epoch 57	 Accuracy: 86.52% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 58 | Accuracy on train set: 73.17% 
labeled data has a size of 39320, f-score: 0.982274
cifar10:0.2-instance | Epoch [ 58/ 75] Iter[  1/1229]	  loss: 0.22cifar10:0.2-instance | Epoch [ 58/ 75] Iter[ 51/1229]	  loss: 0.41cifar10:0.2-instance | Epoch [ 58/ 75] Iter[101/1229]	  loss: 0.43cifar10:0.2-instance | Epoch [ 58/ 75] Iter[151/1229]	  loss: 0.44cifar10:0.2-instance | Epoch [ 58/ 75] Iter[201/1229]	  loss: 0.29cifar10:0.2-instance | Epoch [ 58/ 75] Iter[251/1229]	  loss: 0.41cifar10:0.2-instance | Epoch [ 58/ 75] Iter[301/1229]	  loss: 0.26cifar10:0.2-instance | Epoch [ 58/ 75] Iter[351/1229]	  loss: 0.37cifar10:0.2-instance | Epoch [ 58/ 75] Iter[401/1229]	  loss: 0.33cifar10:0.2-instance | Epoch [ 58/ 75] Iter[451/1229]	  loss: 0.31cifar10:0.2-instance | Epoch [ 58/ 75] Iter[501/1229]	  loss: 0.47cifar10:0.2-instance | Epoch [ 58/ 75] Iter[551/1229]	  loss: 0.48cifar10:0.2-instance | Epoch [ 58/ 75] Iter[601/1229]	  loss: 0.37cifar10:0.2-instance | Epoch [ 58/ 75] Iter[651/1229]	  loss: 0.57cifar10:0.2-instance | Epoch [ 58/ 75] Iter[701/1229]	  loss: 0.69cifar10:0.2-instance | Epoch [ 58/ 75] Iter[751/1229]	  loss: 0.32cifar10:0.2-instance | Epoch [ 58/ 75] Iter[801/1229]	  loss: 0.37cifar10:0.2-instance | Epoch [ 58/ 75] Iter[851/1229]	  loss: 0.41cifar10:0.2-instance | Epoch [ 58/ 75] Iter[901/1229]	  loss: 0.62cifar10:0.2-instance | Epoch [ 58/ 75] Iter[951/1229]	  loss: 0.43cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1001/1229]	  loss: 0.36cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1051/1229]	  loss: 0.36cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1101/1229]	  loss: 0.46cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1151/1229]	  loss: 0.54cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1201/1229]	  loss: 0.41
| Test Epoch 58	 Accuracy: 84.90% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 59 | Accuracy on train set: 72.19% 
labeled data has a size of 39388, f-score: 0.978775
cifar10:0.2-instance | Epoch [ 59/ 75] Iter[  1/1231]	  loss: 0.31cifar10:0.2-instance | Epoch [ 59/ 75] Iter[ 51/1231]	  loss: 0.28cifar10:0.2-instance | Epoch [ 59/ 75] Iter[101/1231]	  loss: 0.37cifar10:0.2-instance | Epoch [ 59/ 75] Iter[151/1231]	  loss: 0.28cifar10:0.2-instance | Epoch [ 59/ 75] Iter[201/1231]	  loss: 0.31cifar10:0.2-instance | Epoch [ 59/ 75] Iter[251/1231]	  loss: 0.24cifar10:0.2-instance | Epoch [ 59/ 75] Iter[301/1231]	  loss: 0.23cifar10:0.2-instance | Epoch [ 59/ 75] Iter[351/1231]	  loss: 0.30cifar10:0.2-instance | Epoch [ 59/ 75] Iter[401/1231]	  loss: 0.42cifar10:0.2-instance | Epoch [ 59/ 75] Iter[451/1231]	  loss: 0.31cifar10:0.2-instance | Epoch [ 59/ 75] Iter[501/1231]	  loss: 0.64cifar10:0.2-instance | Epoch [ 59/ 75] Iter[551/1231]	  loss: 0.61cifar10:0.2-instance | Epoch [ 59/ 75] Iter[601/1231]	  loss: 0.38cifar10:0.2-instance | Epoch [ 59/ 75] Iter[651/1231]	  loss: 0.28cifar10:0.2-instance | Epoch [ 59/ 75] Iter[701/1231]	  loss: 0.46cifar10:0.2-instance | Epoch [ 59/ 75] Iter[751/1231]	  loss: 0.36cifar10:0.2-instance | Epoch [ 59/ 75] Iter[801/1231]	  loss: 0.38cifar10:0.2-instance | Epoch [ 59/ 75] Iter[851/1231]	  loss: 0.41cifar10:0.2-instance | Epoch [ 59/ 75] Iter[901/1231]	  loss: 0.37cifar10:0.2-instance | Epoch [ 59/ 75] Iter[951/1231]	  loss: 0.26cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1001/1231]	  loss: 0.35cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1051/1231]	  loss: 0.37cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1101/1231]	  loss: 0.38cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1151/1231]	  loss: 0.49cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1201/1231]	  loss: 0.44
| Test Epoch 59	 Accuracy: 84.15% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 60 | Accuracy on train set: 71.30% 
labeled data has a size of 39465, f-score: 0.978766
cifar10:0.2-instance | Epoch [ 60/ 75] Iter[  1/1234]	  loss: 0.42cifar10:0.2-instance | Epoch [ 60/ 75] Iter[ 51/1234]	  loss: 0.32cifar10:0.2-instance | Epoch [ 60/ 75] Iter[101/1234]	  loss: 0.32cifar10:0.2-instance | Epoch [ 60/ 75] Iter[151/1234]	  loss: 0.36cifar10:0.2-instance | Epoch [ 60/ 75] Iter[201/1234]	  loss: 0.44cifar10:0.2-instance | Epoch [ 60/ 75] Iter[251/1234]	  loss: 0.20cifar10:0.2-instance | Epoch [ 60/ 75] Iter[301/1234]	  loss: 0.35cifar10:0.2-instance | Epoch [ 60/ 75] Iter[351/1234]	  loss: 0.23cifar10:0.2-instance | Epoch [ 60/ 75] Iter[401/1234]	  loss: 0.20cifar10:0.2-instance | Epoch [ 60/ 75] Iter[451/1234]	  loss: 0.32cifar10:0.2-instance | Epoch [ 60/ 75] Iter[501/1234]	  loss: 0.27cifar10:0.2-instance | Epoch [ 60/ 75] Iter[551/1234]	  loss: 0.43cifar10:0.2-instance | Epoch [ 60/ 75] Iter[601/1234]	  loss: 0.39cifar10:0.2-instance | Epoch [ 60/ 75] Iter[651/1234]	  loss: 0.18cifar10:0.2-instance | Epoch [ 60/ 75] Iter[701/1234]	  loss: 0.42cifar10:0.2-instance | Epoch [ 60/ 75] Iter[751/1234]	  loss: 0.31cifar10:0.2-instance | Epoch [ 60/ 75] Iter[801/1234]	  loss: 0.26cifar10:0.2-instance | Epoch [ 60/ 75] Iter[851/1234]	  loss: 0.28cifar10:0.2-instance | Epoch [ 60/ 75] Iter[901/1234]	  loss: 0.19cifar10:0.2-instance | Epoch [ 60/ 75] Iter[951/1234]	  loss: 0.22cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1001/1234]	  loss: 0.32cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1051/1234]	  loss: 0.40cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1101/1234]	  loss: 0.29cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1151/1234]	  loss: 0.25cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1201/1234]	  loss: 0.38
| Test Epoch 60	 Accuracy: 91.06% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 61 | Accuracy on train set: 76.97% 
labeled data has a size of 39594, f-score: 0.979946
cifar10:0.2-instance | Epoch [ 61/ 75] Iter[  1/1238]	  loss: 0.53cifar10:0.2-instance | Epoch [ 61/ 75] Iter[ 51/1238]	  loss: 0.23cifar10:0.2-instance | Epoch [ 61/ 75] Iter[101/1238]	  loss: 0.42cifar10:0.2-instance | Epoch [ 61/ 75] Iter[151/1238]	  loss: 0.27cifar10:0.2-instance | Epoch [ 61/ 75] Iter[201/1238]	  loss: 0.31cifar10:0.2-instance | Epoch [ 61/ 75] Iter[251/1238]	  loss: 0.33cifar10:0.2-instance | Epoch [ 61/ 75] Iter[301/1238]	  loss: 0.17cifar10:0.2-instance | Epoch [ 61/ 75] Iter[351/1238]	  loss: 0.26cifar10:0.2-instance | Epoch [ 61/ 75] Iter[401/1238]	  loss: 0.21cifar10:0.2-instance | Epoch [ 61/ 75] Iter[451/1238]	  loss: 0.18cifar10:0.2-instance | Epoch [ 61/ 75] Iter[501/1238]	  loss: 0.19cifar10:0.2-instance | Epoch [ 61/ 75] Iter[551/1238]	  loss: 0.16cifar10:0.2-instance | Epoch [ 61/ 75] Iter[601/1238]	  loss: 0.17cifar10:0.2-instance | Epoch [ 61/ 75] Iter[651/1238]	  loss: 0.19cifar10:0.2-instance | Epoch [ 61/ 75] Iter[701/1238]	  loss: 0.16cifar10:0.2-instance | Epoch [ 61/ 75] Iter[751/1238]	  loss: 0.24cifar10:0.2-instance | Epoch [ 61/ 75] Iter[801/1238]	  loss: 0.32cifar10:0.2-instance | Epoch [ 61/ 75] Iter[851/1238]	  loss: 0.20cifar10:0.2-instance | Epoch [ 61/ 75] Iter[901/1238]	  loss: 0.18cifar10:0.2-instance | Epoch [ 61/ 75] Iter[951/1238]	  loss: 0.35cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1001/1238]	  loss: 0.18cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1051/1238]	  loss: 0.28cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1101/1238]	  loss: 0.28cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1151/1238]	  loss: 0.15cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1201/1238]	  loss: 0.18
| Test Epoch 61	 Accuracy: 91.35% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 62 | Accuracy on train set: 77.62% 
labeled data has a size of 39540, f-score: 0.983612
cifar10:0.2-instance | Epoch [ 62/ 75] Iter[  1/1236]	  loss: 0.29cifar10:0.2-instance | Epoch [ 62/ 75] Iter[ 51/1236]	  loss: 0.20cifar10:0.2-instance | Epoch [ 62/ 75] Iter[101/1236]	  loss: 0.24cifar10:0.2-instance | Epoch [ 62/ 75] Iter[151/1236]	  loss: 0.19cifar10:0.2-instance | Epoch [ 62/ 75] Iter[201/1236]	  loss: 0.20cifar10:0.2-instance | Epoch [ 62/ 75] Iter[251/1236]	  loss: 0.15cifar10:0.2-instance | Epoch [ 62/ 75] Iter[301/1236]	  loss: 0.30cifar10:0.2-instance | Epoch [ 62/ 75] Iter[351/1236]	  loss: 0.28cifar10:0.2-instance | Epoch [ 62/ 75] Iter[401/1236]	  loss: 0.17cifar10:0.2-instance | Epoch [ 62/ 75] Iter[451/1236]	  loss: 0.17cifar10:0.2-instance | Epoch [ 62/ 75] Iter[501/1236]	  loss: 0.20cifar10:0.2-instance | Epoch [ 62/ 75] Iter[551/1236]	  loss: 0.50cifar10:0.2-instance | Epoch [ 62/ 75] Iter[601/1236]	  loss: 0.23cifar10:0.2-instance | Epoch [ 62/ 75] Iter[651/1236]	  loss: 0.18cifar10:0.2-instance | Epoch [ 62/ 75] Iter[701/1236]	  loss: 0.23cifar10:0.2-instance | Epoch [ 62/ 75] Iter[751/1236]	  loss: 0.31cifar10:0.2-instance | Epoch [ 62/ 75] Iter[801/1236]	  loss: 0.18cifar10:0.2-instance | Epoch [ 62/ 75] Iter[851/1236]	  loss: 0.23cifar10:0.2-instance | Epoch [ 62/ 75] Iter[901/1236]	  loss: 0.27cifar10:0.2-instance | Epoch [ 62/ 75] Iter[951/1236]	  loss: 0.26cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1001/1236]	  loss: 0.36cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1051/1236]	  loss: 0.15cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1101/1236]	  loss: 0.28cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1151/1236]	  loss: 0.23cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1201/1236]	  loss: 0.16
| Test Epoch 62	 Accuracy: 91.13% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 63 | Accuracy on train set: 77.84% 
labeled data has a size of 39537, f-score: 0.984799
cifar10:0.2-instance | Epoch [ 63/ 75] Iter[  1/1236]	  loss: 0.22cifar10:0.2-instance | Epoch [ 63/ 75] Iter[ 51/1236]	  loss: 0.17cifar10:0.2-instance | Epoch [ 63/ 75] Iter[101/1236]	  loss: 0.19cifar10:0.2-instance | Epoch [ 63/ 75] Iter[151/1236]	  loss: 0.27cifar10:0.2-instance | Epoch [ 63/ 75] Iter[201/1236]	  loss: 0.16cifar10:0.2-instance | Epoch [ 63/ 75] Iter[251/1236]	  loss: 0.22cifar10:0.2-instance | Epoch [ 63/ 75] Iter[301/1236]	  loss: 0.26cifar10:0.2-instance | Epoch [ 63/ 75] Iter[351/1236]	  loss: 0.28cifar10:0.2-instance | Epoch [ 63/ 75] Iter[401/1236]	  loss: 0.23cifar10:0.2-instance | Epoch [ 63/ 75] Iter[451/1236]	  loss: 0.19cifar10:0.2-instance | Epoch [ 63/ 75] Iter[501/1236]	  loss: 0.20cifar10:0.2-instance | Epoch [ 63/ 75] Iter[551/1236]	  loss: 0.24cifar10:0.2-instance | Epoch [ 63/ 75] Iter[601/1236]	  loss: 0.29cifar10:0.2-instance | Epoch [ 63/ 75] Iter[651/1236]	  loss: 0.41cifar10:0.2-instance | Epoch [ 63/ 75] Iter[701/1236]	  loss: 0.21cifar10:0.2-instance | Epoch [ 63/ 75] Iter[751/1236]	  loss: 0.17cifar10:0.2-instance | Epoch [ 63/ 75] Iter[801/1236]	  loss: 0.16cifar10:0.2-instance | Epoch [ 63/ 75] Iter[851/1236]	  loss: 0.27cifar10:0.2-instance | Epoch [ 63/ 75] Iter[901/1236]	  loss: 0.16cifar10:0.2-instance | Epoch [ 63/ 75] Iter[951/1236]	  loss: 0.24cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1001/1236]	  loss: 0.35cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1051/1236]	  loss: 0.17cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1101/1236]	  loss: 0.15cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1151/1236]	  loss: 0.21cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1201/1236]	  loss: 0.21
| Test Epoch 63	 Accuracy: 91.52% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 64 | Accuracy on train set: 78.15% 
labeled data has a size of 39627, f-score: 0.984253
cifar10:0.2-instance | Epoch [ 64/ 75] Iter[  1/1239]	  loss: 0.18cifar10:0.2-instance | Epoch [ 64/ 75] Iter[ 51/1239]	  loss: 0.17cifar10:0.2-instance | Epoch [ 64/ 75] Iter[101/1239]	  loss: 0.17cifar10:0.2-instance | Epoch [ 64/ 75] Iter[151/1239]	  loss: 0.23cifar10:0.2-instance | Epoch [ 64/ 75] Iter[201/1239]	  loss: 0.22cifar10:0.2-instance | Epoch [ 64/ 75] Iter[251/1239]	  loss: 0.17cifar10:0.2-instance | Epoch [ 64/ 75] Iter[301/1239]	  loss: 0.23cifar10:0.2-instance | Epoch [ 64/ 75] Iter[351/1239]	  loss: 0.20cifar10:0.2-instance | Epoch [ 64/ 75] Iter[401/1239]	  loss: 0.27cifar10:0.2-instance | Epoch [ 64/ 75] Iter[451/1239]	  loss: 0.27cifar10:0.2-instance | Epoch [ 64/ 75] Iter[501/1239]	  loss: 0.22cifar10:0.2-instance | Epoch [ 64/ 75] Iter[551/1239]	  loss: 0.24cifar10:0.2-instance | Epoch [ 64/ 75] Iter[601/1239]	  loss: 0.25cifar10:0.2-instance | Epoch [ 64/ 75] Iter[651/1239]	  loss: 0.19cifar10:0.2-instance | Epoch [ 64/ 75] Iter[701/1239]	  loss: 0.20cifar10:0.2-instance | Epoch [ 64/ 75] Iter[751/1239]	  loss: 0.21cifar10:0.2-instance | Epoch [ 64/ 75] Iter[801/1239]	  loss: 0.19cifar10:0.2-instance | Epoch [ 64/ 75] Iter[851/1239]	  loss: 0.17cifar10:0.2-instance | Epoch [ 64/ 75] Iter[901/1239]	  loss: 0.21cifar10:0.2-instance | Epoch [ 64/ 75] Iter[951/1239]	  loss: 0.15cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1001/1239]	  loss: 0.18cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1051/1239]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1101/1239]	  loss: 0.15cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1151/1239]	  loss: 0.17cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1201/1239]	  loss: 0.19
| Test Epoch 64	 Accuracy: 91.71% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 65 | Accuracy on train set: 78.29% 
labeled data has a size of 39679, f-score: 0.983845
cifar10:0.2-instance | Epoch [ 65/ 75] Iter[  1/1240]	  loss: 0.21cifar10:0.2-instance | Epoch [ 65/ 75] Iter[ 51/1240]	  loss: 0.24cifar10:0.2-instance | Epoch [ 65/ 75] Iter[101/1240]	  loss: 0.20cifar10:0.2-instance | Epoch [ 65/ 75] Iter[151/1240]	  loss: 0.26cifar10:0.2-instance | Epoch [ 65/ 75] Iter[201/1240]	  loss: 0.18cifar10:0.2-instance | Epoch [ 65/ 75] Iter[251/1240]	  loss: 0.16cifar10:0.2-instance | Epoch [ 65/ 75] Iter[301/1240]	  loss: 0.20cifar10:0.2-instance | Epoch [ 65/ 75] Iter[351/1240]	  loss: 0.29cifar10:0.2-instance | Epoch [ 65/ 75] Iter[401/1240]	  loss: 0.23cifar10:0.2-instance | Epoch [ 65/ 75] Iter[451/1240]	  loss: 0.15cifar10:0.2-instance | Epoch [ 65/ 75] Iter[501/1240]	  loss: 0.17cifar10:0.2-instance | Epoch [ 65/ 75] Iter[551/1240]	  loss: 0.24cifar10:0.2-instance | Epoch [ 65/ 75] Iter[601/1240]	  loss: 0.25cifar10:0.2-instance | Epoch [ 65/ 75] Iter[651/1240]	  loss: 0.17cifar10:0.2-instance | Epoch [ 65/ 75] Iter[701/1240]	  loss: 0.17cifar10:0.2-instance | Epoch [ 65/ 75] Iter[751/1240]	  loss: 0.26cifar10:0.2-instance | Epoch [ 65/ 75] Iter[801/1240]	  loss: 0.18cifar10:0.2-instance | Epoch [ 65/ 75] Iter[851/1240]	  loss: 0.20cifar10:0.2-instance | Epoch [ 65/ 75] Iter[901/1240]	  loss: 0.20cifar10:0.2-instance | Epoch [ 65/ 75] Iter[951/1240]	  loss: 0.26cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1001/1240]	  loss: 0.37cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1051/1240]	  loss: 0.16cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1101/1240]	  loss: 0.20cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1151/1240]	  loss: 0.20cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1201/1240]	  loss: 0.25
| Test Epoch 65	 Accuracy: 92.05% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 66 | Accuracy on train set: 78.56% 
labeled data has a size of 39740, f-score: 0.983468
cifar10:0.2-instance | Epoch [ 66/ 75] Iter[  1/1242]	  loss: 0.24cifar10:0.2-instance | Epoch [ 66/ 75] Iter[ 51/1242]	  loss: 0.16cifar10:0.2-instance | Epoch [ 66/ 75] Iter[101/1242]	  loss: 0.29cifar10:0.2-instance | Epoch [ 66/ 75] Iter[151/1242]	  loss: 0.16cifar10:0.2-instance | Epoch [ 66/ 75] Iter[201/1242]	  loss: 0.18cifar10:0.2-instance | Epoch [ 66/ 75] Iter[251/1242]	  loss: 0.21cifar10:0.2-instance | Epoch [ 66/ 75] Iter[301/1242]	  loss: 0.23cifar10:0.2-instance | Epoch [ 66/ 75] Iter[351/1242]	  loss: 0.18cifar10:0.2-instance | Epoch [ 66/ 75] Iter[401/1242]	  loss: 0.24cifar10:0.2-instance | Epoch [ 66/ 75] Iter[451/1242]	  loss: 0.15cifar10:0.2-instance | Epoch [ 66/ 75] Iter[501/1242]	  loss: 0.32cifar10:0.2-instance | Epoch [ 66/ 75] Iter[551/1242]	  loss: 0.16cifar10:0.2-instance | Epoch [ 66/ 75] Iter[601/1242]	  loss: 0.19cifar10:0.2-instance | Epoch [ 66/ 75] Iter[651/1242]	  loss: 0.15cifar10:0.2-instance | Epoch [ 66/ 75] Iter[701/1242]	  loss: 0.22cifar10:0.2-instance | Epoch [ 66/ 75] Iter[751/1242]	  loss: 0.17cifar10:0.2-instance | Epoch [ 66/ 75] Iter[801/1242]	  loss: 0.24cifar10:0.2-instance | Epoch [ 66/ 75] Iter[851/1242]	  loss: 0.22cifar10:0.2-instance | Epoch [ 66/ 75] Iter[901/1242]	  loss: 0.28cifar10:0.2-instance | Epoch [ 66/ 75] Iter[951/1242]	  loss: 0.16cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1001/1242]	  loss: 0.18cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1051/1242]	  loss: 0.31cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1101/1242]	  loss: 0.19cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1151/1242]	  loss: 0.23cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1201/1242]	  loss: 0.22
| Test Epoch 66	 Accuracy: 92.21% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 67 | Accuracy on train set: 78.59% 
labeled data has a size of 39765, f-score: 0.983478
cifar10:0.2-instance | Epoch [ 67/ 75] Iter[  1/1243]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[ 51/1243]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[101/1243]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[151/1243]	  loss: 0.18cifar10:0.2-instance | Epoch [ 67/ 75] Iter[201/1243]	  loss: 0.34cifar10:0.2-instance | Epoch [ 67/ 75] Iter[251/1243]	  loss: 0.15cifar10:0.2-instance | Epoch [ 67/ 75] Iter[301/1243]	  loss: 0.19cifar10:0.2-instance | Epoch [ 67/ 75] Iter[351/1243]	  loss: 0.18cifar10:0.2-instance | Epoch [ 67/ 75] Iter[401/1243]	  loss: 0.30cifar10:0.2-instance | Epoch [ 67/ 75] Iter[451/1243]	  loss: 0.26cifar10:0.2-instance | Epoch [ 67/ 75] Iter[501/1243]	  loss: 0.18cifar10:0.2-instance | Epoch [ 67/ 75] Iter[551/1243]	  loss: 0.23cifar10:0.2-instance | Epoch [ 67/ 75] Iter[601/1243]	  loss: 0.18cifar10:0.2-instance | Epoch [ 67/ 75] Iter[651/1243]	  loss: 0.26cifar10:0.2-instance | Epoch [ 67/ 75] Iter[701/1243]	  loss: 0.17cifar10:0.2-instance | Epoch [ 67/ 75] Iter[751/1243]	  loss: 0.17cifar10:0.2-instance | Epoch [ 67/ 75] Iter[801/1243]	  loss: 0.17cifar10:0.2-instance | Epoch [ 67/ 75] Iter[851/1243]	  loss: 0.18cifar10:0.2-instance | Epoch [ 67/ 75] Iter[901/1243]	  loss: 0.17cifar10:0.2-instance | Epoch [ 67/ 75] Iter[951/1243]	  loss: 0.17cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1001/1243]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1051/1243]	  loss: 0.20cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1101/1243]	  loss: 0.38cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1151/1243]	  loss: 0.27cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1201/1243]	  loss: 0.29
| Test Epoch 67	 Accuracy: 92.06% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 68 | Accuracy on train set: 78.81% 
labeled data has a size of 39820, f-score: 0.983099
cifar10:0.2-instance | Epoch [ 68/ 75] Iter[  1/1245]	  loss: 0.17cifar10:0.2-instance | Epoch [ 68/ 75] Iter[ 51/1245]	  loss: 0.30cifar10:0.2-instance | Epoch [ 68/ 75] Iter[101/1245]	  loss: 0.18cifar10:0.2-instance | Epoch [ 68/ 75] Iter[151/1245]	  loss: 0.21cifar10:0.2-instance | Epoch [ 68/ 75] Iter[201/1245]	  loss: 0.16cifar10:0.2-instance | Epoch [ 68/ 75] Iter[251/1245]	  loss: 0.17cifar10:0.2-instance | Epoch [ 68/ 75] Iter[301/1245]	  loss: 0.16cifar10:0.2-instance | Epoch [ 68/ 75] Iter[351/1245]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[401/1245]	  loss: 0.41cifar10:0.2-instance | Epoch [ 68/ 75] Iter[451/1245]	  loss: 0.19cifar10:0.2-instance | Epoch [ 68/ 75] Iter[501/1245]	  loss: 0.17cifar10:0.2-instance | Epoch [ 68/ 75] Iter[551/1245]	  loss: 0.35cifar10:0.2-instance | Epoch [ 68/ 75] Iter[601/1245]	  loss: 0.26cifar10:0.2-instance | Epoch [ 68/ 75] Iter[651/1245]	  loss: 0.21cifar10:0.2-instance | Epoch [ 68/ 75] Iter[701/1245]	  loss: 0.23cifar10:0.2-instance | Epoch [ 68/ 75] Iter[751/1245]	  loss: 0.17cifar10:0.2-instance | Epoch [ 68/ 75] Iter[801/1245]	  loss: 0.16cifar10:0.2-instance | Epoch [ 68/ 75] Iter[851/1245]	  loss: 0.20cifar10:0.2-instance | Epoch [ 68/ 75] Iter[901/1245]	  loss: 0.22cifar10:0.2-instance | Epoch [ 68/ 75] Iter[951/1245]	  loss: 0.18cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1001/1245]	  loss: 0.24cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1051/1245]	  loss: 0.17cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1101/1245]	  loss: 0.21cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1151/1245]	  loss: 0.26cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1201/1245]	  loss: 0.30
| Test Epoch 68	 Accuracy: 91.94% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 69 | Accuracy on train set: 78.96% 
labeled data has a size of 39840, f-score: 0.983107
cifar10:0.2-instance | Epoch [ 69/ 75] Iter[  1/1246]	  loss: 0.31cifar10:0.2-instance | Epoch [ 69/ 75] Iter[ 51/1246]	  loss: 0.16cifar10:0.2-instance | Epoch [ 69/ 75] Iter[101/1246]	  loss: 0.22cifar10:0.2-instance | Epoch [ 69/ 75] Iter[151/1246]	  loss: 0.17cifar10:0.2-instance | Epoch [ 69/ 75] Iter[201/1246]	  loss: 0.22cifar10:0.2-instance | Epoch [ 69/ 75] Iter[251/1246]	  loss: 0.20cifar10:0.2-instance | Epoch [ 69/ 75] Iter[301/1246]	  loss: 0.16cifar10:0.2-instance | Epoch [ 69/ 75] Iter[351/1246]	  loss: 0.28cifar10:0.2-instance | Epoch [ 69/ 75] Iter[401/1246]	  loss: 0.25cifar10:0.2-instance | Epoch [ 69/ 75] Iter[451/1246]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[501/1246]	  loss: 0.21cifar10:0.2-instance | Epoch [ 69/ 75] Iter[551/1246]	  loss: 0.16cifar10:0.2-instance | Epoch [ 69/ 75] Iter[601/1246]	  loss: 0.17cifar10:0.2-instance | Epoch [ 69/ 75] Iter[651/1246]	  loss: 0.17cifar10:0.2-instance | Epoch [ 69/ 75] Iter[701/1246]	  loss: 0.17cifar10:0.2-instance | Epoch [ 69/ 75] Iter[751/1246]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[801/1246]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[851/1246]	  loss: 0.19cifar10:0.2-instance | Epoch [ 69/ 75] Iter[901/1246]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[951/1246]	  loss: 0.17cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1001/1246]	  loss: 0.16cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1051/1246]	  loss: 0.22cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1101/1246]	  loss: 0.16cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1151/1246]	  loss: 0.18cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1201/1246]	  loss: 0.17
| Test Epoch 69	 Accuracy: 91.65% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 70 | Accuracy on train set: 79.05% 
labeled data has a size of 39886, f-score: 0.982325
cifar10:0.2-instance | Epoch [ 70/ 75] Iter[  1/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[ 51/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[101/1247]	  loss: 0.18cifar10:0.2-instance | Epoch [ 70/ 75] Iter[151/1247]	  loss: 0.28cifar10:0.2-instance | Epoch [ 70/ 75] Iter[201/1247]	  loss: 0.29cifar10:0.2-instance | Epoch [ 70/ 75] Iter[251/1247]	  loss: 0.22cifar10:0.2-instance | Epoch [ 70/ 75] Iter[301/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[351/1247]	  loss: 0.28cifar10:0.2-instance | Epoch [ 70/ 75] Iter[401/1247]	  loss: 0.37cifar10:0.2-instance | Epoch [ 70/ 75] Iter[451/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[501/1247]	  loss: 0.21cifar10:0.2-instance | Epoch [ 70/ 75] Iter[551/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[601/1247]	  loss: 0.18cifar10:0.2-instance | Epoch [ 70/ 75] Iter[651/1247]	  loss: 0.17cifar10:0.2-instance | Epoch [ 70/ 75] Iter[701/1247]	  loss: 0.22cifar10:0.2-instance | Epoch [ 70/ 75] Iter[751/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[801/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[851/1247]	  loss: 0.20cifar10:0.2-instance | Epoch [ 70/ 75] Iter[901/1247]	  loss: 0.19cifar10:0.2-instance | Epoch [ 70/ 75] Iter[951/1247]	  loss: 0.27cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1001/1247]	  loss: 0.19cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1051/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1101/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1151/1247]	  loss: 0.20cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1201/1247]	  loss: 0.16
| Test Epoch 70	 Accuracy: 91.73% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 71 | Accuracy on train set: 79.12% 
labeled data has a size of 39910, f-score: 0.982160
cifar10:0.2-instance | Epoch [ 71/ 75] Iter[  1/1248]	  loss: 0.19cifar10:0.2-instance | Epoch [ 71/ 75] Iter[ 51/1248]	  loss: 0.20cifar10:0.2-instance | Epoch [ 71/ 75] Iter[101/1248]	  loss: 0.25cifar10:0.2-instance | Epoch [ 71/ 75] Iter[151/1248]	  loss: 0.18cifar10:0.2-instance | Epoch [ 71/ 75] Iter[201/1248]	  loss: 0.21cifar10:0.2-instance | Epoch [ 71/ 75] Iter[251/1248]	  loss: 0.22cifar10:0.2-instance | Epoch [ 71/ 75] Iter[301/1248]	  loss: 0.19cifar10:0.2-instance | Epoch [ 71/ 75] Iter[351/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[401/1248]	  loss: 0.25cifar10:0.2-instance | Epoch [ 71/ 75] Iter[451/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[501/1248]	  loss: 0.18cifar10:0.2-instance | Epoch [ 71/ 75] Iter[551/1248]	  loss: 0.23cifar10:0.2-instance | Epoch [ 71/ 75] Iter[601/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[651/1248]	  loss: 0.17cifar10:0.2-instance | Epoch [ 71/ 75] Iter[701/1248]	  loss: 0.19cifar10:0.2-instance | Epoch [ 71/ 75] Iter[751/1248]	  loss: 0.19cifar10:0.2-instance | Epoch [ 71/ 75] Iter[801/1248]	  loss: 0.17cifar10:0.2-instance | Epoch [ 71/ 75] Iter[851/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[901/1248]	  loss: 0.25cifar10:0.2-instance | Epoch [ 71/ 75] Iter[951/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1001/1248]	  loss: 0.17cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1051/1248]	  loss: 0.31cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1101/1248]	  loss: 0.20cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1151/1248]	  loss: 0.30cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1201/1248]	  loss: 0.30
| Test Epoch 71	 Accuracy: 91.82% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 72 | Accuracy on train set: 79.21% 
labeled data has a size of 39960, f-score: 0.981907
cifar10:0.2-instance | Epoch [ 72/ 75] Iter[  1/1249]	  loss: 0.21cifar10:0.2-instance | Epoch [ 72/ 75] Iter[ 51/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[101/1249]	  loss: 0.20cifar10:0.2-instance | Epoch [ 72/ 75] Iter[151/1249]	  loss: 0.20cifar10:0.2-instance | Epoch [ 72/ 75] Iter[201/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[251/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[301/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[351/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[401/1249]	  loss: 0.30cifar10:0.2-instance | Epoch [ 72/ 75] Iter[451/1249]	  loss: 0.18cifar10:0.2-instance | Epoch [ 72/ 75] Iter[501/1249]	  loss: 0.17cifar10:0.2-instance | Epoch [ 72/ 75] Iter[551/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[601/1249]	  loss: 0.17cifar10:0.2-instance | Epoch [ 72/ 75] Iter[651/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[701/1249]	  loss: 0.18cifar10:0.2-instance | Epoch [ 72/ 75] Iter[751/1249]	  loss: 0.17cifar10:0.2-instance | Epoch [ 72/ 75] Iter[801/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[851/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[901/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[951/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1001/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1051/1249]	  loss: 0.23cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1101/1249]	  loss: 0.28cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1151/1249]	  loss: 0.23cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1201/1249]	  loss: 0.27
| Test Epoch 72	 Accuracy: 92.14% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 73 | Accuracy on train set: 79.42% 
labeled data has a size of 39977, f-score: 0.981865
cifar10:0.2-instance | Epoch [ 73/ 75] Iter[  1/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[ 51/1250]	  loss: 0.21cifar10:0.2-instance | Epoch [ 73/ 75] Iter[101/1250]	  loss: 0.19cifar10:0.2-instance | Epoch [ 73/ 75] Iter[151/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[201/1250]	  loss: 0.25cifar10:0.2-instance | Epoch [ 73/ 75] Iter[251/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[301/1250]	  loss: 0.17cifar10:0.2-instance | Epoch [ 73/ 75] Iter[351/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[401/1250]	  loss: 0.26cifar10:0.2-instance | Epoch [ 73/ 75] Iter[451/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[501/1250]	  loss: 0.20cifar10:0.2-instance | Epoch [ 73/ 75] Iter[551/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[601/1250]	  loss: 0.23cifar10:0.2-instance | Epoch [ 73/ 75] Iter[651/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[701/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[751/1250]	  loss: 0.14cifar10:0.2-instance | Epoch [ 73/ 75] Iter[801/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[851/1250]	  loss: 0.21cifar10:0.2-instance | Epoch [ 73/ 75] Iter[901/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[951/1250]	  loss: 0.18cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1001/1250]	  loss: 0.18cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1051/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1101/1250]	  loss: 0.34cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1151/1250]	  loss: 0.19cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1201/1250]	  loss: 0.19
| Test Epoch 73	 Accuracy: 91.73% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 74 | Accuracy on train set: 79.37% 
labeled data has a size of 40010, f-score: 0.981405
cifar10:0.2-instance | Epoch [ 74/ 75] Iter[  1/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[ 51/1251]	  loss: 0.23cifar10:0.2-instance | Epoch [ 74/ 75] Iter[101/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[151/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[201/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[251/1251]	  loss: 0.33cifar10:0.2-instance | Epoch [ 74/ 75] Iter[301/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[351/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[401/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[451/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[501/1251]	  loss: 0.22cifar10:0.2-instance | Epoch [ 74/ 75] Iter[551/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[601/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[651/1251]	  loss: 0.28cifar10:0.2-instance | Epoch [ 74/ 75] Iter[701/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[751/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[801/1251]	  loss: 0.21cifar10:0.2-instance | Epoch [ 74/ 75] Iter[851/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[901/1251]	  loss: 0.17cifar10:0.2-instance | Epoch [ 74/ 75] Iter[951/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1001/1251]	  loss: 0.33cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1051/1251]	  loss: 0.17cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1101/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1151/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1201/1251]	  loss: 0.23cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1251/1251]	  loss: 0.15
| Test Epoch 74	 Accuracy: 91.86% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 75 | Accuracy on train set: 79.51% 
labeled data has a size of 40033, f-score: 0.981116
cifar10:0.2-instance | Epoch [ 75/ 75] Iter[  1/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[ 51/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[101/1252]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[151/1252]	  loss: 0.21cifar10:0.2-instance | Epoch [ 75/ 75] Iter[201/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[251/1252]	  loss: 0.17cifar10:0.2-instance | Epoch [ 75/ 75] Iter[301/1252]	  loss: 0.22cifar10:0.2-instance | Epoch [ 75/ 75] Iter[351/1252]	  loss: 0.18cifar10:0.2-instance | Epoch [ 75/ 75] Iter[401/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[451/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[501/1252]	  loss: 0.17cifar10:0.2-instance | Epoch [ 75/ 75] Iter[551/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[601/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[651/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[701/1252]	  loss: 0.23cifar10:0.2-instance | Epoch [ 75/ 75] Iter[751/1252]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[801/1252]	  loss: 0.20cifar10:0.2-instance | Epoch [ 75/ 75] Iter[851/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[901/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[951/1252]	  loss: 0.17cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1001/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1051/1252]	  loss: 0.20cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1101/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1151/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1201/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1251/1252]	  loss: 0.15
| Test Epoch 75	 Accuracy: 91.92% 



best test Acc:  92.21
