Namespace(T=0.2, batch_size=32, data_path='./dataset2/cifar10', dataset='cifar10', fig_7=0, fluctuation_ablation=0, gpuid=0, k=3, lr=0.02, model='resnet18', noise_mode='instance', num_class=10, num_epochs=75, r=0.4, save_sel_sam=0, seed_model=5, seed_noise=1, semi='no', warm_up=10, wdecay=0.0005, without_Lcr=0, without_R=0)
============ Initialize data
============ Actual clean samples number:  30098
============ use resnet18 
============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 0 | Accuracy on train set: 6.42% 
cifar10:0.4-instance | Epoch [  0/ 75] Iter[  1/391]	 CE-loss: 2.4313cifar10:0.4-instance | Epoch [  0/ 75] Iter[ 51/391]	 CE-loss: 1.9408cifar10:0.4-instance | Epoch [  0/ 75] Iter[101/391]	 CE-loss: 1.9645cifar10:0.4-instance | Epoch [  0/ 75] Iter[151/391]	 CE-loss: 2.1174cifar10:0.4-instance | Epoch [  0/ 75] Iter[201/391]	 CE-loss: 1.7062cifar10:0.4-instance | Epoch [  0/ 75] Iter[251/391]	 CE-loss: 1.9090cifar10:0.4-instance | Epoch [  0/ 75] Iter[301/391]	 CE-loss: 1.7602cifar10:0.4-instance | Epoch [  0/ 75] Iter[351/391]	 CE-loss: 1.8456
| Test Epoch 0	 Accuracy: 35.64% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 1 | Accuracy on train set: 29.79% 
cifar10:0.4-instance | Epoch [  1/ 75] Iter[  1/391]	 CE-loss: 1.7465cifar10:0.4-instance | Epoch [  1/ 75] Iter[ 51/391]	 CE-loss: 1.7767cifar10:0.4-instance | Epoch [  1/ 75] Iter[101/391]	 CE-loss: 1.7702cifar10:0.4-instance | Epoch [  1/ 75] Iter[151/391]	 CE-loss: 1.7048cifar10:0.4-instance | Epoch [  1/ 75] Iter[201/391]	 CE-loss: 1.7971cifar10:0.4-instance | Epoch [  1/ 75] Iter[251/391]	 CE-loss: 1.5159cifar10:0.4-instance | Epoch [  1/ 75] Iter[301/391]	 CE-loss: 1.6275cifar10:0.4-instance | Epoch [  1/ 75] Iter[351/391]	 CE-loss: 1.5632
| Test Epoch 1	 Accuracy: 49.82% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 2 | Accuracy on train set: 36.51% 
cifar10:0.4-instance | Epoch [  2/ 75] Iter[  1/391]	 CE-loss: 1.5559cifar10:0.4-instance | Epoch [  2/ 75] Iter[ 51/391]	 CE-loss: 1.6332cifar10:0.4-instance | Epoch [  2/ 75] Iter[101/391]	 CE-loss: 1.5194cifar10:0.4-instance | Epoch [  2/ 75] Iter[151/391]	 CE-loss: 1.6574cifar10:0.4-instance | Epoch [  2/ 75] Iter[201/391]	 CE-loss: 1.6476cifar10:0.4-instance | Epoch [  2/ 75] Iter[251/391]	 CE-loss: 1.4966cifar10:0.4-instance | Epoch [  2/ 75] Iter[301/391]	 CE-loss: 1.5005cifar10:0.4-instance | Epoch [  2/ 75] Iter[351/391]	 CE-loss: 1.5023
| Test Epoch 2	 Accuracy: 54.25% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 3 | Accuracy on train set: 40.52% 
cifar10:0.4-instance | Epoch [  3/ 75] Iter[  1/391]	 CE-loss: 1.4035cifar10:0.4-instance | Epoch [  3/ 75] Iter[ 51/391]	 CE-loss: 1.5001cifar10:0.4-instance | Epoch [  3/ 75] Iter[101/391]	 CE-loss: 1.4333cifar10:0.4-instance | Epoch [  3/ 75] Iter[151/391]	 CE-loss: 1.5372cifar10:0.4-instance | Epoch [  3/ 75] Iter[201/391]	 CE-loss: 1.4488cifar10:0.4-instance | Epoch [  3/ 75] Iter[251/391]	 CE-loss: 1.5049cifar10:0.4-instance | Epoch [  3/ 75] Iter[301/391]	 CE-loss: 1.4478cifar10:0.4-instance | Epoch [  3/ 75] Iter[351/391]	 CE-loss: 1.4563
| Test Epoch 3	 Accuracy: 61.15% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 4 | Accuracy on train set: 44.52% 
cifar10:0.4-instance | Epoch [  4/ 75] Iter[  1/391]	 CE-loss: 1.5851cifar10:0.4-instance | Epoch [  4/ 75] Iter[ 51/391]	 CE-loss: 1.6438cifar10:0.4-instance | Epoch [  4/ 75] Iter[101/391]	 CE-loss: 1.3988cifar10:0.4-instance | Epoch [  4/ 75] Iter[151/391]	 CE-loss: 1.4788cifar10:0.4-instance | Epoch [  4/ 75] Iter[201/391]	 CE-loss: 1.4474cifar10:0.4-instance | Epoch [  4/ 75] Iter[251/391]	 CE-loss: 1.2854cifar10:0.4-instance | Epoch [  4/ 75] Iter[301/391]	 CE-loss: 1.4200cifar10:0.4-instance | Epoch [  4/ 75] Iter[351/391]	 CE-loss: 1.4403
| Test Epoch 4	 Accuracy: 67.55% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 5 | Accuracy on train set: 45.28% 
cifar10:0.4-instance | Epoch [  5/ 75] Iter[  1/391]	 CE-loss: 1.4878cifar10:0.4-instance | Epoch [  5/ 75] Iter[ 51/391]	 CE-loss: 1.3663cifar10:0.4-instance | Epoch [  5/ 75] Iter[101/391]	 CE-loss: 1.4904cifar10:0.4-instance | Epoch [  5/ 75] Iter[151/391]	 CE-loss: 1.5380cifar10:0.4-instance | Epoch [  5/ 75] Iter[201/391]	 CE-loss: 1.2765cifar10:0.4-instance | Epoch [  5/ 75] Iter[251/391]	 CE-loss: 1.4943cifar10:0.4-instance | Epoch [  5/ 75] Iter[301/391]	 CE-loss: 1.4964cifar10:0.4-instance | Epoch [  5/ 75] Iter[351/391]	 CE-loss: 1.4376
| Test Epoch 5	 Accuracy: 69.55% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 6 | Accuracy on train set: 47.56% 
cifar10:0.4-instance | Epoch [  6/ 75] Iter[  1/391]	 CE-loss: 1.4603cifar10:0.4-instance | Epoch [  6/ 75] Iter[ 51/391]	 CE-loss: 1.3043cifar10:0.4-instance | Epoch [  6/ 75] Iter[101/391]	 CE-loss: 1.3145cifar10:0.4-instance | Epoch [  6/ 75] Iter[151/391]	 CE-loss: 1.4964cifar10:0.4-instance | Epoch [  6/ 75] Iter[201/391]	 CE-loss: 1.2239cifar10:0.4-instance | Epoch [  6/ 75] Iter[251/391]	 CE-loss: 1.3642cifar10:0.4-instance | Epoch [  6/ 75] Iter[301/391]	 CE-loss: 1.2313cifar10:0.4-instance | Epoch [  6/ 75] Iter[351/391]	 CE-loss: 1.3130
| Test Epoch 6	 Accuracy: 68.12% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 7 | Accuracy on train set: 46.40% 
cifar10:0.4-instance | Epoch [  7/ 75] Iter[  1/391]	 CE-loss: 1.3899cifar10:0.4-instance | Epoch [  7/ 75] Iter[ 51/391]	 CE-loss: 1.2453cifar10:0.4-instance | Epoch [  7/ 75] Iter[101/391]	 CE-loss: 1.2703cifar10:0.4-instance | Epoch [  7/ 75] Iter[151/391]	 CE-loss: 1.2770cifar10:0.4-instance | Epoch [  7/ 75] Iter[201/391]	 CE-loss: 1.3706cifar10:0.4-instance | Epoch [  7/ 75] Iter[251/391]	 CE-loss: 1.2625cifar10:0.4-instance | Epoch [  7/ 75] Iter[301/391]	 CE-loss: 1.3894cifar10:0.4-instance | Epoch [  7/ 75] Iter[351/391]	 CE-loss: 1.2073
| Test Epoch 7	 Accuracy: 70.32% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 8 | Accuracy on train set: 49.00% 
cifar10:0.4-instance | Epoch [  8/ 75] Iter[  1/391]	 CE-loss: 1.1522cifar10:0.4-instance | Epoch [  8/ 75] Iter[ 51/391]	 CE-loss: 1.1730cifar10:0.4-instance | Epoch [  8/ 75] Iter[101/391]	 CE-loss: 1.2432cifar10:0.4-instance | Epoch [  8/ 75] Iter[151/391]	 CE-loss: 1.2510cifar10:0.4-instance | Epoch [  8/ 75] Iter[201/391]	 CE-loss: 1.4418cifar10:0.4-instance | Epoch [  8/ 75] Iter[251/391]	 CE-loss: 1.2717cifar10:0.4-instance | Epoch [  8/ 75] Iter[301/391]	 CE-loss: 1.2632cifar10:0.4-instance | Epoch [  8/ 75] Iter[351/391]	 CE-loss: 1.2151
| Test Epoch 8	 Accuracy: 75.45% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 9 | Accuracy on train set: 50.97% 
cifar10:0.4-instance | Epoch [  9/ 75] Iter[  1/391]	 CE-loss: 1.2285cifar10:0.4-instance | Epoch [  9/ 75] Iter[ 51/391]	 CE-loss: 1.2659cifar10:0.4-instance | Epoch [  9/ 75] Iter[101/391]	 CE-loss: 1.2324cifar10:0.4-instance | Epoch [  9/ 75] Iter[151/391]	 CE-loss: 1.3553cifar10:0.4-instance | Epoch [  9/ 75] Iter[201/391]	 CE-loss: 1.2212cifar10:0.4-instance | Epoch [  9/ 75] Iter[251/391]	 CE-loss: 1.4153cifar10:0.4-instance | Epoch [  9/ 75] Iter[301/391]	 CE-loss: 1.1606cifar10:0.4-instance | Epoch [  9/ 75] Iter[351/391]	 CE-loss: 1.1487
| Test Epoch 9	 Accuracy: 68.71% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 10 | Accuracy on train set: 49.22% 
labeled data has a size of 31673, f-score: 0.838853
cifar10:0.4-instance | Epoch [ 10/ 75] Iter[  1/990]	  loss: 0.99cifar10:0.4-instance | Epoch [ 10/ 75] Iter[ 51/990]	  loss: 1.05cifar10:0.4-instance | Epoch [ 10/ 75] Iter[101/990]	  loss: 1.05cifar10:0.4-instance | Epoch [ 10/ 75] Iter[151/990]	  loss: 1.08cifar10:0.4-instance | Epoch [ 10/ 75] Iter[201/990]	  loss: 1.10cifar10:0.4-instance | Epoch [ 10/ 75] Iter[251/990]	  loss: 1.14cifar10:0.4-instance | Epoch [ 10/ 75] Iter[301/990]	  loss: 1.01cifar10:0.4-instance | Epoch [ 10/ 75] Iter[351/990]	  loss: 0.94cifar10:0.4-instance | Epoch [ 10/ 75] Iter[401/990]	  loss: 0.67cifar10:0.4-instance | Epoch [ 10/ 75] Iter[451/990]	  loss: 0.88cifar10:0.4-instance | Epoch [ 10/ 75] Iter[501/990]	  loss: 0.73cifar10:0.4-instance | Epoch [ 10/ 75] Iter[551/990]	  loss: 0.86cifar10:0.4-instance | Epoch [ 10/ 75] Iter[601/990]	  loss: 0.84cifar10:0.4-instance | Epoch [ 10/ 75] Iter[651/990]	  loss: 1.26cifar10:0.4-instance | Epoch [ 10/ 75] Iter[701/990]	  loss: 0.70cifar10:0.4-instance | Epoch [ 10/ 75] Iter[751/990]	  loss: 0.81cifar10:0.4-instance | Epoch [ 10/ 75] Iter[801/990]	  loss: 0.60cifar10:0.4-instance | Epoch [ 10/ 75] Iter[851/990]	  loss: 1.09cifar10:0.4-instance | Epoch [ 10/ 75] Iter[901/990]	  loss: 1.12cifar10:0.4-instance | Epoch [ 10/ 75] Iter[951/990]	  loss: 0.61
| Test Epoch 10	 Accuracy: 72.72% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 11 | Accuracy on train set: 47.78% 
labeled data has a size of 31220, f-score: 0.856951
cifar10:0.4-instance | Epoch [ 11/ 75] Iter[  1/976]	  loss: 0.64cifar10:0.4-instance | Epoch [ 11/ 75] Iter[ 51/976]	  loss: 0.74cifar10:0.4-instance | Epoch [ 11/ 75] Iter[101/976]	  loss: 1.03cifar10:0.4-instance | Epoch [ 11/ 75] Iter[151/976]	  loss: 0.54cifar10:0.4-instance | Epoch [ 11/ 75] Iter[201/976]	  loss: 0.69cifar10:0.4-instance | Epoch [ 11/ 75] Iter[251/976]	  loss: 0.55cifar10:0.4-instance | Epoch [ 11/ 75] Iter[301/976]	  loss: 0.74cifar10:0.4-instance | Epoch [ 11/ 75] Iter[351/976]	  loss: 0.70cifar10:0.4-instance | Epoch [ 11/ 75] Iter[401/976]	  loss: 0.65cifar10:0.4-instance | Epoch [ 11/ 75] Iter[451/976]	  loss: 0.55cifar10:0.4-instance | Epoch [ 11/ 75] Iter[501/976]	  loss: 0.68cifar10:0.4-instance | Epoch [ 11/ 75] Iter[551/976]	  loss: 0.87cifar10:0.4-instance | Epoch [ 11/ 75] Iter[601/976]	  loss: 0.56cifar10:0.4-instance | Epoch [ 11/ 75] Iter[651/976]	  loss: 0.85cifar10:0.4-instance | Epoch [ 11/ 75] Iter[701/976]	  loss: 0.91cifar10:0.4-instance | Epoch [ 11/ 75] Iter[751/976]	  loss: 1.30cifar10:0.4-instance | Epoch [ 11/ 75] Iter[801/976]	  loss: 0.50cifar10:0.4-instance | Epoch [ 11/ 75] Iter[851/976]	  loss: 0.67cifar10:0.4-instance | Epoch [ 11/ 75] Iter[901/976]	  loss: 0.64cifar10:0.4-instance | Epoch [ 11/ 75] Iter[951/976]	  loss: 0.82
| Test Epoch 11	 Accuracy: 69.29% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 12 | Accuracy on train set: 46.71% 
labeled data has a size of 31160, f-score: 0.850706
cifar10:0.4-instance | Epoch [ 12/ 75] Iter[  1/974]	  loss: 0.71cifar10:0.4-instance | Epoch [ 12/ 75] Iter[ 51/974]	  loss: 0.82cifar10:0.4-instance | Epoch [ 12/ 75] Iter[101/974]	  loss: 0.63cifar10:0.4-instance | Epoch [ 12/ 75] Iter[151/974]	  loss: 0.69cifar10:0.4-instance | Epoch [ 12/ 75] Iter[201/974]	  loss: 0.79cifar10:0.4-instance | Epoch [ 12/ 75] Iter[251/974]	  loss: 1.07cifar10:0.4-instance | Epoch [ 12/ 75] Iter[301/974]	  loss: 0.68cifar10:0.4-instance | Epoch [ 12/ 75] Iter[351/974]	  loss: 0.88cifar10:0.4-instance | Epoch [ 12/ 75] Iter[401/974]	  loss: 0.75cifar10:0.4-instance | Epoch [ 12/ 75] Iter[451/974]	  loss: 0.87cifar10:0.4-instance | Epoch [ 12/ 75] Iter[501/974]	  loss: 0.89cifar10:0.4-instance | Epoch [ 12/ 75] Iter[551/974]	  loss: 0.68cifar10:0.4-instance | Epoch [ 12/ 75] Iter[601/974]	  loss: 0.93cifar10:0.4-instance | Epoch [ 12/ 75] Iter[651/974]	  loss: 1.16cifar10:0.4-instance | Epoch [ 12/ 75] Iter[701/974]	  loss: 0.69cifar10:0.4-instance | Epoch [ 12/ 75] Iter[751/974]	  loss: 0.47cifar10:0.4-instance | Epoch [ 12/ 75] Iter[801/974]	  loss: 0.62cifar10:0.4-instance | Epoch [ 12/ 75] Iter[851/974]	  loss: 0.69cifar10:0.4-instance | Epoch [ 12/ 75] Iter[901/974]	  loss: 0.58cifar10:0.4-instance | Epoch [ 12/ 75] Iter[951/974]	  loss: 0.79
| Test Epoch 12	 Accuracy: 77.01% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 13 | Accuracy on train set: 50.70% 
labeled data has a size of 30191, f-score: 0.890033
cifar10:0.4-instance | Epoch [ 13/ 75] Iter[  1/944]	  loss: 0.55cifar10:0.4-instance | Epoch [ 13/ 75] Iter[ 51/944]	  loss: 0.88cifar10:0.4-instance | Epoch [ 13/ 75] Iter[101/944]	  loss: 0.69cifar10:0.4-instance | Epoch [ 13/ 75] Iter[151/944]	  loss: 0.65cifar10:0.4-instance | Epoch [ 13/ 75] Iter[201/944]	  loss: 0.52cifar10:0.4-instance | Epoch [ 13/ 75] Iter[251/944]	  loss: 0.74cifar10:0.4-instance | Epoch [ 13/ 75] Iter[301/944]	  loss: 0.83cifar10:0.4-instance | Epoch [ 13/ 75] Iter[351/944]	  loss: 0.69cifar10:0.4-instance | Epoch [ 13/ 75] Iter[401/944]	  loss: 0.61cifar10:0.4-instance | Epoch [ 13/ 75] Iter[451/944]	  loss: 0.79cifar10:0.4-instance | Epoch [ 13/ 75] Iter[501/944]	  loss: 0.82cifar10:0.4-instance | Epoch [ 13/ 75] Iter[551/944]	  loss: 0.65cifar10:0.4-instance | Epoch [ 13/ 75] Iter[601/944]	  loss: 0.86cifar10:0.4-instance | Epoch [ 13/ 75] Iter[651/944]	  loss: 0.51cifar10:0.4-instance | Epoch [ 13/ 75] Iter[701/944]	  loss: 0.79cifar10:0.4-instance | Epoch [ 13/ 75] Iter[751/944]	  loss: 0.55cifar10:0.4-instance | Epoch [ 13/ 75] Iter[801/944]	  loss: 0.72cifar10:0.4-instance | Epoch [ 13/ 75] Iter[851/944]	  loss: 0.53cifar10:0.4-instance | Epoch [ 13/ 75] Iter[901/944]	  loss: 0.73
| Test Epoch 13	 Accuracy: 76.76% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 14 | Accuracy on train set: 51.28% 
labeled data has a size of 29632, f-score: 0.896126
cifar10:0.4-instance | Epoch [ 14/ 75] Iter[  1/927]	  loss: 0.46cifar10:0.4-instance | Epoch [ 14/ 75] Iter[ 51/927]	  loss: 0.48cifar10:0.4-instance | Epoch [ 14/ 75] Iter[101/927]	  loss: 0.53cifar10:0.4-instance | Epoch [ 14/ 75] Iter[151/927]	  loss: 0.53cifar10:0.4-instance | Epoch [ 14/ 75] Iter[201/927]	  loss: 0.65cifar10:0.4-instance | Epoch [ 14/ 75] Iter[251/927]	  loss: 0.67cifar10:0.4-instance | Epoch [ 14/ 75] Iter[301/927]	  loss: 0.49cifar10:0.4-instance | Epoch [ 14/ 75] Iter[351/927]	  loss: 0.48cifar10:0.4-instance | Epoch [ 14/ 75] Iter[401/927]	  loss: 0.71cifar10:0.4-instance | Epoch [ 14/ 75] Iter[451/927]	  loss: 0.71cifar10:0.4-instance | Epoch [ 14/ 75] Iter[501/927]	  loss: 0.87cifar10:0.4-instance | Epoch [ 14/ 75] Iter[551/927]	  loss: 1.03cifar10:0.4-instance | Epoch [ 14/ 75] Iter[601/927]	  loss: 0.53cifar10:0.4-instance | Epoch [ 14/ 75] Iter[651/927]	  loss: 0.55cifar10:0.4-instance | Epoch [ 14/ 75] Iter[701/927]	  loss: 0.54cifar10:0.4-instance | Epoch [ 14/ 75] Iter[751/927]	  loss: 0.72cifar10:0.4-instance | Epoch [ 14/ 75] Iter[801/927]	  loss: 0.72cifar10:0.4-instance | Epoch [ 14/ 75] Iter[851/927]	  loss: 0.76cifar10:0.4-instance | Epoch [ 14/ 75] Iter[901/927]	  loss: 0.71
| Test Epoch 14	 Accuracy: 79.25% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 15 | Accuracy on train set: 51.82% 
labeled data has a size of 29469, f-score: 0.916047
cifar10:0.4-instance | Epoch [ 15/ 75] Iter[  1/921]	  loss: 0.63cifar10:0.4-instance | Epoch [ 15/ 75] Iter[ 51/921]	  loss: 0.49cifar10:0.4-instance | Epoch [ 15/ 75] Iter[101/921]	  loss: 0.75cifar10:0.4-instance | Epoch [ 15/ 75] Iter[151/921]	  loss: 0.43cifar10:0.4-instance | Epoch [ 15/ 75] Iter[201/921]	  loss: 0.71cifar10:0.4-instance | Epoch [ 15/ 75] Iter[251/921]	  loss: 0.72cifar10:0.4-instance | Epoch [ 15/ 75] Iter[301/921]	  loss: 0.79cifar10:0.4-instance | Epoch [ 15/ 75] Iter[351/921]	  loss: 0.67cifar10:0.4-instance | Epoch [ 15/ 75] Iter[401/921]	  loss: 0.46cifar10:0.4-instance | Epoch [ 15/ 75] Iter[451/921]	  loss: 0.69cifar10:0.4-instance | Epoch [ 15/ 75] Iter[501/921]	  loss: 0.68cifar10:0.4-instance | Epoch [ 15/ 75] Iter[551/921]	  loss: 0.68cifar10:0.4-instance | Epoch [ 15/ 75] Iter[601/921]	  loss: 0.49cifar10:0.4-instance | Epoch [ 15/ 75] Iter[651/921]	  loss: 0.44cifar10:0.4-instance | Epoch [ 15/ 75] Iter[701/921]	  loss: 0.58cifar10:0.4-instance | Epoch [ 15/ 75] Iter[751/921]	  loss: 0.79cifar10:0.4-instance | Epoch [ 15/ 75] Iter[801/921]	  loss: 0.80cifar10:0.4-instance | Epoch [ 15/ 75] Iter[851/921]	  loss: 0.50cifar10:0.4-instance | Epoch [ 15/ 75] Iter[901/921]	  loss: 0.56
| Test Epoch 15	 Accuracy: 80.05% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 16 | Accuracy on train set: 52.44% 
labeled data has a size of 29466, f-score: 0.920315
cifar10:0.4-instance | Epoch [ 16/ 75] Iter[  1/921]	  loss: 0.45cifar10:0.4-instance | Epoch [ 16/ 75] Iter[ 51/921]	  loss: 0.62cifar10:0.4-instance | Epoch [ 16/ 75] Iter[101/921]	  loss: 0.48cifar10:0.4-instance | Epoch [ 16/ 75] Iter[151/921]	  loss: 0.48cifar10:0.4-instance | Epoch [ 16/ 75] Iter[201/921]	  loss: 0.58cifar10:0.4-instance | Epoch [ 16/ 75] Iter[251/921]	  loss: 0.61cifar10:0.4-instance | Epoch [ 16/ 75] Iter[301/921]	  loss: 0.40cifar10:0.4-instance | Epoch [ 16/ 75] Iter[351/921]	  loss: 0.60cifar10:0.4-instance | Epoch [ 16/ 75] Iter[401/921]	  loss: 0.73cifar10:0.4-instance | Epoch [ 16/ 75] Iter[451/921]	  loss: 1.01cifar10:0.4-instance | Epoch [ 16/ 75] Iter[501/921]	  loss: 0.59cifar10:0.4-instance | Epoch [ 16/ 75] Iter[551/921]	  loss: 0.42cifar10:0.4-instance | Epoch [ 16/ 75] Iter[601/921]	  loss: 0.60cifar10:0.4-instance | Epoch [ 16/ 75] Iter[651/921]	  loss: 0.49cifar10:0.4-instance | Epoch [ 16/ 75] Iter[701/921]	  loss: 0.67cifar10:0.4-instance | Epoch [ 16/ 75] Iter[751/921]	  loss: 0.62cifar10:0.4-instance | Epoch [ 16/ 75] Iter[801/921]	  loss: 0.88cifar10:0.4-instance | Epoch [ 16/ 75] Iter[851/921]	  loss: 0.56cifar10:0.4-instance | Epoch [ 16/ 75] Iter[901/921]	  loss: 0.64
| Test Epoch 16	 Accuracy: 79.32% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 17 | Accuracy on train set: 52.12% 
labeled data has a size of 29449, f-score: 0.925396
cifar10:0.4-instance | Epoch [ 17/ 75] Iter[  1/921]	  loss: 0.49cifar10:0.4-instance | Epoch [ 17/ 75] Iter[ 51/921]	  loss: 0.39cifar10:0.4-instance | Epoch [ 17/ 75] Iter[101/921]	  loss: 0.48cifar10:0.4-instance | Epoch [ 17/ 75] Iter[151/921]	  loss: 0.85cifar10:0.4-instance | Epoch [ 17/ 75] Iter[201/921]	  loss: 0.63cifar10:0.4-instance | Epoch [ 17/ 75] Iter[251/921]	  loss: 0.55cifar10:0.4-instance | Epoch [ 17/ 75] Iter[301/921]	  loss: 0.43cifar10:0.4-instance | Epoch [ 17/ 75] Iter[351/921]	  loss: 0.55cifar10:0.4-instance | Epoch [ 17/ 75] Iter[401/921]	  loss: 0.87cifar10:0.4-instance | Epoch [ 17/ 75] Iter[451/921]	  loss: 0.33cifar10:0.4-instance | Epoch [ 17/ 75] Iter[501/921]	  loss: 0.38cifar10:0.4-instance | Epoch [ 17/ 75] Iter[551/921]	  loss: 0.42cifar10:0.4-instance | Epoch [ 17/ 75] Iter[601/921]	  loss: 0.31cifar10:0.4-instance | Epoch [ 17/ 75] Iter[651/921]	  loss: 0.44cifar10:0.4-instance | Epoch [ 17/ 75] Iter[701/921]	  loss: 0.45cifar10:0.4-instance | Epoch [ 17/ 75] Iter[751/921]	  loss: 0.68cifar10:0.4-instance | Epoch [ 17/ 75] Iter[801/921]	  loss: 0.65cifar10:0.4-instance | Epoch [ 17/ 75] Iter[851/921]	  loss: 0.40cifar10:0.4-instance | Epoch [ 17/ 75] Iter[901/921]	  loss: 0.57
| Test Epoch 17	 Accuracy: 80.36% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 18 | Accuracy on train set: 52.40% 
labeled data has a size of 29624, f-score: 0.926445
cifar10:0.4-instance | Epoch [ 18/ 75] Iter[  1/926]	  loss: 0.50cifar10:0.4-instance | Epoch [ 18/ 75] Iter[ 51/926]	  loss: 0.50cifar10:0.4-instance | Epoch [ 18/ 75] Iter[101/926]	  loss: 0.45cifar10:0.4-instance | Epoch [ 18/ 75] Iter[151/926]	  loss: 0.36cifar10:0.4-instance | Epoch [ 18/ 75] Iter[201/926]	  loss: 0.47cifar10:0.4-instance | Epoch [ 18/ 75] Iter[251/926]	  loss: 0.66cifar10:0.4-instance | Epoch [ 18/ 75] Iter[301/926]	  loss: 0.60cifar10:0.4-instance | Epoch [ 18/ 75] Iter[351/926]	  loss: 0.45cifar10:0.4-instance | Epoch [ 18/ 75] Iter[401/926]	  loss: 0.58cifar10:0.4-instance | Epoch [ 18/ 75] Iter[451/926]	  loss: 0.54cifar10:0.4-instance | Epoch [ 18/ 75] Iter[501/926]	  loss: 0.54cifar10:0.4-instance | Epoch [ 18/ 75] Iter[551/926]	  loss: 0.71cifar10:0.4-instance | Epoch [ 18/ 75] Iter[601/926]	  loss: 0.57cifar10:0.4-instance | Epoch [ 18/ 75] Iter[651/926]	  loss: 0.43cifar10:0.4-instance | Epoch [ 18/ 75] Iter[701/926]	  loss: 0.82cifar10:0.4-instance | Epoch [ 18/ 75] Iter[751/926]	  loss: 0.53cifar10:0.4-instance | Epoch [ 18/ 75] Iter[801/926]	  loss: 0.55cifar10:0.4-instance | Epoch [ 18/ 75] Iter[851/926]	  loss: 0.38cifar10:0.4-instance | Epoch [ 18/ 75] Iter[901/926]	  loss: 0.64
| Test Epoch 18	 Accuracy: 78.11% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 19 | Accuracy on train set: 51.17% 
labeled data has a size of 29728, f-score: 0.925626
cifar10:0.4-instance | Epoch [ 19/ 75] Iter[  1/930]	  loss: 0.72cifar10:0.4-instance | Epoch [ 19/ 75] Iter[ 51/930]	  loss: 0.44cifar10:0.4-instance | Epoch [ 19/ 75] Iter[101/930]	  loss: 0.60cifar10:0.4-instance | Epoch [ 19/ 75] Iter[151/930]	  loss: 0.62cifar10:0.4-instance | Epoch [ 19/ 75] Iter[201/930]	  loss: 0.47cifar10:0.4-instance | Epoch [ 19/ 75] Iter[251/930]	  loss: 0.74cifar10:0.4-instance | Epoch [ 19/ 75] Iter[301/930]	  loss: 0.44cifar10:0.4-instance | Epoch [ 19/ 75] Iter[351/930]	  loss: 0.42cifar10:0.4-instance | Epoch [ 19/ 75] Iter[401/930]	  loss: 0.79cifar10:0.4-instance | Epoch [ 19/ 75] Iter[451/930]	  loss: 0.90cifar10:0.4-instance | Epoch [ 19/ 75] Iter[501/930]	  loss: 0.61cifar10:0.4-instance | Epoch [ 19/ 75] Iter[551/930]	  loss: 0.34cifar10:0.4-instance | Epoch [ 19/ 75] Iter[601/930]	  loss: 0.29cifar10:0.4-instance | Epoch [ 19/ 75] Iter[651/930]	  loss: 0.81cifar10:0.4-instance | Epoch [ 19/ 75] Iter[701/930]	  loss: 0.52cifar10:0.4-instance | Epoch [ 19/ 75] Iter[751/930]	  loss: 0.54cifar10:0.4-instance | Epoch [ 19/ 75] Iter[801/930]	  loss: 0.72cifar10:0.4-instance | Epoch [ 19/ 75] Iter[851/930]	  loss: 0.53cifar10:0.4-instance | Epoch [ 19/ 75] Iter[901/930]	  loss: 0.60
| Test Epoch 19	 Accuracy: 80.21% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 20 | Accuracy on train set: 52.32% 
labeled data has a size of 29822, f-score: 0.929515
cifar10:0.4-instance | Epoch [ 20/ 75] Iter[  1/932]	  loss: 0.44cifar10:0.4-instance | Epoch [ 20/ 75] Iter[ 51/932]	  loss: 0.49cifar10:0.4-instance | Epoch [ 20/ 75] Iter[101/932]	  loss: 0.41cifar10:0.4-instance | Epoch [ 20/ 75] Iter[151/932]	  loss: 0.36cifar10:0.4-instance | Epoch [ 20/ 75] Iter[201/932]	  loss: 0.61cifar10:0.4-instance | Epoch [ 20/ 75] Iter[251/932]	  loss: 0.59cifar10:0.4-instance | Epoch [ 20/ 75] Iter[301/932]	  loss: 0.56cifar10:0.4-instance | Epoch [ 20/ 75] Iter[351/932]	  loss: 0.34cifar10:0.4-instance | Epoch [ 20/ 75] Iter[401/932]	  loss: 0.43cifar10:0.4-instance | Epoch [ 20/ 75] Iter[451/932]	  loss: 0.43cifar10:0.4-instance | Epoch [ 20/ 75] Iter[501/932]	  loss: 0.41cifar10:0.4-instance | Epoch [ 20/ 75] Iter[551/932]	  loss: 0.61cifar10:0.4-instance | Epoch [ 20/ 75] Iter[601/932]	  loss: 0.42cifar10:0.4-instance | Epoch [ 20/ 75] Iter[651/932]	  loss: 0.54cifar10:0.4-instance | Epoch [ 20/ 75] Iter[701/932]	  loss: 0.54cifar10:0.4-instance | Epoch [ 20/ 75] Iter[751/932]	  loss: 0.32cifar10:0.4-instance | Epoch [ 20/ 75] Iter[801/932]	  loss: 0.56cifar10:0.4-instance | Epoch [ 20/ 75] Iter[851/932]	  loss: 0.53cifar10:0.4-instance | Epoch [ 20/ 75] Iter[901/932]	  loss: 0.63
| Test Epoch 20	 Accuracy: 78.32% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 21 | Accuracy on train set: 51.66% 
labeled data has a size of 29937, f-score: 0.927347
cifar10:0.4-instance | Epoch [ 21/ 75] Iter[  1/936]	  loss: 0.87cifar10:0.4-instance | Epoch [ 21/ 75] Iter[ 51/936]	  loss: 0.53cifar10:0.4-instance | Epoch [ 21/ 75] Iter[101/936]	  loss: 0.44cifar10:0.4-instance | Epoch [ 21/ 75] Iter[151/936]	  loss: 0.45cifar10:0.4-instance | Epoch [ 21/ 75] Iter[201/936]	  loss: 0.51cifar10:0.4-instance | Epoch [ 21/ 75] Iter[251/936]	  loss: 0.51cifar10:0.4-instance | Epoch [ 21/ 75] Iter[301/936]	  loss: 0.72cifar10:0.4-instance | Epoch [ 21/ 75] Iter[351/936]	  loss: 0.59cifar10:0.4-instance | Epoch [ 21/ 75] Iter[401/936]	  loss: 0.29cifar10:0.4-instance | Epoch [ 21/ 75] Iter[451/936]	  loss: 0.49cifar10:0.4-instance | Epoch [ 21/ 75] Iter[501/936]	  loss: 0.80cifar10:0.4-instance | Epoch [ 21/ 75] Iter[551/936]	  loss: 0.48cifar10:0.4-instance | Epoch [ 21/ 75] Iter[601/936]	  loss: 0.61cifar10:0.4-instance | Epoch [ 21/ 75] Iter[651/936]	  loss: 0.51cifar10:0.4-instance | Epoch [ 21/ 75] Iter[701/936]	  loss: 0.51cifar10:0.4-instance | Epoch [ 21/ 75] Iter[751/936]	  loss: 0.49cifar10:0.4-instance | Epoch [ 21/ 75] Iter[801/936]	  loss: 0.58cifar10:0.4-instance | Epoch [ 21/ 75] Iter[851/936]	  loss: 0.33cifar10:0.4-instance | Epoch [ 21/ 75] Iter[901/936]	  loss: 0.75
| Test Epoch 21	 Accuracy: 82.12% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 22 | Accuracy on train set: 53.76% 
labeled data has a size of 30008, f-score: 0.932085
cifar10:0.4-instance | Epoch [ 22/ 75] Iter[  1/938]	  loss: 0.61cifar10:0.4-instance | Epoch [ 22/ 75] Iter[ 51/938]	  loss: 0.51cifar10:0.4-instance | Epoch [ 22/ 75] Iter[101/938]	  loss: 0.66cifar10:0.4-instance | Epoch [ 22/ 75] Iter[151/938]	  loss: 0.44cifar10:0.4-instance | Epoch [ 22/ 75] Iter[201/938]	  loss: 0.56cifar10:0.4-instance | Epoch [ 22/ 75] Iter[251/938]	  loss: 0.55cifar10:0.4-instance | Epoch [ 22/ 75] Iter[301/938]	  loss: 0.78cifar10:0.4-instance | Epoch [ 22/ 75] Iter[351/938]	  loss: 0.48cifar10:0.4-instance | Epoch [ 22/ 75] Iter[401/938]	  loss: 0.52cifar10:0.4-instance | Epoch [ 22/ 75] Iter[451/938]	  loss: 0.32cifar10:0.4-instance | Epoch [ 22/ 75] Iter[501/938]	  loss: 0.56cifar10:0.4-instance | Epoch [ 22/ 75] Iter[551/938]	  loss: 0.63cifar10:0.4-instance | Epoch [ 22/ 75] Iter[601/938]	  loss: 0.51cifar10:0.4-instance | Epoch [ 22/ 75] Iter[651/938]	  loss: 0.51cifar10:0.4-instance | Epoch [ 22/ 75] Iter[701/938]	  loss: 0.40cifar10:0.4-instance | Epoch [ 22/ 75] Iter[751/938]	  loss: 0.49cifar10:0.4-instance | Epoch [ 22/ 75] Iter[801/938]	  loss: 0.46cifar10:0.4-instance | Epoch [ 22/ 75] Iter[851/938]	  loss: 0.57cifar10:0.4-instance | Epoch [ 22/ 75] Iter[901/938]	  loss: 0.44
| Test Epoch 22	 Accuracy: 80.29% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 23 | Accuracy on train set: 53.02% 
labeled data has a size of 30076, f-score: 0.930975
cifar10:0.4-instance | Epoch [ 23/ 75] Iter[  1/940]	  loss: 0.46cifar10:0.4-instance | Epoch [ 23/ 75] Iter[ 51/940]	  loss: 0.48cifar10:0.4-instance | Epoch [ 23/ 75] Iter[101/940]	  loss: 0.48cifar10:0.4-instance | Epoch [ 23/ 75] Iter[151/940]	  loss: 0.35cifar10:0.4-instance | Epoch [ 23/ 75] Iter[201/940]	  loss: 0.64cifar10:0.4-instance | Epoch [ 23/ 75] Iter[251/940]	  loss: 0.41cifar10:0.4-instance | Epoch [ 23/ 75] Iter[301/940]	  loss: 0.75cifar10:0.4-instance | Epoch [ 23/ 75] Iter[351/940]	  loss: 0.46cifar10:0.4-instance | Epoch [ 23/ 75] Iter[401/940]	  loss: 0.43cifar10:0.4-instance | Epoch [ 23/ 75] Iter[451/940]	  loss: 0.47cifar10:0.4-instance | Epoch [ 23/ 75] Iter[501/940]	  loss: 0.37cifar10:0.4-instance | Epoch [ 23/ 75] Iter[551/940]	  loss: 0.37cifar10:0.4-instance | Epoch [ 23/ 75] Iter[601/940]	  loss: 0.63cifar10:0.4-instance | Epoch [ 23/ 75] Iter[651/940]	  loss: 0.37cifar10:0.4-instance | Epoch [ 23/ 75] Iter[701/940]	  loss: 0.55cifar10:0.4-instance | Epoch [ 23/ 75] Iter[751/940]	  loss: 0.45cifar10:0.4-instance | Epoch [ 23/ 75] Iter[801/940]	  loss: 0.32cifar10:0.4-instance | Epoch [ 23/ 75] Iter[851/940]	  loss: 0.35cifar10:0.4-instance | Epoch [ 23/ 75] Iter[901/940]	  loss: 0.52
| Test Epoch 23	 Accuracy: 79.89% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 24 | Accuracy on train set: 52.25% 
labeled data has a size of 30001, f-score: 0.934602
cifar10:0.4-instance | Epoch [ 24/ 75] Iter[  1/938]	  loss: 0.36cifar10:0.4-instance | Epoch [ 24/ 75] Iter[ 51/938]	  loss: 0.40cifar10:0.4-instance | Epoch [ 24/ 75] Iter[101/938]	  loss: 0.41cifar10:0.4-instance | Epoch [ 24/ 75] Iter[151/938]	  loss: 0.48cifar10:0.4-instance | Epoch [ 24/ 75] Iter[201/938]	  loss: 0.32cifar10:0.4-instance | Epoch [ 24/ 75] Iter[251/938]	  loss: 0.55cifar10:0.4-instance | Epoch [ 24/ 75] Iter[301/938]	  loss: 0.40cifar10:0.4-instance | Epoch [ 24/ 75] Iter[351/938]	  loss: 0.43cifar10:0.4-instance | Epoch [ 24/ 75] Iter[401/938]	  loss: 0.55cifar10:0.4-instance | Epoch [ 24/ 75] Iter[451/938]	  loss: 0.79cifar10:0.4-instance | Epoch [ 24/ 75] Iter[501/938]	  loss: 0.35cifar10:0.4-instance | Epoch [ 24/ 75] Iter[551/938]	  loss: 0.33cifar10:0.4-instance | Epoch [ 24/ 75] Iter[601/938]	  loss: 0.46cifar10:0.4-instance | Epoch [ 24/ 75] Iter[651/938]	  loss: 0.34cifar10:0.4-instance | Epoch [ 24/ 75] Iter[701/938]	  loss: 0.46cifar10:0.4-instance | Epoch [ 24/ 75] Iter[751/938]	  loss: 0.49cifar10:0.4-instance | Epoch [ 24/ 75] Iter[801/938]	  loss: 0.51cifar10:0.4-instance | Epoch [ 24/ 75] Iter[851/938]	  loss: 0.43cifar10:0.4-instance | Epoch [ 24/ 75] Iter[901/938]	  loss: 0.46
| Test Epoch 24	 Accuracy: 81.70% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 25 | Accuracy on train set: 53.29% 
labeled data has a size of 30201, f-score: 0.933777
cifar10:0.4-instance | Epoch [ 25/ 75] Iter[  1/944]	  loss: 0.59cifar10:0.4-instance | Epoch [ 25/ 75] Iter[ 51/944]	  loss: 0.45cifar10:0.4-instance | Epoch [ 25/ 75] Iter[101/944]	  loss: 0.75cifar10:0.4-instance | Epoch [ 25/ 75] Iter[151/944]	  loss: 0.52cifar10:0.4-instance | Epoch [ 25/ 75] Iter[201/944]	  loss: 0.37cifar10:0.4-instance | Epoch [ 25/ 75] Iter[251/944]	  loss: 0.48cifar10:0.4-instance | Epoch [ 25/ 75] Iter[301/944]	  loss: 0.39cifar10:0.4-instance | Epoch [ 25/ 75] Iter[351/944]	  loss: 0.91cifar10:0.4-instance | Epoch [ 25/ 75] Iter[401/944]	  loss: 0.33cifar10:0.4-instance | Epoch [ 25/ 75] Iter[451/944]	  loss: 0.78cifar10:0.4-instance | Epoch [ 25/ 75] Iter[501/944]	  loss: 0.70cifar10:0.4-instance | Epoch [ 25/ 75] Iter[551/944]	  loss: 0.68cifar10:0.4-instance | Epoch [ 25/ 75] Iter[601/944]	  loss: 0.36cifar10:0.4-instance | Epoch [ 25/ 75] Iter[651/944]	  loss: 0.55cifar10:0.4-instance | Epoch [ 25/ 75] Iter[701/944]	  loss: 0.65cifar10:0.4-instance | Epoch [ 25/ 75] Iter[751/944]	  loss: 0.52cifar10:0.4-instance | Epoch [ 25/ 75] Iter[801/944]	  loss: 0.61cifar10:0.4-instance | Epoch [ 25/ 75] Iter[851/944]	  loss: 0.36cifar10:0.4-instance | Epoch [ 25/ 75] Iter[901/944]	  loss: 0.47
| Test Epoch 25	 Accuracy: 82.19% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 26 | Accuracy on train set: 54.18% 
labeled data has a size of 30131, f-score: 0.936743
cifar10:0.4-instance | Epoch [ 26/ 75] Iter[  1/942]	  loss: 0.36cifar10:0.4-instance | Epoch [ 26/ 75] Iter[ 51/942]	  loss: 0.60cifar10:0.4-instance | Epoch [ 26/ 75] Iter[101/942]	  loss: 0.34cifar10:0.4-instance | Epoch [ 26/ 75] Iter[151/942]	  loss: 0.56cifar10:0.4-instance | Epoch [ 26/ 75] Iter[201/942]	  loss: 0.33cifar10:0.4-instance | Epoch [ 26/ 75] Iter[251/942]	  loss: 0.52cifar10:0.4-instance | Epoch [ 26/ 75] Iter[301/942]	  loss: 0.72cifar10:0.4-instance | Epoch [ 26/ 75] Iter[351/942]	  loss: 0.43cifar10:0.4-instance | Epoch [ 26/ 75] Iter[401/942]	  loss: 0.70cifar10:0.4-instance | Epoch [ 26/ 75] Iter[451/942]	  loss: 0.54cifar10:0.4-instance | Epoch [ 26/ 75] Iter[501/942]	  loss: 0.37cifar10:0.4-instance | Epoch [ 26/ 75] Iter[551/942]	  loss: 0.91cifar10:0.4-instance | Epoch [ 26/ 75] Iter[601/942]	  loss: 0.42cifar10:0.4-instance | Epoch [ 26/ 75] Iter[651/942]	  loss: 0.59cifar10:0.4-instance | Epoch [ 26/ 75] Iter[701/942]	  loss: 0.79cifar10:0.4-instance | Epoch [ 26/ 75] Iter[751/942]	  loss: 0.40cifar10:0.4-instance | Epoch [ 26/ 75] Iter[801/942]	  loss: 0.69cifar10:0.4-instance | Epoch [ 26/ 75] Iter[851/942]	  loss: 0.54cifar10:0.4-instance | Epoch [ 26/ 75] Iter[901/942]	  loss: 0.56
| Test Epoch 26	 Accuracy: 81.78% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 27 | Accuracy on train set: 53.66% 
labeled data has a size of 30016, f-score: 0.939066
cifar10:0.4-instance | Epoch [ 27/ 75] Iter[  1/939]	  loss: 0.38cifar10:0.4-instance | Epoch [ 27/ 75] Iter[ 51/939]	  loss: 0.51cifar10:0.4-instance | Epoch [ 27/ 75] Iter[101/939]	  loss: 0.47cifar10:0.4-instance | Epoch [ 27/ 75] Iter[151/939]	  loss: 0.47cifar10:0.4-instance | Epoch [ 27/ 75] Iter[201/939]	  loss: 0.47cifar10:0.4-instance | Epoch [ 27/ 75] Iter[251/939]	  loss: 0.38cifar10:0.4-instance | Epoch [ 27/ 75] Iter[301/939]	  loss: 0.73cifar10:0.4-instance | Epoch [ 27/ 75] Iter[351/939]	  loss: 0.47cifar10:0.4-instance | Epoch [ 27/ 75] Iter[401/939]	  loss: 0.41cifar10:0.4-instance | Epoch [ 27/ 75] Iter[451/939]	  loss: 0.64cifar10:0.4-instance | Epoch [ 27/ 75] Iter[501/939]	  loss: 0.59cifar10:0.4-instance | Epoch [ 27/ 75] Iter[551/939]	  loss: 0.47cifar10:0.4-instance | Epoch [ 27/ 75] Iter[601/939]	  loss: 0.45cifar10:0.4-instance | Epoch [ 27/ 75] Iter[651/939]	  loss: 0.61cifar10:0.4-instance | Epoch [ 27/ 75] Iter[701/939]	  loss: 0.23cifar10:0.4-instance | Epoch [ 27/ 75] Iter[751/939]	  loss: 0.82cifar10:0.4-instance | Epoch [ 27/ 75] Iter[801/939]	  loss: 0.56cifar10:0.4-instance | Epoch [ 27/ 75] Iter[851/939]	  loss: 0.45cifar10:0.4-instance | Epoch [ 27/ 75] Iter[901/939]	  loss: 0.68
| Test Epoch 27	 Accuracy: 80.95% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 28 | Accuracy on train set: 53.40% 
labeled data has a size of 30239, f-score: 0.935646
cifar10:0.4-instance | Epoch [ 28/ 75] Iter[  1/945]	  loss: 0.75cifar10:0.4-instance | Epoch [ 28/ 75] Iter[ 51/945]	  loss: 0.62cifar10:0.4-instance | Epoch [ 28/ 75] Iter[101/945]	  loss: 0.49cifar10:0.4-instance | Epoch [ 28/ 75] Iter[151/945]	  loss: 0.62cifar10:0.4-instance | Epoch [ 28/ 75] Iter[201/945]	  loss: 0.70cifar10:0.4-instance | Epoch [ 28/ 75] Iter[251/945]	  loss: 0.36cifar10:0.4-instance | Epoch [ 28/ 75] Iter[301/945]	  loss: 0.55cifar10:0.4-instance | Epoch [ 28/ 75] Iter[351/945]	  loss: 0.62cifar10:0.4-instance | Epoch [ 28/ 75] Iter[401/945]	  loss: 0.48cifar10:0.4-instance | Epoch [ 28/ 75] Iter[451/945]	  loss: 0.40cifar10:0.4-instance | Epoch [ 28/ 75] Iter[501/945]	  loss: 0.55cifar10:0.4-instance | Epoch [ 28/ 75] Iter[551/945]	  loss: 0.50cifar10:0.4-instance | Epoch [ 28/ 75] Iter[601/945]	  loss: 0.46cifar10:0.4-instance | Epoch [ 28/ 75] Iter[651/945]	  loss: 0.40cifar10:0.4-instance | Epoch [ 28/ 75] Iter[701/945]	  loss: 0.23cifar10:0.4-instance | Epoch [ 28/ 75] Iter[751/945]	  loss: 0.48cifar10:0.4-instance | Epoch [ 28/ 75] Iter[801/945]	  loss: 0.55cifar10:0.4-instance | Epoch [ 28/ 75] Iter[851/945]	  loss: 0.50cifar10:0.4-instance | Epoch [ 28/ 75] Iter[901/945]	  loss: 0.68
| Test Epoch 28	 Accuracy: 79.75% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 29 | Accuracy on train set: 52.31% 
labeled data has a size of 30212, f-score: 0.936515
cifar10:0.4-instance | Epoch [ 29/ 75] Iter[  1/945]	  loss: 0.49cifar10:0.4-instance | Epoch [ 29/ 75] Iter[ 51/945]	  loss: 0.37cifar10:0.4-instance | Epoch [ 29/ 75] Iter[101/945]	  loss: 0.39cifar10:0.4-instance | Epoch [ 29/ 75] Iter[151/945]	  loss: 0.27cifar10:0.4-instance | Epoch [ 29/ 75] Iter[201/945]	  loss: 0.64cifar10:0.4-instance | Epoch [ 29/ 75] Iter[251/945]	  loss: 0.63cifar10:0.4-instance | Epoch [ 29/ 75] Iter[301/945]	  loss: 0.39cifar10:0.4-instance | Epoch [ 29/ 75] Iter[351/945]	  loss: 0.56cifar10:0.4-instance | Epoch [ 29/ 75] Iter[401/945]	  loss: 0.41cifar10:0.4-instance | Epoch [ 29/ 75] Iter[451/945]	  loss: 0.43cifar10:0.4-instance | Epoch [ 29/ 75] Iter[501/945]	  loss: 0.61cifar10:0.4-instance | Epoch [ 29/ 75] Iter[551/945]	  loss: 0.46cifar10:0.4-instance | Epoch [ 29/ 75] Iter[601/945]	  loss: 0.82cifar10:0.4-instance | Epoch [ 29/ 75] Iter[651/945]	  loss: 0.61cifar10:0.4-instance | Epoch [ 29/ 75] Iter[701/945]	  loss: 0.48cifar10:0.4-instance | Epoch [ 29/ 75] Iter[751/945]	  loss: 1.05cifar10:0.4-instance | Epoch [ 29/ 75] Iter[801/945]	  loss: 0.86cifar10:0.4-instance | Epoch [ 29/ 75] Iter[851/945]	  loss: 0.59cifar10:0.4-instance | Epoch [ 29/ 75] Iter[901/945]	  loss: 0.57
| Test Epoch 29	 Accuracy: 82.59% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 30 | Accuracy on train set: 54.33% 
labeled data has a size of 30001, f-score: 0.939602
cifar10:0.4-instance | Epoch [ 30/ 75] Iter[  1/938]	  loss: 0.57cifar10:0.4-instance | Epoch [ 30/ 75] Iter[ 51/938]	  loss: 0.42cifar10:0.4-instance | Epoch [ 30/ 75] Iter[101/938]	  loss: 0.56cifar10:0.4-instance | Epoch [ 30/ 75] Iter[151/938]	  loss: 0.32cifar10:0.4-instance | Epoch [ 30/ 75] Iter[201/938]	  loss: 0.43cifar10:0.4-instance | Epoch [ 30/ 75] Iter[251/938]	  loss: 0.59cifar10:0.4-instance | Epoch [ 30/ 75] Iter[301/938]	  loss: 0.29cifar10:0.4-instance | Epoch [ 30/ 75] Iter[351/938]	  loss: 0.45cifar10:0.4-instance | Epoch [ 30/ 75] Iter[401/938]	  loss: 0.45cifar10:0.4-instance | Epoch [ 30/ 75] Iter[451/938]	  loss: 0.39cifar10:0.4-instance | Epoch [ 30/ 75] Iter[501/938]	  loss: 0.61cifar10:0.4-instance | Epoch [ 30/ 75] Iter[551/938]	  loss: 0.60cifar10:0.4-instance | Epoch [ 30/ 75] Iter[601/938]	  loss: 0.48cifar10:0.4-instance | Epoch [ 30/ 75] Iter[651/938]	  loss: 0.45cifar10:0.4-instance | Epoch [ 30/ 75] Iter[701/938]	  loss: 0.42cifar10:0.4-instance | Epoch [ 30/ 75] Iter[751/938]	  loss: 0.42cifar10:0.4-instance | Epoch [ 30/ 75] Iter[801/938]	  loss: 0.64cifar10:0.4-instance | Epoch [ 30/ 75] Iter[851/938]	  loss: 0.47cifar10:0.4-instance | Epoch [ 30/ 75] Iter[901/938]	  loss: 0.45
| Test Epoch 30	 Accuracy: 83.31% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 31 | Accuracy on train set: 54.42% 
labeled data has a size of 30127, f-score: 0.940784
cifar10:0.4-instance | Epoch [ 31/ 75] Iter[  1/942]	  loss: 0.34cifar10:0.4-instance | Epoch [ 31/ 75] Iter[ 51/942]	  loss: 0.71cifar10:0.4-instance | Epoch [ 31/ 75] Iter[101/942]	  loss: 0.42cifar10:0.4-instance | Epoch [ 31/ 75] Iter[151/942]	  loss: 0.38cifar10:0.4-instance | Epoch [ 31/ 75] Iter[201/942]	  loss: 0.33cifar10:0.4-instance | Epoch [ 31/ 75] Iter[251/942]	  loss: 0.30cifar10:0.4-instance | Epoch [ 31/ 75] Iter[301/942]	  loss: 0.54cifar10:0.4-instance | Epoch [ 31/ 75] Iter[351/942]	  loss: 0.40cifar10:0.4-instance | Epoch [ 31/ 75] Iter[401/942]	  loss: 0.41cifar10:0.4-instance | Epoch [ 31/ 75] Iter[451/942]	  loss: 0.49cifar10:0.4-instance | Epoch [ 31/ 75] Iter[501/942]	  loss: 0.44cifar10:0.4-instance | Epoch [ 31/ 75] Iter[551/942]	  loss: 0.44cifar10:0.4-instance | Epoch [ 31/ 75] Iter[601/942]	  loss: 0.49cifar10:0.4-instance | Epoch [ 31/ 75] Iter[651/942]	  loss: 0.46cifar10:0.4-instance | Epoch [ 31/ 75] Iter[701/942]	  loss: 0.33cifar10:0.4-instance | Epoch [ 31/ 75] Iter[751/942]	  loss: 0.31cifar10:0.4-instance | Epoch [ 31/ 75] Iter[801/942]	  loss: 0.38cifar10:0.4-instance | Epoch [ 31/ 75] Iter[851/942]	  loss: 0.30cifar10:0.4-instance | Epoch [ 31/ 75] Iter[901/942]	  loss: 0.54
| Test Epoch 31	 Accuracy: 81.66% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 32 | Accuracy on train set: 53.74% 
labeled data has a size of 30267, f-score: 0.941752
cifar10:0.4-instance | Epoch [ 32/ 75] Iter[  1/946]	  loss: 0.49cifar10:0.4-instance | Epoch [ 32/ 75] Iter[ 51/946]	  loss: 0.52cifar10:0.4-instance | Epoch [ 32/ 75] Iter[101/946]	  loss: 0.43cifar10:0.4-instance | Epoch [ 32/ 75] Iter[151/946]	  loss: 0.26cifar10:0.4-instance | Epoch [ 32/ 75] Iter[201/946]	  loss: 0.39cifar10:0.4-instance | Epoch [ 32/ 75] Iter[251/946]	  loss: 0.37cifar10:0.4-instance | Epoch [ 32/ 75] Iter[301/946]	  loss: 0.45cifar10:0.4-instance | Epoch [ 32/ 75] Iter[351/946]	  loss: 0.44cifar10:0.4-instance | Epoch [ 32/ 75] Iter[401/946]	  loss: 0.33cifar10:0.4-instance | Epoch [ 32/ 75] Iter[451/946]	  loss: 0.54cifar10:0.4-instance | Epoch [ 32/ 75] Iter[501/946]	  loss: 0.46cifar10:0.4-instance | Epoch [ 32/ 75] Iter[551/946]	  loss: 0.39cifar10:0.4-instance | Epoch [ 32/ 75] Iter[601/946]	  loss: 0.36cifar10:0.4-instance | Epoch [ 32/ 75] Iter[651/946]	  loss: 0.53cifar10:0.4-instance | Epoch [ 32/ 75] Iter[701/946]	  loss: 0.56cifar10:0.4-instance | Epoch [ 32/ 75] Iter[751/946]	  loss: 0.53cifar10:0.4-instance | Epoch [ 32/ 75] Iter[801/946]	  loss: 0.61cifar10:0.4-instance | Epoch [ 32/ 75] Iter[851/946]	  loss: 0.62cifar10:0.4-instance | Epoch [ 32/ 75] Iter[901/946]	  loss: 0.59
| Test Epoch 32	 Accuracy: 81.66% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 33 | Accuracy on train set: 53.45% 
labeled data has a size of 30343, f-score: 0.939953
cifar10:0.4-instance | Epoch [ 33/ 75] Iter[  1/949]	  loss: 0.33cifar10:0.4-instance | Epoch [ 33/ 75] Iter[ 51/949]	  loss: 0.64cifar10:0.4-instance | Epoch [ 33/ 75] Iter[101/949]	  loss: 0.39cifar10:0.4-instance | Epoch [ 33/ 75] Iter[151/949]	  loss: 0.41cifar10:0.4-instance | Epoch [ 33/ 75] Iter[201/949]	  loss: 0.67cifar10:0.4-instance | Epoch [ 33/ 75] Iter[251/949]	  loss: 0.51cifar10:0.4-instance | Epoch [ 33/ 75] Iter[301/949]	  loss: 0.35cifar10:0.4-instance | Epoch [ 33/ 75] Iter[351/949]	  loss: 0.59cifar10:0.4-instance | Epoch [ 33/ 75] Iter[401/949]	  loss: 0.24cifar10:0.4-instance | Epoch [ 33/ 75] Iter[451/949]	  loss: 0.24cifar10:0.4-instance | Epoch [ 33/ 75] Iter[501/949]	  loss: 0.57cifar10:0.4-instance | Epoch [ 33/ 75] Iter[551/949]	  loss: 0.38cifar10:0.4-instance | Epoch [ 33/ 75] Iter[601/949]	  loss: 0.42cifar10:0.4-instance | Epoch [ 33/ 75] Iter[651/949]	  loss: 0.37cifar10:0.4-instance | Epoch [ 33/ 75] Iter[701/949]	  loss: 0.34cifar10:0.4-instance | Epoch [ 33/ 75] Iter[751/949]	  loss: 0.46cifar10:0.4-instance | Epoch [ 33/ 75] Iter[801/949]	  loss: 0.51cifar10:0.4-instance | Epoch [ 33/ 75] Iter[851/949]	  loss: 0.42cifar10:0.4-instance | Epoch [ 33/ 75] Iter[901/949]	  loss: 0.61
| Test Epoch 33	 Accuracy: 83.65% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 34 | Accuracy on train set: 55.20% 
labeled data has a size of 30400, f-score: 0.939836
cifar10:0.4-instance | Epoch [ 34/ 75] Iter[  1/951]	  loss: 0.56cifar10:0.4-instance | Epoch [ 34/ 75] Iter[ 51/951]	  loss: 0.30cifar10:0.4-instance | Epoch [ 34/ 75] Iter[101/951]	  loss: 0.53cifar10:0.4-instance | Epoch [ 34/ 75] Iter[151/951]	  loss: 0.45cifar10:0.4-instance | Epoch [ 34/ 75] Iter[201/951]	  loss: 0.63cifar10:0.4-instance | Epoch [ 34/ 75] Iter[251/951]	  loss: 0.44cifar10:0.4-instance | Epoch [ 34/ 75] Iter[301/951]	  loss: 0.59cifar10:0.4-instance | Epoch [ 34/ 75] Iter[351/951]	  loss: 0.55cifar10:0.4-instance | Epoch [ 34/ 75] Iter[401/951]	  loss: 0.50cifar10:0.4-instance | Epoch [ 34/ 75] Iter[451/951]	  loss: 0.41cifar10:0.4-instance | Epoch [ 34/ 75] Iter[501/951]	  loss: 0.51cifar10:0.4-instance | Epoch [ 34/ 75] Iter[551/951]	  loss: 0.66cifar10:0.4-instance | Epoch [ 34/ 75] Iter[601/951]	  loss: 0.58cifar10:0.4-instance | Epoch [ 34/ 75] Iter[651/951]	  loss: 0.66cifar10:0.4-instance | Epoch [ 34/ 75] Iter[701/951]	  loss: 0.38cifar10:0.4-instance | Epoch [ 34/ 75] Iter[751/951]	  loss: 0.42cifar10:0.4-instance | Epoch [ 34/ 75] Iter[801/951]	  loss: 0.43cifar10:0.4-instance | Epoch [ 34/ 75] Iter[851/951]	  loss: 0.54cifar10:0.4-instance | Epoch [ 34/ 75] Iter[901/951]	  loss: 0.46
| Test Epoch 34	 Accuracy: 81.99% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 35 | Accuracy on train set: 54.32% 
labeled data has a size of 30413, f-score: 0.939072
cifar10:0.4-instance | Epoch [ 35/ 75] Iter[  1/951]	  loss: 0.45cifar10:0.4-instance | Epoch [ 35/ 75] Iter[ 51/951]	  loss: 0.37cifar10:0.4-instance | Epoch [ 35/ 75] Iter[101/951]	  loss: 0.41cifar10:0.4-instance | Epoch [ 35/ 75] Iter[151/951]	  loss: 0.50cifar10:0.4-instance | Epoch [ 35/ 75] Iter[201/951]	  loss: 0.42cifar10:0.4-instance | Epoch [ 35/ 75] Iter[251/951]	  loss: 0.61cifar10:0.4-instance | Epoch [ 35/ 75] Iter[301/951]	  loss: 0.50cifar10:0.4-instance | Epoch [ 35/ 75] Iter[351/951]	  loss: 0.54cifar10:0.4-instance | Epoch [ 35/ 75] Iter[401/951]	  loss: 0.38cifar10:0.4-instance | Epoch [ 35/ 75] Iter[451/951]	  loss: 0.56cifar10:0.4-instance | Epoch [ 35/ 75] Iter[501/951]	  loss: 0.60cifar10:0.4-instance | Epoch [ 35/ 75] Iter[551/951]	  loss: 0.51cifar10:0.4-instance | Epoch [ 35/ 75] Iter[601/951]	  loss: 0.26cifar10:0.4-instance | Epoch [ 35/ 75] Iter[651/951]	  loss: 0.50cifar10:0.4-instance | Epoch [ 35/ 75] Iter[701/951]	  loss: 0.67cifar10:0.4-instance | Epoch [ 35/ 75] Iter[751/951]	  loss: 0.51cifar10:0.4-instance | Epoch [ 35/ 75] Iter[801/951]	  loss: 0.45cifar10:0.4-instance | Epoch [ 35/ 75] Iter[851/951]	  loss: 0.41cifar10:0.4-instance | Epoch [ 35/ 75] Iter[901/951]	  loss: 0.34cifar10:0.4-instance | Epoch [ 35/ 75] Iter[951/951]	  loss: 0.82
| Test Epoch 35	 Accuracy: 81.90% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 36 | Accuracy on train set: 54.40% 
labeled data has a size of 30591, f-score: 0.934589
cifar10:0.4-instance | Epoch [ 36/ 75] Iter[  1/956]	  loss: 0.25cifar10:0.4-instance | Epoch [ 36/ 75] Iter[ 51/956]	  loss: 0.58cifar10:0.4-instance | Epoch [ 36/ 75] Iter[101/956]	  loss: 0.42cifar10:0.4-instance | Epoch [ 36/ 75] Iter[151/956]	  loss: 0.62cifar10:0.4-instance | Epoch [ 36/ 75] Iter[201/956]	  loss: 0.37cifar10:0.4-instance | Epoch [ 36/ 75] Iter[251/956]	  loss: 0.52cifar10:0.4-instance | Epoch [ 36/ 75] Iter[301/956]	  loss: 0.26cifar10:0.4-instance | Epoch [ 36/ 75] Iter[351/956]	  loss: 0.33cifar10:0.4-instance | Epoch [ 36/ 75] Iter[401/956]	  loss: 0.41cifar10:0.4-instance | Epoch [ 36/ 75] Iter[451/956]	  loss: 0.55cifar10:0.4-instance | Epoch [ 36/ 75] Iter[501/956]	  loss: 0.38cifar10:0.4-instance | Epoch [ 36/ 75] Iter[551/956]	  loss: 0.36cifar10:0.4-instance | Epoch [ 36/ 75] Iter[601/956]	  loss: 0.67cifar10:0.4-instance | Epoch [ 36/ 75] Iter[651/956]	  loss: 0.35cifar10:0.4-instance | Epoch [ 36/ 75] Iter[701/956]	  loss: 0.53cifar10:0.4-instance | Epoch [ 36/ 75] Iter[751/956]	  loss: 0.56cifar10:0.4-instance | Epoch [ 36/ 75] Iter[801/956]	  loss: 0.38cifar10:0.4-instance | Epoch [ 36/ 75] Iter[851/956]	  loss: 0.32cifar10:0.4-instance | Epoch [ 36/ 75] Iter[901/956]	  loss: 0.49cifar10:0.4-instance | Epoch [ 36/ 75] Iter[951/956]	  loss: 0.42
| Test Epoch 36	 Accuracy: 82.73% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 37 | Accuracy on train set: 54.75% 
labeled data has a size of 30477, f-score: 0.936083
cifar10:0.4-instance | Epoch [ 37/ 75] Iter[  1/953]	  loss: 0.52cifar10:0.4-instance | Epoch [ 37/ 75] Iter[ 51/953]	  loss: 0.49cifar10:0.4-instance | Epoch [ 37/ 75] Iter[101/953]	  loss: 0.75cifar10:0.4-instance | Epoch [ 37/ 75] Iter[151/953]	  loss: 0.42cifar10:0.4-instance | Epoch [ 37/ 75] Iter[201/953]	  loss: 0.50cifar10:0.4-instance | Epoch [ 37/ 75] Iter[251/953]	  loss: 0.38cifar10:0.4-instance | Epoch [ 37/ 75] Iter[301/953]	  loss: 0.71cifar10:0.4-instance | Epoch [ 37/ 75] Iter[351/953]	  loss: 0.62cifar10:0.4-instance | Epoch [ 37/ 75] Iter[401/953]	  loss: 0.75cifar10:0.4-instance | Epoch [ 37/ 75] Iter[451/953]	  loss: 0.65cifar10:0.4-instance | Epoch [ 37/ 75] Iter[501/953]	  loss: 0.41cifar10:0.4-instance | Epoch [ 37/ 75] Iter[551/953]	  loss: 0.73cifar10:0.4-instance | Epoch [ 37/ 75] Iter[601/953]	  loss: 0.58cifar10:0.4-instance | Epoch [ 37/ 75] Iter[651/953]	  loss: 0.51cifar10:0.4-instance | Epoch [ 37/ 75] Iter[701/953]	  loss: 0.44cifar10:0.4-instance | Epoch [ 37/ 75] Iter[751/953]	  loss: 0.62cifar10:0.4-instance | Epoch [ 37/ 75] Iter[801/953]	  loss: 0.65cifar10:0.4-instance | Epoch [ 37/ 75] Iter[851/953]	  loss: 0.45cifar10:0.4-instance | Epoch [ 37/ 75] Iter[901/953]	  loss: 0.51cifar10:0.4-instance | Epoch [ 37/ 75] Iter[951/953]	  loss: 0.52
| Test Epoch 37	 Accuracy: 82.68% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 38 | Accuracy on train set: 55.00% 
labeled data has a size of 30645, f-score: 0.933562
cifar10:0.4-instance | Epoch [ 38/ 75] Iter[  1/958]	  loss: 0.47cifar10:0.4-instance | Epoch [ 38/ 75] Iter[ 51/958]	  loss: 0.55cifar10:0.4-instance | Epoch [ 38/ 75] Iter[101/958]	  loss: 0.39cifar10:0.4-instance | Epoch [ 38/ 75] Iter[151/958]	  loss: 0.65cifar10:0.4-instance | Epoch [ 38/ 75] Iter[201/958]	  loss: 0.53cifar10:0.4-instance | Epoch [ 38/ 75] Iter[251/958]	  loss: 0.54cifar10:0.4-instance | Epoch [ 38/ 75] Iter[301/958]	  loss: 0.40cifar10:0.4-instance | Epoch [ 38/ 75] Iter[351/958]	  loss: 0.36cifar10:0.4-instance | Epoch [ 38/ 75] Iter[401/958]	  loss: 0.53cifar10:0.4-instance | Epoch [ 38/ 75] Iter[451/958]	  loss: 0.33cifar10:0.4-instance | Epoch [ 38/ 75] Iter[501/958]	  loss: 0.53cifar10:0.4-instance | Epoch [ 38/ 75] Iter[551/958]	  loss: 0.63cifar10:0.4-instance | Epoch [ 38/ 75] Iter[601/958]	  loss: 0.45cifar10:0.4-instance | Epoch [ 38/ 75] Iter[651/958]	  loss: 0.42cifar10:0.4-instance | Epoch [ 38/ 75] Iter[701/958]	  loss: 0.49cifar10:0.4-instance | Epoch [ 38/ 75] Iter[751/958]	  loss: 0.45cifar10:0.4-instance | Epoch [ 38/ 75] Iter[801/958]	  loss: 0.70cifar10:0.4-instance | Epoch [ 38/ 75] Iter[851/958]	  loss: 0.69cifar10:0.4-instance | Epoch [ 38/ 75] Iter[901/958]	  loss: 0.55cifar10:0.4-instance | Epoch [ 38/ 75] Iter[951/958]	  loss: 0.42
| Test Epoch 38	 Accuracy: 82.74% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 39 | Accuracy on train set: 55.27% 
labeled data has a size of 30710, f-score: 0.933800
cifar10:0.4-instance | Epoch [ 39/ 75] Iter[  1/960]	  loss: 0.46cifar10:0.4-instance | Epoch [ 39/ 75] Iter[ 51/960]	  loss: 0.37cifar10:0.4-instance | Epoch [ 39/ 75] Iter[101/960]	  loss: 0.43cifar10:0.4-instance | Epoch [ 39/ 75] Iter[151/960]	  loss: 0.71cifar10:0.4-instance | Epoch [ 39/ 75] Iter[201/960]	  loss: 0.49cifar10:0.4-instance | Epoch [ 39/ 75] Iter[251/960]	  loss: 0.56cifar10:0.4-instance | Epoch [ 39/ 75] Iter[301/960]	  loss: 0.49cifar10:0.4-instance | Epoch [ 39/ 75] Iter[351/960]	  loss: 0.47cifar10:0.4-instance | Epoch [ 39/ 75] Iter[401/960]	  loss: 0.42cifar10:0.4-instance | Epoch [ 39/ 75] Iter[451/960]	  loss: 0.25cifar10:0.4-instance | Epoch [ 39/ 75] Iter[501/960]	  loss: 0.29cifar10:0.4-instance | Epoch [ 39/ 75] Iter[551/960]	  loss: 0.27cifar10:0.4-instance | Epoch [ 39/ 75] Iter[601/960]	  loss: 0.45cifar10:0.4-instance | Epoch [ 39/ 75] Iter[651/960]	  loss: 0.42cifar10:0.4-instance | Epoch [ 39/ 75] Iter[701/960]	  loss: 0.72cifar10:0.4-instance | Epoch [ 39/ 75] Iter[751/960]	  loss: 0.56cifar10:0.4-instance | Epoch [ 39/ 75] Iter[801/960]	  loss: 0.47cifar10:0.4-instance | Epoch [ 39/ 75] Iter[851/960]	  loss: 0.41cifar10:0.4-instance | Epoch [ 39/ 75] Iter[901/960]	  loss: 0.42cifar10:0.4-instance | Epoch [ 39/ 75] Iter[951/960]	  loss: 0.37
| Test Epoch 39	 Accuracy: 83.51% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 40 | Accuracy on train set: 55.56% 
labeled data has a size of 30620, f-score: 0.933801
cifar10:0.4-instance | Epoch [ 40/ 75] Iter[  1/957]	  loss: 0.32cifar10:0.4-instance | Epoch [ 40/ 75] Iter[ 51/957]	  loss: 0.60cifar10:0.4-instance | Epoch [ 40/ 75] Iter[101/957]	  loss: 0.59cifar10:0.4-instance | Epoch [ 40/ 75] Iter[151/957]	  loss: 0.59cifar10:0.4-instance | Epoch [ 40/ 75] Iter[201/957]	  loss: 0.31cifar10:0.4-instance | Epoch [ 40/ 75] Iter[251/957]	  loss: 0.23cifar10:0.4-instance | Epoch [ 40/ 75] Iter[301/957]	  loss: 0.43cifar10:0.4-instance | Epoch [ 40/ 75] Iter[351/957]	  loss: 0.28cifar10:0.4-instance | Epoch [ 40/ 75] Iter[401/957]	  loss: 0.37cifar10:0.4-instance | Epoch [ 40/ 75] Iter[451/957]	  loss: 0.47cifar10:0.4-instance | Epoch [ 40/ 75] Iter[501/957]	  loss: 0.46cifar10:0.4-instance | Epoch [ 40/ 75] Iter[551/957]	  loss: 0.49cifar10:0.4-instance | Epoch [ 40/ 75] Iter[601/957]	  loss: 0.65cifar10:0.4-instance | Epoch [ 40/ 75] Iter[651/957]	  loss: 0.44cifar10:0.4-instance | Epoch [ 40/ 75] Iter[701/957]	  loss: 0.54cifar10:0.4-instance | Epoch [ 40/ 75] Iter[751/957]	  loss: 0.34cifar10:0.4-instance | Epoch [ 40/ 75] Iter[801/957]	  loss: 0.50cifar10:0.4-instance | Epoch [ 40/ 75] Iter[851/957]	  loss: 0.44cifar10:0.4-instance | Epoch [ 40/ 75] Iter[901/957]	  loss: 0.60cifar10:0.4-instance | Epoch [ 40/ 75] Iter[951/957]	  loss: 0.56
| Test Epoch 40	 Accuracy: 82.48% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 41 | Accuracy on train set: 54.72% 
labeled data has a size of 30620, f-score: 0.935075
cifar10:0.4-instance | Epoch [ 41/ 75] Iter[  1/957]	  loss: 0.47cifar10:0.4-instance | Epoch [ 41/ 75] Iter[ 51/957]	  loss: 0.42cifar10:0.4-instance | Epoch [ 41/ 75] Iter[101/957]	  loss: 0.46cifar10:0.4-instance | Epoch [ 41/ 75] Iter[151/957]	  loss: 0.45cifar10:0.4-instance | Epoch [ 41/ 75] Iter[201/957]	  loss: 0.41cifar10:0.4-instance | Epoch [ 41/ 75] Iter[251/957]	  loss: 0.35cifar10:0.4-instance | Epoch [ 41/ 75] Iter[301/957]	  loss: 0.43cifar10:0.4-instance | Epoch [ 41/ 75] Iter[351/957]	  loss: 0.35cifar10:0.4-instance | Epoch [ 41/ 75] Iter[401/957]	  loss: 0.50cifar10:0.4-instance | Epoch [ 41/ 75] Iter[451/957]	  loss: 0.59cifar10:0.4-instance | Epoch [ 41/ 75] Iter[501/957]	  loss: 0.46cifar10:0.4-instance | Epoch [ 41/ 75] Iter[551/957]	  loss: 0.30cifar10:0.4-instance | Epoch [ 41/ 75] Iter[601/957]	  loss: 0.56cifar10:0.4-instance | Epoch [ 41/ 75] Iter[651/957]	  loss: 0.42cifar10:0.4-instance | Epoch [ 41/ 75] Iter[701/957]	  loss: 0.66cifar10:0.4-instance | Epoch [ 41/ 75] Iter[751/957]	  loss: 0.54cifar10:0.4-instance | Epoch [ 41/ 75] Iter[801/957]	  loss: 0.47cifar10:0.4-instance | Epoch [ 41/ 75] Iter[851/957]	  loss: 0.59cifar10:0.4-instance | Epoch [ 41/ 75] Iter[901/957]	  loss: 0.59cifar10:0.4-instance | Epoch [ 41/ 75] Iter[951/957]	  loss: 0.45
| Test Epoch 41	 Accuracy: 82.95% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 42 | Accuracy on train set: 54.95% 
labeled data has a size of 30640, f-score: 0.937631
cifar10:0.4-instance | Epoch [ 42/ 75] Iter[  1/958]	  loss: 0.35cifar10:0.4-instance | Epoch [ 42/ 75] Iter[ 51/958]	  loss: 0.74cifar10:0.4-instance | Epoch [ 42/ 75] Iter[101/958]	  loss: 0.52cifar10:0.4-instance | Epoch [ 42/ 75] Iter[151/958]	  loss: 0.45cifar10:0.4-instance | Epoch [ 42/ 75] Iter[201/958]	  loss: 0.62cifar10:0.4-instance | Epoch [ 42/ 75] Iter[251/958]	  loss: 0.40cifar10:0.4-instance | Epoch [ 42/ 75] Iter[301/958]	  loss: 0.52cifar10:0.4-instance | Epoch [ 42/ 75] Iter[351/958]	  loss: 0.61cifar10:0.4-instance | Epoch [ 42/ 75] Iter[401/958]	  loss: 0.55cifar10:0.4-instance | Epoch [ 42/ 75] Iter[451/958]	  loss: 0.48cifar10:0.4-instance | Epoch [ 42/ 75] Iter[501/958]	  loss: 0.56cifar10:0.4-instance | Epoch [ 42/ 75] Iter[551/958]	  loss: 0.35cifar10:0.4-instance | Epoch [ 42/ 75] Iter[601/958]	  loss: 0.47cifar10:0.4-instance | Epoch [ 42/ 75] Iter[651/958]	  loss: 0.78cifar10:0.4-instance | Epoch [ 42/ 75] Iter[701/958]	  loss: 0.57cifar10:0.4-instance | Epoch [ 42/ 75] Iter[751/958]	  loss: 0.86cifar10:0.4-instance | Epoch [ 42/ 75] Iter[801/958]	  loss: 0.28cifar10:0.4-instance | Epoch [ 42/ 75] Iter[851/958]	  loss: 0.52cifar10:0.4-instance | Epoch [ 42/ 75] Iter[901/958]	  loss: 0.58cifar10:0.4-instance | Epoch [ 42/ 75] Iter[951/958]	  loss: 0.36
| Test Epoch 42	 Accuracy: 82.52% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 43 | Accuracy on train set: 54.49% 
labeled data has a size of 30535, f-score: 0.940331
cifar10:0.4-instance | Epoch [ 43/ 75] Iter[  1/955]	  loss: 0.44cifar10:0.4-instance | Epoch [ 43/ 75] Iter[ 51/955]	  loss: 0.31cifar10:0.4-instance | Epoch [ 43/ 75] Iter[101/955]	  loss: 0.38cifar10:0.4-instance | Epoch [ 43/ 75] Iter[151/955]	  loss: 0.53cifar10:0.4-instance | Epoch [ 43/ 75] Iter[201/955]	  loss: 0.38cifar10:0.4-instance | Epoch [ 43/ 75] Iter[251/955]	  loss: 0.75cifar10:0.4-instance | Epoch [ 43/ 75] Iter[301/955]	  loss: 0.53cifar10:0.4-instance | Epoch [ 43/ 75] Iter[351/955]	  loss: 0.53cifar10:0.4-instance | Epoch [ 43/ 75] Iter[401/955]	  loss: 0.55cifar10:0.4-instance | Epoch [ 43/ 75] Iter[451/955]	  loss: 0.42cifar10:0.4-instance | Epoch [ 43/ 75] Iter[501/955]	  loss: 0.39cifar10:0.4-instance | Epoch [ 43/ 75] Iter[551/955]	  loss: 0.56cifar10:0.4-instance | Epoch [ 43/ 75] Iter[601/955]	  loss: 0.43cifar10:0.4-instance | Epoch [ 43/ 75] Iter[651/955]	  loss: 0.57cifar10:0.4-instance | Epoch [ 43/ 75] Iter[701/955]	  loss: 0.54cifar10:0.4-instance | Epoch [ 43/ 75] Iter[751/955]	  loss: 0.47cifar10:0.4-instance | Epoch [ 43/ 75] Iter[801/955]	  loss: 0.42cifar10:0.4-instance | Epoch [ 43/ 75] Iter[851/955]	  loss: 0.44cifar10:0.4-instance | Epoch [ 43/ 75] Iter[901/955]	  loss: 1.02cifar10:0.4-instance | Epoch [ 43/ 75] Iter[951/955]	  loss: 0.75
| Test Epoch 43	 Accuracy: 83.43% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 44 | Accuracy on train set: 54.99% 
labeled data has a size of 30518, f-score: 0.942788
cifar10:0.4-instance | Epoch [ 44/ 75] Iter[  1/954]	  loss: 0.37cifar10:0.4-instance | Epoch [ 44/ 75] Iter[ 51/954]	  loss: 0.58cifar10:0.4-instance | Epoch [ 44/ 75] Iter[101/954]	  loss: 0.43cifar10:0.4-instance | Epoch [ 44/ 75] Iter[151/954]	  loss: 0.50cifar10:0.4-instance | Epoch [ 44/ 75] Iter[201/954]	  loss: 0.36cifar10:0.4-instance | Epoch [ 44/ 75] Iter[251/954]	  loss: 0.65cifar10:0.4-instance | Epoch [ 44/ 75] Iter[301/954]	  loss: 0.40cifar10:0.4-instance | Epoch [ 44/ 75] Iter[351/954]	  loss: 0.34cifar10:0.4-instance | Epoch [ 44/ 75] Iter[401/954]	  loss: 0.59cifar10:0.4-instance | Epoch [ 44/ 75] Iter[451/954]	  loss: 0.41cifar10:0.4-instance | Epoch [ 44/ 75] Iter[501/954]	  loss: 0.54cifar10:0.4-instance | Epoch [ 44/ 75] Iter[551/954]	  loss: 0.79cifar10:0.4-instance | Epoch [ 44/ 75] Iter[601/954]	  loss: 0.68cifar10:0.4-instance | Epoch [ 44/ 75] Iter[651/954]	  loss: 0.45cifar10:0.4-instance | Epoch [ 44/ 75] Iter[701/954]	  loss: 0.66cifar10:0.4-instance | Epoch [ 44/ 75] Iter[751/954]	  loss: 0.42cifar10:0.4-instance | Epoch [ 44/ 75] Iter[801/954]	  loss: 0.43cifar10:0.4-instance | Epoch [ 44/ 75] Iter[851/954]	  loss: 0.34cifar10:0.4-instance | Epoch [ 44/ 75] Iter[901/954]	  loss: 0.65cifar10:0.4-instance | Epoch [ 44/ 75] Iter[951/954]	  loss: 0.36
| Test Epoch 44	 Accuracy: 83.30% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 45 | Accuracy on train set: 55.59% 
labeled data has a size of 30627, f-score: 0.939563
cifar10:0.4-instance | Epoch [ 45/ 75] Iter[  1/958]	  loss: 0.44cifar10:0.4-instance | Epoch [ 45/ 75] Iter[ 51/958]	  loss: 0.59cifar10:0.4-instance | Epoch [ 45/ 75] Iter[101/958]	  loss: 0.45cifar10:0.4-instance | Epoch [ 45/ 75] Iter[151/958]	  loss: 0.42cifar10:0.4-instance | Epoch [ 45/ 75] Iter[201/958]	  loss: 0.23cifar10:0.4-instance | Epoch [ 45/ 75] Iter[251/958]	  loss: 0.63cifar10:0.4-instance | Epoch [ 45/ 75] Iter[301/958]	  loss: 0.51cifar10:0.4-instance | Epoch [ 45/ 75] Iter[351/958]	  loss: 0.67cifar10:0.4-instance | Epoch [ 45/ 75] Iter[401/958]	  loss: 0.67cifar10:0.4-instance | Epoch [ 45/ 75] Iter[451/958]	  loss: 0.36cifar10:0.4-instance | Epoch [ 45/ 75] Iter[501/958]	  loss: 0.38cifar10:0.4-instance | Epoch [ 45/ 75] Iter[551/958]	  loss: 0.52cifar10:0.4-instance | Epoch [ 45/ 75] Iter[601/958]	  loss: 0.47cifar10:0.4-instance | Epoch [ 45/ 75] Iter[651/958]	  loss: 0.36cifar10:0.4-instance | Epoch [ 45/ 75] Iter[701/958]	  loss: 0.53cifar10:0.4-instance | Epoch [ 45/ 75] Iter[751/958]	  loss: 0.64cifar10:0.4-instance | Epoch [ 45/ 75] Iter[801/958]	  loss: 0.36cifar10:0.4-instance | Epoch [ 45/ 75] Iter[851/958]	  loss: 0.54cifar10:0.4-instance | Epoch [ 45/ 75] Iter[901/958]	  loss: 0.37cifar10:0.4-instance | Epoch [ 45/ 75] Iter[951/958]	  loss: 0.52
| Test Epoch 45	 Accuracy: 82.38% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 46 | Accuracy on train set: 54.73% 
labeled data has a size of 30746, f-score: 0.936057
cifar10:0.4-instance | Epoch [ 46/ 75] Iter[  1/961]	  loss: 0.37cifar10:0.4-instance | Epoch [ 46/ 75] Iter[ 51/961]	  loss: 0.61cifar10:0.4-instance | Epoch [ 46/ 75] Iter[101/961]	  loss: 0.62cifar10:0.4-instance | Epoch [ 46/ 75] Iter[151/961]	  loss: 0.47cifar10:0.4-instance | Epoch [ 46/ 75] Iter[201/961]	  loss: 0.35cifar10:0.4-instance | Epoch [ 46/ 75] Iter[251/961]	  loss: 0.52cifar10:0.4-instance | Epoch [ 46/ 75] Iter[301/961]	  loss: 0.39cifar10:0.4-instance | Epoch [ 46/ 75] Iter[351/961]	  loss: 0.41cifar10:0.4-instance | Epoch [ 46/ 75] Iter[401/961]	  loss: 0.58cifar10:0.4-instance | Epoch [ 46/ 75] Iter[451/961]	  loss: 0.49cifar10:0.4-instance | Epoch [ 46/ 75] Iter[501/961]	  loss: 0.37cifar10:0.4-instance | Epoch [ 46/ 75] Iter[551/961]	  loss: 0.55cifar10:0.4-instance | Epoch [ 46/ 75] Iter[601/961]	  loss: 0.38cifar10:0.4-instance | Epoch [ 46/ 75] Iter[651/961]	  loss: 0.47cifar10:0.4-instance | Epoch [ 46/ 75] Iter[701/961]	  loss: 0.33cifar10:0.4-instance | Epoch [ 46/ 75] Iter[751/961]	  loss: 0.44cifar10:0.4-instance | Epoch [ 46/ 75] Iter[801/961]	  loss: 0.52cifar10:0.4-instance | Epoch [ 46/ 75] Iter[851/961]	  loss: 0.54cifar10:0.4-instance | Epoch [ 46/ 75] Iter[901/961]	  loss: 0.58cifar10:0.4-instance | Epoch [ 46/ 75] Iter[951/961]	  loss: 0.59
| Test Epoch 46	 Accuracy: 82.97% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 47 | Accuracy on train set: 55.32% 
labeled data has a size of 30844, f-score: 0.934736
cifar10:0.4-instance | Epoch [ 47/ 75] Iter[  1/964]	  loss: 0.31cifar10:0.4-instance | Epoch [ 47/ 75] Iter[ 51/964]	  loss: 0.33cifar10:0.4-instance | Epoch [ 47/ 75] Iter[101/964]	  loss: 0.44cifar10:0.4-instance | Epoch [ 47/ 75] Iter[151/964]	  loss: 0.49cifar10:0.4-instance | Epoch [ 47/ 75] Iter[201/964]	  loss: 0.40cifar10:0.4-instance | Epoch [ 47/ 75] Iter[251/964]	  loss: 0.42cifar10:0.4-instance | Epoch [ 47/ 75] Iter[301/964]	  loss: 0.37cifar10:0.4-instance | Epoch [ 47/ 75] Iter[351/964]	  loss: 0.47cifar10:0.4-instance | Epoch [ 47/ 75] Iter[401/964]	  loss: 0.44cifar10:0.4-instance | Epoch [ 47/ 75] Iter[451/964]	  loss: 0.43cifar10:0.4-instance | Epoch [ 47/ 75] Iter[501/964]	  loss: 0.52cifar10:0.4-instance | Epoch [ 47/ 75] Iter[551/964]	  loss: 0.64cifar10:0.4-instance | Epoch [ 47/ 75] Iter[601/964]	  loss: 0.66cifar10:0.4-instance | Epoch [ 47/ 75] Iter[651/964]	  loss: 0.43cifar10:0.4-instance | Epoch [ 47/ 75] Iter[701/964]	  loss: 0.47cifar10:0.4-instance | Epoch [ 47/ 75] Iter[751/964]	  loss: 0.29cifar10:0.4-instance | Epoch [ 47/ 75] Iter[801/964]	  loss: 0.41cifar10:0.4-instance | Epoch [ 47/ 75] Iter[851/964]	  loss: 0.48cifar10:0.4-instance | Epoch [ 47/ 75] Iter[901/964]	  loss: 0.39cifar10:0.4-instance | Epoch [ 47/ 75] Iter[951/964]	  loss: 0.55
| Test Epoch 47	 Accuracy: 82.80% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 48 | Accuracy on train set: 55.17% 
labeled data has a size of 30616, f-score: 0.938594
cifar10:0.4-instance | Epoch [ 48/ 75] Iter[  1/957]	  loss: 0.42cifar10:0.4-instance | Epoch [ 48/ 75] Iter[ 51/957]	  loss: 0.44cifar10:0.4-instance | Epoch [ 48/ 75] Iter[101/957]	  loss: 0.42cifar10:0.4-instance | Epoch [ 48/ 75] Iter[151/957]	  loss: 0.38cifar10:0.4-instance | Epoch [ 48/ 75] Iter[201/957]	  loss: 0.58cifar10:0.4-instance | Epoch [ 48/ 75] Iter[251/957]	  loss: 0.54cifar10:0.4-instance | Epoch [ 48/ 75] Iter[301/957]	  loss: 0.45cifar10:0.4-instance | Epoch [ 48/ 75] Iter[351/957]	  loss: 0.45cifar10:0.4-instance | Epoch [ 48/ 75] Iter[401/957]	  loss: 0.27cifar10:0.4-instance | Epoch [ 48/ 75] Iter[451/957]	  loss: 0.38cifar10:0.4-instance | Epoch [ 48/ 75] Iter[501/957]	  loss: 0.40cifar10:0.4-instance | Epoch [ 48/ 75] Iter[551/957]	  loss: 0.75cifar10:0.4-instance | Epoch [ 48/ 75] Iter[601/957]	  loss: 0.39cifar10:0.4-instance | Epoch [ 48/ 75] Iter[651/957]	  loss: 0.39cifar10:0.4-instance | Epoch [ 48/ 75] Iter[701/957]	  loss: 0.49cifar10:0.4-instance | Epoch [ 48/ 75] Iter[751/957]	  loss: 0.69cifar10:0.4-instance | Epoch [ 48/ 75] Iter[801/957]	  loss: 0.49cifar10:0.4-instance | Epoch [ 48/ 75] Iter[851/957]	  loss: 0.68cifar10:0.4-instance | Epoch [ 48/ 75] Iter[901/957]	  loss: 0.51cifar10:0.4-instance | Epoch [ 48/ 75] Iter[951/957]	  loss: 0.52
| Test Epoch 48	 Accuracy: 81.71% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 49 | Accuracy on train set: 54.56% 
labeled data has a size of 30566, f-score: 0.939475
cifar10:0.4-instance | Epoch [ 49/ 75] Iter[  1/956]	  loss: 0.37cifar10:0.4-instance | Epoch [ 49/ 75] Iter[ 51/956]	  loss: 0.28cifar10:0.4-instance | Epoch [ 49/ 75] Iter[101/956]	  loss: 0.54cifar10:0.4-instance | Epoch [ 49/ 75] Iter[151/956]	  loss: 0.40cifar10:0.4-instance | Epoch [ 49/ 75] Iter[201/956]	  loss: 0.33cifar10:0.4-instance | Epoch [ 49/ 75] Iter[251/956]	  loss: 0.45cifar10:0.4-instance | Epoch [ 49/ 75] Iter[301/956]	  loss: 0.44cifar10:0.4-instance | Epoch [ 49/ 75] Iter[351/956]	  loss: 0.39cifar10:0.4-instance | Epoch [ 49/ 75] Iter[401/956]	  loss: 0.27cifar10:0.4-instance | Epoch [ 49/ 75] Iter[451/956]	  loss: 0.58cifar10:0.4-instance | Epoch [ 49/ 75] Iter[501/956]	  loss: 0.51cifar10:0.4-instance | Epoch [ 49/ 75] Iter[551/956]	  loss: 0.34cifar10:0.4-instance | Epoch [ 49/ 75] Iter[601/956]	  loss: 0.51cifar10:0.4-instance | Epoch [ 49/ 75] Iter[651/956]	  loss: 0.48cifar10:0.4-instance | Epoch [ 49/ 75] Iter[701/956]	  loss: 0.44cifar10:0.4-instance | Epoch [ 49/ 75] Iter[751/956]	  loss: 0.48cifar10:0.4-instance | Epoch [ 49/ 75] Iter[801/956]	  loss: 0.40cifar10:0.4-instance | Epoch [ 49/ 75] Iter[851/956]	  loss: 0.82cifar10:0.4-instance | Epoch [ 49/ 75] Iter[901/956]	  loss: 0.42cifar10:0.4-instance | Epoch [ 49/ 75] Iter[951/956]	  loss: 0.32
| Test Epoch 49	 Accuracy: 82.14% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 50 | Accuracy on train set: 55.14% 
labeled data has a size of 30530, f-score: 0.937013
cifar10:0.4-instance | Epoch [ 50/ 75] Iter[  1/955]	  loss: 0.39cifar10:0.4-instance | Epoch [ 50/ 75] Iter[ 51/955]	  loss: 0.31cifar10:0.4-instance | Epoch [ 50/ 75] Iter[101/955]	  loss: 0.36cifar10:0.4-instance | Epoch [ 50/ 75] Iter[151/955]	  loss: 0.41cifar10:0.4-instance | Epoch [ 50/ 75] Iter[201/955]	  loss: 0.40cifar10:0.4-instance | Epoch [ 50/ 75] Iter[251/955]	  loss: 0.44cifar10:0.4-instance | Epoch [ 50/ 75] Iter[301/955]	  loss: 0.67cifar10:0.4-instance | Epoch [ 50/ 75] Iter[351/955]	  loss: 0.35cifar10:0.4-instance | Epoch [ 50/ 75] Iter[401/955]	  loss: 0.66cifar10:0.4-instance | Epoch [ 50/ 75] Iter[451/955]	  loss: 0.40cifar10:0.4-instance | Epoch [ 50/ 75] Iter[501/955]	  loss: 0.54cifar10:0.4-instance | Epoch [ 50/ 75] Iter[551/955]	  loss: 0.79cifar10:0.4-instance | Epoch [ 50/ 75] Iter[601/955]	  loss: 0.31cifar10:0.4-instance | Epoch [ 50/ 75] Iter[651/955]	  loss: 0.57cifar10:0.4-instance | Epoch [ 50/ 75] Iter[701/955]	  loss: 0.29cifar10:0.4-instance | Epoch [ 50/ 75] Iter[751/955]	  loss: 0.43cifar10:0.4-instance | Epoch [ 50/ 75] Iter[801/955]	  loss: 0.51cifar10:0.4-instance | Epoch [ 50/ 75] Iter[851/955]	  loss: 0.49cifar10:0.4-instance | Epoch [ 50/ 75] Iter[901/955]	  loss: 0.38cifar10:0.4-instance | Epoch [ 50/ 75] Iter[951/955]	  loss: 0.27
| Test Epoch 50	 Accuracy: 82.43% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 51 | Accuracy on train set: 54.93% 
labeled data has a size of 30813, f-score: 0.929218
cifar10:0.4-instance | Epoch [ 51/ 75] Iter[  1/963]	  loss: 0.61cifar10:0.4-instance | Epoch [ 51/ 75] Iter[ 51/963]	  loss: 0.80cifar10:0.4-instance | Epoch [ 51/ 75] Iter[101/963]	  loss: 0.33cifar10:0.4-instance | Epoch [ 51/ 75] Iter[151/963]	  loss: 0.59cifar10:0.4-instance | Epoch [ 51/ 75] Iter[201/963]	  loss: 0.54cifar10:0.4-instance | Epoch [ 51/ 75] Iter[251/963]	  loss: 0.35cifar10:0.4-instance | Epoch [ 51/ 75] Iter[301/963]	  loss: 0.69cifar10:0.4-instance | Epoch [ 51/ 75] Iter[351/963]	  loss: 0.43cifar10:0.4-instance | Epoch [ 51/ 75] Iter[401/963]	  loss: 0.44cifar10:0.4-instance | Epoch [ 51/ 75] Iter[451/963]	  loss: 0.64cifar10:0.4-instance | Epoch [ 51/ 75] Iter[501/963]	  loss: 0.33cifar10:0.4-instance | Epoch [ 51/ 75] Iter[551/963]	  loss: 0.35cifar10:0.4-instance | Epoch [ 51/ 75] Iter[601/963]	  loss: 0.68cifar10:0.4-instance | Epoch [ 51/ 75] Iter[651/963]	  loss: 0.34cifar10:0.4-instance | Epoch [ 51/ 75] Iter[701/963]	  loss: 0.87cifar10:0.4-instance | Epoch [ 51/ 75] Iter[751/963]	  loss: 0.58cifar10:0.4-instance | Epoch [ 51/ 75] Iter[801/963]	  loss: 0.27cifar10:0.4-instance | Epoch [ 51/ 75] Iter[851/963]	  loss: 0.49cifar10:0.4-instance | Epoch [ 51/ 75] Iter[901/963]	  loss: 0.38cifar10:0.4-instance | Epoch [ 51/ 75] Iter[951/963]	  loss: 0.30
| Test Epoch 51	 Accuracy: 82.90% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 52 | Accuracy on train set: 55.50% 
labeled data has a size of 30958, f-score: 0.931197
cifar10:0.4-instance | Epoch [ 52/ 75] Iter[  1/968]	  loss: 0.48cifar10:0.4-instance | Epoch [ 52/ 75] Iter[ 51/968]	  loss: 0.51cifar10:0.4-instance | Epoch [ 52/ 75] Iter[101/968]	  loss: 0.45cifar10:0.4-instance | Epoch [ 52/ 75] Iter[151/968]	  loss: 0.49cifar10:0.4-instance | Epoch [ 52/ 75] Iter[201/968]	  loss: 0.35cifar10:0.4-instance | Epoch [ 52/ 75] Iter[251/968]	  loss: 0.46cifar10:0.4-instance | Epoch [ 52/ 75] Iter[301/968]	  loss: 0.56cifar10:0.4-instance | Epoch [ 52/ 75] Iter[351/968]	  loss: 0.44cifar10:0.4-instance | Epoch [ 52/ 75] Iter[401/968]	  loss: 0.66cifar10:0.4-instance | Epoch [ 52/ 75] Iter[451/968]	  loss: 0.58cifar10:0.4-instance | Epoch [ 52/ 75] Iter[501/968]	  loss: 0.53cifar10:0.4-instance | Epoch [ 52/ 75] Iter[551/968]	  loss: 0.57cifar10:0.4-instance | Epoch [ 52/ 75] Iter[601/968]	  loss: 0.31cifar10:0.4-instance | Epoch [ 52/ 75] Iter[651/968]	  loss: 0.44cifar10:0.4-instance | Epoch [ 52/ 75] Iter[701/968]	  loss: 0.42cifar10:0.4-instance | Epoch [ 52/ 75] Iter[751/968]	  loss: 0.54cifar10:0.4-instance | Epoch [ 52/ 75] Iter[801/968]	  loss: 0.47cifar10:0.4-instance | Epoch [ 52/ 75] Iter[851/968]	  loss: 0.64cifar10:0.4-instance | Epoch [ 52/ 75] Iter[901/968]	  loss: 0.67cifar10:0.4-instance | Epoch [ 52/ 75] Iter[951/968]	  loss: 0.38
| Test Epoch 52	 Accuracy: 82.66% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 53 | Accuracy on train set: 54.77% 
labeled data has a size of 30932, f-score: 0.932723
cifar10:0.4-instance | Epoch [ 53/ 75] Iter[  1/967]	  loss: 0.47cifar10:0.4-instance | Epoch [ 53/ 75] Iter[ 51/967]	  loss: 0.38cifar10:0.4-instance | Epoch [ 53/ 75] Iter[101/967]	  loss: 0.47cifar10:0.4-instance | Epoch [ 53/ 75] Iter[151/967]	  loss: 0.39cifar10:0.4-instance | Epoch [ 53/ 75] Iter[201/967]	  loss: 0.50cifar10:0.4-instance | Epoch [ 53/ 75] Iter[251/967]	  loss: 0.37cifar10:0.4-instance | Epoch [ 53/ 75] Iter[301/967]	  loss: 0.47cifar10:0.4-instance | Epoch [ 53/ 75] Iter[351/967]	  loss: 0.35cifar10:0.4-instance | Epoch [ 53/ 75] Iter[401/967]	  loss: 0.60cifar10:0.4-instance | Epoch [ 53/ 75] Iter[451/967]	  loss: 0.45cifar10:0.4-instance | Epoch [ 53/ 75] Iter[501/967]	  loss: 0.78cifar10:0.4-instance | Epoch [ 53/ 75] Iter[551/967]	  loss: 0.20cifar10:0.4-instance | Epoch [ 53/ 75] Iter[601/967]	  loss: 0.46cifar10:0.4-instance | Epoch [ 53/ 75] Iter[651/967]	  loss: 0.59cifar10:0.4-instance | Epoch [ 53/ 75] Iter[701/967]	  loss: 0.34cifar10:0.4-instance | Epoch [ 53/ 75] Iter[751/967]	  loss: 0.69cifar10:0.4-instance | Epoch [ 53/ 75] Iter[801/967]	  loss: 0.44cifar10:0.4-instance | Epoch [ 53/ 75] Iter[851/967]	  loss: 0.34cifar10:0.4-instance | Epoch [ 53/ 75] Iter[901/967]	  loss: 0.48cifar10:0.4-instance | Epoch [ 53/ 75] Iter[951/967]	  loss: 0.76
| Test Epoch 53	 Accuracy: 81.93% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 54 | Accuracy on train set: 54.58% 
labeled data has a size of 31022, f-score: 0.932016
cifar10:0.4-instance | Epoch [ 54/ 75] Iter[  1/970]	  loss: 0.38cifar10:0.4-instance | Epoch [ 54/ 75] Iter[ 51/970]	  loss: 0.38cifar10:0.4-instance | Epoch [ 54/ 75] Iter[101/970]	  loss: 0.35cifar10:0.4-instance | Epoch [ 54/ 75] Iter[151/970]	  loss: 0.52cifar10:0.4-instance | Epoch [ 54/ 75] Iter[201/970]	  loss: 0.46cifar10:0.4-instance | Epoch [ 54/ 75] Iter[251/970]	  loss: 0.45cifar10:0.4-instance | Epoch [ 54/ 75] Iter[301/970]	  loss: 0.34cifar10:0.4-instance | Epoch [ 54/ 75] Iter[351/970]	  loss: 0.39cifar10:0.4-instance | Epoch [ 54/ 75] Iter[401/970]	  loss: 0.37cifar10:0.4-instance | Epoch [ 54/ 75] Iter[451/970]	  loss: 0.46cifar10:0.4-instance | Epoch [ 54/ 75] Iter[501/970]	  loss: 0.56cifar10:0.4-instance | Epoch [ 54/ 75] Iter[551/970]	  loss: 0.62cifar10:0.4-instance | Epoch [ 54/ 75] Iter[601/970]	  loss: 0.32cifar10:0.4-instance | Epoch [ 54/ 75] Iter[651/970]	  loss: 0.50cifar10:0.4-instance | Epoch [ 54/ 75] Iter[701/970]	  loss: 0.40cifar10:0.4-instance | Epoch [ 54/ 75] Iter[751/970]	  loss: 0.72cifar10:0.4-instance | Epoch [ 54/ 75] Iter[801/970]	  loss: 0.46cifar10:0.4-instance | Epoch [ 54/ 75] Iter[851/970]	  loss: 0.67cifar10:0.4-instance | Epoch [ 54/ 75] Iter[901/970]	  loss: 0.65cifar10:0.4-instance | Epoch [ 54/ 75] Iter[951/970]	  loss: 0.78
| Test Epoch 54	 Accuracy: 82.93% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 55 | Accuracy on train set: 55.35% 
labeled data has a size of 30971, f-score: 0.928546
cifar10:0.4-instance | Epoch [ 55/ 75] Iter[  1/968]	  loss: 0.41cifar10:0.4-instance | Epoch [ 55/ 75] Iter[ 51/968]	  loss: 0.53cifar10:0.4-instance | Epoch [ 55/ 75] Iter[101/968]	  loss: 0.47cifar10:0.4-instance | Epoch [ 55/ 75] Iter[151/968]	  loss: 0.52cifar10:0.4-instance | Epoch [ 55/ 75] Iter[201/968]	  loss: 0.54cifar10:0.4-instance | Epoch [ 55/ 75] Iter[251/968]	  loss: 0.78cifar10:0.4-instance | Epoch [ 55/ 75] Iter[301/968]	  loss: 0.70cifar10:0.4-instance | Epoch [ 55/ 75] Iter[351/968]	  loss: 0.42cifar10:0.4-instance | Epoch [ 55/ 75] Iter[401/968]	  loss: 0.65cifar10:0.4-instance | Epoch [ 55/ 75] Iter[451/968]	  loss: 0.47cifar10:0.4-instance | Epoch [ 55/ 75] Iter[501/968]	  loss: 0.32cifar10:0.4-instance | Epoch [ 55/ 75] Iter[551/968]	  loss: 0.39cifar10:0.4-instance | Epoch [ 55/ 75] Iter[601/968]	  loss: 0.79cifar10:0.4-instance | Epoch [ 55/ 75] Iter[651/968]	  loss: 0.48cifar10:0.4-instance | Epoch [ 55/ 75] Iter[701/968]	  loss: 0.62cifar10:0.4-instance | Epoch [ 55/ 75] Iter[751/968]	  loss: 0.33cifar10:0.4-instance | Epoch [ 55/ 75] Iter[801/968]	  loss: 0.49cifar10:0.4-instance | Epoch [ 55/ 75] Iter[851/968]	  loss: 0.57cifar10:0.4-instance | Epoch [ 55/ 75] Iter[901/968]	  loss: 0.49cifar10:0.4-instance | Epoch [ 55/ 75] Iter[951/968]	  loss: 0.43
| Test Epoch 55	 Accuracy: 83.59% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 56 | Accuracy on train set: 56.28% 
labeled data has a size of 31061, f-score: 0.926789
cifar10:0.4-instance | Epoch [ 56/ 75] Iter[  1/971]	  loss: 0.40cifar10:0.4-instance | Epoch [ 56/ 75] Iter[ 51/971]	  loss: 0.42cifar10:0.4-instance | Epoch [ 56/ 75] Iter[101/971]	  loss: 0.47cifar10:0.4-instance | Epoch [ 56/ 75] Iter[151/971]	  loss: 0.37cifar10:0.4-instance | Epoch [ 56/ 75] Iter[201/971]	  loss: 0.52cifar10:0.4-instance | Epoch [ 56/ 75] Iter[251/971]	  loss: 0.42cifar10:0.4-instance | Epoch [ 56/ 75] Iter[301/971]	  loss: 0.47cifar10:0.4-instance | Epoch [ 56/ 75] Iter[351/971]	  loss: 0.42cifar10:0.4-instance | Epoch [ 56/ 75] Iter[401/971]	  loss: 0.36cifar10:0.4-instance | Epoch [ 56/ 75] Iter[451/971]	  loss: 0.75cifar10:0.4-instance | Epoch [ 56/ 75] Iter[501/971]	  loss: 0.25cifar10:0.4-instance | Epoch [ 56/ 75] Iter[551/971]	  loss: 0.70cifar10:0.4-instance | Epoch [ 56/ 75] Iter[601/971]	  loss: 0.63cifar10:0.4-instance | Epoch [ 56/ 75] Iter[651/971]	  loss: 0.41cifar10:0.4-instance | Epoch [ 56/ 75] Iter[701/971]	  loss: 0.67cifar10:0.4-instance | Epoch [ 56/ 75] Iter[751/971]	  loss: 0.61cifar10:0.4-instance | Epoch [ 56/ 75] Iter[801/971]	  loss: 0.37cifar10:0.4-instance | Epoch [ 56/ 75] Iter[851/971]	  loss: 0.36cifar10:0.4-instance | Epoch [ 56/ 75] Iter[901/971]	  loss: 0.52cifar10:0.4-instance | Epoch [ 56/ 75] Iter[951/971]	  loss: 0.35
| Test Epoch 56	 Accuracy: 83.05% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 57 | Accuracy on train set: 55.40% 
labeled data has a size of 31068, f-score: 0.927997
cifar10:0.4-instance | Epoch [ 57/ 75] Iter[  1/971]	  loss: 0.37cifar10:0.4-instance | Epoch [ 57/ 75] Iter[ 51/971]	  loss: 0.53cifar10:0.4-instance | Epoch [ 57/ 75] Iter[101/971]	  loss: 0.35cifar10:0.4-instance | Epoch [ 57/ 75] Iter[151/971]	  loss: 0.38cifar10:0.4-instance | Epoch [ 57/ 75] Iter[201/971]	  loss: 0.20cifar10:0.4-instance | Epoch [ 57/ 75] Iter[251/971]	  loss: 0.41cifar10:0.4-instance | Epoch [ 57/ 75] Iter[301/971]	  loss: 0.35cifar10:0.4-instance | Epoch [ 57/ 75] Iter[351/971]	  loss: 0.34cifar10:0.4-instance | Epoch [ 57/ 75] Iter[401/971]	  loss: 0.59cifar10:0.4-instance | Epoch [ 57/ 75] Iter[451/971]	  loss: 0.46cifar10:0.4-instance | Epoch [ 57/ 75] Iter[501/971]	  loss: 0.54cifar10:0.4-instance | Epoch [ 57/ 75] Iter[551/971]	  loss: 0.50cifar10:0.4-instance | Epoch [ 57/ 75] Iter[601/971]	  loss: 0.47cifar10:0.4-instance | Epoch [ 57/ 75] Iter[651/971]	  loss: 0.57cifar10:0.4-instance | Epoch [ 57/ 75] Iter[701/971]	  loss: 0.40cifar10:0.4-instance | Epoch [ 57/ 75] Iter[751/971]	  loss: 0.53cifar10:0.4-instance | Epoch [ 57/ 75] Iter[801/971]	  loss: 0.67cifar10:0.4-instance | Epoch [ 57/ 75] Iter[851/971]	  loss: 0.40cifar10:0.4-instance | Epoch [ 57/ 75] Iter[901/971]	  loss: 0.50cifar10:0.4-instance | Epoch [ 57/ 75] Iter[951/971]	  loss: 0.43
| Test Epoch 57	 Accuracy: 83.81% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 58 | Accuracy on train set: 55.73% 
labeled data has a size of 30936, f-score: 0.931827
cifar10:0.4-instance | Epoch [ 58/ 75] Iter[  1/967]	  loss: 0.42cifar10:0.4-instance | Epoch [ 58/ 75] Iter[ 51/967]	  loss: 0.43cifar10:0.4-instance | Epoch [ 58/ 75] Iter[101/967]	  loss: 0.56cifar10:0.4-instance | Epoch [ 58/ 75] Iter[151/967]	  loss: 0.22cifar10:0.4-instance | Epoch [ 58/ 75] Iter[201/967]	  loss: 0.39cifar10:0.4-instance | Epoch [ 58/ 75] Iter[251/967]	  loss: 0.32cifar10:0.4-instance | Epoch [ 58/ 75] Iter[301/967]	  loss: 0.55cifar10:0.4-instance | Epoch [ 58/ 75] Iter[351/967]	  loss: 0.52cifar10:0.4-instance | Epoch [ 58/ 75] Iter[401/967]	  loss: 0.33cifar10:0.4-instance | Epoch [ 58/ 75] Iter[451/967]	  loss: 0.51cifar10:0.4-instance | Epoch [ 58/ 75] Iter[501/967]	  loss: 0.58cifar10:0.4-instance | Epoch [ 58/ 75] Iter[551/967]	  loss: 0.68cifar10:0.4-instance | Epoch [ 58/ 75] Iter[601/967]	  loss: 0.55cifar10:0.4-instance | Epoch [ 58/ 75] Iter[651/967]	  loss: 0.32cifar10:0.4-instance | Epoch [ 58/ 75] Iter[701/967]	  loss: 0.40cifar10:0.4-instance | Epoch [ 58/ 75] Iter[751/967]	  loss: 0.42cifar10:0.4-instance | Epoch [ 58/ 75] Iter[801/967]	  loss: 0.33cifar10:0.4-instance | Epoch [ 58/ 75] Iter[851/967]	  loss: 0.59cifar10:0.4-instance | Epoch [ 58/ 75] Iter[901/967]	  loss: 0.38cifar10:0.4-instance | Epoch [ 58/ 75] Iter[951/967]	  loss: 0.33
| Test Epoch 58	 Accuracy: 83.83% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 59 | Accuracy on train set: 55.67% 
labeled data has a size of 30863, f-score: 0.935295
cifar10:0.4-instance | Epoch [ 59/ 75] Iter[  1/965]	  loss: 0.44cifar10:0.4-instance | Epoch [ 59/ 75] Iter[ 51/965]	  loss: 0.30cifar10:0.4-instance | Epoch [ 59/ 75] Iter[101/965]	  loss: 0.26cifar10:0.4-instance | Epoch [ 59/ 75] Iter[151/965]	  loss: 0.56cifar10:0.4-instance | Epoch [ 59/ 75] Iter[201/965]	  loss: 0.48cifar10:0.4-instance | Epoch [ 59/ 75] Iter[251/965]	  loss: 0.25cifar10:0.4-instance | Epoch [ 59/ 75] Iter[301/965]	  loss: 0.56cifar10:0.4-instance | Epoch [ 59/ 75] Iter[351/965]	  loss: 0.38cifar10:0.4-instance | Epoch [ 59/ 75] Iter[401/965]	  loss: 0.32cifar10:0.4-instance | Epoch [ 59/ 75] Iter[451/965]	  loss: 0.44cifar10:0.4-instance | Epoch [ 59/ 75] Iter[501/965]	  loss: 0.50cifar10:0.4-instance | Epoch [ 59/ 75] Iter[551/965]	  loss: 0.68cifar10:0.4-instance | Epoch [ 59/ 75] Iter[601/965]	  loss: 0.61cifar10:0.4-instance | Epoch [ 59/ 75] Iter[651/965]	  loss: 0.52cifar10:0.4-instance | Epoch [ 59/ 75] Iter[701/965]	  loss: 0.26cifar10:0.4-instance | Epoch [ 59/ 75] Iter[751/965]	  loss: 0.59cifar10:0.4-instance | Epoch [ 59/ 75] Iter[801/965]	  loss: 0.29cifar10:0.4-instance | Epoch [ 59/ 75] Iter[851/965]	  loss: 0.47cifar10:0.4-instance | Epoch [ 59/ 75] Iter[901/965]	  loss: 0.40cifar10:0.4-instance | Epoch [ 59/ 75] Iter[951/965]	  loss: 0.36
| Test Epoch 59	 Accuracy: 80.39% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 60 | Accuracy on train set: 54.06% 
labeled data has a size of 31031, f-score: 0.933067
cifar10:0.4-instance | Epoch [ 60/ 75] Iter[  1/970]	  loss: 0.44cifar10:0.4-instance | Epoch [ 60/ 75] Iter[ 51/970]	  loss: 0.46cifar10:0.4-instance | Epoch [ 60/ 75] Iter[101/970]	  loss: 0.39cifar10:0.4-instance | Epoch [ 60/ 75] Iter[151/970]	  loss: 0.38cifar10:0.4-instance | Epoch [ 60/ 75] Iter[201/970]	  loss: 0.45cifar10:0.4-instance | Epoch [ 60/ 75] Iter[251/970]	  loss: 0.35cifar10:0.4-instance | Epoch [ 60/ 75] Iter[301/970]	  loss: 0.33cifar10:0.4-instance | Epoch [ 60/ 75] Iter[351/970]	  loss: 0.35cifar10:0.4-instance | Epoch [ 60/ 75] Iter[401/970]	  loss: 0.26cifar10:0.4-instance | Epoch [ 60/ 75] Iter[451/970]	  loss: 0.25cifar10:0.4-instance | Epoch [ 60/ 75] Iter[501/970]	  loss: 0.53cifar10:0.4-instance | Epoch [ 60/ 75] Iter[551/970]	  loss: 0.28cifar10:0.4-instance | Epoch [ 60/ 75] Iter[601/970]	  loss: 0.31cifar10:0.4-instance | Epoch [ 60/ 75] Iter[651/970]	  loss: 0.22cifar10:0.4-instance | Epoch [ 60/ 75] Iter[701/970]	  loss: 0.62cifar10:0.4-instance | Epoch [ 60/ 75] Iter[751/970]	  loss: 0.30cifar10:0.4-instance | Epoch [ 60/ 75] Iter[801/970]	  loss: 0.25cifar10:0.4-instance | Epoch [ 60/ 75] Iter[851/970]	  loss: 0.29cifar10:0.4-instance | Epoch [ 60/ 75] Iter[901/970]	  loss: 0.24cifar10:0.4-instance | Epoch [ 60/ 75] Iter[951/970]	  loss: 0.34
| Test Epoch 60	 Accuracy: 88.27% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 61 | Accuracy on train set: 59.28% 
labeled data has a size of 30998, f-score: 0.936802
cifar10:0.4-instance | Epoch [ 61/ 75] Iter[  1/969]	  loss: 0.25cifar10:0.4-instance | Epoch [ 61/ 75] Iter[ 51/969]	  loss: 0.32cifar10:0.4-instance | Epoch [ 61/ 75] Iter[101/969]	  loss: 0.31cifar10:0.4-instance | Epoch [ 61/ 75] Iter[151/969]	  loss: 0.33cifar10:0.4-instance | Epoch [ 61/ 75] Iter[201/969]	  loss: 0.34cifar10:0.4-instance | Epoch [ 61/ 75] Iter[251/969]	  loss: 0.27cifar10:0.4-instance | Epoch [ 61/ 75] Iter[301/969]	  loss: 0.31cifar10:0.4-instance | Epoch [ 61/ 75] Iter[351/969]	  loss: 0.23cifar10:0.4-instance | Epoch [ 61/ 75] Iter[401/969]	  loss: 0.33cifar10:0.4-instance | Epoch [ 61/ 75] Iter[451/969]	  loss: 0.25cifar10:0.4-instance | Epoch [ 61/ 75] Iter[501/969]	  loss: 0.26cifar10:0.4-instance | Epoch [ 61/ 75] Iter[551/969]	  loss: 0.44cifar10:0.4-instance | Epoch [ 61/ 75] Iter[601/969]	  loss: 0.24cifar10:0.4-instance | Epoch [ 61/ 75] Iter[651/969]	  loss: 0.30cifar10:0.4-instance | Epoch [ 61/ 75] Iter[701/969]	  loss: 0.37cifar10:0.4-instance | Epoch [ 61/ 75] Iter[751/969]	  loss: 0.30cifar10:0.4-instance | Epoch [ 61/ 75] Iter[801/969]	  loss: 0.24cifar10:0.4-instance | Epoch [ 61/ 75] Iter[851/969]	  loss: 0.26cifar10:0.4-instance | Epoch [ 61/ 75] Iter[901/969]	  loss: 0.20cifar10:0.4-instance | Epoch [ 61/ 75] Iter[951/969]	  loss: 0.22
| Test Epoch 61	 Accuracy: 88.43% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 62 | Accuracy on train set: 59.66% 
labeled data has a size of 30997, f-score: 0.938381
cifar10:0.4-instance | Epoch [ 62/ 75] Iter[  1/969]	  loss: 0.20cifar10:0.4-instance | Epoch [ 62/ 75] Iter[ 51/969]	  loss: 0.27cifar10:0.4-instance | Epoch [ 62/ 75] Iter[101/969]	  loss: 0.23cifar10:0.4-instance | Epoch [ 62/ 75] Iter[151/969]	  loss: 0.48cifar10:0.4-instance | Epoch [ 62/ 75] Iter[201/969]	  loss: 0.43cifar10:0.4-instance | Epoch [ 62/ 75] Iter[251/969]	  loss: 0.33cifar10:0.4-instance | Epoch [ 62/ 75] Iter[301/969]	  loss: 0.28cifar10:0.4-instance | Epoch [ 62/ 75] Iter[351/969]	  loss: 0.47cifar10:0.4-instance | Epoch [ 62/ 75] Iter[401/969]	  loss: 0.25cifar10:0.4-instance | Epoch [ 62/ 75] Iter[451/969]	  loss: 0.60cifar10:0.4-instance | Epoch [ 62/ 75] Iter[501/969]	  loss: 0.21cifar10:0.4-instance | Epoch [ 62/ 75] Iter[551/969]	  loss: 0.26cifar10:0.4-instance | Epoch [ 62/ 75] Iter[601/969]	  loss: 0.41cifar10:0.4-instance | Epoch [ 62/ 75] Iter[651/969]	  loss: 0.31cifar10:0.4-instance | Epoch [ 62/ 75] Iter[701/969]	  loss: 0.41cifar10:0.4-instance | Epoch [ 62/ 75] Iter[751/969]	  loss: 0.21cifar10:0.4-instance | Epoch [ 62/ 75] Iter[801/969]	  loss: 0.24cifar10:0.4-instance | Epoch [ 62/ 75] Iter[851/969]	  loss: 0.27cifar10:0.4-instance | Epoch [ 62/ 75] Iter[901/969]	  loss: 0.23cifar10:0.4-instance | Epoch [ 62/ 75] Iter[951/969]	  loss: 0.18
| Test Epoch 62	 Accuracy: 88.63% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 63 | Accuracy on train set: 60.24% 
labeled data has a size of 30999, f-score: 0.940321
cifar10:0.4-instance | Epoch [ 63/ 75] Iter[  1/969]	  loss: 0.20cifar10:0.4-instance | Epoch [ 63/ 75] Iter[ 51/969]	  loss: 0.25cifar10:0.4-instance | Epoch [ 63/ 75] Iter[101/969]	  loss: 0.28cifar10:0.4-instance | Epoch [ 63/ 75] Iter[151/969]	  loss: 0.20cifar10:0.4-instance | Epoch [ 63/ 75] Iter[201/969]	  loss: 0.23cifar10:0.4-instance | Epoch [ 63/ 75] Iter[251/969]	  loss: 0.28cifar10:0.4-instance | Epoch [ 63/ 75] Iter[301/969]	  loss: 0.21cifar10:0.4-instance | Epoch [ 63/ 75] Iter[351/969]	  loss: 0.18cifar10:0.4-instance | Epoch [ 63/ 75] Iter[401/969]	  loss: 0.39cifar10:0.4-instance | Epoch [ 63/ 75] Iter[451/969]	  loss: 0.20cifar10:0.4-instance | Epoch [ 63/ 75] Iter[501/969]	  loss: 0.24cifar10:0.4-instance | Epoch [ 63/ 75] Iter[551/969]	  loss: 0.23cifar10:0.4-instance | Epoch [ 63/ 75] Iter[601/969]	  loss: 0.19cifar10:0.4-instance | Epoch [ 63/ 75] Iter[651/969]	  loss: 0.25cifar10:0.4-instance | Epoch [ 63/ 75] Iter[701/969]	  loss: 0.35cifar10:0.4-instance | Epoch [ 63/ 75] Iter[751/969]	  loss: 0.25cifar10:0.4-instance | Epoch [ 63/ 75] Iter[801/969]	  loss: 0.46cifar10:0.4-instance | Epoch [ 63/ 75] Iter[851/969]	  loss: 0.52cifar10:0.4-instance | Epoch [ 63/ 75] Iter[901/969]	  loss: 0.22cifar10:0.4-instance | Epoch [ 63/ 75] Iter[951/969]	  loss: 0.21
| Test Epoch 63	 Accuracy: 88.84% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 64 | Accuracy on train set: 60.60% 
labeled data has a size of 31122, f-score: 0.938179
cifar10:0.4-instance | Epoch [ 64/ 75] Iter[  1/973]	  loss: 0.27cifar10:0.4-instance | Epoch [ 64/ 75] Iter[ 51/973]	  loss: 0.22cifar10:0.4-instance | Epoch [ 64/ 75] Iter[101/973]	  loss: 0.23cifar10:0.4-instance | Epoch [ 64/ 75] Iter[151/973]	  loss: 0.22cifar10:0.4-instance | Epoch [ 64/ 75] Iter[201/973]	  loss: 0.22cifar10:0.4-instance | Epoch [ 64/ 75] Iter[251/973]	  loss: 0.35cifar10:0.4-instance | Epoch [ 64/ 75] Iter[301/973]	  loss: 0.21cifar10:0.4-instance | Epoch [ 64/ 75] Iter[351/973]	  loss: 0.16cifar10:0.4-instance | Epoch [ 64/ 75] Iter[401/973]	  loss: 0.36cifar10:0.4-instance | Epoch [ 64/ 75] Iter[451/973]	  loss: 0.26cifar10:0.4-instance | Epoch [ 64/ 75] Iter[501/973]	  loss: 0.17cifar10:0.4-instance | Epoch [ 64/ 75] Iter[551/973]	  loss: 0.27cifar10:0.4-instance | Epoch [ 64/ 75] Iter[601/973]	  loss: 0.32cifar10:0.4-instance | Epoch [ 64/ 75] Iter[651/973]	  loss: 0.22cifar10:0.4-instance | Epoch [ 64/ 75] Iter[701/973]	  loss: 0.36cifar10:0.4-instance | Epoch [ 64/ 75] Iter[751/973]	  loss: 0.19cifar10:0.4-instance | Epoch [ 64/ 75] Iter[801/973]	  loss: 0.30cifar10:0.4-instance | Epoch [ 64/ 75] Iter[851/973]	  loss: 0.40cifar10:0.4-instance | Epoch [ 64/ 75] Iter[901/973]	  loss: 0.25cifar10:0.4-instance | Epoch [ 64/ 75] Iter[951/973]	  loss: 0.22
| Test Epoch 64	 Accuracy: 89.41% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 65 | Accuracy on train set: 60.74% 
labeled data has a size of 31172, f-score: 0.938567
cifar10:0.4-instance | Epoch [ 65/ 75] Iter[  1/975]	  loss: 0.21cifar10:0.4-instance | Epoch [ 65/ 75] Iter[ 51/975]	  loss: 0.24cifar10:0.4-instance | Epoch [ 65/ 75] Iter[101/975]	  loss: 0.32cifar10:0.4-instance | Epoch [ 65/ 75] Iter[151/975]	  loss: 0.27cifar10:0.4-instance | Epoch [ 65/ 75] Iter[201/975]	  loss: 0.17cifar10:0.4-instance | Epoch [ 65/ 75] Iter[251/975]	  loss: 0.20cifar10:0.4-instance | Epoch [ 65/ 75] Iter[301/975]	  loss: 0.35cifar10:0.4-instance | Epoch [ 65/ 75] Iter[351/975]	  loss: 0.29cifar10:0.4-instance | Epoch [ 65/ 75] Iter[401/975]	  loss: 0.24cifar10:0.4-instance | Epoch [ 65/ 75] Iter[451/975]	  loss: 0.36cifar10:0.4-instance | Epoch [ 65/ 75] Iter[501/975]	  loss: 0.17cifar10:0.4-instance | Epoch [ 65/ 75] Iter[551/975]	  loss: 0.20cifar10:0.4-instance | Epoch [ 65/ 75] Iter[601/975]	  loss: 0.20cifar10:0.4-instance | Epoch [ 65/ 75] Iter[651/975]	  loss: 0.16cifar10:0.4-instance | Epoch [ 65/ 75] Iter[701/975]	  loss: 0.18cifar10:0.4-instance | Epoch [ 65/ 75] Iter[751/975]	  loss: 0.24cifar10:0.4-instance | Epoch [ 65/ 75] Iter[801/975]	  loss: 0.17cifar10:0.4-instance | Epoch [ 65/ 75] Iter[851/975]	  loss: 0.30cifar10:0.4-instance | Epoch [ 65/ 75] Iter[901/975]	  loss: 0.19cifar10:0.4-instance | Epoch [ 65/ 75] Iter[951/975]	  loss: 0.20
| Test Epoch 65	 Accuracy: 88.80% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 66 | Accuracy on train set: 61.05% 
labeled data has a size of 31249, f-score: 0.937502
cifar10:0.4-instance | Epoch [ 66/ 75] Iter[  1/977]	  loss: 0.22cifar10:0.4-instance | Epoch [ 66/ 75] Iter[ 51/977]	  loss: 0.25cifar10:0.4-instance | Epoch [ 66/ 75] Iter[101/977]	  loss: 0.19cifar10:0.4-instance | Epoch [ 66/ 75] Iter[151/977]	  loss: 0.21cifar10:0.4-instance | Epoch [ 66/ 75] Iter[201/977]	  loss: 0.23cifar10:0.4-instance | Epoch [ 66/ 75] Iter[251/977]	  loss: 0.17cifar10:0.4-instance | Epoch [ 66/ 75] Iter[301/977]	  loss: 0.23cifar10:0.4-instance | Epoch [ 66/ 75] Iter[351/977]	  loss: 0.19cifar10:0.4-instance | Epoch [ 66/ 75] Iter[401/977]	  loss: 0.19cifar10:0.4-instance | Epoch [ 66/ 75] Iter[451/977]	  loss: 0.52cifar10:0.4-instance | Epoch [ 66/ 75] Iter[501/977]	  loss: 0.26cifar10:0.4-instance | Epoch [ 66/ 75] Iter[551/977]	  loss: 0.22cifar10:0.4-instance | Epoch [ 66/ 75] Iter[601/977]	  loss: 0.16cifar10:0.4-instance | Epoch [ 66/ 75] Iter[651/977]	  loss: 0.48cifar10:0.4-instance | Epoch [ 66/ 75] Iter[701/977]	  loss: 0.23cifar10:0.4-instance | Epoch [ 66/ 75] Iter[751/977]	  loss: 0.26cifar10:0.4-instance | Epoch [ 66/ 75] Iter[801/977]	  loss: 0.31cifar10:0.4-instance | Epoch [ 66/ 75] Iter[851/977]	  loss: 0.33cifar10:0.4-instance | Epoch [ 66/ 75] Iter[901/977]	  loss: 0.21cifar10:0.4-instance | Epoch [ 66/ 75] Iter[951/977]	  loss: 0.21
| Test Epoch 66	 Accuracy: 88.42% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 67 | Accuracy on train set: 61.46% 
labeled data has a size of 31337, f-score: 0.935380
cifar10:0.4-instance | Epoch [ 67/ 75] Iter[  1/980]	  loss: 0.29cifar10:0.4-instance | Epoch [ 67/ 75] Iter[ 51/980]	  loss: 0.19cifar10:0.4-instance | Epoch [ 67/ 75] Iter[101/980]	  loss: 0.16cifar10:0.4-instance | Epoch [ 67/ 75] Iter[151/980]	  loss: 0.21cifar10:0.4-instance | Epoch [ 67/ 75] Iter[201/980]	  loss: 0.18cifar10:0.4-instance | Epoch [ 67/ 75] Iter[251/980]	  loss: 0.29cifar10:0.4-instance | Epoch [ 67/ 75] Iter[301/980]	  loss: 0.29cifar10:0.4-instance | Epoch [ 67/ 75] Iter[351/980]	  loss: 0.44cifar10:0.4-instance | Epoch [ 67/ 75] Iter[401/980]	  loss: 0.19cifar10:0.4-instance | Epoch [ 67/ 75] Iter[451/980]	  loss: 0.16cifar10:0.4-instance | Epoch [ 67/ 75] Iter[501/980]	  loss: 0.23cifar10:0.4-instance | Epoch [ 67/ 75] Iter[551/980]	  loss: 0.20cifar10:0.4-instance | Epoch [ 67/ 75] Iter[601/980]	  loss: 0.24cifar10:0.4-instance | Epoch [ 67/ 75] Iter[651/980]	  loss: 0.16cifar10:0.4-instance | Epoch [ 67/ 75] Iter[701/980]	  loss: 0.20cifar10:0.4-instance | Epoch [ 67/ 75] Iter[751/980]	  loss: 0.30cifar10:0.4-instance | Epoch [ 67/ 75] Iter[801/980]	  loss: 0.18cifar10:0.4-instance | Epoch [ 67/ 75] Iter[851/980]	  loss: 0.18cifar10:0.4-instance | Epoch [ 67/ 75] Iter[901/980]	  loss: 0.19cifar10:0.4-instance | Epoch [ 67/ 75] Iter[951/980]	  loss: 0.27
| Test Epoch 67	 Accuracy: 88.07% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 68 | Accuracy on train set: 61.60% 
labeled data has a size of 31477, f-score: 0.931982
cifar10:0.4-instance | Epoch [ 68/ 75] Iter[  1/984]	  loss: 0.27cifar10:0.4-instance | Epoch [ 68/ 75] Iter[ 51/984]	  loss: 0.30cifar10:0.4-instance | Epoch [ 68/ 75] Iter[101/984]	  loss: 0.17cifar10:0.4-instance | Epoch [ 68/ 75] Iter[151/984]	  loss: 0.21cifar10:0.4-instance | Epoch [ 68/ 75] Iter[201/984]	  loss: 0.16cifar10:0.4-instance | Epoch [ 68/ 75] Iter[251/984]	  loss: 0.17cifar10:0.4-instance | Epoch [ 68/ 75] Iter[301/984]	  loss: 0.36cifar10:0.4-instance | Epoch [ 68/ 75] Iter[351/984]	  loss: 0.29cifar10:0.4-instance | Epoch [ 68/ 75] Iter[401/984]	  loss: 0.21cifar10:0.4-instance | Epoch [ 68/ 75] Iter[451/984]	  loss: 0.40cifar10:0.4-instance | Epoch [ 68/ 75] Iter[501/984]	  loss: 0.28cifar10:0.4-instance | Epoch [ 68/ 75] Iter[551/984]	  loss: 0.24cifar10:0.4-instance | Epoch [ 68/ 75] Iter[601/984]	  loss: 0.18cifar10:0.4-instance | Epoch [ 68/ 75] Iter[651/984]	  loss: 0.26cifar10:0.4-instance | Epoch [ 68/ 75] Iter[701/984]	  loss: 0.38cifar10:0.4-instance | Epoch [ 68/ 75] Iter[751/984]	  loss: 0.24cifar10:0.4-instance | Epoch [ 68/ 75] Iter[801/984]	  loss: 0.43cifar10:0.4-instance | Epoch [ 68/ 75] Iter[851/984]	  loss: 0.21cifar10:0.4-instance | Epoch [ 68/ 75] Iter[901/984]	  loss: 0.47cifar10:0.4-instance | Epoch [ 68/ 75] Iter[951/984]	  loss: 0.18
| Test Epoch 68	 Accuracy: 88.71% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 69 | Accuracy on train set: 61.73% 
labeled data has a size of 31547, f-score: 0.930611
cifar10:0.4-instance | Epoch [ 69/ 75] Iter[  1/986]	  loss: 0.22cifar10:0.4-instance | Epoch [ 69/ 75] Iter[ 51/986]	  loss: 0.25cifar10:0.4-instance | Epoch [ 69/ 75] Iter[101/986]	  loss: 0.26cifar10:0.4-instance | Epoch [ 69/ 75] Iter[151/986]	  loss: 0.16cifar10:0.4-instance | Epoch [ 69/ 75] Iter[201/986]	  loss: 0.24cifar10:0.4-instance | Epoch [ 69/ 75] Iter[251/986]	  loss: 0.21cifar10:0.4-instance | Epoch [ 69/ 75] Iter[301/986]	  loss: 0.29cifar10:0.4-instance | Epoch [ 69/ 75] Iter[351/986]	  loss: 0.34cifar10:0.4-instance | Epoch [ 69/ 75] Iter[401/986]	  loss: 0.18cifar10:0.4-instance | Epoch [ 69/ 75] Iter[451/986]	  loss: 0.18cifar10:0.4-instance | Epoch [ 69/ 75] Iter[501/986]	  loss: 0.22cifar10:0.4-instance | Epoch [ 69/ 75] Iter[551/986]	  loss: 0.19cifar10:0.4-instance | Epoch [ 69/ 75] Iter[601/986]	  loss: 0.34cifar10:0.4-instance | Epoch [ 69/ 75] Iter[651/986]	  loss: 0.17cifar10:0.4-instance | Epoch [ 69/ 75] Iter[701/986]	  loss: 0.22cifar10:0.4-instance | Epoch [ 69/ 75] Iter[751/986]	  loss: 0.34cifar10:0.4-instance | Epoch [ 69/ 75] Iter[801/986]	  loss: 0.26cifar10:0.4-instance | Epoch [ 69/ 75] Iter[851/986]	  loss: 0.21cifar10:0.4-instance | Epoch [ 69/ 75] Iter[901/986]	  loss: 0.22cifar10:0.4-instance | Epoch [ 69/ 75] Iter[951/986]	  loss: 0.43
| Test Epoch 69	 Accuracy: 88.42% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 70 | Accuracy on train set: 62.04% 
labeled data has a size of 31639, f-score: 0.929043
cifar10:0.4-instance | Epoch [ 70/ 75] Iter[  1/989]	  loss: 0.22cifar10:0.4-instance | Epoch [ 70/ 75] Iter[ 51/989]	  loss: 0.26cifar10:0.4-instance | Epoch [ 70/ 75] Iter[101/989]	  loss: 0.18cifar10:0.4-instance | Epoch [ 70/ 75] Iter[151/989]	  loss: 0.21cifar10:0.4-instance | Epoch [ 70/ 75] Iter[201/989]	  loss: 0.25cifar10:0.4-instance | Epoch [ 70/ 75] Iter[251/989]	  loss: 0.21cifar10:0.4-instance | Epoch [ 70/ 75] Iter[301/989]	  loss: 0.17cifar10:0.4-instance | Epoch [ 70/ 75] Iter[351/989]	  loss: 0.15cifar10:0.4-instance | Epoch [ 70/ 75] Iter[401/989]	  loss: 0.16cifar10:0.4-instance | Epoch [ 70/ 75] Iter[451/989]	  loss: 0.18cifar10:0.4-instance | Epoch [ 70/ 75] Iter[501/989]	  loss: 0.31cifar10:0.4-instance | Epoch [ 70/ 75] Iter[551/989]	  loss: 0.18cifar10:0.4-instance | Epoch [ 70/ 75] Iter[601/989]	  loss: 0.21cifar10:0.4-instance | Epoch [ 70/ 75] Iter[651/989]	  loss: 0.22cifar10:0.4-instance | Epoch [ 70/ 75] Iter[701/989]	  loss: 0.22cifar10:0.4-instance | Epoch [ 70/ 75] Iter[751/989]	  loss: 0.18cifar10:0.4-instance | Epoch [ 70/ 75] Iter[801/989]	  loss: 0.19cifar10:0.4-instance | Epoch [ 70/ 75] Iter[851/989]	  loss: 0.17cifar10:0.4-instance | Epoch [ 70/ 75] Iter[901/989]	  loss: 0.24cifar10:0.4-instance | Epoch [ 70/ 75] Iter[951/989]	  loss: 0.16
| Test Epoch 70	 Accuracy: 88.55% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 71 | Accuracy on train set: 62.08% 
labeled data has a size of 31687, f-score: 0.929056
cifar10:0.4-instance | Epoch [ 71/ 75] Iter[  1/991]	  loss: 0.18cifar10:0.4-instance | Epoch [ 71/ 75] Iter[ 51/991]	  loss: 0.16cifar10:0.4-instance | Epoch [ 71/ 75] Iter[101/991]	  loss: 0.21cifar10:0.4-instance | Epoch [ 71/ 75] Iter[151/991]	  loss: 0.34cifar10:0.4-instance | Epoch [ 71/ 75] Iter[201/991]	  loss: 0.21cifar10:0.4-instance | Epoch [ 71/ 75] Iter[251/991]	  loss: 0.16cifar10:0.4-instance | Epoch [ 71/ 75] Iter[301/991]	  loss: 0.28cifar10:0.4-instance | Epoch [ 71/ 75] Iter[351/991]	  loss: 0.24cifar10:0.4-instance | Epoch [ 71/ 75] Iter[401/991]	  loss: 0.31cifar10:0.4-instance | Epoch [ 71/ 75] Iter[451/991]	  loss: 0.18cifar10:0.4-instance | Epoch [ 71/ 75] Iter[501/991]	  loss: 0.20cifar10:0.4-instance | Epoch [ 71/ 75] Iter[551/991]	  loss: 0.16cifar10:0.4-instance | Epoch [ 71/ 75] Iter[601/991]	  loss: 0.18cifar10:0.4-instance | Epoch [ 71/ 75] Iter[651/991]	  loss: 0.24cifar10:0.4-instance | Epoch [ 71/ 75] Iter[701/991]	  loss: 0.20cifar10:0.4-instance | Epoch [ 71/ 75] Iter[751/991]	  loss: 0.16cifar10:0.4-instance | Epoch [ 71/ 75] Iter[801/991]	  loss: 0.16cifar10:0.4-instance | Epoch [ 71/ 75] Iter[851/991]	  loss: 0.16cifar10:0.4-instance | Epoch [ 71/ 75] Iter[901/991]	  loss: 0.29cifar10:0.4-instance | Epoch [ 71/ 75] Iter[951/991]	  loss: 0.16
| Test Epoch 71	 Accuracy: 88.37% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 72 | Accuracy on train set: 62.46% 
labeled data has a size of 31751, f-score: 0.927435
cifar10:0.4-instance | Epoch [ 72/ 75] Iter[  1/993]	  loss: 0.19cifar10:0.4-instance | Epoch [ 72/ 75] Iter[ 51/993]	  loss: 0.19cifar10:0.4-instance | Epoch [ 72/ 75] Iter[101/993]	  loss: 0.18cifar10:0.4-instance | Epoch [ 72/ 75] Iter[151/993]	  loss: 0.19cifar10:0.4-instance | Epoch [ 72/ 75] Iter[201/993]	  loss: 0.21cifar10:0.4-instance | Epoch [ 72/ 75] Iter[251/993]	  loss: 0.24cifar10:0.4-instance | Epoch [ 72/ 75] Iter[301/993]	  loss: 0.28cifar10:0.4-instance | Epoch [ 72/ 75] Iter[351/993]	  loss: 0.31cifar10:0.4-instance | Epoch [ 72/ 75] Iter[401/993]	  loss: 0.28cifar10:0.4-instance | Epoch [ 72/ 75] Iter[451/993]	  loss: 0.31cifar10:0.4-instance | Epoch [ 72/ 75] Iter[501/993]	  loss: 0.41cifar10:0.4-instance | Epoch [ 72/ 75] Iter[551/993]	  loss: 0.18cifar10:0.4-instance | Epoch [ 72/ 75] Iter[601/993]	  loss: 0.22cifar10:0.4-instance | Epoch [ 72/ 75] Iter[651/993]	  loss: 0.20cifar10:0.4-instance | Epoch [ 72/ 75] Iter[701/993]	  loss: 0.29cifar10:0.4-instance | Epoch [ 72/ 75] Iter[751/993]	  loss: 0.16cifar10:0.4-instance | Epoch [ 72/ 75] Iter[801/993]	  loss: 0.16cifar10:0.4-instance | Epoch [ 72/ 75] Iter[851/993]	  loss: 0.35cifar10:0.4-instance | Epoch [ 72/ 75] Iter[901/993]	  loss: 0.25cifar10:0.4-instance | Epoch [ 72/ 75] Iter[951/993]	  loss: 0.19
| Test Epoch 72	 Accuracy: 88.62% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 73 | Accuracy on train set: 62.37% 
labeled data has a size of 31786, f-score: 0.926855
cifar10:0.4-instance | Epoch [ 73/ 75] Iter[  1/994]	  loss: 0.17cifar10:0.4-instance | Epoch [ 73/ 75] Iter[ 51/994]	  loss: 0.30cifar10:0.4-instance | Epoch [ 73/ 75] Iter[101/994]	  loss: 0.17cifar10:0.4-instance | Epoch [ 73/ 75] Iter[151/994]	  loss: 0.48cifar10:0.4-instance | Epoch [ 73/ 75] Iter[201/994]	  loss: 0.27cifar10:0.4-instance | Epoch [ 73/ 75] Iter[251/994]	  loss: 0.23cifar10:0.4-instance | Epoch [ 73/ 75] Iter[301/994]	  loss: 0.27cifar10:0.4-instance | Epoch [ 73/ 75] Iter[351/994]	  loss: 0.20cifar10:0.4-instance | Epoch [ 73/ 75] Iter[401/994]	  loss: 0.17cifar10:0.4-instance | Epoch [ 73/ 75] Iter[451/994]	  loss: 0.36cifar10:0.4-instance | Epoch [ 73/ 75] Iter[501/994]	  loss: 0.16cifar10:0.4-instance | Epoch [ 73/ 75] Iter[551/994]	  loss: 0.16cifar10:0.4-instance | Epoch [ 73/ 75] Iter[601/994]	  loss: 0.23cifar10:0.4-instance | Epoch [ 73/ 75] Iter[651/994]	  loss: 0.17cifar10:0.4-instance | Epoch [ 73/ 75] Iter[701/994]	  loss: 0.21cifar10:0.4-instance | Epoch [ 73/ 75] Iter[751/994]	  loss: 0.17cifar10:0.4-instance | Epoch [ 73/ 75] Iter[801/994]	  loss: 0.17cifar10:0.4-instance | Epoch [ 73/ 75] Iter[851/994]	  loss: 0.30cifar10:0.4-instance | Epoch [ 73/ 75] Iter[901/994]	  loss: 0.19cifar10:0.4-instance | Epoch [ 73/ 75] Iter[951/994]	  loss: 0.17
| Test Epoch 73	 Accuracy: 88.30% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 74 | Accuracy on train set: 62.59% 
labeled data has a size of 31851, f-score: 0.925811
cifar10:0.4-instance | Epoch [ 74/ 75] Iter[  1/996]	  loss: 0.19cifar10:0.4-instance | Epoch [ 74/ 75] Iter[ 51/996]	  loss: 0.32cifar10:0.4-instance | Epoch [ 74/ 75] Iter[101/996]	  loss: 0.21cifar10:0.4-instance | Epoch [ 74/ 75] Iter[151/996]	  loss: 0.29cifar10:0.4-instance | Epoch [ 74/ 75] Iter[201/996]	  loss: 0.25cifar10:0.4-instance | Epoch [ 74/ 75] Iter[251/996]	  loss: 0.30cifar10:0.4-instance | Epoch [ 74/ 75] Iter[301/996]	  loss: 0.19cifar10:0.4-instance | Epoch [ 74/ 75] Iter[351/996]	  loss: 0.31cifar10:0.4-instance | Epoch [ 74/ 75] Iter[401/996]	  loss: 0.16cifar10:0.4-instance | Epoch [ 74/ 75] Iter[451/996]	  loss: 0.17cifar10:0.4-instance | Epoch [ 74/ 75] Iter[501/996]	  loss: 0.16cifar10:0.4-instance | Epoch [ 74/ 75] Iter[551/996]	  loss: 0.23cifar10:0.4-instance | Epoch [ 74/ 75] Iter[601/996]	  loss: 0.25cifar10:0.4-instance | Epoch [ 74/ 75] Iter[651/996]	  loss: 0.31cifar10:0.4-instance | Epoch [ 74/ 75] Iter[701/996]	  loss: 0.26cifar10:0.4-instance | Epoch [ 74/ 75] Iter[751/996]	  loss: 0.21cifar10:0.4-instance | Epoch [ 74/ 75] Iter[801/996]	  loss: 0.40cifar10:0.4-instance | Epoch [ 74/ 75] Iter[851/996]	  loss: 0.23cifar10:0.4-instance | Epoch [ 74/ 75] Iter[901/996]	  loss: 0.30cifar10:0.4-instance | Epoch [ 74/ 75] Iter[951/996]	  loss: 0.25
| Test Epoch 74	 Accuracy: 87.29% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 75 | Accuracy on train set: 62.69% 
labeled data has a size of 31933, f-score: 0.923841
cifar10:0.4-instance | Epoch [ 75/ 75] Iter[  1/998]	  loss: 0.15cifar10:0.4-instance | Epoch [ 75/ 75] Iter[ 51/998]	  loss: 0.32cifar10:0.4-instance | Epoch [ 75/ 75] Iter[101/998]	  loss: 0.26cifar10:0.4-instance | Epoch [ 75/ 75] Iter[151/998]	  loss: 0.15cifar10:0.4-instance | Epoch [ 75/ 75] Iter[201/998]	  loss: 0.18cifar10:0.4-instance | Epoch [ 75/ 75] Iter[251/998]	  loss: 0.18cifar10:0.4-instance | Epoch [ 75/ 75] Iter[301/998]	  loss: 0.15cifar10:0.4-instance | Epoch [ 75/ 75] Iter[351/998]	  loss: 0.17cifar10:0.4-instance | Epoch [ 75/ 75] Iter[401/998]	  loss: 0.31cifar10:0.4-instance | Epoch [ 75/ 75] Iter[451/998]	  loss: 0.28cifar10:0.4-instance | Epoch [ 75/ 75] Iter[501/998]	  loss: 0.18cifar10:0.4-instance | Epoch [ 75/ 75] Iter[551/998]	  loss: 0.22cifar10:0.4-instance | Epoch [ 75/ 75] Iter[601/998]	  loss: 0.17cifar10:0.4-instance | Epoch [ 75/ 75] Iter[651/998]	  loss: 0.24cifar10:0.4-instance | Epoch [ 75/ 75] Iter[701/998]	  loss: 0.23cifar10:0.4-instance | Epoch [ 75/ 75] Iter[751/998]	  loss: 0.23cifar10:0.4-instance | Epoch [ 75/ 75] Iter[801/998]	  loss: 0.24cifar10:0.4-instance | Epoch [ 75/ 75] Iter[851/998]	  loss: 0.26cifar10:0.4-instance | Epoch [ 75/ 75] Iter[901/998]	  loss: 0.30cifar10:0.4-instance | Epoch [ 75/ 75] Iter[951/998]	  loss: 0.32
| Test Epoch 75	 Accuracy: 87.85% 



best test Acc:  89.41
