Namespace(T=0.2, batch_size=32, data_path='./dataset2/cifar10', dataset='cifar10', fig_7=0, fluctuation_ablation=0, gpuid=0, k=3, lr=0.02, model='resnet18', noise_mode='instance', num_class=10, num_epochs=75, r=0.2, save_sel_sam=0, seed_model=4, seed_noise=1, semi='no', warm_up=10, wdecay=0.0005, without_Lcr=0, without_R=0)
============ Initialize data
============ Actual clean samples number:  39820
============ use resnet18 
============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 0 | Accuracy on train set: 7.55% 
cifar10:0.2-instance | Epoch [  0/ 75] Iter[  1/391]	 CE-loss: 2.4246cifar10:0.2-instance | Epoch [  0/ 75] Iter[ 51/391]	 CE-loss: 2.0630cifar10:0.2-instance | Epoch [  0/ 75] Iter[101/391]	 CE-loss: 1.8696cifar10:0.2-instance | Epoch [  0/ 75] Iter[151/391]	 CE-loss: 1.9889cifar10:0.2-instance | Epoch [  0/ 75] Iter[201/391]	 CE-loss: 1.7940cifar10:0.2-instance | Epoch [  0/ 75] Iter[251/391]	 CE-loss: 1.7705cifar10:0.2-instance | Epoch [  0/ 75] Iter[301/391]	 CE-loss: 1.5555cifar10:0.2-instance | Epoch [  0/ 75] Iter[351/391]	 CE-loss: 1.7272
| Test Epoch 0	 Accuracy: 46.99% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 1 | Accuracy on train set: 41.13% 
cifar10:0.2-instance | Epoch [  1/ 75] Iter[  1/391]	 CE-loss: 1.5687cifar10:0.2-instance | Epoch [  1/ 75] Iter[ 51/391]	 CE-loss: 1.5186cifar10:0.2-instance | Epoch [  1/ 75] Iter[101/391]	 CE-loss: 1.5699cifar10:0.2-instance | Epoch [  1/ 75] Iter[151/391]	 CE-loss: 1.5006cifar10:0.2-instance | Epoch [  1/ 75] Iter[201/391]	 CE-loss: 1.5970cifar10:0.2-instance | Epoch [  1/ 75] Iter[251/391]	 CE-loss: 1.3547cifar10:0.2-instance | Epoch [  1/ 75] Iter[301/391]	 CE-loss: 1.3716cifar10:0.2-instance | Epoch [  1/ 75] Iter[351/391]	 CE-loss: 1.5432
| Test Epoch 1	 Accuracy: 53.39% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 2 | Accuracy on train set: 45.69% 
cifar10:0.2-instance | Epoch [  2/ 75] Iter[  1/391]	 CE-loss: 1.1990cifar10:0.2-instance | Epoch [  2/ 75] Iter[ 51/391]	 CE-loss: 1.3477cifar10:0.2-instance | Epoch [  2/ 75] Iter[101/391]	 CE-loss: 1.3025cifar10:0.2-instance | Epoch [  2/ 75] Iter[151/391]	 CE-loss: 1.2519cifar10:0.2-instance | Epoch [  2/ 75] Iter[201/391]	 CE-loss: 1.5034cifar10:0.2-instance | Epoch [  2/ 75] Iter[251/391]	 CE-loss: 1.2016cifar10:0.2-instance | Epoch [  2/ 75] Iter[301/391]	 CE-loss: 1.2377cifar10:0.2-instance | Epoch [  2/ 75] Iter[351/391]	 CE-loss: 1.2240
| Test Epoch 2	 Accuracy: 67.20% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 3 | Accuracy on train set: 56.35% 
cifar10:0.2-instance | Epoch [  3/ 75] Iter[  1/391]	 CE-loss: 1.1514cifar10:0.2-instance | Epoch [  3/ 75] Iter[ 51/391]	 CE-loss: 1.3374cifar10:0.2-instance | Epoch [  3/ 75] Iter[101/391]	 CE-loss: 1.1081cifar10:0.2-instance | Epoch [  3/ 75] Iter[151/391]	 CE-loss: 1.1442cifar10:0.2-instance | Epoch [  3/ 75] Iter[201/391]	 CE-loss: 1.1567cifar10:0.2-instance | Epoch [  3/ 75] Iter[251/391]	 CE-loss: 1.1914cifar10:0.2-instance | Epoch [  3/ 75] Iter[301/391]	 CE-loss: 1.1796cifar10:0.2-instance | Epoch [  3/ 75] Iter[351/391]	 CE-loss: 1.1200
| Test Epoch 3	 Accuracy: 62.03% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 4 | Accuracy on train set: 54.34% 
cifar10:0.2-instance | Epoch [  4/ 75] Iter[  1/391]	 CE-loss: 1.2946cifar10:0.2-instance | Epoch [  4/ 75] Iter[ 51/391]	 CE-loss: 1.3429cifar10:0.2-instance | Epoch [  4/ 75] Iter[101/391]	 CE-loss: 1.0524cifar10:0.2-instance | Epoch [  4/ 75] Iter[151/391]	 CE-loss: 1.2145cifar10:0.2-instance | Epoch [  4/ 75] Iter[201/391]	 CE-loss: 1.1591cifar10:0.2-instance | Epoch [  4/ 75] Iter[251/391]	 CE-loss: 1.0166cifar10:0.2-instance | Epoch [  4/ 75] Iter[301/391]	 CE-loss: 1.1511cifar10:0.2-instance | Epoch [  4/ 75] Iter[351/391]	 CE-loss: 1.2752
| Test Epoch 4	 Accuracy: 75.20% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 5 | Accuracy on train set: 61.96% 
cifar10:0.2-instance | Epoch [  5/ 75] Iter[  1/391]	 CE-loss: 1.1770cifar10:0.2-instance | Epoch [  5/ 75] Iter[ 51/391]	 CE-loss: 1.1591cifar10:0.2-instance | Epoch [  5/ 75] Iter[101/391]	 CE-loss: 1.1212cifar10:0.2-instance | Epoch [  5/ 75] Iter[151/391]	 CE-loss: 1.1343cifar10:0.2-instance | Epoch [  5/ 75] Iter[201/391]	 CE-loss: 0.9470cifar10:0.2-instance | Epoch [  5/ 75] Iter[251/391]	 CE-loss: 1.0778cifar10:0.2-instance | Epoch [  5/ 75] Iter[301/391]	 CE-loss: 1.3280cifar10:0.2-instance | Epoch [  5/ 75] Iter[351/391]	 CE-loss: 1.0938
| Test Epoch 5	 Accuracy: 78.99% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 6 | Accuracy on train set: 65.44% 
cifar10:0.2-instance | Epoch [  6/ 75] Iter[  1/391]	 CE-loss: 1.1152cifar10:0.2-instance | Epoch [  6/ 75] Iter[ 51/391]	 CE-loss: 1.0370cifar10:0.2-instance | Epoch [  6/ 75] Iter[101/391]	 CE-loss: 1.1506cifar10:0.2-instance | Epoch [  6/ 75] Iter[151/391]	 CE-loss: 1.1905cifar10:0.2-instance | Epoch [  6/ 75] Iter[201/391]	 CE-loss: 0.9689cifar10:0.2-instance | Epoch [  6/ 75] Iter[251/391]	 CE-loss: 1.1050cifar10:0.2-instance | Epoch [  6/ 75] Iter[301/391]	 CE-loss: 1.0725cifar10:0.2-instance | Epoch [  6/ 75] Iter[351/391]	 CE-loss: 0.9556
| Test Epoch 6	 Accuracy: 76.95% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 7 | Accuracy on train set: 64.47% 
cifar10:0.2-instance | Epoch [  7/ 75] Iter[  1/391]	 CE-loss: 1.1256cifar10:0.2-instance | Epoch [  7/ 75] Iter[ 51/391]	 CE-loss: 1.0070cifar10:0.2-instance | Epoch [  7/ 75] Iter[101/391]	 CE-loss: 1.0380cifar10:0.2-instance | Epoch [  7/ 75] Iter[151/391]	 CE-loss: 1.0222cifar10:0.2-instance | Epoch [  7/ 75] Iter[201/391]	 CE-loss: 0.9910cifar10:0.2-instance | Epoch [  7/ 75] Iter[251/391]	 CE-loss: 0.8829cifar10:0.2-instance | Epoch [  7/ 75] Iter[301/391]	 CE-loss: 1.1653cifar10:0.2-instance | Epoch [  7/ 75] Iter[351/391]	 CE-loss: 0.9983
| Test Epoch 7	 Accuracy: 77.38% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 8 | Accuracy on train set: 64.52% 
cifar10:0.2-instance | Epoch [  8/ 75] Iter[  1/391]	 CE-loss: 0.8486cifar10:0.2-instance | Epoch [  8/ 75] Iter[ 51/391]	 CE-loss: 0.9139cifar10:0.2-instance | Epoch [  8/ 75] Iter[101/391]	 CE-loss: 0.9755cifar10:0.2-instance | Epoch [  8/ 75] Iter[151/391]	 CE-loss: 0.9298cifar10:0.2-instance | Epoch [  8/ 75] Iter[201/391]	 CE-loss: 1.0537cifar10:0.2-instance | Epoch [  8/ 75] Iter[251/391]	 CE-loss: 1.0873cifar10:0.2-instance | Epoch [  8/ 75] Iter[301/391]	 CE-loss: 1.0814cifar10:0.2-instance | Epoch [  8/ 75] Iter[351/391]	 CE-loss: 0.8163
| Test Epoch 8	 Accuracy: 81.36% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 9 | Accuracy on train set: 68.29% 
cifar10:0.2-instance | Epoch [  9/ 75] Iter[  1/391]	 CE-loss: 0.9107cifar10:0.2-instance | Epoch [  9/ 75] Iter[ 51/391]	 CE-loss: 0.9602cifar10:0.2-instance | Epoch [  9/ 75] Iter[101/391]	 CE-loss: 0.9823cifar10:0.2-instance | Epoch [  9/ 75] Iter[151/391]	 CE-loss: 1.1025cifar10:0.2-instance | Epoch [  9/ 75] Iter[201/391]	 CE-loss: 0.9230cifar10:0.2-instance | Epoch [  9/ 75] Iter[251/391]	 CE-loss: 1.1209cifar10:0.2-instance | Epoch [  9/ 75] Iter[301/391]	 CE-loss: 0.8388cifar10:0.2-instance | Epoch [  9/ 75] Iter[351/391]	 CE-loss: 0.9078
| Test Epoch 9	 Accuracy: 80.65% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 10 | Accuracy on train set: 68.19% 
labeled data has a size of 38489, f-score: 0.968355
cifar10:0.2-instance | Epoch [ 10/ 75] Iter[  1/1203]	  loss: 0.74cifar10:0.2-instance | Epoch [ 10/ 75] Iter[ 51/1203]	  loss: 1.35cifar10:0.2-instance | Epoch [ 10/ 75] Iter[101/1203]	  loss: 0.81cifar10:0.2-instance | Epoch [ 10/ 75] Iter[151/1203]	  loss: 1.00cifar10:0.2-instance | Epoch [ 10/ 75] Iter[201/1203]	  loss: 0.74cifar10:0.2-instance | Epoch [ 10/ 75] Iter[251/1203]	  loss: 0.76cifar10:0.2-instance | Epoch [ 10/ 75] Iter[301/1203]	  loss: 0.59cifar10:0.2-instance | Epoch [ 10/ 75] Iter[351/1203]	  loss: 0.68cifar10:0.2-instance | Epoch [ 10/ 75] Iter[401/1203]	  loss: 0.59cifar10:0.2-instance | Epoch [ 10/ 75] Iter[451/1203]	  loss: 0.57cifar10:0.2-instance | Epoch [ 10/ 75] Iter[501/1203]	  loss: 0.66cifar10:0.2-instance | Epoch [ 10/ 75] Iter[551/1203]	  loss: 1.00cifar10:0.2-instance | Epoch [ 10/ 75] Iter[601/1203]	  loss: 0.87cifar10:0.2-instance | Epoch [ 10/ 75] Iter[651/1203]	  loss: 0.54cifar10:0.2-instance | Epoch [ 10/ 75] Iter[701/1203]	  loss: 0.74cifar10:0.2-instance | Epoch [ 10/ 75] Iter[751/1203]	  loss: 0.77cifar10:0.2-instance | Epoch [ 10/ 75] Iter[801/1203]	  loss: 0.68cifar10:0.2-instance | Epoch [ 10/ 75] Iter[851/1203]	  loss: 0.75cifar10:0.2-instance | Epoch [ 10/ 75] Iter[901/1203]	  loss: 0.48cifar10:0.2-instance | Epoch [ 10/ 75] Iter[951/1203]	  loss: 0.58cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1001/1203]	  loss: 1.12cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1051/1203]	  loss: 0.65cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1101/1203]	  loss: 0.93cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1151/1203]	  loss: 0.68cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1201/1203]	  loss: 0.97
| Test Epoch 10	 Accuracy: 76.64% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 11 | Accuracy on train set: 63.19% 
labeled data has a size of 38144, f-score: 0.973312
cifar10:0.2-instance | Epoch [ 11/ 75] Iter[  1/1193]	  loss: 0.53cifar10:0.2-instance | Epoch [ 11/ 75] Iter[ 51/1193]	  loss: 0.53cifar10:0.2-instance | Epoch [ 11/ 75] Iter[101/1193]	  loss: 0.88cifar10:0.2-instance | Epoch [ 11/ 75] Iter[151/1193]	  loss: 0.47cifar10:0.2-instance | Epoch [ 11/ 75] Iter[201/1193]	  loss: 0.57cifar10:0.2-instance | Epoch [ 11/ 75] Iter[251/1193]	  loss: 0.45cifar10:0.2-instance | Epoch [ 11/ 75] Iter[301/1193]	  loss: 0.56cifar10:0.2-instance | Epoch [ 11/ 75] Iter[351/1193]	  loss: 0.44cifar10:0.2-instance | Epoch [ 11/ 75] Iter[401/1193]	  loss: 0.63cifar10:0.2-instance | Epoch [ 11/ 75] Iter[451/1193]	  loss: 0.88cifar10:0.2-instance | Epoch [ 11/ 75] Iter[501/1193]	  loss: 0.61cifar10:0.2-instance | Epoch [ 11/ 75] Iter[551/1193]	  loss: 0.43cifar10:0.2-instance | Epoch [ 11/ 75] Iter[601/1193]	  loss: 0.89cifar10:0.2-instance | Epoch [ 11/ 75] Iter[651/1193]	  loss: 0.56cifar10:0.2-instance | Epoch [ 11/ 75] Iter[701/1193]	  loss: 0.54cifar10:0.2-instance | Epoch [ 11/ 75] Iter[751/1193]	  loss: 0.61cifar10:0.2-instance | Epoch [ 11/ 75] Iter[801/1193]	  loss: 0.77cifar10:0.2-instance | Epoch [ 11/ 75] Iter[851/1193]	  loss: 0.53cifar10:0.2-instance | Epoch [ 11/ 75] Iter[901/1193]	  loss: 0.53cifar10:0.2-instance | Epoch [ 11/ 75] Iter[951/1193]	  loss: 0.68cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1001/1193]	  loss: 0.72cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1051/1193]	  loss: 0.50cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1101/1193]	  loss: 0.49cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1151/1193]	  loss: 0.90
| Test Epoch 11	 Accuracy: 78.36% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 12 | Accuracy on train set: 64.57% 
labeled data has a size of 38156, f-score: 0.974893
cifar10:0.2-instance | Epoch [ 12/ 75] Iter[  1/1193]	  loss: 0.63cifar10:0.2-instance | Epoch [ 12/ 75] Iter[ 51/1193]	  loss: 0.46cifar10:0.2-instance | Epoch [ 12/ 75] Iter[101/1193]	  loss: 0.50cifar10:0.2-instance | Epoch [ 12/ 75] Iter[151/1193]	  loss: 0.48cifar10:0.2-instance | Epoch [ 12/ 75] Iter[201/1193]	  loss: 0.44cifar10:0.2-instance | Epoch [ 12/ 75] Iter[251/1193]	  loss: 0.64cifar10:0.2-instance | Epoch [ 12/ 75] Iter[301/1193]	  loss: 0.44cifar10:0.2-instance | Epoch [ 12/ 75] Iter[351/1193]	  loss: 0.77cifar10:0.2-instance | Epoch [ 12/ 75] Iter[401/1193]	  loss: 0.53cifar10:0.2-instance | Epoch [ 12/ 75] Iter[451/1193]	  loss: 0.52cifar10:0.2-instance | Epoch [ 12/ 75] Iter[501/1193]	  loss: 0.40cifar10:0.2-instance | Epoch [ 12/ 75] Iter[551/1193]	  loss: 0.44cifar10:0.2-instance | Epoch [ 12/ 75] Iter[601/1193]	  loss: 0.64cifar10:0.2-instance | Epoch [ 12/ 75] Iter[651/1193]	  loss: 0.58cifar10:0.2-instance | Epoch [ 12/ 75] Iter[701/1193]	  loss: 0.31cifar10:0.2-instance | Epoch [ 12/ 75] Iter[751/1193]	  loss: 0.62cifar10:0.2-instance | Epoch [ 12/ 75] Iter[801/1193]	  loss: 0.44cifar10:0.2-instance | Epoch [ 12/ 75] Iter[851/1193]	  loss: 0.66cifar10:0.2-instance | Epoch [ 12/ 75] Iter[901/1193]	  loss: 0.76cifar10:0.2-instance | Epoch [ 12/ 75] Iter[951/1193]	  loss: 0.50cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1001/1193]	  loss: 0.70cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1051/1193]	  loss: 0.43cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1101/1193]	  loss: 0.56cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1151/1193]	  loss: 0.64
| Test Epoch 12	 Accuracy: 80.56% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 13 | Accuracy on train set: 67.20% 
labeled data has a size of 37533, f-score: 0.980657
cifar10:0.2-instance | Epoch [ 13/ 75] Iter[  1/1173]	  loss: 0.48cifar10:0.2-instance | Epoch [ 13/ 75] Iter[ 51/1173]	  loss: 0.62cifar10:0.2-instance | Epoch [ 13/ 75] Iter[101/1173]	  loss: 0.34cifar10:0.2-instance | Epoch [ 13/ 75] Iter[151/1173]	  loss: 0.65cifar10:0.2-instance | Epoch [ 13/ 75] Iter[201/1173]	  loss: 0.68cifar10:0.2-instance | Epoch [ 13/ 75] Iter[251/1173]	  loss: 0.45cifar10:0.2-instance | Epoch [ 13/ 75] Iter[301/1173]	  loss: 0.47cifar10:0.2-instance | Epoch [ 13/ 75] Iter[351/1173]	  loss: 0.69cifar10:0.2-instance | Epoch [ 13/ 75] Iter[401/1173]	  loss: 0.32cifar10:0.2-instance | Epoch [ 13/ 75] Iter[451/1173]	  loss: 0.33cifar10:0.2-instance | Epoch [ 13/ 75] Iter[501/1173]	  loss: 0.48cifar10:0.2-instance | Epoch [ 13/ 75] Iter[551/1173]	  loss: 0.33cifar10:0.2-instance | Epoch [ 13/ 75] Iter[601/1173]	  loss: 0.48cifar10:0.2-instance | Epoch [ 13/ 75] Iter[651/1173]	  loss: 0.32cifar10:0.2-instance | Epoch [ 13/ 75] Iter[701/1173]	  loss: 0.39cifar10:0.2-instance | Epoch [ 13/ 75] Iter[751/1173]	  loss: 0.52cifar10:0.2-instance | Epoch [ 13/ 75] Iter[801/1173]	  loss: 0.45cifar10:0.2-instance | Epoch [ 13/ 75] Iter[851/1173]	  loss: 0.36cifar10:0.2-instance | Epoch [ 13/ 75] Iter[901/1173]	  loss: 0.41cifar10:0.2-instance | Epoch [ 13/ 75] Iter[951/1173]	  loss: 0.34cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1001/1173]	  loss: 0.54cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1051/1173]	  loss: 0.50cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1101/1173]	  loss: 0.36cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1151/1173]	  loss: 0.41
| Test Epoch 13	 Accuracy: 80.68% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 14 | Accuracy on train set: 67.23% 
labeled data has a size of 37713, f-score: 0.980193
cifar10:0.2-instance | Epoch [ 14/ 75] Iter[  1/1179]	  loss: 0.53cifar10:0.2-instance | Epoch [ 14/ 75] Iter[ 51/1179]	  loss: 0.29cifar10:0.2-instance | Epoch [ 14/ 75] Iter[101/1179]	  loss: 0.38cifar10:0.2-instance | Epoch [ 14/ 75] Iter[151/1179]	  loss: 0.61cifar10:0.2-instance | Epoch [ 14/ 75] Iter[201/1179]	  loss: 0.52cifar10:0.2-instance | Epoch [ 14/ 75] Iter[251/1179]	  loss: 0.49cifar10:0.2-instance | Epoch [ 14/ 75] Iter[301/1179]	  loss: 0.70cifar10:0.2-instance | Epoch [ 14/ 75] Iter[351/1179]	  loss: 0.73cifar10:0.2-instance | Epoch [ 14/ 75] Iter[401/1179]	  loss: 0.80cifar10:0.2-instance | Epoch [ 14/ 75] Iter[451/1179]	  loss: 0.49cifar10:0.2-instance | Epoch [ 14/ 75] Iter[501/1179]	  loss: 0.31cifar10:0.2-instance | Epoch [ 14/ 75] Iter[551/1179]	  loss: 0.80cifar10:0.2-instance | Epoch [ 14/ 75] Iter[601/1179]	  loss: 0.32cifar10:0.2-instance | Epoch [ 14/ 75] Iter[651/1179]	  loss: 0.34cifar10:0.2-instance | Epoch [ 14/ 75] Iter[701/1179]	  loss: 0.52cifar10:0.2-instance | Epoch [ 14/ 75] Iter[751/1179]	  loss: 1.02cifar10:0.2-instance | Epoch [ 14/ 75] Iter[801/1179]	  loss: 0.55cifar10:0.2-instance | Epoch [ 14/ 75] Iter[851/1179]	  loss: 0.39cifar10:0.2-instance | Epoch [ 14/ 75] Iter[901/1179]	  loss: 0.63cifar10:0.2-instance | Epoch [ 14/ 75] Iter[951/1179]	  loss: 0.48cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1001/1179]	  loss: 0.39cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1051/1179]	  loss: 0.42cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1101/1179]	  loss: 0.49cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1151/1179]	  loss: 0.50
| Test Epoch 14	 Accuracy: 83.24% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 15 | Accuracy on train set: 69.23% 
labeled data has a size of 37819, f-score: 0.980433
cifar10:0.2-instance | Epoch [ 15/ 75] Iter[  1/1182]	  loss: 0.46cifar10:0.2-instance | Epoch [ 15/ 75] Iter[ 51/1182]	  loss: 0.60cifar10:0.2-instance | Epoch [ 15/ 75] Iter[101/1182]	  loss: 0.44cifar10:0.2-instance | Epoch [ 15/ 75] Iter[151/1182]	  loss: 0.42cifar10:0.2-instance | Epoch [ 15/ 75] Iter[201/1182]	  loss: 0.38cifar10:0.2-instance | Epoch [ 15/ 75] Iter[251/1182]	  loss: 0.48cifar10:0.2-instance | Epoch [ 15/ 75] Iter[301/1182]	  loss: 0.39cifar10:0.2-instance | Epoch [ 15/ 75] Iter[351/1182]	  loss: 0.87cifar10:0.2-instance | Epoch [ 15/ 75] Iter[401/1182]	  loss: 0.38cifar10:0.2-instance | Epoch [ 15/ 75] Iter[451/1182]	  loss: 0.62cifar10:0.2-instance | Epoch [ 15/ 75] Iter[501/1182]	  loss: 0.46cifar10:0.2-instance | Epoch [ 15/ 75] Iter[551/1182]	  loss: 0.47cifar10:0.2-instance | Epoch [ 15/ 75] Iter[601/1182]	  loss: 0.46cifar10:0.2-instance | Epoch [ 15/ 75] Iter[651/1182]	  loss: 0.25cifar10:0.2-instance | Epoch [ 15/ 75] Iter[701/1182]	  loss: 0.41cifar10:0.2-instance | Epoch [ 15/ 75] Iter[751/1182]	  loss: 0.64cifar10:0.2-instance | Epoch [ 15/ 75] Iter[801/1182]	  loss: 0.56cifar10:0.2-instance | Epoch [ 15/ 75] Iter[851/1182]	  loss: 0.42cifar10:0.2-instance | Epoch [ 15/ 75] Iter[901/1182]	  loss: 0.37cifar10:0.2-instance | Epoch [ 15/ 75] Iter[951/1182]	  loss: 0.54cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1001/1182]	  loss: 0.48cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1051/1182]	  loss: 0.39cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1101/1182]	  loss: 0.40cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1151/1182]	  loss: 0.51
| Test Epoch 15	 Accuracy: 83.17% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 16 | Accuracy on train set: 69.37% 
labeled data has a size of 37846, f-score: 0.980658
cifar10:0.2-instance | Epoch [ 16/ 75] Iter[  1/1183]	  loss: 0.35cifar10:0.2-instance | Epoch [ 16/ 75] Iter[ 51/1183]	  loss: 0.49cifar10:0.2-instance | Epoch [ 16/ 75] Iter[101/1183]	  loss: 0.43cifar10:0.2-instance | Epoch [ 16/ 75] Iter[151/1183]	  loss: 0.54cifar10:0.2-instance | Epoch [ 16/ 75] Iter[201/1183]	  loss: 0.44cifar10:0.2-instance | Epoch [ 16/ 75] Iter[251/1183]	  loss: 0.39cifar10:0.2-instance | Epoch [ 16/ 75] Iter[301/1183]	  loss: 0.79cifar10:0.2-instance | Epoch [ 16/ 75] Iter[351/1183]	  loss: 0.58cifar10:0.2-instance | Epoch [ 16/ 75] Iter[401/1183]	  loss: 0.42cifar10:0.2-instance | Epoch [ 16/ 75] Iter[451/1183]	  loss: 0.26cifar10:0.2-instance | Epoch [ 16/ 75] Iter[501/1183]	  loss: 0.38cifar10:0.2-instance | Epoch [ 16/ 75] Iter[551/1183]	  loss: 0.25cifar10:0.2-instance | Epoch [ 16/ 75] Iter[601/1183]	  loss: 0.59cifar10:0.2-instance | Epoch [ 16/ 75] Iter[651/1183]	  loss: 0.69cifar10:0.2-instance | Epoch [ 16/ 75] Iter[701/1183]	  loss: 0.32cifar10:0.2-instance | Epoch [ 16/ 75] Iter[751/1183]	  loss: 0.44cifar10:0.2-instance | Epoch [ 16/ 75] Iter[801/1183]	  loss: 0.45cifar10:0.2-instance | Epoch [ 16/ 75] Iter[851/1183]	  loss: 0.34cifar10:0.2-instance | Epoch [ 16/ 75] Iter[901/1183]	  loss: 0.58cifar10:0.2-instance | Epoch [ 16/ 75] Iter[951/1183]	  loss: 0.32cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1001/1183]	  loss: 0.34cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1051/1183]	  loss: 0.62cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1101/1183]	  loss: 0.43cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1151/1183]	  loss: 0.55
| Test Epoch 16	 Accuracy: 82.40% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 17 | Accuracy on train set: 68.69% 
labeled data has a size of 38217, f-score: 0.980375
cifar10:0.2-instance | Epoch [ 17/ 75] Iter[  1/1195]	  loss: 0.36cifar10:0.2-instance | Epoch [ 17/ 75] Iter[ 51/1195]	  loss: 0.49cifar10:0.2-instance | Epoch [ 17/ 75] Iter[101/1195]	  loss: 0.38cifar10:0.2-instance | Epoch [ 17/ 75] Iter[151/1195]	  loss: 0.28cifar10:0.2-instance | Epoch [ 17/ 75] Iter[201/1195]	  loss: 0.31cifar10:0.2-instance | Epoch [ 17/ 75] Iter[251/1195]	  loss: 0.51cifar10:0.2-instance | Epoch [ 17/ 75] Iter[301/1195]	  loss: 0.49cifar10:0.2-instance | Epoch [ 17/ 75] Iter[351/1195]	  loss: 0.42cifar10:0.2-instance | Epoch [ 17/ 75] Iter[401/1195]	  loss: 0.43cifar10:0.2-instance | Epoch [ 17/ 75] Iter[451/1195]	  loss: 0.40cifar10:0.2-instance | Epoch [ 17/ 75] Iter[501/1195]	  loss: 0.44cifar10:0.2-instance | Epoch [ 17/ 75] Iter[551/1195]	  loss: 0.27cifar10:0.2-instance | Epoch [ 17/ 75] Iter[601/1195]	  loss: 0.43cifar10:0.2-instance | Epoch [ 17/ 75] Iter[651/1195]	  loss: 0.45cifar10:0.2-instance | Epoch [ 17/ 75] Iter[701/1195]	  loss: 0.28cifar10:0.2-instance | Epoch [ 17/ 75] Iter[751/1195]	  loss: 0.43cifar10:0.2-instance | Epoch [ 17/ 75] Iter[801/1195]	  loss: 0.30cifar10:0.2-instance | Epoch [ 17/ 75] Iter[851/1195]	  loss: 0.35cifar10:0.2-instance | Epoch [ 17/ 75] Iter[901/1195]	  loss: 0.72cifar10:0.2-instance | Epoch [ 17/ 75] Iter[951/1195]	  loss: 0.67cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1001/1195]	  loss: 0.45cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1051/1195]	  loss: 0.45cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1101/1195]	  loss: 0.25cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1151/1195]	  loss: 0.39
| Test Epoch 17	 Accuracy: 81.73% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 18 | Accuracy on train set: 68.31% 
labeled data has a size of 38241, f-score: 0.979995
cifar10:0.2-instance | Epoch [ 18/ 75] Iter[  1/1196]	  loss: 0.71cifar10:0.2-instance | Epoch [ 18/ 75] Iter[ 51/1196]	  loss: 0.55cifar10:0.2-instance | Epoch [ 18/ 75] Iter[101/1196]	  loss: 0.34cifar10:0.2-instance | Epoch [ 18/ 75] Iter[151/1196]	  loss: 0.48cifar10:0.2-instance | Epoch [ 18/ 75] Iter[201/1196]	  loss: 0.40cifar10:0.2-instance | Epoch [ 18/ 75] Iter[251/1196]	  loss: 0.44cifar10:0.2-instance | Epoch [ 18/ 75] Iter[301/1196]	  loss: 0.23cifar10:0.2-instance | Epoch [ 18/ 75] Iter[351/1196]	  loss: 0.50cifar10:0.2-instance | Epoch [ 18/ 75] Iter[401/1196]	  loss: 0.36cifar10:0.2-instance | Epoch [ 18/ 75] Iter[451/1196]	  loss: 0.53cifar10:0.2-instance | Epoch [ 18/ 75] Iter[501/1196]	  loss: 0.37cifar10:0.2-instance | Epoch [ 18/ 75] Iter[551/1196]	  loss: 0.33cifar10:0.2-instance | Epoch [ 18/ 75] Iter[601/1196]	  loss: 0.50cifar10:0.2-instance | Epoch [ 18/ 75] Iter[651/1196]	  loss: 0.45cifar10:0.2-instance | Epoch [ 18/ 75] Iter[701/1196]	  loss: 0.24cifar10:0.2-instance | Epoch [ 18/ 75] Iter[751/1196]	  loss: 0.38cifar10:0.2-instance | Epoch [ 18/ 75] Iter[801/1196]	  loss: 0.62cifar10:0.2-instance | Epoch [ 18/ 75] Iter[851/1196]	  loss: 0.45cifar10:0.2-instance | Epoch [ 18/ 75] Iter[901/1196]	  loss: 0.39cifar10:0.2-instance | Epoch [ 18/ 75] Iter[951/1196]	  loss: 0.26cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1001/1196]	  loss: 0.50cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1051/1196]	  loss: 0.44cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1101/1196]	  loss: 0.39cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1151/1196]	  loss: 0.25
| Test Epoch 18	 Accuracy: 79.18% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 19 | Accuracy on train set: 66.63% 
labeled data has a size of 38226, f-score: 0.980694
cifar10:0.2-instance | Epoch [ 19/ 75] Iter[  1/1195]	  loss: 0.55cifar10:0.2-instance | Epoch [ 19/ 75] Iter[ 51/1195]	  loss: 0.23cifar10:0.2-instance | Epoch [ 19/ 75] Iter[101/1195]	  loss: 0.55cifar10:0.2-instance | Epoch [ 19/ 75] Iter[151/1195]	  loss: 0.50cifar10:0.2-instance | Epoch [ 19/ 75] Iter[201/1195]	  loss: 0.45cifar10:0.2-instance | Epoch [ 19/ 75] Iter[251/1195]	  loss: 0.32cifar10:0.2-instance | Epoch [ 19/ 75] Iter[301/1195]	  loss: 0.41cifar10:0.2-instance | Epoch [ 19/ 75] Iter[351/1195]	  loss: 0.57cifar10:0.2-instance | Epoch [ 19/ 75] Iter[401/1195]	  loss: 0.23cifar10:0.2-instance | Epoch [ 19/ 75] Iter[451/1195]	  loss: 0.30cifar10:0.2-instance | Epoch [ 19/ 75] Iter[501/1195]	  loss: 0.50cifar10:0.2-instance | Epoch [ 19/ 75] Iter[551/1195]	  loss: 0.28cifar10:0.2-instance | Epoch [ 19/ 75] Iter[601/1195]	  loss: 0.44cifar10:0.2-instance | Epoch [ 19/ 75] Iter[651/1195]	  loss: 0.40cifar10:0.2-instance | Epoch [ 19/ 75] Iter[701/1195]	  loss: 0.44cifar10:0.2-instance | Epoch [ 19/ 75] Iter[751/1195]	  loss: 0.59cifar10:0.2-instance | Epoch [ 19/ 75] Iter[801/1195]	  loss: 0.41cifar10:0.2-instance | Epoch [ 19/ 75] Iter[851/1195]	  loss: 0.59cifar10:0.2-instance | Epoch [ 19/ 75] Iter[901/1195]	  loss: 0.32cifar10:0.2-instance | Epoch [ 19/ 75] Iter[951/1195]	  loss: 0.44cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1001/1195]	  loss: 0.38cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1051/1195]	  loss: 0.34cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1101/1195]	  loss: 0.45cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1151/1195]	  loss: 0.46
| Test Epoch 19	 Accuracy: 81.96% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 20 | Accuracy on train set: 68.26% 
labeled data has a size of 38212, f-score: 0.980922
cifar10:0.2-instance | Epoch [ 20/ 75] Iter[  1/1195]	  loss: 0.45cifar10:0.2-instance | Epoch [ 20/ 75] Iter[ 51/1195]	  loss: 0.41cifar10:0.2-instance | Epoch [ 20/ 75] Iter[101/1195]	  loss: 0.30cifar10:0.2-instance | Epoch [ 20/ 75] Iter[151/1195]	  loss: 0.28cifar10:0.2-instance | Epoch [ 20/ 75] Iter[201/1195]	  loss: 0.33cifar10:0.2-instance | Epoch [ 20/ 75] Iter[251/1195]	  loss: 0.47cifar10:0.2-instance | Epoch [ 20/ 75] Iter[301/1195]	  loss: 0.48cifar10:0.2-instance | Epoch [ 20/ 75] Iter[351/1195]	  loss: 0.36cifar10:0.2-instance | Epoch [ 20/ 75] Iter[401/1195]	  loss: 0.63cifar10:0.2-instance | Epoch [ 20/ 75] Iter[451/1195]	  loss: 0.54cifar10:0.2-instance | Epoch [ 20/ 75] Iter[501/1195]	  loss: 0.26cifar10:0.2-instance | Epoch [ 20/ 75] Iter[551/1195]	  loss: 0.33cifar10:0.2-instance | Epoch [ 20/ 75] Iter[601/1195]	  loss: 0.36cifar10:0.2-instance | Epoch [ 20/ 75] Iter[651/1195]	  loss: 0.41cifar10:0.2-instance | Epoch [ 20/ 75] Iter[701/1195]	  loss: 0.41cifar10:0.2-instance | Epoch [ 20/ 75] Iter[751/1195]	  loss: 0.38cifar10:0.2-instance | Epoch [ 20/ 75] Iter[801/1195]	  loss: 0.43cifar10:0.2-instance | Epoch [ 20/ 75] Iter[851/1195]	  loss: 0.35cifar10:0.2-instance | Epoch [ 20/ 75] Iter[901/1195]	  loss: 0.52cifar10:0.2-instance | Epoch [ 20/ 75] Iter[951/1195]	  loss: 0.28cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1001/1195]	  loss: 0.30cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1051/1195]	  loss: 0.35cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1101/1195]	  loss: 0.25cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1151/1195]	  loss: 0.30
| Test Epoch 20	 Accuracy: 83.01% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 21 | Accuracy on train set: 69.13% 
labeled data has a size of 38351, f-score: 0.981278
cifar10:0.2-instance | Epoch [ 21/ 75] Iter[  1/1199]	  loss: 0.44cifar10:0.2-instance | Epoch [ 21/ 75] Iter[ 51/1199]	  loss: 0.62cifar10:0.2-instance | Epoch [ 21/ 75] Iter[101/1199]	  loss: 0.43cifar10:0.2-instance | Epoch [ 21/ 75] Iter[151/1199]	  loss: 0.33cifar10:0.2-instance | Epoch [ 21/ 75] Iter[201/1199]	  loss: 0.44cifar10:0.2-instance | Epoch [ 21/ 75] Iter[251/1199]	  loss: 0.46cifar10:0.2-instance | Epoch [ 21/ 75] Iter[301/1199]	  loss: 0.45cifar10:0.2-instance | Epoch [ 21/ 75] Iter[351/1199]	  loss: 0.46cifar10:0.2-instance | Epoch [ 21/ 75] Iter[401/1199]	  loss: 0.43cifar10:0.2-instance | Epoch [ 21/ 75] Iter[451/1199]	  loss: 0.54cifar10:0.2-instance | Epoch [ 21/ 75] Iter[501/1199]	  loss: 0.51cifar10:0.2-instance | Epoch [ 21/ 75] Iter[551/1199]	  loss: 0.56cifar10:0.2-instance | Epoch [ 21/ 75] Iter[601/1199]	  loss: 0.48cifar10:0.2-instance | Epoch [ 21/ 75] Iter[651/1199]	  loss: 0.28cifar10:0.2-instance | Epoch [ 21/ 75] Iter[701/1199]	  loss: 0.52cifar10:0.2-instance | Epoch [ 21/ 75] Iter[751/1199]	  loss: 0.47cifar10:0.2-instance | Epoch [ 21/ 75] Iter[801/1199]	  loss: 0.57cifar10:0.2-instance | Epoch [ 21/ 75] Iter[851/1199]	  loss: 0.43cifar10:0.2-instance | Epoch [ 21/ 75] Iter[901/1199]	  loss: 0.39cifar10:0.2-instance | Epoch [ 21/ 75] Iter[951/1199]	  loss: 0.37cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1001/1199]	  loss: 0.97cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1051/1199]	  loss: 0.26cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1101/1199]	  loss: 0.42cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1151/1199]	  loss: 0.28
| Test Epoch 21	 Accuracy: 82.70% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 22 | Accuracy on train set: 69.16% 
labeled data has a size of 38433, f-score: 0.980329
cifar10:0.2-instance | Epoch [ 22/ 75] Iter[  1/1202]	  loss: 0.46cifar10:0.2-instance | Epoch [ 22/ 75] Iter[ 51/1202]	  loss: 0.39cifar10:0.2-instance | Epoch [ 22/ 75] Iter[101/1202]	  loss: 0.41cifar10:0.2-instance | Epoch [ 22/ 75] Iter[151/1202]	  loss: 0.45cifar10:0.2-instance | Epoch [ 22/ 75] Iter[201/1202]	  loss: 0.41cifar10:0.2-instance | Epoch [ 22/ 75] Iter[251/1202]	  loss: 0.42cifar10:0.2-instance | Epoch [ 22/ 75] Iter[301/1202]	  loss: 0.49cifar10:0.2-instance | Epoch [ 22/ 75] Iter[351/1202]	  loss: 0.45cifar10:0.2-instance | Epoch [ 22/ 75] Iter[401/1202]	  loss: 0.37cifar10:0.2-instance | Epoch [ 22/ 75] Iter[451/1202]	  loss: 0.43cifar10:0.2-instance | Epoch [ 22/ 75] Iter[501/1202]	  loss: 0.29cifar10:0.2-instance | Epoch [ 22/ 75] Iter[551/1202]	  loss: 0.30cifar10:0.2-instance | Epoch [ 22/ 75] Iter[601/1202]	  loss: 0.25cifar10:0.2-instance | Epoch [ 22/ 75] Iter[651/1202]	  loss: 0.55cifar10:0.2-instance | Epoch [ 22/ 75] Iter[701/1202]	  loss: 0.40cifar10:0.2-instance | Epoch [ 22/ 75] Iter[751/1202]	  loss: 0.28cifar10:0.2-instance | Epoch [ 22/ 75] Iter[801/1202]	  loss: 0.48cifar10:0.2-instance | Epoch [ 22/ 75] Iter[851/1202]	  loss: 0.30cifar10:0.2-instance | Epoch [ 22/ 75] Iter[901/1202]	  loss: 0.66cifar10:0.2-instance | Epoch [ 22/ 75] Iter[951/1202]	  loss: 0.27cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1001/1202]	  loss: 0.52cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1051/1202]	  loss: 0.39cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1101/1202]	  loss: 0.65cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1151/1202]	  loss: 0.44cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1201/1202]	  loss: 0.51
| Test Epoch 22	 Accuracy: 82.83% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 23 | Accuracy on train set: 68.91% 
labeled data has a size of 38676, f-score: 0.981280
cifar10:0.2-instance | Epoch [ 23/ 75] Iter[  1/1209]	  loss: 0.42cifar10:0.2-instance | Epoch [ 23/ 75] Iter[ 51/1209]	  loss: 0.36cifar10:0.2-instance | Epoch [ 23/ 75] Iter[101/1209]	  loss: 0.27cifar10:0.2-instance | Epoch [ 23/ 75] Iter[151/1209]	  loss: 0.49cifar10:0.2-instance | Epoch [ 23/ 75] Iter[201/1209]	  loss: 0.44cifar10:0.2-instance | Epoch [ 23/ 75] Iter[251/1209]	  loss: 0.65cifar10:0.2-instance | Epoch [ 23/ 75] Iter[301/1209]	  loss: 0.47cifar10:0.2-instance | Epoch [ 23/ 75] Iter[351/1209]	  loss: 0.41cifar10:0.2-instance | Epoch [ 23/ 75] Iter[401/1209]	  loss: 0.55cifar10:0.2-instance | Epoch [ 23/ 75] Iter[451/1209]	  loss: 0.28cifar10:0.2-instance | Epoch [ 23/ 75] Iter[501/1209]	  loss: 0.37cifar10:0.2-instance | Epoch [ 23/ 75] Iter[551/1209]	  loss: 0.39cifar10:0.2-instance | Epoch [ 23/ 75] Iter[601/1209]	  loss: 0.66cifar10:0.2-instance | Epoch [ 23/ 75] Iter[651/1209]	  loss: 0.56cifar10:0.2-instance | Epoch [ 23/ 75] Iter[701/1209]	  loss: 0.55cifar10:0.2-instance | Epoch [ 23/ 75] Iter[751/1209]	  loss: 0.30cifar10:0.2-instance | Epoch [ 23/ 75] Iter[801/1209]	  loss: 0.26cifar10:0.2-instance | Epoch [ 23/ 75] Iter[851/1209]	  loss: 0.53cifar10:0.2-instance | Epoch [ 23/ 75] Iter[901/1209]	  loss: 0.47cifar10:0.2-instance | Epoch [ 23/ 75] Iter[951/1209]	  loss: 0.62cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1001/1209]	  loss: 0.45cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1051/1209]	  loss: 0.23cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1101/1209]	  loss: 0.39cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1151/1209]	  loss: 0.43cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1201/1209]	  loss: 0.29
| Test Epoch 23	 Accuracy: 84.69% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 24 | Accuracy on train set: 71.24% 
labeled data has a size of 38666, f-score: 0.980965
cifar10:0.2-instance | Epoch [ 24/ 75] Iter[  1/1209]	  loss: 0.39cifar10:0.2-instance | Epoch [ 24/ 75] Iter[ 51/1209]	  loss: 0.56cifar10:0.2-instance | Epoch [ 24/ 75] Iter[101/1209]	  loss: 0.54cifar10:0.2-instance | Epoch [ 24/ 75] Iter[151/1209]	  loss: 0.36cifar10:0.2-instance | Epoch [ 24/ 75] Iter[201/1209]	  loss: 0.32cifar10:0.2-instance | Epoch [ 24/ 75] Iter[251/1209]	  loss: 0.27cifar10:0.2-instance | Epoch [ 24/ 75] Iter[301/1209]	  loss: 0.41cifar10:0.2-instance | Epoch [ 24/ 75] Iter[351/1209]	  loss: 0.51cifar10:0.2-instance | Epoch [ 24/ 75] Iter[401/1209]	  loss: 0.36cifar10:0.2-instance | Epoch [ 24/ 75] Iter[451/1209]	  loss: 0.60cifar10:0.2-instance | Epoch [ 24/ 75] Iter[501/1209]	  loss: 0.37cifar10:0.2-instance | Epoch [ 24/ 75] Iter[551/1209]	  loss: 0.66cifar10:0.2-instance | Epoch [ 24/ 75] Iter[601/1209]	  loss: 0.29cifar10:0.2-instance | Epoch [ 24/ 75] Iter[651/1209]	  loss: 0.49cifar10:0.2-instance | Epoch [ 24/ 75] Iter[701/1209]	  loss: 0.36cifar10:0.2-instance | Epoch [ 24/ 75] Iter[751/1209]	  loss: 0.40cifar10:0.2-instance | Epoch [ 24/ 75] Iter[801/1209]	  loss: 0.49cifar10:0.2-instance | Epoch [ 24/ 75] Iter[851/1209]	  loss: 0.45cifar10:0.2-instance | Epoch [ 24/ 75] Iter[901/1209]	  loss: 0.35cifar10:0.2-instance | Epoch [ 24/ 75] Iter[951/1209]	  loss: 0.69cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1001/1209]	  loss: 0.65cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1051/1209]	  loss: 0.48cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1101/1209]	  loss: 0.47cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1151/1209]	  loss: 0.50cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1201/1209]	  loss: 0.34
| Test Epoch 24	 Accuracy: 84.86% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 25 | Accuracy on train set: 71.49% 
labeled data has a size of 38695, f-score: 0.982375
cifar10:0.2-instance | Epoch [ 25/ 75] Iter[  1/1210]	  loss: 0.44cifar10:0.2-instance | Epoch [ 25/ 75] Iter[ 51/1210]	  loss: 0.52cifar10:0.2-instance | Epoch [ 25/ 75] Iter[101/1210]	  loss: 0.58cifar10:0.2-instance | Epoch [ 25/ 75] Iter[151/1210]	  loss: 0.42cifar10:0.2-instance | Epoch [ 25/ 75] Iter[201/1210]	  loss: 0.51cifar10:0.2-instance | Epoch [ 25/ 75] Iter[251/1210]	  loss: 0.54cifar10:0.2-instance | Epoch [ 25/ 75] Iter[301/1210]	  loss: 0.48cifar10:0.2-instance | Epoch [ 25/ 75] Iter[351/1210]	  loss: 0.33cifar10:0.2-instance | Epoch [ 25/ 75] Iter[401/1210]	  loss: 0.29cifar10:0.2-instance | Epoch [ 25/ 75] Iter[451/1210]	  loss: 0.45cifar10:0.2-instance | Epoch [ 25/ 75] Iter[501/1210]	  loss: 0.46cifar10:0.2-instance | Epoch [ 25/ 75] Iter[551/1210]	  loss: 0.44cifar10:0.2-instance | Epoch [ 25/ 75] Iter[601/1210]	  loss: 0.22cifar10:0.2-instance | Epoch [ 25/ 75] Iter[651/1210]	  loss: 0.54cifar10:0.2-instance | Epoch [ 25/ 75] Iter[701/1210]	  loss: 0.47cifar10:0.2-instance | Epoch [ 25/ 75] Iter[751/1210]	  loss: 0.64cifar10:0.2-instance | Epoch [ 25/ 75] Iter[801/1210]	  loss: 0.26cifar10:0.2-instance | Epoch [ 25/ 75] Iter[851/1210]	  loss: 0.57cifar10:0.2-instance | Epoch [ 25/ 75] Iter[901/1210]	  loss: 0.37cifar10:0.2-instance | Epoch [ 25/ 75] Iter[951/1210]	  loss: 0.76cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1001/1210]	  loss: 0.41cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1051/1210]	  loss: 0.50cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1101/1210]	  loss: 0.58cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1151/1210]	  loss: 0.50cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1201/1210]	  loss: 0.39
| Test Epoch 25	 Accuracy: 82.41% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 26 | Accuracy on train set: 69.11% 
labeled data has a size of 38740, f-score: 0.982266
cifar10:0.2-instance | Epoch [ 26/ 75] Iter[  1/1211]	  loss: 0.27cifar10:0.2-instance | Epoch [ 26/ 75] Iter[ 51/1211]	  loss: 0.34cifar10:0.2-instance | Epoch [ 26/ 75] Iter[101/1211]	  loss: 0.39cifar10:0.2-instance | Epoch [ 26/ 75] Iter[151/1211]	  loss: 0.41cifar10:0.2-instance | Epoch [ 26/ 75] Iter[201/1211]	  loss: 0.42cifar10:0.2-instance | Epoch [ 26/ 75] Iter[251/1211]	  loss: 0.53cifar10:0.2-instance | Epoch [ 26/ 75] Iter[301/1211]	  loss: 0.41cifar10:0.2-instance | Epoch [ 26/ 75] Iter[351/1211]	  loss: 0.32cifar10:0.2-instance | Epoch [ 26/ 75] Iter[401/1211]	  loss: 0.42cifar10:0.2-instance | Epoch [ 26/ 75] Iter[451/1211]	  loss: 0.45cifar10:0.2-instance | Epoch [ 26/ 75] Iter[501/1211]	  loss: 0.46cifar10:0.2-instance | Epoch [ 26/ 75] Iter[551/1211]	  loss: 0.70cifar10:0.2-instance | Epoch [ 26/ 75] Iter[601/1211]	  loss: 0.30cifar10:0.2-instance | Epoch [ 26/ 75] Iter[651/1211]	  loss: 0.37cifar10:0.2-instance | Epoch [ 26/ 75] Iter[701/1211]	  loss: 0.46cifar10:0.2-instance | Epoch [ 26/ 75] Iter[751/1211]	  loss: 0.53cifar10:0.2-instance | Epoch [ 26/ 75] Iter[801/1211]	  loss: 0.41cifar10:0.2-instance | Epoch [ 26/ 75] Iter[851/1211]	  loss: 0.30cifar10:0.2-instance | Epoch [ 26/ 75] Iter[901/1211]	  loss: 0.46cifar10:0.2-instance | Epoch [ 26/ 75] Iter[951/1211]	  loss: 0.38cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1001/1211]	  loss: 0.36cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1051/1211]	  loss: 0.75cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1101/1211]	  loss: 0.36cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1151/1211]	  loss: 0.58cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1201/1211]	  loss: 0.55
| Test Epoch 26	 Accuracy: 83.66% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 27 | Accuracy on train set: 70.08% 
labeled data has a size of 38808, f-score: 0.982066
cifar10:0.2-instance | Epoch [ 27/ 75] Iter[  1/1213]	  loss: 0.32cifar10:0.2-instance | Epoch [ 27/ 75] Iter[ 51/1213]	  loss: 0.24cifar10:0.2-instance | Epoch [ 27/ 75] Iter[101/1213]	  loss: 0.31cifar10:0.2-instance | Epoch [ 27/ 75] Iter[151/1213]	  loss: 0.54cifar10:0.2-instance | Epoch [ 27/ 75] Iter[201/1213]	  loss: 0.38cifar10:0.2-instance | Epoch [ 27/ 75] Iter[251/1213]	  loss: 0.53cifar10:0.2-instance | Epoch [ 27/ 75] Iter[301/1213]	  loss: 0.59cifar10:0.2-instance | Epoch [ 27/ 75] Iter[351/1213]	  loss: 0.62cifar10:0.2-instance | Epoch [ 27/ 75] Iter[401/1213]	  loss: 0.39cifar10:0.2-instance | Epoch [ 27/ 75] Iter[451/1213]	  loss: 0.59cifar10:0.2-instance | Epoch [ 27/ 75] Iter[501/1213]	  loss: 0.42cifar10:0.2-instance | Epoch [ 27/ 75] Iter[551/1213]	  loss: 0.49cifar10:0.2-instance | Epoch [ 27/ 75] Iter[601/1213]	  loss: 0.35cifar10:0.2-instance | Epoch [ 27/ 75] Iter[651/1213]	  loss: 0.31cifar10:0.2-instance | Epoch [ 27/ 75] Iter[701/1213]	  loss: 0.64cifar10:0.2-instance | Epoch [ 27/ 75] Iter[751/1213]	  loss: 0.31cifar10:0.2-instance | Epoch [ 27/ 75] Iter[801/1213]	  loss: 0.38cifar10:0.2-instance | Epoch [ 27/ 75] Iter[851/1213]	  loss: 0.35cifar10:0.2-instance | Epoch [ 27/ 75] Iter[901/1213]	  loss: 0.51cifar10:0.2-instance | Epoch [ 27/ 75] Iter[951/1213]	  loss: 0.41cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1001/1213]	  loss: 0.33cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1051/1213]	  loss: 0.64cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1101/1213]	  loss: 0.43cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1151/1213]	  loss: 0.41cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1201/1213]	  loss: 0.56
| Test Epoch 27	 Accuracy: 85.23% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 28 | Accuracy on train set: 71.19% 
labeled data has a size of 38722, f-score: 0.982646
cifar10:0.2-instance | Epoch [ 28/ 75] Iter[  1/1211]	  loss: 0.28cifar10:0.2-instance | Epoch [ 28/ 75] Iter[ 51/1211]	  loss: 0.37cifar10:0.2-instance | Epoch [ 28/ 75] Iter[101/1211]	  loss: 0.44cifar10:0.2-instance | Epoch [ 28/ 75] Iter[151/1211]	  loss: 0.36cifar10:0.2-instance | Epoch [ 28/ 75] Iter[201/1211]	  loss: 0.45cifar10:0.2-instance | Epoch [ 28/ 75] Iter[251/1211]	  loss: 0.30cifar10:0.2-instance | Epoch [ 28/ 75] Iter[301/1211]	  loss: 0.48cifar10:0.2-instance | Epoch [ 28/ 75] Iter[351/1211]	  loss: 0.27cifar10:0.2-instance | Epoch [ 28/ 75] Iter[401/1211]	  loss: 0.49cifar10:0.2-instance | Epoch [ 28/ 75] Iter[451/1211]	  loss: 0.39cifar10:0.2-instance | Epoch [ 28/ 75] Iter[501/1211]	  loss: 0.35cifar10:0.2-instance | Epoch [ 28/ 75] Iter[551/1211]	  loss: 0.50cifar10:0.2-instance | Epoch [ 28/ 75] Iter[601/1211]	  loss: 0.32cifar10:0.2-instance | Epoch [ 28/ 75] Iter[651/1211]	  loss: 0.40cifar10:0.2-instance | Epoch [ 28/ 75] Iter[701/1211]	  loss: 0.63cifar10:0.2-instance | Epoch [ 28/ 75] Iter[751/1211]	  loss: 0.57cifar10:0.2-instance | Epoch [ 28/ 75] Iter[801/1211]	  loss: 0.51cifar10:0.2-instance | Epoch [ 28/ 75] Iter[851/1211]	  loss: 0.58cifar10:0.2-instance | Epoch [ 28/ 75] Iter[901/1211]	  loss: 0.35cifar10:0.2-instance | Epoch [ 28/ 75] Iter[951/1211]	  loss: 0.37cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1001/1211]	  loss: 0.55cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1051/1211]	  loss: 0.87cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1101/1211]	  loss: 0.51cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1151/1211]	  loss: 0.34cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1201/1211]	  loss: 0.30
| Test Epoch 28	 Accuracy: 84.95% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 29 | Accuracy on train set: 70.67% 
labeled data has a size of 38878, f-score: 0.982381
cifar10:0.2-instance | Epoch [ 29/ 75] Iter[  1/1215]	  loss: 0.24cifar10:0.2-instance | Epoch [ 29/ 75] Iter[ 51/1215]	  loss: 0.33cifar10:0.2-instance | Epoch [ 29/ 75] Iter[101/1215]	  loss: 0.53cifar10:0.2-instance | Epoch [ 29/ 75] Iter[151/1215]	  loss: 0.54cifar10:0.2-instance | Epoch [ 29/ 75] Iter[201/1215]	  loss: 0.30cifar10:0.2-instance | Epoch [ 29/ 75] Iter[251/1215]	  loss: 0.45cifar10:0.2-instance | Epoch [ 29/ 75] Iter[301/1215]	  loss: 0.66cifar10:0.2-instance | Epoch [ 29/ 75] Iter[351/1215]	  loss: 0.27cifar10:0.2-instance | Epoch [ 29/ 75] Iter[401/1215]	  loss: 0.53cifar10:0.2-instance | Epoch [ 29/ 75] Iter[451/1215]	  loss: 0.24cifar10:0.2-instance | Epoch [ 29/ 75] Iter[501/1215]	  loss: 0.32cifar10:0.2-instance | Epoch [ 29/ 75] Iter[551/1215]	  loss: 0.32cifar10:0.2-instance | Epoch [ 29/ 75] Iter[601/1215]	  loss: 0.26cifar10:0.2-instance | Epoch [ 29/ 75] Iter[651/1215]	  loss: 0.51cifar10:0.2-instance | Epoch [ 29/ 75] Iter[701/1215]	  loss: 0.63cifar10:0.2-instance | Epoch [ 29/ 75] Iter[751/1215]	  loss: 0.57cifar10:0.2-instance | Epoch [ 29/ 75] Iter[801/1215]	  loss: 0.53cifar10:0.2-instance | Epoch [ 29/ 75] Iter[851/1215]	  loss: 0.37cifar10:0.2-instance | Epoch [ 29/ 75] Iter[901/1215]	  loss: 0.45cifar10:0.2-instance | Epoch [ 29/ 75] Iter[951/1215]	  loss: 0.44cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1001/1215]	  loss: 0.51cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1051/1215]	  loss: 0.46cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1101/1215]	  loss: 0.42cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1151/1215]	  loss: 0.39cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1201/1215]	  loss: 0.63
| Test Epoch 29	 Accuracy: 84.24% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 30 | Accuracy on train set: 70.60% 
labeled data has a size of 38856, f-score: 0.982860
cifar10:0.2-instance | Epoch [ 30/ 75] Iter[  1/1215]	  loss: 0.59cifar10:0.2-instance | Epoch [ 30/ 75] Iter[ 51/1215]	  loss: 0.64cifar10:0.2-instance | Epoch [ 30/ 75] Iter[101/1215]	  loss: 0.43cifar10:0.2-instance | Epoch [ 30/ 75] Iter[151/1215]	  loss: 0.52cifar10:0.2-instance | Epoch [ 30/ 75] Iter[201/1215]	  loss: 0.29cifar10:0.2-instance | Epoch [ 30/ 75] Iter[251/1215]	  loss: 0.33cifar10:0.2-instance | Epoch [ 30/ 75] Iter[301/1215]	  loss: 0.40cifar10:0.2-instance | Epoch [ 30/ 75] Iter[351/1215]	  loss: 0.54cifar10:0.2-instance | Epoch [ 30/ 75] Iter[401/1215]	  loss: 0.25cifar10:0.2-instance | Epoch [ 30/ 75] Iter[451/1215]	  loss: 0.36cifar10:0.2-instance | Epoch [ 30/ 75] Iter[501/1215]	  loss: 0.56cifar10:0.2-instance | Epoch [ 30/ 75] Iter[551/1215]	  loss: 0.45cifar10:0.2-instance | Epoch [ 30/ 75] Iter[601/1215]	  loss: 0.50cifar10:0.2-instance | Epoch [ 30/ 75] Iter[651/1215]	  loss: 0.34cifar10:0.2-instance | Epoch [ 30/ 75] Iter[701/1215]	  loss: 0.31cifar10:0.2-instance | Epoch [ 30/ 75] Iter[751/1215]	  loss: 0.56cifar10:0.2-instance | Epoch [ 30/ 75] Iter[801/1215]	  loss: 0.39cifar10:0.2-instance | Epoch [ 30/ 75] Iter[851/1215]	  loss: 0.47cifar10:0.2-instance | Epoch [ 30/ 75] Iter[901/1215]	  loss: 0.28cifar10:0.2-instance | Epoch [ 30/ 75] Iter[951/1215]	  loss: 0.28cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1001/1215]	  loss: 0.24cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1051/1215]	  loss: 0.51cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1101/1215]	  loss: 0.62cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1151/1215]	  loss: 0.34cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1201/1215]	  loss: 0.50
| Test Epoch 30	 Accuracy: 84.37% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 31 | Accuracy on train set: 70.49% 
labeled data has a size of 38891, f-score: 0.983055
cifar10:0.2-instance | Epoch [ 31/ 75] Iter[  1/1216]	  loss: 0.69cifar10:0.2-instance | Epoch [ 31/ 75] Iter[ 51/1216]	  loss: 0.33cifar10:0.2-instance | Epoch [ 31/ 75] Iter[101/1216]	  loss: 0.39cifar10:0.2-instance | Epoch [ 31/ 75] Iter[151/1216]	  loss: 0.42cifar10:0.2-instance | Epoch [ 31/ 75] Iter[201/1216]	  loss: 0.52cifar10:0.2-instance | Epoch [ 31/ 75] Iter[251/1216]	  loss: 0.30cifar10:0.2-instance | Epoch [ 31/ 75] Iter[301/1216]	  loss: 0.33cifar10:0.2-instance | Epoch [ 31/ 75] Iter[351/1216]	  loss: 0.46cifar10:0.2-instance | Epoch [ 31/ 75] Iter[401/1216]	  loss: 0.42cifar10:0.2-instance | Epoch [ 31/ 75] Iter[451/1216]	  loss: 0.38cifar10:0.2-instance | Epoch [ 31/ 75] Iter[501/1216]	  loss: 0.50cifar10:0.2-instance | Epoch [ 31/ 75] Iter[551/1216]	  loss: 0.36cifar10:0.2-instance | Epoch [ 31/ 75] Iter[601/1216]	  loss: 0.24cifar10:0.2-instance | Epoch [ 31/ 75] Iter[651/1216]	  loss: 0.42cifar10:0.2-instance | Epoch [ 31/ 75] Iter[701/1216]	  loss: 0.38cifar10:0.2-instance | Epoch [ 31/ 75] Iter[751/1216]	  loss: 0.38cifar10:0.2-instance | Epoch [ 31/ 75] Iter[801/1216]	  loss: 0.45cifar10:0.2-instance | Epoch [ 31/ 75] Iter[851/1216]	  loss: 0.45cifar10:0.2-instance | Epoch [ 31/ 75] Iter[901/1216]	  loss: 0.36cifar10:0.2-instance | Epoch [ 31/ 75] Iter[951/1216]	  loss: 0.38cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1001/1216]	  loss: 0.34cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1051/1216]	  loss: 0.45cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1101/1216]	  loss: 0.54cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1151/1216]	  loss: 0.32cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1201/1216]	  loss: 0.47
| Test Epoch 31	 Accuracy: 83.98% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 32 | Accuracy on train set: 70.08% 
labeled data has a size of 38924, f-score: 0.982967
cifar10:0.2-instance | Epoch [ 32/ 75] Iter[  1/1217]	  loss: 0.41cifar10:0.2-instance | Epoch [ 32/ 75] Iter[ 51/1217]	  loss: 0.33cifar10:0.2-instance | Epoch [ 32/ 75] Iter[101/1217]	  loss: 0.33cifar10:0.2-instance | Epoch [ 32/ 75] Iter[151/1217]	  loss: 0.33cifar10:0.2-instance | Epoch [ 32/ 75] Iter[201/1217]	  loss: 0.41cifar10:0.2-instance | Epoch [ 32/ 75] Iter[251/1217]	  loss: 0.38cifar10:0.2-instance | Epoch [ 32/ 75] Iter[301/1217]	  loss: 0.56cifar10:0.2-instance | Epoch [ 32/ 75] Iter[351/1217]	  loss: 0.29cifar10:0.2-instance | Epoch [ 32/ 75] Iter[401/1217]	  loss: 0.23cifar10:0.2-instance | Epoch [ 32/ 75] Iter[451/1217]	  loss: 0.35cifar10:0.2-instance | Epoch [ 32/ 75] Iter[501/1217]	  loss: 0.30cifar10:0.2-instance | Epoch [ 32/ 75] Iter[551/1217]	  loss: 0.56cifar10:0.2-instance | Epoch [ 32/ 75] Iter[601/1217]	  loss: 0.43cifar10:0.2-instance | Epoch [ 32/ 75] Iter[651/1217]	  loss: 0.37cifar10:0.2-instance | Epoch [ 32/ 75] Iter[701/1217]	  loss: 0.43cifar10:0.2-instance | Epoch [ 32/ 75] Iter[751/1217]	  loss: 0.71cifar10:0.2-instance | Epoch [ 32/ 75] Iter[801/1217]	  loss: 0.35cifar10:0.2-instance | Epoch [ 32/ 75] Iter[851/1217]	  loss: 0.33cifar10:0.2-instance | Epoch [ 32/ 75] Iter[901/1217]	  loss: 0.31cifar10:0.2-instance | Epoch [ 32/ 75] Iter[951/1217]	  loss: 0.50cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1001/1217]	  loss: 0.56cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1051/1217]	  loss: 0.36cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1101/1217]	  loss: 0.57cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1151/1217]	  loss: 0.67cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1201/1217]	  loss: 0.74
| Test Epoch 32	 Accuracy: 84.81% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 33 | Accuracy on train set: 70.88% 
labeled data has a size of 38912, f-score: 0.984118
cifar10:0.2-instance | Epoch [ 33/ 75] Iter[  1/1217]	  loss: 0.40cifar10:0.2-instance | Epoch [ 33/ 75] Iter[ 51/1217]	  loss: 0.47cifar10:0.2-instance | Epoch [ 33/ 75] Iter[101/1217]	  loss: 0.69cifar10:0.2-instance | Epoch [ 33/ 75] Iter[151/1217]	  loss: 0.63cifar10:0.2-instance | Epoch [ 33/ 75] Iter[201/1217]	  loss: 0.37cifar10:0.2-instance | Epoch [ 33/ 75] Iter[251/1217]	  loss: 0.36cifar10:0.2-instance | Epoch [ 33/ 75] Iter[301/1217]	  loss: 0.33cifar10:0.2-instance | Epoch [ 33/ 75] Iter[351/1217]	  loss: 0.42cifar10:0.2-instance | Epoch [ 33/ 75] Iter[401/1217]	  loss: 0.54cifar10:0.2-instance | Epoch [ 33/ 75] Iter[451/1217]	  loss: 0.52cifar10:0.2-instance | Epoch [ 33/ 75] Iter[501/1217]	  loss: 0.51cifar10:0.2-instance | Epoch [ 33/ 75] Iter[551/1217]	  loss: 0.69cifar10:0.2-instance | Epoch [ 33/ 75] Iter[601/1217]	  loss: 0.34cifar10:0.2-instance | Epoch [ 33/ 75] Iter[651/1217]	  loss: 0.60cifar10:0.2-instance | Epoch [ 33/ 75] Iter[701/1217]	  loss: 0.25cifar10:0.2-instance | Epoch [ 33/ 75] Iter[751/1217]	  loss: 0.42cifar10:0.2-instance | Epoch [ 33/ 75] Iter[801/1217]	  loss: 0.51cifar10:0.2-instance | Epoch [ 33/ 75] Iter[851/1217]	  loss: 0.43cifar10:0.2-instance | Epoch [ 33/ 75] Iter[901/1217]	  loss: 0.26cifar10:0.2-instance | Epoch [ 33/ 75] Iter[951/1217]	  loss: 0.63cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1001/1217]	  loss: 0.35cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1051/1217]	  loss: 0.54cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1101/1217]	  loss: 0.44cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1151/1217]	  loss: 0.47cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1201/1217]	  loss: 0.28
| Test Epoch 33	 Accuracy: 85.80% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 34 | Accuracy on train set: 71.96% 
labeled data has a size of 38892, f-score: 0.984007
cifar10:0.2-instance | Epoch [ 34/ 75] Iter[  1/1216]	  loss: 0.37cifar10:0.2-instance | Epoch [ 34/ 75] Iter[ 51/1216]	  loss: 0.38cifar10:0.2-instance | Epoch [ 34/ 75] Iter[101/1216]	  loss: 0.38cifar10:0.2-instance | Epoch [ 34/ 75] Iter[151/1216]	  loss: 0.37cifar10:0.2-instance | Epoch [ 34/ 75] Iter[201/1216]	  loss: 0.43cifar10:0.2-instance | Epoch [ 34/ 75] Iter[251/1216]	  loss: 0.52cifar10:0.2-instance | Epoch [ 34/ 75] Iter[301/1216]	  loss: 0.42cifar10:0.2-instance | Epoch [ 34/ 75] Iter[351/1216]	  loss: 0.51cifar10:0.2-instance | Epoch [ 34/ 75] Iter[401/1216]	  loss: 0.41cifar10:0.2-instance | Epoch [ 34/ 75] Iter[451/1216]	  loss: 0.63cifar10:0.2-instance | Epoch [ 34/ 75] Iter[501/1216]	  loss: 0.21cifar10:0.2-instance | Epoch [ 34/ 75] Iter[551/1216]	  loss: 0.35cifar10:0.2-instance | Epoch [ 34/ 75] Iter[601/1216]	  loss: 0.29cifar10:0.2-instance | Epoch [ 34/ 75] Iter[651/1216]	  loss: 0.29cifar10:0.2-instance | Epoch [ 34/ 75] Iter[701/1216]	  loss: 0.47cifar10:0.2-instance | Epoch [ 34/ 75] Iter[751/1216]	  loss: 0.33cifar10:0.2-instance | Epoch [ 34/ 75] Iter[801/1216]	  loss: 0.23cifar10:0.2-instance | Epoch [ 34/ 75] Iter[851/1216]	  loss: 0.45cifar10:0.2-instance | Epoch [ 34/ 75] Iter[901/1216]	  loss: 0.34cifar10:0.2-instance | Epoch [ 34/ 75] Iter[951/1216]	  loss: 0.68cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1001/1216]	  loss: 0.24cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1051/1216]	  loss: 0.28cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1101/1216]	  loss: 0.52cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1151/1216]	  loss: 0.41cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1201/1216]	  loss: 0.48
| Test Epoch 34	 Accuracy: 85.41% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 35 | Accuracy on train set: 71.81% 
labeled data has a size of 38905, f-score: 0.985015
cifar10:0.2-instance | Epoch [ 35/ 75] Iter[  1/1216]	  loss: 0.34cifar10:0.2-instance | Epoch [ 35/ 75] Iter[ 51/1216]	  loss: 0.19cifar10:0.2-instance | Epoch [ 35/ 75] Iter[101/1216]	  loss: 0.67cifar10:0.2-instance | Epoch [ 35/ 75] Iter[151/1216]	  loss: 0.42cifar10:0.2-instance | Epoch [ 35/ 75] Iter[201/1216]	  loss: 0.48cifar10:0.2-instance | Epoch [ 35/ 75] Iter[251/1216]	  loss: 0.32cifar10:0.2-instance | Epoch [ 35/ 75] Iter[301/1216]	  loss: 0.49cifar10:0.2-instance | Epoch [ 35/ 75] Iter[351/1216]	  loss: 0.35cifar10:0.2-instance | Epoch [ 35/ 75] Iter[401/1216]	  loss: 0.62cifar10:0.2-instance | Epoch [ 35/ 75] Iter[451/1216]	  loss: 0.48cifar10:0.2-instance | Epoch [ 35/ 75] Iter[501/1216]	  loss: 0.64cifar10:0.2-instance | Epoch [ 35/ 75] Iter[551/1216]	  loss: 0.82cifar10:0.2-instance | Epoch [ 35/ 75] Iter[601/1216]	  loss: 0.37cifar10:0.2-instance | Epoch [ 35/ 75] Iter[651/1216]	  loss: 0.29cifar10:0.2-instance | Epoch [ 35/ 75] Iter[701/1216]	  loss: 0.31cifar10:0.2-instance | Epoch [ 35/ 75] Iter[751/1216]	  loss: 0.39cifar10:0.2-instance | Epoch [ 35/ 75] Iter[801/1216]	  loss: 0.48cifar10:0.2-instance | Epoch [ 35/ 75] Iter[851/1216]	  loss: 0.23cifar10:0.2-instance | Epoch [ 35/ 75] Iter[901/1216]	  loss: 0.34cifar10:0.2-instance | Epoch [ 35/ 75] Iter[951/1216]	  loss: 0.47cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1001/1216]	  loss: 0.37cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1051/1216]	  loss: 0.35cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1101/1216]	  loss: 0.34cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1151/1216]	  loss: 0.39cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1201/1216]	  loss: 0.36
| Test Epoch 35	 Accuracy: 84.68% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 36 | Accuracy on train set: 71.00% 
labeled data has a size of 38970, f-score: 0.983885
cifar10:0.2-instance | Epoch [ 36/ 75] Iter[  1/1218]	  loss: 0.26cifar10:0.2-instance | Epoch [ 36/ 75] Iter[ 51/1218]	  loss: 0.37cifar10:0.2-instance | Epoch [ 36/ 75] Iter[101/1218]	  loss: 0.70cifar10:0.2-instance | Epoch [ 36/ 75] Iter[151/1218]	  loss: 0.41cifar10:0.2-instance | Epoch [ 36/ 75] Iter[201/1218]	  loss: 0.59cifar10:0.2-instance | Epoch [ 36/ 75] Iter[251/1218]	  loss: 0.72cifar10:0.2-instance | Epoch [ 36/ 75] Iter[301/1218]	  loss: 0.47cifar10:0.2-instance | Epoch [ 36/ 75] Iter[351/1218]	  loss: 0.27cifar10:0.2-instance | Epoch [ 36/ 75] Iter[401/1218]	  loss: 0.41cifar10:0.2-instance | Epoch [ 36/ 75] Iter[451/1218]	  loss: 0.58cifar10:0.2-instance | Epoch [ 36/ 75] Iter[501/1218]	  loss: 0.29cifar10:0.2-instance | Epoch [ 36/ 75] Iter[551/1218]	  loss: 0.44cifar10:0.2-instance | Epoch [ 36/ 75] Iter[601/1218]	  loss: 0.56cifar10:0.2-instance | Epoch [ 36/ 75] Iter[651/1218]	  loss: 0.69cifar10:0.2-instance | Epoch [ 36/ 75] Iter[701/1218]	  loss: 0.37cifar10:0.2-instance | Epoch [ 36/ 75] Iter[751/1218]	  loss: 0.74cifar10:0.2-instance | Epoch [ 36/ 75] Iter[801/1218]	  loss: 0.40cifar10:0.2-instance | Epoch [ 36/ 75] Iter[851/1218]	  loss: 0.30cifar10:0.2-instance | Epoch [ 36/ 75] Iter[901/1218]	  loss: 0.37cifar10:0.2-instance | Epoch [ 36/ 75] Iter[951/1218]	  loss: 0.51cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1001/1218]	  loss: 0.63cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1051/1218]	  loss: 0.18cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1101/1218]	  loss: 0.50cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1151/1218]	  loss: 0.34cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1201/1218]	  loss: 0.37
| Test Epoch 36	 Accuracy: 83.40% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 37 | Accuracy on train set: 69.88% 
labeled data has a size of 38982, f-score: 0.983454
cifar10:0.2-instance | Epoch [ 37/ 75] Iter[  1/1219]	  loss: 0.64cifar10:0.2-instance | Epoch [ 37/ 75] Iter[ 51/1219]	  loss: 0.39cifar10:0.2-instance | Epoch [ 37/ 75] Iter[101/1219]	  loss: 0.56cifar10:0.2-instance | Epoch [ 37/ 75] Iter[151/1219]	  loss: 0.35cifar10:0.2-instance | Epoch [ 37/ 75] Iter[201/1219]	  loss: 0.61cifar10:0.2-instance | Epoch [ 37/ 75] Iter[251/1219]	  loss: 0.37cifar10:0.2-instance | Epoch [ 37/ 75] Iter[301/1219]	  loss: 0.34cifar10:0.2-instance | Epoch [ 37/ 75] Iter[351/1219]	  loss: 0.45cifar10:0.2-instance | Epoch [ 37/ 75] Iter[401/1219]	  loss: 0.29cifar10:0.2-instance | Epoch [ 37/ 75] Iter[451/1219]	  loss: 0.39cifar10:0.2-instance | Epoch [ 37/ 75] Iter[501/1219]	  loss: 0.32cifar10:0.2-instance | Epoch [ 37/ 75] Iter[551/1219]	  loss: 0.42cifar10:0.2-instance | Epoch [ 37/ 75] Iter[601/1219]	  loss: 0.38cifar10:0.2-instance | Epoch [ 37/ 75] Iter[651/1219]	  loss: 0.41cifar10:0.2-instance | Epoch [ 37/ 75] Iter[701/1219]	  loss: 0.55cifar10:0.2-instance | Epoch [ 37/ 75] Iter[751/1219]	  loss: 0.66cifar10:0.2-instance | Epoch [ 37/ 75] Iter[801/1219]	  loss: 0.73cifar10:0.2-instance | Epoch [ 37/ 75] Iter[851/1219]	  loss: 0.41cifar10:0.2-instance | Epoch [ 37/ 75] Iter[901/1219]	  loss: 0.47cifar10:0.2-instance | Epoch [ 37/ 75] Iter[951/1219]	  loss: 0.43cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1001/1219]	  loss: 0.38cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1051/1219]	  loss: 0.47cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1101/1219]	  loss: 0.51cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1151/1219]	  loss: 0.42cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1201/1219]	  loss: 0.36
| Test Epoch 37	 Accuracy: 83.39% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 38 | Accuracy on train set: 70.27% 
labeled data has a size of 38971, f-score: 0.982115
cifar10:0.2-instance | Epoch [ 38/ 75] Iter[  1/1218]	  loss: 0.45cifar10:0.2-instance | Epoch [ 38/ 75] Iter[ 51/1218]	  loss: 0.21cifar10:0.2-instance | Epoch [ 38/ 75] Iter[101/1218]	  loss: 0.32cifar10:0.2-instance | Epoch [ 38/ 75] Iter[151/1218]	  loss: 0.54cifar10:0.2-instance | Epoch [ 38/ 75] Iter[201/1218]	  loss: 0.28cifar10:0.2-instance | Epoch [ 38/ 75] Iter[251/1218]	  loss: 0.37cifar10:0.2-instance | Epoch [ 38/ 75] Iter[301/1218]	  loss: 0.38cifar10:0.2-instance | Epoch [ 38/ 75] Iter[351/1218]	  loss: 0.50cifar10:0.2-instance | Epoch [ 38/ 75] Iter[401/1218]	  loss: 0.74cifar10:0.2-instance | Epoch [ 38/ 75] Iter[451/1218]	  loss: 0.45cifar10:0.2-instance | Epoch [ 38/ 75] Iter[501/1218]	  loss: 0.62cifar10:0.2-instance | Epoch [ 38/ 75] Iter[551/1218]	  loss: 0.35cifar10:0.2-instance | Epoch [ 38/ 75] Iter[601/1218]	  loss: 0.32cifar10:0.2-instance | Epoch [ 38/ 75] Iter[651/1218]	  loss: 0.33cifar10:0.2-instance | Epoch [ 38/ 75] Iter[701/1218]	  loss: 0.39cifar10:0.2-instance | Epoch [ 38/ 75] Iter[751/1218]	  loss: 0.32cifar10:0.2-instance | Epoch [ 38/ 75] Iter[801/1218]	  loss: 0.41cifar10:0.2-instance | Epoch [ 38/ 75] Iter[851/1218]	  loss: 0.42cifar10:0.2-instance | Epoch [ 38/ 75] Iter[901/1218]	  loss: 0.51cifar10:0.2-instance | Epoch [ 38/ 75] Iter[951/1218]	  loss: 0.21cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1001/1218]	  loss: 0.49cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1051/1218]	  loss: 0.47cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1101/1218]	  loss: 0.29cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1151/1218]	  loss: 0.51cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1201/1218]	  loss: 0.40
| Test Epoch 38	 Accuracy: 84.61% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 39 | Accuracy on train set: 71.34% 
labeled data has a size of 38941, f-score: 0.981639
cifar10:0.2-instance | Epoch [ 39/ 75] Iter[  1/1217]	  loss: 0.33cifar10:0.2-instance | Epoch [ 39/ 75] Iter[ 51/1217]	  loss: 0.24cifar10:0.2-instance | Epoch [ 39/ 75] Iter[101/1217]	  loss: 0.54cifar10:0.2-instance | Epoch [ 39/ 75] Iter[151/1217]	  loss: 0.35cifar10:0.2-instance | Epoch [ 39/ 75] Iter[201/1217]	  loss: 0.38cifar10:0.2-instance | Epoch [ 39/ 75] Iter[251/1217]	  loss: 0.37cifar10:0.2-instance | Epoch [ 39/ 75] Iter[301/1217]	  loss: 0.37cifar10:0.2-instance | Epoch [ 39/ 75] Iter[351/1217]	  loss: 0.43cifar10:0.2-instance | Epoch [ 39/ 75] Iter[401/1217]	  loss: 0.38cifar10:0.2-instance | Epoch [ 39/ 75] Iter[451/1217]	  loss: 0.61cifar10:0.2-instance | Epoch [ 39/ 75] Iter[501/1217]	  loss: 0.42cifar10:0.2-instance | Epoch [ 39/ 75] Iter[551/1217]	  loss: 0.47cifar10:0.2-instance | Epoch [ 39/ 75] Iter[601/1217]	  loss: 0.50cifar10:0.2-instance | Epoch [ 39/ 75] Iter[651/1217]	  loss: 0.44cifar10:0.2-instance | Epoch [ 39/ 75] Iter[701/1217]	  loss: 0.50cifar10:0.2-instance | Epoch [ 39/ 75] Iter[751/1217]	  loss: 0.30cifar10:0.2-instance | Epoch [ 39/ 75] Iter[801/1217]	  loss: 0.73cifar10:0.2-instance | Epoch [ 39/ 75] Iter[851/1217]	  loss: 0.33cifar10:0.2-instance | Epoch [ 39/ 75] Iter[901/1217]	  loss: 0.48cifar10:0.2-instance | Epoch [ 39/ 75] Iter[951/1217]	  loss: 0.30cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1001/1217]	  loss: 0.33cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1051/1217]	  loss: 0.58cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1101/1217]	  loss: 0.32cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1151/1217]	  loss: 0.32cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1201/1217]	  loss: 0.40
| Test Epoch 39	 Accuracy: 84.07% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 40 | Accuracy on train set: 70.42% 
labeled data has a size of 38821, f-score: 0.980912
cifar10:0.2-instance | Epoch [ 40/ 75] Iter[  1/1214]	  loss: 0.38cifar10:0.2-instance | Epoch [ 40/ 75] Iter[ 51/1214]	  loss: 0.40cifar10:0.2-instance | Epoch [ 40/ 75] Iter[101/1214]	  loss: 0.38cifar10:0.2-instance | Epoch [ 40/ 75] Iter[151/1214]	  loss: 0.49cifar10:0.2-instance | Epoch [ 40/ 75] Iter[201/1214]	  loss: 0.42cifar10:0.2-instance | Epoch [ 40/ 75] Iter[251/1214]	  loss: 0.51cifar10:0.2-instance | Epoch [ 40/ 75] Iter[301/1214]	  loss: 0.33cifar10:0.2-instance | Epoch [ 40/ 75] Iter[351/1214]	  loss: 0.32cifar10:0.2-instance | Epoch [ 40/ 75] Iter[401/1214]	  loss: 0.42cifar10:0.2-instance | Epoch [ 40/ 75] Iter[451/1214]	  loss: 0.36cifar10:0.2-instance | Epoch [ 40/ 75] Iter[501/1214]	  loss: 0.41cifar10:0.2-instance | Epoch [ 40/ 75] Iter[551/1214]	  loss: 0.31cifar10:0.2-instance | Epoch [ 40/ 75] Iter[601/1214]	  loss: 0.52cifar10:0.2-instance | Epoch [ 40/ 75] Iter[651/1214]	  loss: 0.34cifar10:0.2-instance | Epoch [ 40/ 75] Iter[701/1214]	  loss: 0.44cifar10:0.2-instance | Epoch [ 40/ 75] Iter[751/1214]	  loss: 0.40cifar10:0.2-instance | Epoch [ 40/ 75] Iter[801/1214]	  loss: 0.38cifar10:0.2-instance | Epoch [ 40/ 75] Iter[851/1214]	  loss: 0.42cifar10:0.2-instance | Epoch [ 40/ 75] Iter[901/1214]	  loss: 0.26cifar10:0.2-instance | Epoch [ 40/ 75] Iter[951/1214]	  loss: 0.45cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1001/1214]	  loss: 0.34cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1051/1214]	  loss: 0.54cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1101/1214]	  loss: 0.57cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1151/1214]	  loss: 0.32cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1201/1214]	  loss: 0.29
| Test Epoch 40	 Accuracy: 84.95% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 41 | Accuracy on train set: 71.20% 
labeled data has a size of 39043, f-score: 0.980970
cifar10:0.2-instance | Epoch [ 41/ 75] Iter[  1/1221]	  loss: 0.53cifar10:0.2-instance | Epoch [ 41/ 75] Iter[ 51/1221]	  loss: 0.45cifar10:0.2-instance | Epoch [ 41/ 75] Iter[101/1221]	  loss: 0.37cifar10:0.2-instance | Epoch [ 41/ 75] Iter[151/1221]	  loss: 0.23cifar10:0.2-instance | Epoch [ 41/ 75] Iter[201/1221]	  loss: 0.25cifar10:0.2-instance | Epoch [ 41/ 75] Iter[251/1221]	  loss: 0.37cifar10:0.2-instance | Epoch [ 41/ 75] Iter[301/1221]	  loss: 0.73cifar10:0.2-instance | Epoch [ 41/ 75] Iter[351/1221]	  loss: 0.38cifar10:0.2-instance | Epoch [ 41/ 75] Iter[401/1221]	  loss: 0.31cifar10:0.2-instance | Epoch [ 41/ 75] Iter[451/1221]	  loss: 0.43cifar10:0.2-instance | Epoch [ 41/ 75] Iter[501/1221]	  loss: 0.55cifar10:0.2-instance | Epoch [ 41/ 75] Iter[551/1221]	  loss: 0.50cifar10:0.2-instance | Epoch [ 41/ 75] Iter[601/1221]	  loss: 0.44cifar10:0.2-instance | Epoch [ 41/ 75] Iter[651/1221]	  loss: 0.42cifar10:0.2-instance | Epoch [ 41/ 75] Iter[701/1221]	  loss: 0.42cifar10:0.2-instance | Epoch [ 41/ 75] Iter[751/1221]	  loss: 0.31cifar10:0.2-instance | Epoch [ 41/ 75] Iter[801/1221]	  loss: 0.39cifar10:0.2-instance | Epoch [ 41/ 75] Iter[851/1221]	  loss: 0.41cifar10:0.2-instance | Epoch [ 41/ 75] Iter[901/1221]	  loss: 0.33cifar10:0.2-instance | Epoch [ 41/ 75] Iter[951/1221]	  loss: 0.45cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1001/1221]	  loss: 0.46cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1051/1221]	  loss: 0.49cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1101/1221]	  loss: 0.29cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1151/1221]	  loss: 0.48cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1201/1221]	  loss: 0.58
| Test Epoch 41	 Accuracy: 86.02% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 42 | Accuracy on train set: 72.08% 
labeled data has a size of 39247, f-score: 0.981069
cifar10:0.2-instance | Epoch [ 42/ 75] Iter[  1/1227]	  loss: 0.36cifar10:0.2-instance | Epoch [ 42/ 75] Iter[ 51/1227]	  loss: 0.41cifar10:0.2-instance | Epoch [ 42/ 75] Iter[101/1227]	  loss: 0.20cifar10:0.2-instance | Epoch [ 42/ 75] Iter[151/1227]	  loss: 0.25cifar10:0.2-instance | Epoch [ 42/ 75] Iter[201/1227]	  loss: 0.33cifar10:0.2-instance | Epoch [ 42/ 75] Iter[251/1227]	  loss: 0.31cifar10:0.2-instance | Epoch [ 42/ 75] Iter[301/1227]	  loss: 0.50cifar10:0.2-instance | Epoch [ 42/ 75] Iter[351/1227]	  loss: 0.34cifar10:0.2-instance | Epoch [ 42/ 75] Iter[401/1227]	  loss: 0.47cifar10:0.2-instance | Epoch [ 42/ 75] Iter[451/1227]	  loss: 0.41cifar10:0.2-instance | Epoch [ 42/ 75] Iter[501/1227]	  loss: 0.32cifar10:0.2-instance | Epoch [ 42/ 75] Iter[551/1227]	  loss: 0.41cifar10:0.2-instance | Epoch [ 42/ 75] Iter[601/1227]	  loss: 0.36cifar10:0.2-instance | Epoch [ 42/ 75] Iter[651/1227]	  loss: 0.31cifar10:0.2-instance | Epoch [ 42/ 75] Iter[701/1227]	  loss: 0.42cifar10:0.2-instance | Epoch [ 42/ 75] Iter[751/1227]	  loss: 0.34cifar10:0.2-instance | Epoch [ 42/ 75] Iter[801/1227]	  loss: 0.58cifar10:0.2-instance | Epoch [ 42/ 75] Iter[851/1227]	  loss: 0.34cifar10:0.2-instance | Epoch [ 42/ 75] Iter[901/1227]	  loss: 0.46cifar10:0.2-instance | Epoch [ 42/ 75] Iter[951/1227]	  loss: 0.53cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1001/1227]	  loss: 0.37cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1051/1227]	  loss: 0.37cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1101/1227]	  loss: 0.36cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1151/1227]	  loss: 0.57cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1201/1227]	  loss: 0.35
| Test Epoch 42	 Accuracy: 84.99% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 43 | Accuracy on train set: 71.63% 
labeled data has a size of 39096, f-score: 0.983170
cifar10:0.2-instance | Epoch [ 43/ 75] Iter[  1/1222]	  loss: 0.32cifar10:0.2-instance | Epoch [ 43/ 75] Iter[ 51/1222]	  loss: 0.28cifar10:0.2-instance | Epoch [ 43/ 75] Iter[101/1222]	  loss: 0.27cifar10:0.2-instance | Epoch [ 43/ 75] Iter[151/1222]	  loss: 0.42cifar10:0.2-instance | Epoch [ 43/ 75] Iter[201/1222]	  loss: 0.38cifar10:0.2-instance | Epoch [ 43/ 75] Iter[251/1222]	  loss: 0.29cifar10:0.2-instance | Epoch [ 43/ 75] Iter[301/1222]	  loss: 0.33cifar10:0.2-instance | Epoch [ 43/ 75] Iter[351/1222]	  loss: 0.31cifar10:0.2-instance | Epoch [ 43/ 75] Iter[401/1222]	  loss: 0.36cifar10:0.2-instance | Epoch [ 43/ 75] Iter[451/1222]	  loss: 0.26cifar10:0.2-instance | Epoch [ 43/ 75] Iter[501/1222]	  loss: 0.43cifar10:0.2-instance | Epoch [ 43/ 75] Iter[551/1222]	  loss: 0.43cifar10:0.2-instance | Epoch [ 43/ 75] Iter[601/1222]	  loss: 0.44cifar10:0.2-instance | Epoch [ 43/ 75] Iter[651/1222]	  loss: 0.36cifar10:0.2-instance | Epoch [ 43/ 75] Iter[701/1222]	  loss: 0.26cifar10:0.2-instance | Epoch [ 43/ 75] Iter[751/1222]	  loss: 0.37cifar10:0.2-instance | Epoch [ 43/ 75] Iter[801/1222]	  loss: 0.55cifar10:0.2-instance | Epoch [ 43/ 75] Iter[851/1222]	  loss: 0.37cifar10:0.2-instance | Epoch [ 43/ 75] Iter[901/1222]	  loss: 0.61cifar10:0.2-instance | Epoch [ 43/ 75] Iter[951/1222]	  loss: 0.37cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1001/1222]	  loss: 0.40cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1051/1222]	  loss: 0.63cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1101/1222]	  loss: 0.37cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1151/1222]	  loss: 0.52cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1201/1222]	  loss: 0.24
| Test Epoch 43	 Accuracy: 85.27% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 44 | Accuracy on train set: 71.99% 
labeled data has a size of 39139, f-score: 0.982626
cifar10:0.2-instance | Epoch [ 44/ 75] Iter[  1/1224]	  loss: 0.35cifar10:0.2-instance | Epoch [ 44/ 75] Iter[ 51/1224]	  loss: 0.41cifar10:0.2-instance | Epoch [ 44/ 75] Iter[101/1224]	  loss: 0.30cifar10:0.2-instance | Epoch [ 44/ 75] Iter[151/1224]	  loss: 0.29cifar10:0.2-instance | Epoch [ 44/ 75] Iter[201/1224]	  loss: 0.30cifar10:0.2-instance | Epoch [ 44/ 75] Iter[251/1224]	  loss: 0.53cifar10:0.2-instance | Epoch [ 44/ 75] Iter[301/1224]	  loss: 0.41cifar10:0.2-instance | Epoch [ 44/ 75] Iter[351/1224]	  loss: 0.23cifar10:0.2-instance | Epoch [ 44/ 75] Iter[401/1224]	  loss: 0.33cifar10:0.2-instance | Epoch [ 44/ 75] Iter[451/1224]	  loss: 0.27cifar10:0.2-instance | Epoch [ 44/ 75] Iter[501/1224]	  loss: 0.23cifar10:0.2-instance | Epoch [ 44/ 75] Iter[551/1224]	  loss: 0.27cifar10:0.2-instance | Epoch [ 44/ 75] Iter[601/1224]	  loss: 0.66cifar10:0.2-instance | Epoch [ 44/ 75] Iter[651/1224]	  loss: 0.36cifar10:0.2-instance | Epoch [ 44/ 75] Iter[701/1224]	  loss: 0.49cifar10:0.2-instance | Epoch [ 44/ 75] Iter[751/1224]	  loss: 0.25cifar10:0.2-instance | Epoch [ 44/ 75] Iter[801/1224]	  loss: 0.51cifar10:0.2-instance | Epoch [ 44/ 75] Iter[851/1224]	  loss: 0.38cifar10:0.2-instance | Epoch [ 44/ 75] Iter[901/1224]	  loss: 0.45cifar10:0.2-instance | Epoch [ 44/ 75] Iter[951/1224]	  loss: 0.30cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1001/1224]	  loss: 0.46cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1051/1224]	  loss: 0.36cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1101/1224]	  loss: 0.44cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1151/1224]	  loss: 0.49cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1201/1224]	  loss: 0.32
| Test Epoch 44	 Accuracy: 87.03% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 45 | Accuracy on train set: 73.35% 
labeled data has a size of 39256, f-score: 0.982296
cifar10:0.2-instance | Epoch [ 45/ 75] Iter[  1/1227]	  loss: 0.45cifar10:0.2-instance | Epoch [ 45/ 75] Iter[ 51/1227]	  loss: 0.27cifar10:0.2-instance | Epoch [ 45/ 75] Iter[101/1227]	  loss: 0.41cifar10:0.2-instance | Epoch [ 45/ 75] Iter[151/1227]	  loss: 0.33cifar10:0.2-instance | Epoch [ 45/ 75] Iter[201/1227]	  loss: 0.48cifar10:0.2-instance | Epoch [ 45/ 75] Iter[251/1227]	  loss: 0.32cifar10:0.2-instance | Epoch [ 45/ 75] Iter[301/1227]	  loss: 0.43cifar10:0.2-instance | Epoch [ 45/ 75] Iter[351/1227]	  loss: 0.39cifar10:0.2-instance | Epoch [ 45/ 75] Iter[401/1227]	  loss: 0.48cifar10:0.2-instance | Epoch [ 45/ 75] Iter[451/1227]	  loss: 0.43cifar10:0.2-instance | Epoch [ 45/ 75] Iter[501/1227]	  loss: 0.40cifar10:0.2-instance | Epoch [ 45/ 75] Iter[551/1227]	  loss: 0.24cifar10:0.2-instance | Epoch [ 45/ 75] Iter[601/1227]	  loss: 0.43cifar10:0.2-instance | Epoch [ 45/ 75] Iter[651/1227]	  loss: 0.31cifar10:0.2-instance | Epoch [ 45/ 75] Iter[701/1227]	  loss: 0.41cifar10:0.2-instance | Epoch [ 45/ 75] Iter[751/1227]	  loss: 0.42cifar10:0.2-instance | Epoch [ 45/ 75] Iter[801/1227]	  loss: 0.54cifar10:0.2-instance | Epoch [ 45/ 75] Iter[851/1227]	  loss: 0.39cifar10:0.2-instance | Epoch [ 45/ 75] Iter[901/1227]	  loss: 0.27cifar10:0.2-instance | Epoch [ 45/ 75] Iter[951/1227]	  loss: 0.54cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1001/1227]	  loss: 0.46cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1051/1227]	  loss: 0.72cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1101/1227]	  loss: 0.59cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1151/1227]	  loss: 0.54cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1201/1227]	  loss: 0.50
| Test Epoch 45	 Accuracy: 85.83% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 46 | Accuracy on train set: 72.27% 
labeled data has a size of 39289, f-score: 0.983074
cifar10:0.2-instance | Epoch [ 46/ 75] Iter[  1/1228]	  loss: 0.61cifar10:0.2-instance | Epoch [ 46/ 75] Iter[ 51/1228]	  loss: 0.31cifar10:0.2-instance | Epoch [ 46/ 75] Iter[101/1228]	  loss: 0.35cifar10:0.2-instance | Epoch [ 46/ 75] Iter[151/1228]	  loss: 0.42cifar10:0.2-instance | Epoch [ 46/ 75] Iter[201/1228]	  loss: 0.29cifar10:0.2-instance | Epoch [ 46/ 75] Iter[251/1228]	  loss: 0.27cifar10:0.2-instance | Epoch [ 46/ 75] Iter[301/1228]	  loss: 0.37cifar10:0.2-instance | Epoch [ 46/ 75] Iter[351/1228]	  loss: 0.32cifar10:0.2-instance | Epoch [ 46/ 75] Iter[401/1228]	  loss: 0.24cifar10:0.2-instance | Epoch [ 46/ 75] Iter[451/1228]	  loss: 0.39cifar10:0.2-instance | Epoch [ 46/ 75] Iter[501/1228]	  loss: 0.52cifar10:0.2-instance | Epoch [ 46/ 75] Iter[551/1228]	  loss: 0.23cifar10:0.2-instance | Epoch [ 46/ 75] Iter[601/1228]	  loss: 0.77cifar10:0.2-instance | Epoch [ 46/ 75] Iter[651/1228]	  loss: 0.31cifar10:0.2-instance | Epoch [ 46/ 75] Iter[701/1228]	  loss: 0.29cifar10:0.2-instance | Epoch [ 46/ 75] Iter[751/1228]	  loss: 0.21cifar10:0.2-instance | Epoch [ 46/ 75] Iter[801/1228]	  loss: 0.46cifar10:0.2-instance | Epoch [ 46/ 75] Iter[851/1228]	  loss: 0.41cifar10:0.2-instance | Epoch [ 46/ 75] Iter[901/1228]	  loss: 0.31cifar10:0.2-instance | Epoch [ 46/ 75] Iter[951/1228]	  loss: 0.61cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1001/1228]	  loss: 0.24cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1051/1228]	  loss: 0.52cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1101/1228]	  loss: 0.28cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1151/1228]	  loss: 0.45cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1201/1228]	  loss: 0.31
| Test Epoch 46	 Accuracy: 85.62% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 47 | Accuracy on train set: 71.67% 
labeled data has a size of 39217, f-score: 0.983936
cifar10:0.2-instance | Epoch [ 47/ 75] Iter[  1/1226]	  loss: 0.36cifar10:0.2-instance | Epoch [ 47/ 75] Iter[ 51/1226]	  loss: 0.35cifar10:0.2-instance | Epoch [ 47/ 75] Iter[101/1226]	  loss: 0.34cifar10:0.2-instance | Epoch [ 47/ 75] Iter[151/1226]	  loss: 0.37cifar10:0.2-instance | Epoch [ 47/ 75] Iter[201/1226]	  loss: 0.43cifar10:0.2-instance | Epoch [ 47/ 75] Iter[251/1226]	  loss: 0.30cifar10:0.2-instance | Epoch [ 47/ 75] Iter[301/1226]	  loss: 0.43cifar10:0.2-instance | Epoch [ 47/ 75] Iter[351/1226]	  loss: 0.37cifar10:0.2-instance | Epoch [ 47/ 75] Iter[401/1226]	  loss: 0.28cifar10:0.2-instance | Epoch [ 47/ 75] Iter[451/1226]	  loss: 0.40cifar10:0.2-instance | Epoch [ 47/ 75] Iter[501/1226]	  loss: 0.30cifar10:0.2-instance | Epoch [ 47/ 75] Iter[551/1226]	  loss: 0.26cifar10:0.2-instance | Epoch [ 47/ 75] Iter[601/1226]	  loss: 0.33cifar10:0.2-instance | Epoch [ 47/ 75] Iter[651/1226]	  loss: 0.27cifar10:0.2-instance | Epoch [ 47/ 75] Iter[701/1226]	  loss: 0.44cifar10:0.2-instance | Epoch [ 47/ 75] Iter[751/1226]	  loss: 0.51cifar10:0.2-instance | Epoch [ 47/ 75] Iter[801/1226]	  loss: 0.35cifar10:0.2-instance | Epoch [ 47/ 75] Iter[851/1226]	  loss: 0.46cifar10:0.2-instance | Epoch [ 47/ 75] Iter[901/1226]	  loss: 0.46cifar10:0.2-instance | Epoch [ 47/ 75] Iter[951/1226]	  loss: 0.68cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1001/1226]	  loss: 0.44cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1051/1226]	  loss: 0.51cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1101/1226]	  loss: 0.53cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1151/1226]	  loss: 0.32cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1201/1226]	  loss: 0.35
| Test Epoch 47	 Accuracy: 84.85% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 48 | Accuracy on train set: 71.79% 
labeled data has a size of 39046, f-score: 0.984352
cifar10:0.2-instance | Epoch [ 48/ 75] Iter[  1/1221]	  loss: 0.43cifar10:0.2-instance | Epoch [ 48/ 75] Iter[ 51/1221]	  loss: 0.27cifar10:0.2-instance | Epoch [ 48/ 75] Iter[101/1221]	  loss: 0.48cifar10:0.2-instance | Epoch [ 48/ 75] Iter[151/1221]	  loss: 0.37cifar10:0.2-instance | Epoch [ 48/ 75] Iter[201/1221]	  loss: 0.70cifar10:0.2-instance | Epoch [ 48/ 75] Iter[251/1221]	  loss: 0.38cifar10:0.2-instance | Epoch [ 48/ 75] Iter[301/1221]	  loss: 0.41cifar10:0.2-instance | Epoch [ 48/ 75] Iter[351/1221]	  loss: 0.38cifar10:0.2-instance | Epoch [ 48/ 75] Iter[401/1221]	  loss: 0.45cifar10:0.2-instance | Epoch [ 48/ 75] Iter[451/1221]	  loss: 0.45cifar10:0.2-instance | Epoch [ 48/ 75] Iter[501/1221]	  loss: 0.35cifar10:0.2-instance | Epoch [ 48/ 75] Iter[551/1221]	  loss: 0.37cifar10:0.2-instance | Epoch [ 48/ 75] Iter[601/1221]	  loss: 0.33cifar10:0.2-instance | Epoch [ 48/ 75] Iter[651/1221]	  loss: 0.47cifar10:0.2-instance | Epoch [ 48/ 75] Iter[701/1221]	  loss: 0.44cifar10:0.2-instance | Epoch [ 48/ 75] Iter[751/1221]	  loss: 0.45cifar10:0.2-instance | Epoch [ 48/ 75] Iter[801/1221]	  loss: 0.31cifar10:0.2-instance | Epoch [ 48/ 75] Iter[851/1221]	  loss: 0.29cifar10:0.2-instance | Epoch [ 48/ 75] Iter[901/1221]	  loss: 0.27cifar10:0.2-instance | Epoch [ 48/ 75] Iter[951/1221]	  loss: 0.47cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1001/1221]	  loss: 0.21cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1051/1221]	  loss: 0.40cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1101/1221]	  loss: 0.28cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1151/1221]	  loss: 0.55cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1201/1221]	  loss: 0.34
| Test Epoch 48	 Accuracy: 84.68% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 49 | Accuracy on train set: 71.46% 
labeled data has a size of 39110, f-score: 0.983917
cifar10:0.2-instance | Epoch [ 49/ 75] Iter[  1/1223]	  loss: 0.28cifar10:0.2-instance | Epoch [ 49/ 75] Iter[ 51/1223]	  loss: 0.36cifar10:0.2-instance | Epoch [ 49/ 75] Iter[101/1223]	  loss: 0.38cifar10:0.2-instance | Epoch [ 49/ 75] Iter[151/1223]	  loss: 0.44cifar10:0.2-instance | Epoch [ 49/ 75] Iter[201/1223]	  loss: 0.37cifar10:0.2-instance | Epoch [ 49/ 75] Iter[251/1223]	  loss: 0.21cifar10:0.2-instance | Epoch [ 49/ 75] Iter[301/1223]	  loss: 0.41cifar10:0.2-instance | Epoch [ 49/ 75] Iter[351/1223]	  loss: 0.42cifar10:0.2-instance | Epoch [ 49/ 75] Iter[401/1223]	  loss: 0.34cifar10:0.2-instance | Epoch [ 49/ 75] Iter[451/1223]	  loss: 0.61cifar10:0.2-instance | Epoch [ 49/ 75] Iter[501/1223]	  loss: 0.57cifar10:0.2-instance | Epoch [ 49/ 75] Iter[551/1223]	  loss: 0.56cifar10:0.2-instance | Epoch [ 49/ 75] Iter[601/1223]	  loss: 0.30cifar10:0.2-instance | Epoch [ 49/ 75] Iter[651/1223]	  loss: 0.47cifar10:0.2-instance | Epoch [ 49/ 75] Iter[701/1223]	  loss: 0.27cifar10:0.2-instance | Epoch [ 49/ 75] Iter[751/1223]	  loss: 0.48cifar10:0.2-instance | Epoch [ 49/ 75] Iter[801/1223]	  loss: 0.23cifar10:0.2-instance | Epoch [ 49/ 75] Iter[851/1223]	  loss: 0.48cifar10:0.2-instance | Epoch [ 49/ 75] Iter[901/1223]	  loss: 0.45cifar10:0.2-instance | Epoch [ 49/ 75] Iter[951/1223]	  loss: 0.27cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1001/1223]	  loss: 0.30cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1051/1223]	  loss: 0.60cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1101/1223]	  loss: 0.32cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1151/1223]	  loss: 0.70cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1201/1223]	  loss: 0.34
| Test Epoch 49	 Accuracy: 85.17% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 50 | Accuracy on train set: 71.75% 
labeled data has a size of 39023, f-score: 0.984189
cifar10:0.2-instance | Epoch [ 50/ 75] Iter[  1/1220]	  loss: 0.40cifar10:0.2-instance | Epoch [ 50/ 75] Iter[ 51/1220]	  loss: 0.59cifar10:0.2-instance | Epoch [ 50/ 75] Iter[101/1220]	  loss: 0.44cifar10:0.2-instance | Epoch [ 50/ 75] Iter[151/1220]	  loss: 0.39cifar10:0.2-instance | Epoch [ 50/ 75] Iter[201/1220]	  loss: 0.45cifar10:0.2-instance | Epoch [ 50/ 75] Iter[251/1220]	  loss: 0.32cifar10:0.2-instance | Epoch [ 50/ 75] Iter[301/1220]	  loss: 0.38cifar10:0.2-instance | Epoch [ 50/ 75] Iter[351/1220]	  loss: 0.30cifar10:0.2-instance | Epoch [ 50/ 75] Iter[401/1220]	  loss: 0.53cifar10:0.2-instance | Epoch [ 50/ 75] Iter[451/1220]	  loss: 0.30cifar10:0.2-instance | Epoch [ 50/ 75] Iter[501/1220]	  loss: 0.43cifar10:0.2-instance | Epoch [ 50/ 75] Iter[551/1220]	  loss: 0.28cifar10:0.2-instance | Epoch [ 50/ 75] Iter[601/1220]	  loss: 0.32cifar10:0.2-instance | Epoch [ 50/ 75] Iter[651/1220]	  loss: 0.67cifar10:0.2-instance | Epoch [ 50/ 75] Iter[701/1220]	  loss: 0.40cifar10:0.2-instance | Epoch [ 50/ 75] Iter[751/1220]	  loss: 0.57cifar10:0.2-instance | Epoch [ 50/ 75] Iter[801/1220]	  loss: 0.33cifar10:0.2-instance | Epoch [ 50/ 75] Iter[851/1220]	  loss: 0.35cifar10:0.2-instance | Epoch [ 50/ 75] Iter[901/1220]	  loss: 0.66cifar10:0.2-instance | Epoch [ 50/ 75] Iter[951/1220]	  loss: 0.33cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1001/1220]	  loss: 0.34cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1051/1220]	  loss: 0.40cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1101/1220]	  loss: 0.52cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1151/1220]	  loss: 0.43cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1201/1220]	  loss: 0.44
| Test Epoch 50	 Accuracy: 85.92% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 51 | Accuracy on train set: 72.30% 
labeled data has a size of 39035, f-score: 0.984783
cifar10:0.2-instance | Epoch [ 51/ 75] Iter[  1/1220]	  loss: 0.41cifar10:0.2-instance | Epoch [ 51/ 75] Iter[ 51/1220]	  loss: 0.44cifar10:0.2-instance | Epoch [ 51/ 75] Iter[101/1220]	  loss: 0.32cifar10:0.2-instance | Epoch [ 51/ 75] Iter[151/1220]	  loss: 0.35cifar10:0.2-instance | Epoch [ 51/ 75] Iter[201/1220]	  loss: 0.25cifar10:0.2-instance | Epoch [ 51/ 75] Iter[251/1220]	  loss: 0.25cifar10:0.2-instance | Epoch [ 51/ 75] Iter[301/1220]	  loss: 0.27cifar10:0.2-instance | Epoch [ 51/ 75] Iter[351/1220]	  loss: 0.49cifar10:0.2-instance | Epoch [ 51/ 75] Iter[401/1220]	  loss: 0.36cifar10:0.2-instance | Epoch [ 51/ 75] Iter[451/1220]	  loss: 0.48cifar10:0.2-instance | Epoch [ 51/ 75] Iter[501/1220]	  loss: 0.47cifar10:0.2-instance | Epoch [ 51/ 75] Iter[551/1220]	  loss: 0.42cifar10:0.2-instance | Epoch [ 51/ 75] Iter[601/1220]	  loss: 0.74cifar10:0.2-instance | Epoch [ 51/ 75] Iter[651/1220]	  loss: 0.44cifar10:0.2-instance | Epoch [ 51/ 75] Iter[701/1220]	  loss: 0.42cifar10:0.2-instance | Epoch [ 51/ 75] Iter[751/1220]	  loss: 0.46cifar10:0.2-instance | Epoch [ 51/ 75] Iter[801/1220]	  loss: 0.50cifar10:0.2-instance | Epoch [ 51/ 75] Iter[851/1220]	  loss: 0.51cifar10:0.2-instance | Epoch [ 51/ 75] Iter[901/1220]	  loss: 0.25cifar10:0.2-instance | Epoch [ 51/ 75] Iter[951/1220]	  loss: 0.31cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1001/1220]	  loss: 0.48cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1051/1220]	  loss: 0.51cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1101/1220]	  loss: 0.30cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1151/1220]	  loss: 0.40cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1201/1220]	  loss: 0.40
| Test Epoch 51	 Accuracy: 85.01% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 52 | Accuracy on train set: 71.66% 
labeled data has a size of 39098, f-score: 0.983068
cifar10:0.2-instance | Epoch [ 52/ 75] Iter[  1/1222]	  loss: 0.29cifar10:0.2-instance | Epoch [ 52/ 75] Iter[ 51/1222]	  loss: 0.20cifar10:0.2-instance | Epoch [ 52/ 75] Iter[101/1222]	  loss: 0.45cifar10:0.2-instance | Epoch [ 52/ 75] Iter[151/1222]	  loss: 0.56cifar10:0.2-instance | Epoch [ 52/ 75] Iter[201/1222]	  loss: 0.40cifar10:0.2-instance | Epoch [ 52/ 75] Iter[251/1222]	  loss: 0.54cifar10:0.2-instance | Epoch [ 52/ 75] Iter[301/1222]	  loss: 0.37cifar10:0.2-instance | Epoch [ 52/ 75] Iter[351/1222]	  loss: 0.22cifar10:0.2-instance | Epoch [ 52/ 75] Iter[401/1222]	  loss: 0.29cifar10:0.2-instance | Epoch [ 52/ 75] Iter[451/1222]	  loss: 0.30cifar10:0.2-instance | Epoch [ 52/ 75] Iter[501/1222]	  loss: 0.36cifar10:0.2-instance | Epoch [ 52/ 75] Iter[551/1222]	  loss: 0.43cifar10:0.2-instance | Epoch [ 52/ 75] Iter[601/1222]	  loss: 0.30cifar10:0.2-instance | Epoch [ 52/ 75] Iter[651/1222]	  loss: 0.53cifar10:0.2-instance | Epoch [ 52/ 75] Iter[701/1222]	  loss: 0.57cifar10:0.2-instance | Epoch [ 52/ 75] Iter[751/1222]	  loss: 0.43cifar10:0.2-instance | Epoch [ 52/ 75] Iter[801/1222]	  loss: 0.51cifar10:0.2-instance | Epoch [ 52/ 75] Iter[851/1222]	  loss: 0.34cifar10:0.2-instance | Epoch [ 52/ 75] Iter[901/1222]	  loss: 0.34cifar10:0.2-instance | Epoch [ 52/ 75] Iter[951/1222]	  loss: 0.41cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1001/1222]	  loss: 0.39cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1051/1222]	  loss: 0.39cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1101/1222]	  loss: 0.29cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1151/1222]	  loss: 0.50cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1201/1222]	  loss: 0.32
| Test Epoch 52	 Accuracy: 86.52% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 53 | Accuracy on train set: 72.70% 
labeled data has a size of 39172, f-score: 0.982743
cifar10:0.2-instance | Epoch [ 53/ 75] Iter[  1/1225]	  loss: 0.31cifar10:0.2-instance | Epoch [ 53/ 75] Iter[ 51/1225]	  loss: 0.35cifar10:0.2-instance | Epoch [ 53/ 75] Iter[101/1225]	  loss: 0.28cifar10:0.2-instance | Epoch [ 53/ 75] Iter[151/1225]	  loss: 0.32cifar10:0.2-instance | Epoch [ 53/ 75] Iter[201/1225]	  loss: 0.49cifar10:0.2-instance | Epoch [ 53/ 75] Iter[251/1225]	  loss: 0.32cifar10:0.2-instance | Epoch [ 53/ 75] Iter[301/1225]	  loss: 0.39cifar10:0.2-instance | Epoch [ 53/ 75] Iter[351/1225]	  loss: 0.49cifar10:0.2-instance | Epoch [ 53/ 75] Iter[401/1225]	  loss: 0.31cifar10:0.2-instance | Epoch [ 53/ 75] Iter[451/1225]	  loss: 0.35cifar10:0.2-instance | Epoch [ 53/ 75] Iter[501/1225]	  loss: 0.59cifar10:0.2-instance | Epoch [ 53/ 75] Iter[551/1225]	  loss: 0.24cifar10:0.2-instance | Epoch [ 53/ 75] Iter[601/1225]	  loss: 0.30cifar10:0.2-instance | Epoch [ 53/ 75] Iter[651/1225]	  loss: 0.52cifar10:0.2-instance | Epoch [ 53/ 75] Iter[701/1225]	  loss: 0.34cifar10:0.2-instance | Epoch [ 53/ 75] Iter[751/1225]	  loss: 0.32cifar10:0.2-instance | Epoch [ 53/ 75] Iter[801/1225]	  loss: 0.33cifar10:0.2-instance | Epoch [ 53/ 75] Iter[851/1225]	  loss: 0.31cifar10:0.2-instance | Epoch [ 53/ 75] Iter[901/1225]	  loss: 0.36cifar10:0.2-instance | Epoch [ 53/ 75] Iter[951/1225]	  loss: 0.36cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1001/1225]	  loss: 0.56cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1051/1225]	  loss: 0.68cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1101/1225]	  loss: 0.55cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1151/1225]	  loss: 0.55cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1201/1225]	  loss: 0.41
| Test Epoch 53	 Accuracy: 86.71% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 54 | Accuracy on train set: 72.90% 
labeled data has a size of 39271, f-score: 0.982150
cifar10:0.2-instance | Epoch [ 54/ 75] Iter[  1/1228]	  loss: 0.38cifar10:0.2-instance | Epoch [ 54/ 75] Iter[ 51/1228]	  loss: 0.37cifar10:0.2-instance | Epoch [ 54/ 75] Iter[101/1228]	  loss: 0.49cifar10:0.2-instance | Epoch [ 54/ 75] Iter[151/1228]	  loss: 0.39cifar10:0.2-instance | Epoch [ 54/ 75] Iter[201/1228]	  loss: 0.37cifar10:0.2-instance | Epoch [ 54/ 75] Iter[251/1228]	  loss: 0.61cifar10:0.2-instance | Epoch [ 54/ 75] Iter[301/1228]	  loss: 0.42cifar10:0.2-instance | Epoch [ 54/ 75] Iter[351/1228]	  loss: 0.28cifar10:0.2-instance | Epoch [ 54/ 75] Iter[401/1228]	  loss: 0.35cifar10:0.2-instance | Epoch [ 54/ 75] Iter[451/1228]	  loss: 0.61cifar10:0.2-instance | Epoch [ 54/ 75] Iter[501/1228]	  loss: 0.51cifar10:0.2-instance | Epoch [ 54/ 75] Iter[551/1228]	  loss: 0.32cifar10:0.2-instance | Epoch [ 54/ 75] Iter[601/1228]	  loss: 0.37cifar10:0.2-instance | Epoch [ 54/ 75] Iter[651/1228]	  loss: 0.54cifar10:0.2-instance | Epoch [ 54/ 75] Iter[701/1228]	  loss: 0.40cifar10:0.2-instance | Epoch [ 54/ 75] Iter[751/1228]	  loss: 0.34cifar10:0.2-instance | Epoch [ 54/ 75] Iter[801/1228]	  loss: 0.58cifar10:0.2-instance | Epoch [ 54/ 75] Iter[851/1228]	  loss: 0.47cifar10:0.2-instance | Epoch [ 54/ 75] Iter[901/1228]	  loss: 0.29cifar10:0.2-instance | Epoch [ 54/ 75] Iter[951/1228]	  loss: 0.44cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1001/1228]	  loss: 0.31cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1051/1228]	  loss: 0.44cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1101/1228]	  loss: 0.69cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1151/1228]	  loss: 0.53cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1201/1228]	  loss: 0.60
| Test Epoch 54	 Accuracy: 81.32% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 55 | Accuracy on train set: 68.77% 
labeled data has a size of 39431, f-score: 0.977962
cifar10:0.2-instance | Epoch [ 55/ 75] Iter[  1/1233]	  loss: 0.39cifar10:0.2-instance | Epoch [ 55/ 75] Iter[ 51/1233]	  loss: 0.40cifar10:0.2-instance | Epoch [ 55/ 75] Iter[101/1233]	  loss: 0.27cifar10:0.2-instance | Epoch [ 55/ 75] Iter[151/1233]	  loss: 0.42cifar10:0.2-instance | Epoch [ 55/ 75] Iter[201/1233]	  loss: 0.20cifar10:0.2-instance | Epoch [ 55/ 75] Iter[251/1233]	  loss: 0.44cifar10:0.2-instance | Epoch [ 55/ 75] Iter[301/1233]	  loss: 0.45cifar10:0.2-instance | Epoch [ 55/ 75] Iter[351/1233]	  loss: 0.32cifar10:0.2-instance | Epoch [ 55/ 75] Iter[401/1233]	  loss: 0.51cifar10:0.2-instance | Epoch [ 55/ 75] Iter[451/1233]	  loss: 0.52cifar10:0.2-instance | Epoch [ 55/ 75] Iter[501/1233]	  loss: 0.29cifar10:0.2-instance | Epoch [ 55/ 75] Iter[551/1233]	  loss: 0.63cifar10:0.2-instance | Epoch [ 55/ 75] Iter[601/1233]	  loss: 0.38cifar10:0.2-instance | Epoch [ 55/ 75] Iter[651/1233]	  loss: 0.58cifar10:0.2-instance | Epoch [ 55/ 75] Iter[701/1233]	  loss: 0.43cifar10:0.2-instance | Epoch [ 55/ 75] Iter[751/1233]	  loss: 0.30cifar10:0.2-instance | Epoch [ 55/ 75] Iter[801/1233]	  loss: 0.32cifar10:0.2-instance | Epoch [ 55/ 75] Iter[851/1233]	  loss: 0.61cifar10:0.2-instance | Epoch [ 55/ 75] Iter[901/1233]	  loss: 0.33cifar10:0.2-instance | Epoch [ 55/ 75] Iter[951/1233]	  loss: 0.45cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1001/1233]	  loss: 0.25cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1051/1233]	  loss: 0.43cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1101/1233]	  loss: 0.43cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1151/1233]	  loss: 0.52cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1201/1233]	  loss: 0.24
| Test Epoch 55	 Accuracy: 86.37% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 56 | Accuracy on train set: 72.84% 
labeled data has a size of 39447, f-score: 0.977768
cifar10:0.2-instance | Epoch [ 56/ 75] Iter[  1/1233]	  loss: 0.41cifar10:0.2-instance | Epoch [ 56/ 75] Iter[ 51/1233]	  loss: 0.25cifar10:0.2-instance | Epoch [ 56/ 75] Iter[101/1233]	  loss: 0.35cifar10:0.2-instance | Epoch [ 56/ 75] Iter[151/1233]	  loss: 0.48cifar10:0.2-instance | Epoch [ 56/ 75] Iter[201/1233]	  loss: 0.37cifar10:0.2-instance | Epoch [ 56/ 75] Iter[251/1233]	  loss: 0.40cifar10:0.2-instance | Epoch [ 56/ 75] Iter[301/1233]	  loss: 0.45cifar10:0.2-instance | Epoch [ 56/ 75] Iter[351/1233]	  loss: 0.51cifar10:0.2-instance | Epoch [ 56/ 75] Iter[401/1233]	  loss: 0.32cifar10:0.2-instance | Epoch [ 56/ 75] Iter[451/1233]	  loss: 0.32cifar10:0.2-instance | Epoch [ 56/ 75] Iter[501/1233]	  loss: 0.31cifar10:0.2-instance | Epoch [ 56/ 75] Iter[551/1233]	  loss: 0.45cifar10:0.2-instance | Epoch [ 56/ 75] Iter[601/1233]	  loss: 0.38cifar10:0.2-instance | Epoch [ 56/ 75] Iter[651/1233]	  loss: 0.39cifar10:0.2-instance | Epoch [ 56/ 75] Iter[701/1233]	  loss: 0.47cifar10:0.2-instance | Epoch [ 56/ 75] Iter[751/1233]	  loss: 0.48cifar10:0.2-instance | Epoch [ 56/ 75] Iter[801/1233]	  loss: 0.36cifar10:0.2-instance | Epoch [ 56/ 75] Iter[851/1233]	  loss: 0.38cifar10:0.2-instance | Epoch [ 56/ 75] Iter[901/1233]	  loss: 0.66cifar10:0.2-instance | Epoch [ 56/ 75] Iter[951/1233]	  loss: 0.44cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1001/1233]	  loss: 0.47cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1051/1233]	  loss: 0.46cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1101/1233]	  loss: 0.30cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1151/1233]	  loss: 0.48cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1201/1233]	  loss: 0.51
| Test Epoch 56	 Accuracy: 85.32% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 57 | Accuracy on train set: 72.13% 
labeled data has a size of 39412, f-score: 0.976936
cifar10:0.2-instance | Epoch [ 57/ 75] Iter[  1/1232]	  loss: 0.52cifar10:0.2-instance | Epoch [ 57/ 75] Iter[ 51/1232]	  loss: 0.28cifar10:0.2-instance | Epoch [ 57/ 75] Iter[101/1232]	  loss: 0.39cifar10:0.2-instance | Epoch [ 57/ 75] Iter[151/1232]	  loss: 0.28cifar10:0.2-instance | Epoch [ 57/ 75] Iter[201/1232]	  loss: 0.45cifar10:0.2-instance | Epoch [ 57/ 75] Iter[251/1232]	  loss: 0.45cifar10:0.2-instance | Epoch [ 57/ 75] Iter[301/1232]	  loss: 0.39cifar10:0.2-instance | Epoch [ 57/ 75] Iter[351/1232]	  loss: 0.28cifar10:0.2-instance | Epoch [ 57/ 75] Iter[401/1232]	  loss: 0.63cifar10:0.2-instance | Epoch [ 57/ 75] Iter[451/1232]	  loss: 0.46cifar10:0.2-instance | Epoch [ 57/ 75] Iter[501/1232]	  loss: 0.35cifar10:0.2-instance | Epoch [ 57/ 75] Iter[551/1232]	  loss: 0.24cifar10:0.2-instance | Epoch [ 57/ 75] Iter[601/1232]	  loss: 0.31cifar10:0.2-instance | Epoch [ 57/ 75] Iter[651/1232]	  loss: 0.38cifar10:0.2-instance | Epoch [ 57/ 75] Iter[701/1232]	  loss: 0.30cifar10:0.2-instance | Epoch [ 57/ 75] Iter[751/1232]	  loss: 0.47cifar10:0.2-instance | Epoch [ 57/ 75] Iter[801/1232]	  loss: 0.36cifar10:0.2-instance | Epoch [ 57/ 75] Iter[851/1232]	  loss: 0.36cifar10:0.2-instance | Epoch [ 57/ 75] Iter[901/1232]	  loss: 0.69cifar10:0.2-instance | Epoch [ 57/ 75] Iter[951/1232]	  loss: 0.45cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1001/1232]	  loss: 0.40cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1051/1232]	  loss: 0.40cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1101/1232]	  loss: 0.35cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1151/1232]	  loss: 0.39cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1201/1232]	  loss: 0.30
| Test Epoch 57	 Accuracy: 84.86% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 58 | Accuracy on train set: 71.53% 
labeled data has a size of 39354, f-score: 0.981527
cifar10:0.2-instance | Epoch [ 58/ 75] Iter[  1/1230]	  loss: 0.35cifar10:0.2-instance | Epoch [ 58/ 75] Iter[ 51/1230]	  loss: 0.84cifar10:0.2-instance | Epoch [ 58/ 75] Iter[101/1230]	  loss: 0.30cifar10:0.2-instance | Epoch [ 58/ 75] Iter[151/1230]	  loss: 0.39cifar10:0.2-instance | Epoch [ 58/ 75] Iter[201/1230]	  loss: 0.47cifar10:0.2-instance | Epoch [ 58/ 75] Iter[251/1230]	  loss: 0.33cifar10:0.2-instance | Epoch [ 58/ 75] Iter[301/1230]	  loss: 0.52cifar10:0.2-instance | Epoch [ 58/ 75] Iter[351/1230]	  loss: 0.42cifar10:0.2-instance | Epoch [ 58/ 75] Iter[401/1230]	  loss: 0.39cifar10:0.2-instance | Epoch [ 58/ 75] Iter[451/1230]	  loss: 0.23cifar10:0.2-instance | Epoch [ 58/ 75] Iter[501/1230]	  loss: 0.27cifar10:0.2-instance | Epoch [ 58/ 75] Iter[551/1230]	  loss: 0.41cifar10:0.2-instance | Epoch [ 58/ 75] Iter[601/1230]	  loss: 0.43cifar10:0.2-instance | Epoch [ 58/ 75] Iter[651/1230]	  loss: 0.47cifar10:0.2-instance | Epoch [ 58/ 75] Iter[701/1230]	  loss: 0.29cifar10:0.2-instance | Epoch [ 58/ 75] Iter[751/1230]	  loss: 0.30cifar10:0.2-instance | Epoch [ 58/ 75] Iter[801/1230]	  loss: 0.43cifar10:0.2-instance | Epoch [ 58/ 75] Iter[851/1230]	  loss: 0.37cifar10:0.2-instance | Epoch [ 58/ 75] Iter[901/1230]	  loss: 0.41cifar10:0.2-instance | Epoch [ 58/ 75] Iter[951/1230]	  loss: 0.34cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1001/1230]	  loss: 0.31cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1051/1230]	  loss: 0.36cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1101/1230]	  loss: 0.31cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1151/1230]	  loss: 0.39cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1201/1230]	  loss: 0.32
| Test Epoch 58	 Accuracy: 85.40% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 59 | Accuracy on train set: 72.16% 
labeled data has a size of 39451, f-score: 0.979899
cifar10:0.2-instance | Epoch [ 59/ 75] Iter[  1/1233]	  loss: 0.59cifar10:0.2-instance | Epoch [ 59/ 75] Iter[ 51/1233]	  loss: 0.42cifar10:0.2-instance | Epoch [ 59/ 75] Iter[101/1233]	  loss: 0.41cifar10:0.2-instance | Epoch [ 59/ 75] Iter[151/1233]	  loss: 0.29cifar10:0.2-instance | Epoch [ 59/ 75] Iter[201/1233]	  loss: 0.45cifar10:0.2-instance | Epoch [ 59/ 75] Iter[251/1233]	  loss: 0.41cifar10:0.2-instance | Epoch [ 59/ 75] Iter[301/1233]	  loss: 0.31cifar10:0.2-instance | Epoch [ 59/ 75] Iter[351/1233]	  loss: 0.64cifar10:0.2-instance | Epoch [ 59/ 75] Iter[401/1233]	  loss: 0.31cifar10:0.2-instance | Epoch [ 59/ 75] Iter[451/1233]	  loss: 0.30cifar10:0.2-instance | Epoch [ 59/ 75] Iter[501/1233]	  loss: 0.38cifar10:0.2-instance | Epoch [ 59/ 75] Iter[551/1233]	  loss: 0.39cifar10:0.2-instance | Epoch [ 59/ 75] Iter[601/1233]	  loss: 0.60cifar10:0.2-instance | Epoch [ 59/ 75] Iter[651/1233]	  loss: 0.44cifar10:0.2-instance | Epoch [ 59/ 75] Iter[701/1233]	  loss: 0.25cifar10:0.2-instance | Epoch [ 59/ 75] Iter[751/1233]	  loss: 0.31cifar10:0.2-instance | Epoch [ 59/ 75] Iter[801/1233]	  loss: 0.35cifar10:0.2-instance | Epoch [ 59/ 75] Iter[851/1233]	  loss: 0.32cifar10:0.2-instance | Epoch [ 59/ 75] Iter[901/1233]	  loss: 0.42cifar10:0.2-instance | Epoch [ 59/ 75] Iter[951/1233]	  loss: 0.64cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1001/1233]	  loss: 0.41cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1051/1233]	  loss: 0.45cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1101/1233]	  loss: 0.56cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1151/1233]	  loss: 0.45cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1201/1233]	  loss: 0.58
| Test Epoch 59	 Accuracy: 85.69% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 60 | Accuracy on train set: 71.81% 
labeled data has a size of 39444, f-score: 0.981315
cifar10:0.2-instance | Epoch [ 60/ 75] Iter[  1/1233]	  loss: 0.23cifar10:0.2-instance | Epoch [ 60/ 75] Iter[ 51/1233]	  loss: 0.24cifar10:0.2-instance | Epoch [ 60/ 75] Iter[101/1233]	  loss: 0.33cifar10:0.2-instance | Epoch [ 60/ 75] Iter[151/1233]	  loss: 0.37cifar10:0.2-instance | Epoch [ 60/ 75] Iter[201/1233]	  loss: 0.28cifar10:0.2-instance | Epoch [ 60/ 75] Iter[251/1233]	  loss: 0.20cifar10:0.2-instance | Epoch [ 60/ 75] Iter[301/1233]	  loss: 0.28cifar10:0.2-instance | Epoch [ 60/ 75] Iter[351/1233]	  loss: 0.29cifar10:0.2-instance | Epoch [ 60/ 75] Iter[401/1233]	  loss: 0.23cifar10:0.2-instance | Epoch [ 60/ 75] Iter[451/1233]	  loss: 0.49cifar10:0.2-instance | Epoch [ 60/ 75] Iter[501/1233]	  loss: 0.33cifar10:0.2-instance | Epoch [ 60/ 75] Iter[551/1233]	  loss: 0.40cifar10:0.2-instance | Epoch [ 60/ 75] Iter[601/1233]	  loss: 0.20cifar10:0.2-instance | Epoch [ 60/ 75] Iter[651/1233]	  loss: 0.25cifar10:0.2-instance | Epoch [ 60/ 75] Iter[701/1233]	  loss: 0.23cifar10:0.2-instance | Epoch [ 60/ 75] Iter[751/1233]	  loss: 0.30cifar10:0.2-instance | Epoch [ 60/ 75] Iter[801/1233]	  loss: 0.34cifar10:0.2-instance | Epoch [ 60/ 75] Iter[851/1233]	  loss: 0.23cifar10:0.2-instance | Epoch [ 60/ 75] Iter[901/1233]	  loss: 0.22cifar10:0.2-instance | Epoch [ 60/ 75] Iter[951/1233]	  loss: 0.16cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1001/1233]	  loss: 0.24cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1051/1233]	  loss: 0.20cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1101/1233]	  loss: 0.44cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1151/1233]	  loss: 0.18cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1201/1233]	  loss: 0.24
| Test Epoch 60	 Accuracy: 91.19% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 61 | Accuracy on train set: 76.97% 
labeled data has a size of 39430, f-score: 0.983819
cifar10:0.2-instance | Epoch [ 61/ 75] Iter[  1/1233]	  loss: 0.28cifar10:0.2-instance | Epoch [ 61/ 75] Iter[ 51/1233]	  loss: 0.21cifar10:0.2-instance | Epoch [ 61/ 75] Iter[101/1233]	  loss: 0.23cifar10:0.2-instance | Epoch [ 61/ 75] Iter[151/1233]	  loss: 0.17cifar10:0.2-instance | Epoch [ 61/ 75] Iter[201/1233]	  loss: 0.32cifar10:0.2-instance | Epoch [ 61/ 75] Iter[251/1233]	  loss: 0.35cifar10:0.2-instance | Epoch [ 61/ 75] Iter[301/1233]	  loss: 0.24cifar10:0.2-instance | Epoch [ 61/ 75] Iter[351/1233]	  loss: 0.40cifar10:0.2-instance | Epoch [ 61/ 75] Iter[401/1233]	  loss: 0.29cifar10:0.2-instance | Epoch [ 61/ 75] Iter[451/1233]	  loss: 0.31cifar10:0.2-instance | Epoch [ 61/ 75] Iter[501/1233]	  loss: 0.18cifar10:0.2-instance | Epoch [ 61/ 75] Iter[551/1233]	  loss: 0.33cifar10:0.2-instance | Epoch [ 61/ 75] Iter[601/1233]	  loss: 0.47cifar10:0.2-instance | Epoch [ 61/ 75] Iter[651/1233]	  loss: 0.22cifar10:0.2-instance | Epoch [ 61/ 75] Iter[701/1233]	  loss: 0.24cifar10:0.2-instance | Epoch [ 61/ 75] Iter[751/1233]	  loss: 0.27cifar10:0.2-instance | Epoch [ 61/ 75] Iter[801/1233]	  loss: 0.37cifar10:0.2-instance | Epoch [ 61/ 75] Iter[851/1233]	  loss: 0.17cifar10:0.2-instance | Epoch [ 61/ 75] Iter[901/1233]	  loss: 0.29cifar10:0.2-instance | Epoch [ 61/ 75] Iter[951/1233]	  loss: 0.26cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1001/1233]	  loss: 0.23cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1051/1233]	  loss: 0.23cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1101/1233]	  loss: 0.22cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1151/1233]	  loss: 0.39cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1201/1233]	  loss: 0.22
| Test Epoch 61	 Accuracy: 91.73% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 62 | Accuracy on train set: 77.49% 
labeled data has a size of 39452, f-score: 0.985552
cifar10:0.2-instance | Epoch [ 62/ 75] Iter[  1/1233]	  loss: 0.23cifar10:0.2-instance | Epoch [ 62/ 75] Iter[ 51/1233]	  loss: 0.20cifar10:0.2-instance | Epoch [ 62/ 75] Iter[101/1233]	  loss: 0.17cifar10:0.2-instance | Epoch [ 62/ 75] Iter[151/1233]	  loss: 0.34cifar10:0.2-instance | Epoch [ 62/ 75] Iter[201/1233]	  loss: 0.36cifar10:0.2-instance | Epoch [ 62/ 75] Iter[251/1233]	  loss: 0.18cifar10:0.2-instance | Epoch [ 62/ 75] Iter[301/1233]	  loss: 0.22cifar10:0.2-instance | Epoch [ 62/ 75] Iter[351/1233]	  loss: 0.36cifar10:0.2-instance | Epoch [ 62/ 75] Iter[401/1233]	  loss: 0.18cifar10:0.2-instance | Epoch [ 62/ 75] Iter[451/1233]	  loss: 0.20cifar10:0.2-instance | Epoch [ 62/ 75] Iter[501/1233]	  loss: 0.19cifar10:0.2-instance | Epoch [ 62/ 75] Iter[551/1233]	  loss: 0.21cifar10:0.2-instance | Epoch [ 62/ 75] Iter[601/1233]	  loss: 0.26cifar10:0.2-instance | Epoch [ 62/ 75] Iter[651/1233]	  loss: 0.23cifar10:0.2-instance | Epoch [ 62/ 75] Iter[701/1233]	  loss: 0.25cifar10:0.2-instance | Epoch [ 62/ 75] Iter[751/1233]	  loss: 0.15cifar10:0.2-instance | Epoch [ 62/ 75] Iter[801/1233]	  loss: 0.16cifar10:0.2-instance | Epoch [ 62/ 75] Iter[851/1233]	  loss: 0.20cifar10:0.2-instance | Epoch [ 62/ 75] Iter[901/1233]	  loss: 0.17cifar10:0.2-instance | Epoch [ 62/ 75] Iter[951/1233]	  loss: 0.17cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1001/1233]	  loss: 0.21cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1051/1233]	  loss: 0.29cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1101/1233]	  loss: 0.15cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1151/1233]	  loss: 0.17cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1201/1233]	  loss: 0.16
| Test Epoch 62	 Accuracy: 91.91% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 63 | Accuracy on train set: 77.79% 
labeled data has a size of 39477, f-score: 0.986321
cifar10:0.2-instance | Epoch [ 63/ 75] Iter[  1/1234]	  loss: 0.24cifar10:0.2-instance | Epoch [ 63/ 75] Iter[ 51/1234]	  loss: 0.19cifar10:0.2-instance | Epoch [ 63/ 75] Iter[101/1234]	  loss: 0.33cifar10:0.2-instance | Epoch [ 63/ 75] Iter[151/1234]	  loss: 0.26cifar10:0.2-instance | Epoch [ 63/ 75] Iter[201/1234]	  loss: 0.16cifar10:0.2-instance | Epoch [ 63/ 75] Iter[251/1234]	  loss: 0.21cifar10:0.2-instance | Epoch [ 63/ 75] Iter[301/1234]	  loss: 0.33cifar10:0.2-instance | Epoch [ 63/ 75] Iter[351/1234]	  loss: 0.19cifar10:0.2-instance | Epoch [ 63/ 75] Iter[401/1234]	  loss: 0.22cifar10:0.2-instance | Epoch [ 63/ 75] Iter[451/1234]	  loss: 0.29cifar10:0.2-instance | Epoch [ 63/ 75] Iter[501/1234]	  loss: 0.18cifar10:0.2-instance | Epoch [ 63/ 75] Iter[551/1234]	  loss: 0.15cifar10:0.2-instance | Epoch [ 63/ 75] Iter[601/1234]	  loss: 0.22cifar10:0.2-instance | Epoch [ 63/ 75] Iter[651/1234]	  loss: 0.40cifar10:0.2-instance | Epoch [ 63/ 75] Iter[701/1234]	  loss: 0.33cifar10:0.2-instance | Epoch [ 63/ 75] Iter[751/1234]	  loss: 0.17cifar10:0.2-instance | Epoch [ 63/ 75] Iter[801/1234]	  loss: 0.17cifar10:0.2-instance | Epoch [ 63/ 75] Iter[851/1234]	  loss: 0.23cifar10:0.2-instance | Epoch [ 63/ 75] Iter[901/1234]	  loss: 0.24cifar10:0.2-instance | Epoch [ 63/ 75] Iter[951/1234]	  loss: 0.35cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1001/1234]	  loss: 0.17cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1051/1234]	  loss: 0.22cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1101/1234]	  loss: 0.21cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1151/1234]	  loss: 0.19cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1201/1234]	  loss: 0.18
| Test Epoch 63	 Accuracy: 92.07% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 64 | Accuracy on train set: 78.01% 
labeled data has a size of 39564, f-score: 0.986048
cifar10:0.2-instance | Epoch [ 64/ 75] Iter[  1/1237]	  loss: 0.24cifar10:0.2-instance | Epoch [ 64/ 75] Iter[ 51/1237]	  loss: 0.19cifar10:0.2-instance | Epoch [ 64/ 75] Iter[101/1237]	  loss: 0.19cifar10:0.2-instance | Epoch [ 64/ 75] Iter[151/1237]	  loss: 0.31cifar10:0.2-instance | Epoch [ 64/ 75] Iter[201/1237]	  loss: 0.24cifar10:0.2-instance | Epoch [ 64/ 75] Iter[251/1237]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[301/1237]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[351/1237]	  loss: 0.18cifar10:0.2-instance | Epoch [ 64/ 75] Iter[401/1237]	  loss: 0.18cifar10:0.2-instance | Epoch [ 64/ 75] Iter[451/1237]	  loss: 0.36cifar10:0.2-instance | Epoch [ 64/ 75] Iter[501/1237]	  loss: 0.21cifar10:0.2-instance | Epoch [ 64/ 75] Iter[551/1237]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[601/1237]	  loss: 0.17cifar10:0.2-instance | Epoch [ 64/ 75] Iter[651/1237]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[701/1237]	  loss: 0.19cifar10:0.2-instance | Epoch [ 64/ 75] Iter[751/1237]	  loss: 0.28cifar10:0.2-instance | Epoch [ 64/ 75] Iter[801/1237]	  loss: 0.23cifar10:0.2-instance | Epoch [ 64/ 75] Iter[851/1237]	  loss: 0.19cifar10:0.2-instance | Epoch [ 64/ 75] Iter[901/1237]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[951/1237]	  loss: 0.18cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1001/1237]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1051/1237]	  loss: 0.21cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1101/1237]	  loss: 0.25cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1151/1237]	  loss: 0.17cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1201/1237]	  loss: 0.16
| Test Epoch 64	 Accuracy: 92.25% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 65 | Accuracy on train set: 78.30% 
labeled data has a size of 39631, f-score: 0.985542
cifar10:0.2-instance | Epoch [ 65/ 75] Iter[  1/1239]	  loss: 0.26cifar10:0.2-instance | Epoch [ 65/ 75] Iter[ 51/1239]	  loss: 0.26cifar10:0.2-instance | Epoch [ 65/ 75] Iter[101/1239]	  loss: 0.17cifar10:0.2-instance | Epoch [ 65/ 75] Iter[151/1239]	  loss: 0.15cifar10:0.2-instance | Epoch [ 65/ 75] Iter[201/1239]	  loss: 0.16cifar10:0.2-instance | Epoch [ 65/ 75] Iter[251/1239]	  loss: 0.22cifar10:0.2-instance | Epoch [ 65/ 75] Iter[301/1239]	  loss: 0.17cifar10:0.2-instance | Epoch [ 65/ 75] Iter[351/1239]	  loss: 0.22cifar10:0.2-instance | Epoch [ 65/ 75] Iter[401/1239]	  loss: 0.19cifar10:0.2-instance | Epoch [ 65/ 75] Iter[451/1239]	  loss: 0.17cifar10:0.2-instance | Epoch [ 65/ 75] Iter[501/1239]	  loss: 0.27cifar10:0.2-instance | Epoch [ 65/ 75] Iter[551/1239]	  loss: 0.19cifar10:0.2-instance | Epoch [ 65/ 75] Iter[601/1239]	  loss: 0.20cifar10:0.2-instance | Epoch [ 65/ 75] Iter[651/1239]	  loss: 0.22cifar10:0.2-instance | Epoch [ 65/ 75] Iter[701/1239]	  loss: 0.19cifar10:0.2-instance | Epoch [ 65/ 75] Iter[751/1239]	  loss: 0.16cifar10:0.2-instance | Epoch [ 65/ 75] Iter[801/1239]	  loss: 0.22cifar10:0.2-instance | Epoch [ 65/ 75] Iter[851/1239]	  loss: 0.23cifar10:0.2-instance | Epoch [ 65/ 75] Iter[901/1239]	  loss: 0.20cifar10:0.2-instance | Epoch [ 65/ 75] Iter[951/1239]	  loss: 0.15cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1001/1239]	  loss: 0.26cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1051/1239]	  loss: 0.15cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1101/1239]	  loss: 0.15cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1151/1239]	  loss: 0.22cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1201/1239]	  loss: 0.31
| Test Epoch 65	 Accuracy: 92.40% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 66 | Accuracy on train set: 78.46% 
labeled data has a size of 39704, f-score: 0.984787
cifar10:0.2-instance | Epoch [ 66/ 75] Iter[  1/1241]	  loss: 0.20cifar10:0.2-instance | Epoch [ 66/ 75] Iter[ 51/1241]	  loss: 0.19cifar10:0.2-instance | Epoch [ 66/ 75] Iter[101/1241]	  loss: 0.28cifar10:0.2-instance | Epoch [ 66/ 75] Iter[151/1241]	  loss: 0.21cifar10:0.2-instance | Epoch [ 66/ 75] Iter[201/1241]	  loss: 0.22cifar10:0.2-instance | Epoch [ 66/ 75] Iter[251/1241]	  loss: 0.16cifar10:0.2-instance | Epoch [ 66/ 75] Iter[301/1241]	  loss: 0.16cifar10:0.2-instance | Epoch [ 66/ 75] Iter[351/1241]	  loss: 0.17cifar10:0.2-instance | Epoch [ 66/ 75] Iter[401/1241]	  loss: 0.25cifar10:0.2-instance | Epoch [ 66/ 75] Iter[451/1241]	  loss: 0.17cifar10:0.2-instance | Epoch [ 66/ 75] Iter[501/1241]	  loss: 0.21cifar10:0.2-instance | Epoch [ 66/ 75] Iter[551/1241]	  loss: 0.23cifar10:0.2-instance | Epoch [ 66/ 75] Iter[601/1241]	  loss: 0.15cifar10:0.2-instance | Epoch [ 66/ 75] Iter[651/1241]	  loss: 0.17cifar10:0.2-instance | Epoch [ 66/ 75] Iter[701/1241]	  loss: 0.16cifar10:0.2-instance | Epoch [ 66/ 75] Iter[751/1241]	  loss: 0.44cifar10:0.2-instance | Epoch [ 66/ 75] Iter[801/1241]	  loss: 0.16cifar10:0.2-instance | Epoch [ 66/ 75] Iter[851/1241]	  loss: 0.20cifar10:0.2-instance | Epoch [ 66/ 75] Iter[901/1241]	  loss: 0.18cifar10:0.2-instance | Epoch [ 66/ 75] Iter[951/1241]	  loss: 0.21cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1001/1241]	  loss: 0.15cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1051/1241]	  loss: 0.17cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1101/1241]	  loss: 0.17cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1151/1241]	  loss: 0.16cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1201/1241]	  loss: 0.21
| Test Epoch 66	 Accuracy: 92.23% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 67 | Accuracy on train set: 78.61% 
labeled data has a size of 39757, f-score: 0.984355
cifar10:0.2-instance | Epoch [ 67/ 75] Iter[  1/1243]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[ 51/1243]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[101/1243]	  loss: 0.15cifar10:0.2-instance | Epoch [ 67/ 75] Iter[151/1243]	  loss: 0.26cifar10:0.2-instance | Epoch [ 67/ 75] Iter[201/1243]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[251/1243]	  loss: 0.17cifar10:0.2-instance | Epoch [ 67/ 75] Iter[301/1243]	  loss: 0.15cifar10:0.2-instance | Epoch [ 67/ 75] Iter[351/1243]	  loss: 0.20cifar10:0.2-instance | Epoch [ 67/ 75] Iter[401/1243]	  loss: 0.17cifar10:0.2-instance | Epoch [ 67/ 75] Iter[451/1243]	  loss: 0.33cifar10:0.2-instance | Epoch [ 67/ 75] Iter[501/1243]	  loss: 0.29cifar10:0.2-instance | Epoch [ 67/ 75] Iter[551/1243]	  loss: 0.15cifar10:0.2-instance | Epoch [ 67/ 75] Iter[601/1243]	  loss: 0.18cifar10:0.2-instance | Epoch [ 67/ 75] Iter[651/1243]	  loss: 0.27cifar10:0.2-instance | Epoch [ 67/ 75] Iter[701/1243]	  loss: 0.22cifar10:0.2-instance | Epoch [ 67/ 75] Iter[751/1243]	  loss: 0.41cifar10:0.2-instance | Epoch [ 67/ 75] Iter[801/1243]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[851/1243]	  loss: 0.21cifar10:0.2-instance | Epoch [ 67/ 75] Iter[901/1243]	  loss: 0.20cifar10:0.2-instance | Epoch [ 67/ 75] Iter[951/1243]	  loss: 0.26cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1001/1243]	  loss: 0.15cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1051/1243]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1101/1243]	  loss: 0.19cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1151/1243]	  loss: 0.35cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1201/1243]	  loss: 0.16
| Test Epoch 67	 Accuracy: 92.14% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 68 | Accuracy on train set: 78.80% 
labeled data has a size of 39808, f-score: 0.984099
cifar10:0.2-instance | Epoch [ 68/ 75] Iter[  1/1245]	  loss: 0.22cifar10:0.2-instance | Epoch [ 68/ 75] Iter[ 51/1245]	  loss: 0.17cifar10:0.2-instance | Epoch [ 68/ 75] Iter[101/1245]	  loss: 0.18cifar10:0.2-instance | Epoch [ 68/ 75] Iter[151/1245]	  loss: 0.27cifar10:0.2-instance | Epoch [ 68/ 75] Iter[201/1245]	  loss: 0.27cifar10:0.2-instance | Epoch [ 68/ 75] Iter[251/1245]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[301/1245]	  loss: 0.18cifar10:0.2-instance | Epoch [ 68/ 75] Iter[351/1245]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[401/1245]	  loss: 0.19cifar10:0.2-instance | Epoch [ 68/ 75] Iter[451/1245]	  loss: 0.16cifar10:0.2-instance | Epoch [ 68/ 75] Iter[501/1245]	  loss: 0.26cifar10:0.2-instance | Epoch [ 68/ 75] Iter[551/1245]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[601/1245]	  loss: 0.22cifar10:0.2-instance | Epoch [ 68/ 75] Iter[651/1245]	  loss: 0.21cifar10:0.2-instance | Epoch [ 68/ 75] Iter[701/1245]	  loss: 0.26cifar10:0.2-instance | Epoch [ 68/ 75] Iter[751/1245]	  loss: 0.17cifar10:0.2-instance | Epoch [ 68/ 75] Iter[801/1245]	  loss: 0.31cifar10:0.2-instance | Epoch [ 68/ 75] Iter[851/1245]	  loss: 0.28cifar10:0.2-instance | Epoch [ 68/ 75] Iter[901/1245]	  loss: 0.18cifar10:0.2-instance | Epoch [ 68/ 75] Iter[951/1245]	  loss: 0.18cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1001/1245]	  loss: 0.16cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1051/1245]	  loss: 0.17cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1101/1245]	  loss: 0.26cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1151/1245]	  loss: 0.18cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1201/1245]	  loss: 0.17
| Test Epoch 68	 Accuracy: 92.27% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 69 | Accuracy on train set: 78.94% 
labeled data has a size of 39839, f-score: 0.984086
cifar10:0.2-instance | Epoch [ 69/ 75] Iter[  1/1245]	  loss: 0.25cifar10:0.2-instance | Epoch [ 69/ 75] Iter[ 51/1245]	  loss: 0.29cifar10:0.2-instance | Epoch [ 69/ 75] Iter[101/1245]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[151/1245]	  loss: 0.29cifar10:0.2-instance | Epoch [ 69/ 75] Iter[201/1245]	  loss: 0.20cifar10:0.2-instance | Epoch [ 69/ 75] Iter[251/1245]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[301/1245]	  loss: 0.19cifar10:0.2-instance | Epoch [ 69/ 75] Iter[351/1245]	  loss: 0.19cifar10:0.2-instance | Epoch [ 69/ 75] Iter[401/1245]	  loss: 0.24cifar10:0.2-instance | Epoch [ 69/ 75] Iter[451/1245]	  loss: 0.24cifar10:0.2-instance | Epoch [ 69/ 75] Iter[501/1245]	  loss: 0.21cifar10:0.2-instance | Epoch [ 69/ 75] Iter[551/1245]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[601/1245]	  loss: 0.21cifar10:0.2-instance | Epoch [ 69/ 75] Iter[651/1245]	  loss: 0.28cifar10:0.2-instance | Epoch [ 69/ 75] Iter[701/1245]	  loss: 0.18cifar10:0.2-instance | Epoch [ 69/ 75] Iter[751/1245]	  loss: 0.17cifar10:0.2-instance | Epoch [ 69/ 75] Iter[801/1245]	  loss: 0.30cifar10:0.2-instance | Epoch [ 69/ 75] Iter[851/1245]	  loss: 0.18cifar10:0.2-instance | Epoch [ 69/ 75] Iter[901/1245]	  loss: 0.16cifar10:0.2-instance | Epoch [ 69/ 75] Iter[951/1245]	  loss: 0.17cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1001/1245]	  loss: 0.22cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1051/1245]	  loss: 0.16cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1101/1245]	  loss: 0.22cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1151/1245]	  loss: 0.20cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1201/1245]	  loss: 0.30
| Test Epoch 69	 Accuracy: 91.93% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 70 | Accuracy on train set: 79.00% 
labeled data has a size of 39875, f-score: 0.983824
cifar10:0.2-instance | Epoch [ 70/ 75] Iter[  1/1247]	  loss: 0.18cifar10:0.2-instance | Epoch [ 70/ 75] Iter[ 51/1247]	  loss: 0.30cifar10:0.2-instance | Epoch [ 70/ 75] Iter[101/1247]	  loss: 0.17cifar10:0.2-instance | Epoch [ 70/ 75] Iter[151/1247]	  loss: 0.19cifar10:0.2-instance | Epoch [ 70/ 75] Iter[201/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[251/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[301/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[351/1247]	  loss: 0.17cifar10:0.2-instance | Epoch [ 70/ 75] Iter[401/1247]	  loss: 0.17cifar10:0.2-instance | Epoch [ 70/ 75] Iter[451/1247]	  loss: 0.29cifar10:0.2-instance | Epoch [ 70/ 75] Iter[501/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[551/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[601/1247]	  loss: 0.17cifar10:0.2-instance | Epoch [ 70/ 75] Iter[651/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[701/1247]	  loss: 0.17cifar10:0.2-instance | Epoch [ 70/ 75] Iter[751/1247]	  loss: 0.18cifar10:0.2-instance | Epoch [ 70/ 75] Iter[801/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[851/1247]	  loss: 0.19cifar10:0.2-instance | Epoch [ 70/ 75] Iter[901/1247]	  loss: 0.18cifar10:0.2-instance | Epoch [ 70/ 75] Iter[951/1247]	  loss: 0.19cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1001/1247]	  loss: 0.24cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1051/1247]	  loss: 0.30cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1101/1247]	  loss: 0.19cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1151/1247]	  loss: 0.25cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1201/1247]	  loss: 0.28
| Test Epoch 70	 Accuracy: 92.19% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 71 | Accuracy on train set: 79.23% 
labeled data has a size of 39936, f-score: 0.983148
cifar10:0.2-instance | Epoch [ 71/ 75] Iter[  1/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[ 51/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[101/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[151/1249]	  loss: 0.17cifar10:0.2-instance | Epoch [ 71/ 75] Iter[201/1249]	  loss: 0.18cifar10:0.2-instance | Epoch [ 71/ 75] Iter[251/1249]	  loss: 0.27cifar10:0.2-instance | Epoch [ 71/ 75] Iter[301/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[351/1249]	  loss: 0.19cifar10:0.2-instance | Epoch [ 71/ 75] Iter[401/1249]	  loss: 0.21cifar10:0.2-instance | Epoch [ 71/ 75] Iter[451/1249]	  loss: 0.20cifar10:0.2-instance | Epoch [ 71/ 75] Iter[501/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[551/1249]	  loss: 0.19cifar10:0.2-instance | Epoch [ 71/ 75] Iter[601/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[651/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[701/1249]	  loss: 0.17cifar10:0.2-instance | Epoch [ 71/ 75] Iter[751/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[801/1249]	  loss: 0.20cifar10:0.2-instance | Epoch [ 71/ 75] Iter[851/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[901/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[951/1249]	  loss: 0.17cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1001/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1051/1249]	  loss: 0.18cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1101/1249]	  loss: 0.20cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1151/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1201/1249]	  loss: 0.42
| Test Epoch 71	 Accuracy: 91.81% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 72 | Accuracy on train set: 79.13% 
labeled data has a size of 39968, f-score: 0.982636
cifar10:0.2-instance | Epoch [ 72/ 75] Iter[  1/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[ 51/1250]	  loss: 0.20cifar10:0.2-instance | Epoch [ 72/ 75] Iter[101/1250]	  loss: 0.17cifar10:0.2-instance | Epoch [ 72/ 75] Iter[151/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[201/1250]	  loss: 0.24cifar10:0.2-instance | Epoch [ 72/ 75] Iter[251/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[301/1250]	  loss: 0.18cifar10:0.2-instance | Epoch [ 72/ 75] Iter[351/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[401/1250]	  loss: 0.19cifar10:0.2-instance | Epoch [ 72/ 75] Iter[451/1250]	  loss: 0.21cifar10:0.2-instance | Epoch [ 72/ 75] Iter[501/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[551/1250]	  loss: 0.24cifar10:0.2-instance | Epoch [ 72/ 75] Iter[601/1250]	  loss: 0.25cifar10:0.2-instance | Epoch [ 72/ 75] Iter[651/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[701/1250]	  loss: 0.20cifar10:0.2-instance | Epoch [ 72/ 75] Iter[751/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[801/1250]	  loss: 0.28cifar10:0.2-instance | Epoch [ 72/ 75] Iter[851/1250]	  loss: 0.22cifar10:0.2-instance | Epoch [ 72/ 75] Iter[901/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[951/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1001/1250]	  loss: 0.20cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1051/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1101/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1151/1250]	  loss: 0.18cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1201/1250]	  loss: 0.17
| Test Epoch 72	 Accuracy: 91.87% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 73 | Accuracy on train set: 79.36% 
labeled data has a size of 39994, f-score: 0.982347
cifar10:0.2-instance | Epoch [ 73/ 75] Iter[  1/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[ 51/1250]	  loss: 0.19cifar10:0.2-instance | Epoch [ 73/ 75] Iter[101/1250]	  loss: 0.18cifar10:0.2-instance | Epoch [ 73/ 75] Iter[151/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[201/1250]	  loss: 0.18cifar10:0.2-instance | Epoch [ 73/ 75] Iter[251/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[301/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[351/1250]	  loss: 0.21cifar10:0.2-instance | Epoch [ 73/ 75] Iter[401/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[451/1250]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[501/1250]	  loss: 0.27cifar10:0.2-instance | Epoch [ 73/ 75] Iter[551/1250]	  loss: 0.18cifar10:0.2-instance | Epoch [ 73/ 75] Iter[601/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[651/1250]	  loss: 0.21cifar10:0.2-instance | Epoch [ 73/ 75] Iter[701/1250]	  loss: 0.18cifar10:0.2-instance | Epoch [ 73/ 75] Iter[751/1250]	  loss: 0.22cifar10:0.2-instance | Epoch [ 73/ 75] Iter[801/1250]	  loss: 0.37cifar10:0.2-instance | Epoch [ 73/ 75] Iter[851/1250]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[901/1250]	  loss: 0.17cifar10:0.2-instance | Epoch [ 73/ 75] Iter[951/1250]	  loss: 0.18cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1001/1250]	  loss: 0.17cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1051/1250]	  loss: 0.19cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1101/1250]	  loss: 0.17cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1151/1250]	  loss: 0.25cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1201/1250]	  loss: 0.16
| Test Epoch 73	 Accuracy: 92.18% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 74 | Accuracy on train set: 79.46% 
labeled data has a size of 40025, f-score: 0.982011
cifar10:0.2-instance | Epoch [ 74/ 75] Iter[  1/1251]	  loss: 0.20cifar10:0.2-instance | Epoch [ 74/ 75] Iter[ 51/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[101/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[151/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[201/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[251/1251]	  loss: 0.29cifar10:0.2-instance | Epoch [ 74/ 75] Iter[301/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[351/1251]	  loss: 0.18cifar10:0.2-instance | Epoch [ 74/ 75] Iter[401/1251]	  loss: 0.19cifar10:0.2-instance | Epoch [ 74/ 75] Iter[451/1251]	  loss: 0.17cifar10:0.2-instance | Epoch [ 74/ 75] Iter[501/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[551/1251]	  loss: 0.28cifar10:0.2-instance | Epoch [ 74/ 75] Iter[601/1251]	  loss: 0.17cifar10:0.2-instance | Epoch [ 74/ 75] Iter[651/1251]	  loss: 0.21cifar10:0.2-instance | Epoch [ 74/ 75] Iter[701/1251]	  loss: 0.21cifar10:0.2-instance | Epoch [ 74/ 75] Iter[751/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[801/1251]	  loss: 0.17cifar10:0.2-instance | Epoch [ 74/ 75] Iter[851/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[901/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[951/1251]	  loss: 0.21cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1001/1251]	  loss: 0.17cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1051/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1101/1251]	  loss: 0.29cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1151/1251]	  loss: 0.32cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1201/1251]	  loss: 0.26cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1251/1251]	  loss: 0.18
| Test Epoch 74	 Accuracy: 91.56% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 75 | Accuracy on train set: 79.43% 
labeled data has a size of 40055, f-score: 0.981500
cifar10:0.2-instance | Epoch [ 75/ 75] Iter[  1/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[ 51/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[101/1252]	  loss: 0.23cifar10:0.2-instance | Epoch [ 75/ 75] Iter[151/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[201/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[251/1252]	  loss: 0.20cifar10:0.2-instance | Epoch [ 75/ 75] Iter[301/1252]	  loss: 0.31cifar10:0.2-instance | Epoch [ 75/ 75] Iter[351/1252]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[401/1252]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[451/1252]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[501/1252]	  loss: 0.23cifar10:0.2-instance | Epoch [ 75/ 75] Iter[551/1252]	  loss: 0.33cifar10:0.2-instance | Epoch [ 75/ 75] Iter[601/1252]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[651/1252]	  loss: 0.17cifar10:0.2-instance | Epoch [ 75/ 75] Iter[701/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[751/1252]	  loss: 0.21cifar10:0.2-instance | Epoch [ 75/ 75] Iter[801/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[851/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[901/1252]	  loss: 0.18cifar10:0.2-instance | Epoch [ 75/ 75] Iter[951/1252]	  loss: 0.29cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1001/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1051/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1101/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1151/1252]	  loss: 0.17cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1201/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1251/1252]	  loss: 0.20
| Test Epoch 75	 Accuracy: 92.05% 



best test Acc:  92.4
