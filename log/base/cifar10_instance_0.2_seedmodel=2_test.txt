Namespace(T=0.2, batch_size=32, data_path='./dataset2/cifar10', dataset='cifar10', fig_7=0, fluctuation_ablation=0, gpuid=0, k=3, lr=0.02, model='resnet18', noise_mode='instance', num_class=10, num_epochs=75, r=0.2, save_sel_sam=0, seed_model=2, seed_noise=1, semi='no', warm_up=10, wdecay=0.0005, without_Lcr=0, without_R=0)
============ Initialize data
============ Actual clean samples number:  39820
============ use resnet18 
============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 0 | Accuracy on train set: 7.55% 
cifar10:0.2-instance | Epoch [  0/ 75] Iter[  1/391]	 CE-loss: 2.4246cifar10:0.2-instance | Epoch [  0/ 75] Iter[ 51/391]	 CE-loss: 2.0348cifar10:0.2-instance | Epoch [  0/ 75] Iter[101/391]	 CE-loss: 1.9418cifar10:0.2-instance | Epoch [  0/ 75] Iter[151/391]	 CE-loss: 1.9622cifar10:0.2-instance | Epoch [  0/ 75] Iter[201/391]	 CE-loss: 1.8336cifar10:0.2-instance | Epoch [  0/ 75] Iter[251/391]	 CE-loss: 1.8154cifar10:0.2-instance | Epoch [  0/ 75] Iter[301/391]	 CE-loss: 1.5513cifar10:0.2-instance | Epoch [  0/ 75] Iter[351/391]	 CE-loss: 1.7289
| Test Epoch 0	 Accuracy: 42.21% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 1 | Accuracy on train set: 36.95% 
cifar10:0.2-instance | Epoch [  1/ 75] Iter[  1/391]	 CE-loss: 1.5306cifar10:0.2-instance | Epoch [  1/ 75] Iter[ 51/391]	 CE-loss: 1.5764cifar10:0.2-instance | Epoch [  1/ 75] Iter[101/391]	 CE-loss: 1.5854cifar10:0.2-instance | Epoch [  1/ 75] Iter[151/391]	 CE-loss: 1.5573cifar10:0.2-instance | Epoch [  1/ 75] Iter[201/391]	 CE-loss: 1.5294cifar10:0.2-instance | Epoch [  1/ 75] Iter[251/391]	 CE-loss: 1.3457cifar10:0.2-instance | Epoch [  1/ 75] Iter[301/391]	 CE-loss: 1.4467cifar10:0.2-instance | Epoch [  1/ 75] Iter[351/391]	 CE-loss: 1.5397
| Test Epoch 1	 Accuracy: 58.02% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 2 | Accuracy on train set: 48.94% 
cifar10:0.2-instance | Epoch [  2/ 75] Iter[  1/391]	 CE-loss: 1.2037cifar10:0.2-instance | Epoch [  2/ 75] Iter[ 51/391]	 CE-loss: 1.3338cifar10:0.2-instance | Epoch [  2/ 75] Iter[101/391]	 CE-loss: 1.3457cifar10:0.2-instance | Epoch [  2/ 75] Iter[151/391]	 CE-loss: 1.2528cifar10:0.2-instance | Epoch [  2/ 75] Iter[201/391]	 CE-loss: 1.4750cifar10:0.2-instance | Epoch [  2/ 75] Iter[251/391]	 CE-loss: 1.1823cifar10:0.2-instance | Epoch [  2/ 75] Iter[301/391]	 CE-loss: 1.2351cifar10:0.2-instance | Epoch [  2/ 75] Iter[351/391]	 CE-loss: 1.1939
| Test Epoch 2	 Accuracy: 66.86% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 3 | Accuracy on train set: 55.65% 
cifar10:0.2-instance | Epoch [  3/ 75] Iter[  1/391]	 CE-loss: 1.2257cifar10:0.2-instance | Epoch [  3/ 75] Iter[ 51/391]	 CE-loss: 1.2781cifar10:0.2-instance | Epoch [  3/ 75] Iter[101/391]	 CE-loss: 1.1478cifar10:0.2-instance | Epoch [  3/ 75] Iter[151/391]	 CE-loss: 1.1790cifar10:0.2-instance | Epoch [  3/ 75] Iter[201/391]	 CE-loss: 1.2098cifar10:0.2-instance | Epoch [  3/ 75] Iter[251/391]	 CE-loss: 1.1793cifar10:0.2-instance | Epoch [  3/ 75] Iter[301/391]	 CE-loss: 1.1426cifar10:0.2-instance | Epoch [  3/ 75] Iter[351/391]	 CE-loss: 1.1087
| Test Epoch 3	 Accuracy: 60.04% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 4 | Accuracy on train set: 53.32% 
cifar10:0.2-instance | Epoch [  4/ 75] Iter[  1/391]	 CE-loss: 1.2652cifar10:0.2-instance | Epoch [  4/ 75] Iter[ 51/391]	 CE-loss: 1.3631cifar10:0.2-instance | Epoch [  4/ 75] Iter[101/391]	 CE-loss: 1.0696cifar10:0.2-instance | Epoch [  4/ 75] Iter[151/391]	 CE-loss: 1.2053cifar10:0.2-instance | Epoch [  4/ 75] Iter[201/391]	 CE-loss: 1.1501cifar10:0.2-instance | Epoch [  4/ 75] Iter[251/391]	 CE-loss: 1.0390cifar10:0.2-instance | Epoch [  4/ 75] Iter[301/391]	 CE-loss: 1.1800cifar10:0.2-instance | Epoch [  4/ 75] Iter[351/391]	 CE-loss: 1.2611
| Test Epoch 4	 Accuracy: 76.76% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 5 | Accuracy on train set: 63.64% 
cifar10:0.2-instance | Epoch [  5/ 75] Iter[  1/391]	 CE-loss: 1.1457cifar10:0.2-instance | Epoch [  5/ 75] Iter[ 51/391]	 CE-loss: 1.1233cifar10:0.2-instance | Epoch [  5/ 75] Iter[101/391]	 CE-loss: 1.1332cifar10:0.2-instance | Epoch [  5/ 75] Iter[151/391]	 CE-loss: 1.1090cifar10:0.2-instance | Epoch [  5/ 75] Iter[201/391]	 CE-loss: 0.9474cifar10:0.2-instance | Epoch [  5/ 75] Iter[251/391]	 CE-loss: 1.1500cifar10:0.2-instance | Epoch [  5/ 75] Iter[301/391]	 CE-loss: 1.3178cifar10:0.2-instance | Epoch [  5/ 75] Iter[351/391]	 CE-loss: 1.1409
| Test Epoch 5	 Accuracy: 79.01% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 6 | Accuracy on train set: 65.89% 
cifar10:0.2-instance | Epoch [  6/ 75] Iter[  1/391]	 CE-loss: 1.1185cifar10:0.2-instance | Epoch [  6/ 75] Iter[ 51/391]	 CE-loss: 1.0545cifar10:0.2-instance | Epoch [  6/ 75] Iter[101/391]	 CE-loss: 1.1214cifar10:0.2-instance | Epoch [  6/ 75] Iter[151/391]	 CE-loss: 1.1769cifar10:0.2-instance | Epoch [  6/ 75] Iter[201/391]	 CE-loss: 0.9940cifar10:0.2-instance | Epoch [  6/ 75] Iter[251/391]	 CE-loss: 1.1102cifar10:0.2-instance | Epoch [  6/ 75] Iter[301/391]	 CE-loss: 1.0501cifar10:0.2-instance | Epoch [  6/ 75] Iter[351/391]	 CE-loss: 0.9203
| Test Epoch 6	 Accuracy: 78.05% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 7 | Accuracy on train set: 65.68% 
cifar10:0.2-instance | Epoch [  7/ 75] Iter[  1/391]	 CE-loss: 1.1524cifar10:0.2-instance | Epoch [  7/ 75] Iter[ 51/391]	 CE-loss: 1.0042cifar10:0.2-instance | Epoch [  7/ 75] Iter[101/391]	 CE-loss: 1.0848cifar10:0.2-instance | Epoch [  7/ 75] Iter[151/391]	 CE-loss: 1.0225cifar10:0.2-instance | Epoch [  7/ 75] Iter[201/391]	 CE-loss: 0.9831cifar10:0.2-instance | Epoch [  7/ 75] Iter[251/391]	 CE-loss: 0.9116cifar10:0.2-instance | Epoch [  7/ 75] Iter[301/391]	 CE-loss: 1.1827cifar10:0.2-instance | Epoch [  7/ 75] Iter[351/391]	 CE-loss: 1.0160
| Test Epoch 7	 Accuracy: 81.45% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 8 | Accuracy on train set: 67.53% 
cifar10:0.2-instance | Epoch [  8/ 75] Iter[  1/391]	 CE-loss: 0.8430cifar10:0.2-instance | Epoch [  8/ 75] Iter[ 51/391]	 CE-loss: 0.9043cifar10:0.2-instance | Epoch [  8/ 75] Iter[101/391]	 CE-loss: 0.9592cifar10:0.2-instance | Epoch [  8/ 75] Iter[151/391]	 CE-loss: 0.9397cifar10:0.2-instance | Epoch [  8/ 75] Iter[201/391]	 CE-loss: 1.0478cifar10:0.2-instance | Epoch [  8/ 75] Iter[251/391]	 CE-loss: 1.0434cifar10:0.2-instance | Epoch [  8/ 75] Iter[301/391]	 CE-loss: 1.0537cifar10:0.2-instance | Epoch [  8/ 75] Iter[351/391]	 CE-loss: 0.8185
| Test Epoch 8	 Accuracy: 81.83% 



============ Warmup stage | lr = 0.020, T in penalty = 0.200
Epoch 9 | Accuracy on train set: 68.10% 
cifar10:0.2-instance | Epoch [  9/ 75] Iter[  1/391]	 CE-loss: 0.8779cifar10:0.2-instance | Epoch [  9/ 75] Iter[ 51/391]	 CE-loss: 0.9524cifar10:0.2-instance | Epoch [  9/ 75] Iter[101/391]	 CE-loss: 1.0344cifar10:0.2-instance | Epoch [  9/ 75] Iter[151/391]	 CE-loss: 1.0364cifar10:0.2-instance | Epoch [  9/ 75] Iter[201/391]	 CE-loss: 0.9031cifar10:0.2-instance | Epoch [  9/ 75] Iter[251/391]	 CE-loss: 1.0529cifar10:0.2-instance | Epoch [  9/ 75] Iter[301/391]	 CE-loss: 0.8032cifar10:0.2-instance | Epoch [  9/ 75] Iter[351/391]	 CE-loss: 0.9531
| Test Epoch 9	 Accuracy: 82.21% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 10 | Accuracy on train set: 69.06% 
labeled data has a size of 38322, f-score: 0.974949
cifar10:0.2-instance | Epoch [ 10/ 75] Iter[  1/1198]	  loss: 0.58cifar10:0.2-instance | Epoch [ 10/ 75] Iter[ 51/1198]	  loss: 0.98cifar10:0.2-instance | Epoch [ 10/ 75] Iter[101/1198]	  loss: 0.78cifar10:0.2-instance | Epoch [ 10/ 75] Iter[151/1198]	  loss: 0.78cifar10:0.2-instance | Epoch [ 10/ 75] Iter[201/1198]	  loss: 0.52cifar10:0.2-instance | Epoch [ 10/ 75] Iter[251/1198]	  loss: 0.59cifar10:0.2-instance | Epoch [ 10/ 75] Iter[301/1198]	  loss: 0.82cifar10:0.2-instance | Epoch [ 10/ 75] Iter[351/1198]	  loss: 0.61cifar10:0.2-instance | Epoch [ 10/ 75] Iter[401/1198]	  loss: 0.90cifar10:0.2-instance | Epoch [ 10/ 75] Iter[451/1198]	  loss: 1.06cifar10:0.2-instance | Epoch [ 10/ 75] Iter[501/1198]	  loss: 0.60cifar10:0.2-instance | Epoch [ 10/ 75] Iter[551/1198]	  loss: 0.55cifar10:0.2-instance | Epoch [ 10/ 75] Iter[601/1198]	  loss: 0.43cifar10:0.2-instance | Epoch [ 10/ 75] Iter[651/1198]	  loss: 0.78cifar10:0.2-instance | Epoch [ 10/ 75] Iter[701/1198]	  loss: 0.80cifar10:0.2-instance | Epoch [ 10/ 75] Iter[751/1198]	  loss: 0.63cifar10:0.2-instance | Epoch [ 10/ 75] Iter[801/1198]	  loss: 0.84cifar10:0.2-instance | Epoch [ 10/ 75] Iter[851/1198]	  loss: 0.51cifar10:0.2-instance | Epoch [ 10/ 75] Iter[901/1198]	  loss: 0.71cifar10:0.2-instance | Epoch [ 10/ 75] Iter[951/1198]	  loss: 1.07cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1001/1198]	  loss: 0.55cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1051/1198]	  loss: 0.55cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1101/1198]	  loss: 0.72cifar10:0.2-instance | Epoch [ 10/ 75] Iter[1151/1198]	  loss: 0.63
| Test Epoch 10	 Accuracy: 79.29% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 11 | Accuracy on train set: 65.60% 
labeled data has a size of 38176, f-score: 0.976215
cifar10:0.2-instance | Epoch [ 11/ 75] Iter[  1/1194]	  loss: 0.52cifar10:0.2-instance | Epoch [ 11/ 75] Iter[ 51/1194]	  loss: 0.51cifar10:0.2-instance | Epoch [ 11/ 75] Iter[101/1194]	  loss: 0.32cifar10:0.2-instance | Epoch [ 11/ 75] Iter[151/1194]	  loss: 0.55cifar10:0.2-instance | Epoch [ 11/ 75] Iter[201/1194]	  loss: 0.89cifar10:0.2-instance | Epoch [ 11/ 75] Iter[251/1194]	  loss: 0.97cifar10:0.2-instance | Epoch [ 11/ 75] Iter[301/1194]	  loss: 0.78cifar10:0.2-instance | Epoch [ 11/ 75] Iter[351/1194]	  loss: 0.63cifar10:0.2-instance | Epoch [ 11/ 75] Iter[401/1194]	  loss: 0.62cifar10:0.2-instance | Epoch [ 11/ 75] Iter[451/1194]	  loss: 0.59cifar10:0.2-instance | Epoch [ 11/ 75] Iter[501/1194]	  loss: 0.43cifar10:0.2-instance | Epoch [ 11/ 75] Iter[551/1194]	  loss: 0.82cifar10:0.2-instance | Epoch [ 11/ 75] Iter[601/1194]	  loss: 0.34cifar10:0.2-instance | Epoch [ 11/ 75] Iter[651/1194]	  loss: 0.60cifar10:0.2-instance | Epoch [ 11/ 75] Iter[701/1194]	  loss: 0.51cifar10:0.2-instance | Epoch [ 11/ 75] Iter[751/1194]	  loss: 0.54cifar10:0.2-instance | Epoch [ 11/ 75] Iter[801/1194]	  loss: 0.97cifar10:0.2-instance | Epoch [ 11/ 75] Iter[851/1194]	  loss: 0.51cifar10:0.2-instance | Epoch [ 11/ 75] Iter[901/1194]	  loss: 0.67cifar10:0.2-instance | Epoch [ 11/ 75] Iter[951/1194]	  loss: 0.44cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1001/1194]	  loss: 0.60cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1051/1194]	  loss: 0.47cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1101/1194]	  loss: 0.50cifar10:0.2-instance | Epoch [ 11/ 75] Iter[1151/1194]	  loss: 0.59
| Test Epoch 11	 Accuracy: 81.60% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 12 | Accuracy on train set: 67.76% 
labeled data has a size of 37920, f-score: 0.979035
cifar10:0.2-instance | Epoch [ 12/ 75] Iter[  1/1186]	  loss: 0.46cifar10:0.2-instance | Epoch [ 12/ 75] Iter[ 51/1186]	  loss: 0.49cifar10:0.2-instance | Epoch [ 12/ 75] Iter[101/1186]	  loss: 0.42cifar10:0.2-instance | Epoch [ 12/ 75] Iter[151/1186]	  loss: 0.82cifar10:0.2-instance | Epoch [ 12/ 75] Iter[201/1186]	  loss: 0.54cifar10:0.2-instance | Epoch [ 12/ 75] Iter[251/1186]	  loss: 0.74cifar10:0.2-instance | Epoch [ 12/ 75] Iter[301/1186]	  loss: 0.47cifar10:0.2-instance | Epoch [ 12/ 75] Iter[351/1186]	  loss: 0.58cifar10:0.2-instance | Epoch [ 12/ 75] Iter[401/1186]	  loss: 0.53cifar10:0.2-instance | Epoch [ 12/ 75] Iter[451/1186]	  loss: 0.54cifar10:0.2-instance | Epoch [ 12/ 75] Iter[501/1186]	  loss: 0.50cifar10:0.2-instance | Epoch [ 12/ 75] Iter[551/1186]	  loss: 0.42cifar10:0.2-instance | Epoch [ 12/ 75] Iter[601/1186]	  loss: 0.52cifar10:0.2-instance | Epoch [ 12/ 75] Iter[651/1186]	  loss: 0.51cifar10:0.2-instance | Epoch [ 12/ 75] Iter[701/1186]	  loss: 0.75cifar10:0.2-instance | Epoch [ 12/ 75] Iter[751/1186]	  loss: 0.54cifar10:0.2-instance | Epoch [ 12/ 75] Iter[801/1186]	  loss: 0.58cifar10:0.2-instance | Epoch [ 12/ 75] Iter[851/1186]	  loss: 0.27cifar10:0.2-instance | Epoch [ 12/ 75] Iter[901/1186]	  loss: 0.52cifar10:0.2-instance | Epoch [ 12/ 75] Iter[951/1186]	  loss: 0.51cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1001/1186]	  loss: 0.65cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1051/1186]	  loss: 0.70cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1101/1186]	  loss: 0.21cifar10:0.2-instance | Epoch [ 12/ 75] Iter[1151/1186]	  loss: 0.44
| Test Epoch 12	 Accuracy: 76.39% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 13 | Accuracy on train set: 63.31% 
labeled data has a size of 37452, f-score: 0.982885
cifar10:0.2-instance | Epoch [ 13/ 75] Iter[  1/1171]	  loss: 0.56cifar10:0.2-instance | Epoch [ 13/ 75] Iter[ 51/1171]	  loss: 0.45cifar10:0.2-instance | Epoch [ 13/ 75] Iter[101/1171]	  loss: 0.41cifar10:0.2-instance | Epoch [ 13/ 75] Iter[151/1171]	  loss: 0.34cifar10:0.2-instance | Epoch [ 13/ 75] Iter[201/1171]	  loss: 0.64cifar10:0.2-instance | Epoch [ 13/ 75] Iter[251/1171]	  loss: 0.52cifar10:0.2-instance | Epoch [ 13/ 75] Iter[301/1171]	  loss: 0.42cifar10:0.2-instance | Epoch [ 13/ 75] Iter[351/1171]	  loss: 0.48cifar10:0.2-instance | Epoch [ 13/ 75] Iter[401/1171]	  loss: 0.52cifar10:0.2-instance | Epoch [ 13/ 75] Iter[451/1171]	  loss: 0.31cifar10:0.2-instance | Epoch [ 13/ 75] Iter[501/1171]	  loss: 0.51cifar10:0.2-instance | Epoch [ 13/ 75] Iter[551/1171]	  loss: 0.65cifar10:0.2-instance | Epoch [ 13/ 75] Iter[601/1171]	  loss: 0.48cifar10:0.2-instance | Epoch [ 13/ 75] Iter[651/1171]	  loss: 0.51cifar10:0.2-instance | Epoch [ 13/ 75] Iter[701/1171]	  loss: 0.34cifar10:0.2-instance | Epoch [ 13/ 75] Iter[751/1171]	  loss: 0.62cifar10:0.2-instance | Epoch [ 13/ 75] Iter[801/1171]	  loss: 0.45cifar10:0.2-instance | Epoch [ 13/ 75] Iter[851/1171]	  loss: 0.52cifar10:0.2-instance | Epoch [ 13/ 75] Iter[901/1171]	  loss: 0.49cifar10:0.2-instance | Epoch [ 13/ 75] Iter[951/1171]	  loss: 0.57cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1001/1171]	  loss: 0.53cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1051/1171]	  loss: 0.59cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1101/1171]	  loss: 0.32cifar10:0.2-instance | Epoch [ 13/ 75] Iter[1151/1171]	  loss: 0.46
| Test Epoch 13	 Accuracy: 82.65% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 14 | Accuracy on train set: 68.71% 
labeled data has a size of 37646, f-score: 0.983929
cifar10:0.2-instance | Epoch [ 14/ 75] Iter[  1/1177]	  loss: 0.42cifar10:0.2-instance | Epoch [ 14/ 75] Iter[ 51/1177]	  loss: 0.34cifar10:0.2-instance | Epoch [ 14/ 75] Iter[101/1177]	  loss: 0.29cifar10:0.2-instance | Epoch [ 14/ 75] Iter[151/1177]	  loss: 0.38cifar10:0.2-instance | Epoch [ 14/ 75] Iter[201/1177]	  loss: 0.61cifar10:0.2-instance | Epoch [ 14/ 75] Iter[251/1177]	  loss: 0.40cifar10:0.2-instance | Epoch [ 14/ 75] Iter[301/1177]	  loss: 0.46cifar10:0.2-instance | Epoch [ 14/ 75] Iter[351/1177]	  loss: 0.26cifar10:0.2-instance | Epoch [ 14/ 75] Iter[401/1177]	  loss: 0.32cifar10:0.2-instance | Epoch [ 14/ 75] Iter[451/1177]	  loss: 0.69cifar10:0.2-instance | Epoch [ 14/ 75] Iter[501/1177]	  loss: 0.26cifar10:0.2-instance | Epoch [ 14/ 75] Iter[551/1177]	  loss: 0.41cifar10:0.2-instance | Epoch [ 14/ 75] Iter[601/1177]	  loss: 0.33cifar10:0.2-instance | Epoch [ 14/ 75] Iter[651/1177]	  loss: 0.40cifar10:0.2-instance | Epoch [ 14/ 75] Iter[701/1177]	  loss: 0.60cifar10:0.2-instance | Epoch [ 14/ 75] Iter[751/1177]	  loss: 0.57cifar10:0.2-instance | Epoch [ 14/ 75] Iter[801/1177]	  loss: 0.24cifar10:0.2-instance | Epoch [ 14/ 75] Iter[851/1177]	  loss: 0.29cifar10:0.2-instance | Epoch [ 14/ 75] Iter[901/1177]	  loss: 0.99cifar10:0.2-instance | Epoch [ 14/ 75] Iter[951/1177]	  loss: 0.47cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1001/1177]	  loss: 0.38cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1051/1177]	  loss: 0.44cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1101/1177]	  loss: 0.33cifar10:0.2-instance | Epoch [ 14/ 75] Iter[1151/1177]	  loss: 0.74
| Test Epoch 14	 Accuracy: 82.48% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 15 | Accuracy on train set: 68.80% 
labeled data has a size of 37720, f-score: 0.985445
cifar10:0.2-instance | Epoch [ 15/ 75] Iter[  1/1179]	  loss: 0.34cifar10:0.2-instance | Epoch [ 15/ 75] Iter[ 51/1179]	  loss: 0.31cifar10:0.2-instance | Epoch [ 15/ 75] Iter[101/1179]	  loss: 0.54cifar10:0.2-instance | Epoch [ 15/ 75] Iter[151/1179]	  loss: 0.41cifar10:0.2-instance | Epoch [ 15/ 75] Iter[201/1179]	  loss: 0.52cifar10:0.2-instance | Epoch [ 15/ 75] Iter[251/1179]	  loss: 0.44cifar10:0.2-instance | Epoch [ 15/ 75] Iter[301/1179]	  loss: 0.41cifar10:0.2-instance | Epoch [ 15/ 75] Iter[351/1179]	  loss: 0.36cifar10:0.2-instance | Epoch [ 15/ 75] Iter[401/1179]	  loss: 0.54cifar10:0.2-instance | Epoch [ 15/ 75] Iter[451/1179]	  loss: 0.42cifar10:0.2-instance | Epoch [ 15/ 75] Iter[501/1179]	  loss: 0.37cifar10:0.2-instance | Epoch [ 15/ 75] Iter[551/1179]	  loss: 0.30cifar10:0.2-instance | Epoch [ 15/ 75] Iter[601/1179]	  loss: 0.52cifar10:0.2-instance | Epoch [ 15/ 75] Iter[651/1179]	  loss: 0.52cifar10:0.2-instance | Epoch [ 15/ 75] Iter[701/1179]	  loss: 0.59cifar10:0.2-instance | Epoch [ 15/ 75] Iter[751/1179]	  loss: 0.45cifar10:0.2-instance | Epoch [ 15/ 75] Iter[801/1179]	  loss: 0.33cifar10:0.2-instance | Epoch [ 15/ 75] Iter[851/1179]	  loss: 0.39cifar10:0.2-instance | Epoch [ 15/ 75] Iter[901/1179]	  loss: 0.44cifar10:0.2-instance | Epoch [ 15/ 75] Iter[951/1179]	  loss: 0.46cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1001/1179]	  loss: 0.49cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1051/1179]	  loss: 0.41cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1101/1179]	  loss: 0.64cifar10:0.2-instance | Epoch [ 15/ 75] Iter[1151/1179]	  loss: 0.41
| Test Epoch 15	 Accuracy: 81.96% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 16 | Accuracy on train set: 68.24% 
labeled data has a size of 38019, f-score: 0.983035
cifar10:0.2-instance | Epoch [ 16/ 75] Iter[  1/1189]	  loss: 0.43cifar10:0.2-instance | Epoch [ 16/ 75] Iter[ 51/1189]	  loss: 0.49cifar10:0.2-instance | Epoch [ 16/ 75] Iter[101/1189]	  loss: 0.32cifar10:0.2-instance | Epoch [ 16/ 75] Iter[151/1189]	  loss: 0.44cifar10:0.2-instance | Epoch [ 16/ 75] Iter[201/1189]	  loss: 0.41cifar10:0.2-instance | Epoch [ 16/ 75] Iter[251/1189]	  loss: 0.57cifar10:0.2-instance | Epoch [ 16/ 75] Iter[301/1189]	  loss: 0.35cifar10:0.2-instance | Epoch [ 16/ 75] Iter[351/1189]	  loss: 0.49cifar10:0.2-instance | Epoch [ 16/ 75] Iter[401/1189]	  loss: 0.64cifar10:0.2-instance | Epoch [ 16/ 75] Iter[451/1189]	  loss: 0.48cifar10:0.2-instance | Epoch [ 16/ 75] Iter[501/1189]	  loss: 0.69cifar10:0.2-instance | Epoch [ 16/ 75] Iter[551/1189]	  loss: 0.52cifar10:0.2-instance | Epoch [ 16/ 75] Iter[601/1189]	  loss: 0.44cifar10:0.2-instance | Epoch [ 16/ 75] Iter[651/1189]	  loss: 0.40cifar10:0.2-instance | Epoch [ 16/ 75] Iter[701/1189]	  loss: 0.30cifar10:0.2-instance | Epoch [ 16/ 75] Iter[751/1189]	  loss: 0.47cifar10:0.2-instance | Epoch [ 16/ 75] Iter[801/1189]	  loss: 0.34cifar10:0.2-instance | Epoch [ 16/ 75] Iter[851/1189]	  loss: 0.38cifar10:0.2-instance | Epoch [ 16/ 75] Iter[901/1189]	  loss: 0.29cifar10:0.2-instance | Epoch [ 16/ 75] Iter[951/1189]	  loss: 0.69cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1001/1189]	  loss: 0.49cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1051/1189]	  loss: 0.42cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1101/1189]	  loss: 0.55cifar10:0.2-instance | Epoch [ 16/ 75] Iter[1151/1189]	  loss: 0.36
| Test Epoch 16	 Accuracy: 81.50% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 17 | Accuracy on train set: 68.75% 
labeled data has a size of 38551, f-score: 0.978522
cifar10:0.2-instance | Epoch [ 17/ 75] Iter[  1/1205]	  loss: 0.43cifar10:0.2-instance | Epoch [ 17/ 75] Iter[ 51/1205]	  loss: 0.54cifar10:0.2-instance | Epoch [ 17/ 75] Iter[101/1205]	  loss: 0.41cifar10:0.2-instance | Epoch [ 17/ 75] Iter[151/1205]	  loss: 0.38cifar10:0.2-instance | Epoch [ 17/ 75] Iter[201/1205]	  loss: 0.48cifar10:0.2-instance | Epoch [ 17/ 75] Iter[251/1205]	  loss: 0.43cifar10:0.2-instance | Epoch [ 17/ 75] Iter[301/1205]	  loss: 0.35cifar10:0.2-instance | Epoch [ 17/ 75] Iter[351/1205]	  loss: 0.44cifar10:0.2-instance | Epoch [ 17/ 75] Iter[401/1205]	  loss: 0.60cifar10:0.2-instance | Epoch [ 17/ 75] Iter[451/1205]	  loss: 0.45cifar10:0.2-instance | Epoch [ 17/ 75] Iter[501/1205]	  loss: 0.48cifar10:0.2-instance | Epoch [ 17/ 75] Iter[551/1205]	  loss: 0.31cifar10:0.2-instance | Epoch [ 17/ 75] Iter[601/1205]	  loss: 0.77cifar10:0.2-instance | Epoch [ 17/ 75] Iter[651/1205]	  loss: 0.77cifar10:0.2-instance | Epoch [ 17/ 75] Iter[701/1205]	  loss: 0.66cifar10:0.2-instance | Epoch [ 17/ 75] Iter[751/1205]	  loss: 0.48cifar10:0.2-instance | Epoch [ 17/ 75] Iter[801/1205]	  loss: 0.44cifar10:0.2-instance | Epoch [ 17/ 75] Iter[851/1205]	  loss: 0.30cifar10:0.2-instance | Epoch [ 17/ 75] Iter[901/1205]	  loss: 0.42cifar10:0.2-instance | Epoch [ 17/ 75] Iter[951/1205]	  loss: 0.48cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1001/1205]	  loss: 0.43cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1051/1205]	  loss: 0.54cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1101/1205]	  loss: 0.38cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1151/1205]	  loss: 0.66cifar10:0.2-instance | Epoch [ 17/ 75] Iter[1201/1205]	  loss: 0.34
| Test Epoch 17	 Accuracy: 83.71% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 18 | Accuracy on train set: 69.77% 
labeled data has a size of 38559, f-score: 0.978552
cifar10:0.2-instance | Epoch [ 18/ 75] Iter[  1/1205]	  loss: 0.79cifar10:0.2-instance | Epoch [ 18/ 75] Iter[ 51/1205]	  loss: 0.31cifar10:0.2-instance | Epoch [ 18/ 75] Iter[101/1205]	  loss: 0.64cifar10:0.2-instance | Epoch [ 18/ 75] Iter[151/1205]	  loss: 0.49cifar10:0.2-instance | Epoch [ 18/ 75] Iter[201/1205]	  loss: 0.37cifar10:0.2-instance | Epoch [ 18/ 75] Iter[251/1205]	  loss: 0.39cifar10:0.2-instance | Epoch [ 18/ 75] Iter[301/1205]	  loss: 0.34cifar10:0.2-instance | Epoch [ 18/ 75] Iter[351/1205]	  loss: 0.47cifar10:0.2-instance | Epoch [ 18/ 75] Iter[401/1205]	  loss: 0.53cifar10:0.2-instance | Epoch [ 18/ 75] Iter[451/1205]	  loss: 0.46cifar10:0.2-instance | Epoch [ 18/ 75] Iter[501/1205]	  loss: 0.49cifar10:0.2-instance | Epoch [ 18/ 75] Iter[551/1205]	  loss: 0.59cifar10:0.2-instance | Epoch [ 18/ 75] Iter[601/1205]	  loss: 0.32cifar10:0.2-instance | Epoch [ 18/ 75] Iter[651/1205]	  loss: 0.65cifar10:0.2-instance | Epoch [ 18/ 75] Iter[701/1205]	  loss: 0.46cifar10:0.2-instance | Epoch [ 18/ 75] Iter[751/1205]	  loss: 0.38cifar10:0.2-instance | Epoch [ 18/ 75] Iter[801/1205]	  loss: 0.47cifar10:0.2-instance | Epoch [ 18/ 75] Iter[851/1205]	  loss: 0.36cifar10:0.2-instance | Epoch [ 18/ 75] Iter[901/1205]	  loss: 0.59cifar10:0.2-instance | Epoch [ 18/ 75] Iter[951/1205]	  loss: 0.50cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1001/1205]	  loss: 0.60cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1051/1205]	  loss: 0.35cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1101/1205]	  loss: 0.45cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1151/1205]	  loss: 0.44cifar10:0.2-instance | Epoch [ 18/ 75] Iter[1201/1205]	  loss: 0.33
| Test Epoch 18	 Accuracy: 82.35% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 19 | Accuracy on train set: 69.29% 
labeled data has a size of 38354, f-score: 0.980237
cifar10:0.2-instance | Epoch [ 19/ 75] Iter[  1/1199]	  loss: 0.39cifar10:0.2-instance | Epoch [ 19/ 75] Iter[ 51/1199]	  loss: 0.49cifar10:0.2-instance | Epoch [ 19/ 75] Iter[101/1199]	  loss: 0.44cifar10:0.2-instance | Epoch [ 19/ 75] Iter[151/1199]	  loss: 0.33cifar10:0.2-instance | Epoch [ 19/ 75] Iter[201/1199]	  loss: 0.27cifar10:0.2-instance | Epoch [ 19/ 75] Iter[251/1199]	  loss: 0.33cifar10:0.2-instance | Epoch [ 19/ 75] Iter[301/1199]	  loss: 0.29cifar10:0.2-instance | Epoch [ 19/ 75] Iter[351/1199]	  loss: 0.31cifar10:0.2-instance | Epoch [ 19/ 75] Iter[401/1199]	  loss: 0.24cifar10:0.2-instance | Epoch [ 19/ 75] Iter[451/1199]	  loss: 0.51cifar10:0.2-instance | Epoch [ 19/ 75] Iter[501/1199]	  loss: 0.49cifar10:0.2-instance | Epoch [ 19/ 75] Iter[551/1199]	  loss: 0.36cifar10:0.2-instance | Epoch [ 19/ 75] Iter[601/1199]	  loss: 0.42cifar10:0.2-instance | Epoch [ 19/ 75] Iter[651/1199]	  loss: 0.44cifar10:0.2-instance | Epoch [ 19/ 75] Iter[701/1199]	  loss: 0.42cifar10:0.2-instance | Epoch [ 19/ 75] Iter[751/1199]	  loss: 0.50cifar10:0.2-instance | Epoch [ 19/ 75] Iter[801/1199]	  loss: 0.43cifar10:0.2-instance | Epoch [ 19/ 75] Iter[851/1199]	  loss: 0.39cifar10:0.2-instance | Epoch [ 19/ 75] Iter[901/1199]	  loss: 0.38cifar10:0.2-instance | Epoch [ 19/ 75] Iter[951/1199]	  loss: 0.35cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1001/1199]	  loss: 0.44cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1051/1199]	  loss: 0.58cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1101/1199]	  loss: 0.41cifar10:0.2-instance | Epoch [ 19/ 75] Iter[1151/1199]	  loss: 0.29
| Test Epoch 19	 Accuracy: 83.53% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 20 | Accuracy on train set: 70.26% 
labeled data has a size of 38407, f-score: 0.983102
cifar10:0.2-instance | Epoch [ 20/ 75] Iter[  1/1201]	  loss: 0.37cifar10:0.2-instance | Epoch [ 20/ 75] Iter[ 51/1201]	  loss: 0.57cifar10:0.2-instance | Epoch [ 20/ 75] Iter[101/1201]	  loss: 0.55cifar10:0.2-instance | Epoch [ 20/ 75] Iter[151/1201]	  loss: 0.59cifar10:0.2-instance | Epoch [ 20/ 75] Iter[201/1201]	  loss: 0.44cifar10:0.2-instance | Epoch [ 20/ 75] Iter[251/1201]	  loss: 0.38cifar10:0.2-instance | Epoch [ 20/ 75] Iter[301/1201]	  loss: 0.29cifar10:0.2-instance | Epoch [ 20/ 75] Iter[351/1201]	  loss: 0.43cifar10:0.2-instance | Epoch [ 20/ 75] Iter[401/1201]	  loss: 0.44cifar10:0.2-instance | Epoch [ 20/ 75] Iter[451/1201]	  loss: 0.74cifar10:0.2-instance | Epoch [ 20/ 75] Iter[501/1201]	  loss: 0.38cifar10:0.2-instance | Epoch [ 20/ 75] Iter[551/1201]	  loss: 0.53cifar10:0.2-instance | Epoch [ 20/ 75] Iter[601/1201]	  loss: 0.26cifar10:0.2-instance | Epoch [ 20/ 75] Iter[651/1201]	  loss: 0.43cifar10:0.2-instance | Epoch [ 20/ 75] Iter[701/1201]	  loss: 0.58cifar10:0.2-instance | Epoch [ 20/ 75] Iter[751/1201]	  loss: 0.27cifar10:0.2-instance | Epoch [ 20/ 75] Iter[801/1201]	  loss: 0.54cifar10:0.2-instance | Epoch [ 20/ 75] Iter[851/1201]	  loss: 0.63cifar10:0.2-instance | Epoch [ 20/ 75] Iter[901/1201]	  loss: 0.56cifar10:0.2-instance | Epoch [ 20/ 75] Iter[951/1201]	  loss: 0.34cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1001/1201]	  loss: 0.41cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1051/1201]	  loss: 0.50cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1101/1201]	  loss: 0.31cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1151/1201]	  loss: 0.27cifar10:0.2-instance | Epoch [ 20/ 75] Iter[1201/1201]	  loss: 0.46
| Test Epoch 20	 Accuracy: 84.91% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 21 | Accuracy on train set: 71.09% 
labeled data has a size of 38604, f-score: 0.981764
cifar10:0.2-instance | Epoch [ 21/ 75] Iter[  1/1207]	  loss: 0.41cifar10:0.2-instance | Epoch [ 21/ 75] Iter[ 51/1207]	  loss: 0.44cifar10:0.2-instance | Epoch [ 21/ 75] Iter[101/1207]	  loss: 0.61cifar10:0.2-instance | Epoch [ 21/ 75] Iter[151/1207]	  loss: 0.32cifar10:0.2-instance | Epoch [ 21/ 75] Iter[201/1207]	  loss: 0.59cifar10:0.2-instance | Epoch [ 21/ 75] Iter[251/1207]	  loss: 0.39cifar10:0.2-instance | Epoch [ 21/ 75] Iter[301/1207]	  loss: 0.40cifar10:0.2-instance | Epoch [ 21/ 75] Iter[351/1207]	  loss: 0.28cifar10:0.2-instance | Epoch [ 21/ 75] Iter[401/1207]	  loss: 0.42cifar10:0.2-instance | Epoch [ 21/ 75] Iter[451/1207]	  loss: 0.54cifar10:0.2-instance | Epoch [ 21/ 75] Iter[501/1207]	  loss: 0.44cifar10:0.2-instance | Epoch [ 21/ 75] Iter[551/1207]	  loss: 0.54cifar10:0.2-instance | Epoch [ 21/ 75] Iter[601/1207]	  loss: 0.77cifar10:0.2-instance | Epoch [ 21/ 75] Iter[651/1207]	  loss: 0.55cifar10:0.2-instance | Epoch [ 21/ 75] Iter[701/1207]	  loss: 0.24cifar10:0.2-instance | Epoch [ 21/ 75] Iter[751/1207]	  loss: 0.68cifar10:0.2-instance | Epoch [ 21/ 75] Iter[801/1207]	  loss: 0.40cifar10:0.2-instance | Epoch [ 21/ 75] Iter[851/1207]	  loss: 0.38cifar10:0.2-instance | Epoch [ 21/ 75] Iter[901/1207]	  loss: 0.34cifar10:0.2-instance | Epoch [ 21/ 75] Iter[951/1207]	  loss: 0.53cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1001/1207]	  loss: 0.44cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1051/1207]	  loss: 0.61cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1101/1207]	  loss: 0.40cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1151/1207]	  loss: 0.41cifar10:0.2-instance | Epoch [ 21/ 75] Iter[1201/1207]	  loss: 0.65
| Test Epoch 21	 Accuracy: 84.03% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 22 | Accuracy on train set: 70.78% 
labeled data has a size of 38770, f-score: 0.981919
cifar10:0.2-instance | Epoch [ 22/ 75] Iter[  1/1212]	  loss: 0.27cifar10:0.2-instance | Epoch [ 22/ 75] Iter[ 51/1212]	  loss: 0.33cifar10:0.2-instance | Epoch [ 22/ 75] Iter[101/1212]	  loss: 0.32cifar10:0.2-instance | Epoch [ 22/ 75] Iter[151/1212]	  loss: 0.41cifar10:0.2-instance | Epoch [ 22/ 75] Iter[201/1212]	  loss: 0.36cifar10:0.2-instance | Epoch [ 22/ 75] Iter[251/1212]	  loss: 0.46cifar10:0.2-instance | Epoch [ 22/ 75] Iter[301/1212]	  loss: 0.39cifar10:0.2-instance | Epoch [ 22/ 75] Iter[351/1212]	  loss: 0.59cifar10:0.2-instance | Epoch [ 22/ 75] Iter[401/1212]	  loss: 0.45cifar10:0.2-instance | Epoch [ 22/ 75] Iter[451/1212]	  loss: 0.59cifar10:0.2-instance | Epoch [ 22/ 75] Iter[501/1212]	  loss: 0.36cifar10:0.2-instance | Epoch [ 22/ 75] Iter[551/1212]	  loss: 0.32cifar10:0.2-instance | Epoch [ 22/ 75] Iter[601/1212]	  loss: 0.36cifar10:0.2-instance | Epoch [ 22/ 75] Iter[651/1212]	  loss: 0.46cifar10:0.2-instance | Epoch [ 22/ 75] Iter[701/1212]	  loss: 0.47cifar10:0.2-instance | Epoch [ 22/ 75] Iter[751/1212]	  loss: 0.47cifar10:0.2-instance | Epoch [ 22/ 75] Iter[801/1212]	  loss: 0.32cifar10:0.2-instance | Epoch [ 22/ 75] Iter[851/1212]	  loss: 0.44cifar10:0.2-instance | Epoch [ 22/ 75] Iter[901/1212]	  loss: 0.49cifar10:0.2-instance | Epoch [ 22/ 75] Iter[951/1212]	  loss: 0.35cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1001/1212]	  loss: 0.29cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1051/1212]	  loss: 0.50cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1101/1212]	  loss: 0.31cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1151/1212]	  loss: 0.65cifar10:0.2-instance | Epoch [ 22/ 75] Iter[1201/1212]	  loss: 0.58
| Test Epoch 22	 Accuracy: 83.86% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 23 | Accuracy on train set: 69.81% 
labeled data has a size of 38746, f-score: 0.982553
cifar10:0.2-instance | Epoch [ 23/ 75] Iter[  1/1211]	  loss: 0.50cifar10:0.2-instance | Epoch [ 23/ 75] Iter[ 51/1211]	  loss: 0.54cifar10:0.2-instance | Epoch [ 23/ 75] Iter[101/1211]	  loss: 0.36cifar10:0.2-instance | Epoch [ 23/ 75] Iter[151/1211]	  loss: 0.37cifar10:0.2-instance | Epoch [ 23/ 75] Iter[201/1211]	  loss: 0.35cifar10:0.2-instance | Epoch [ 23/ 75] Iter[251/1211]	  loss: 0.40cifar10:0.2-instance | Epoch [ 23/ 75] Iter[301/1211]	  loss: 0.90cifar10:0.2-instance | Epoch [ 23/ 75] Iter[351/1211]	  loss: 0.38cifar10:0.2-instance | Epoch [ 23/ 75] Iter[401/1211]	  loss: 0.68cifar10:0.2-instance | Epoch [ 23/ 75] Iter[451/1211]	  loss: 0.42cifar10:0.2-instance | Epoch [ 23/ 75] Iter[501/1211]	  loss: 0.34cifar10:0.2-instance | Epoch [ 23/ 75] Iter[551/1211]	  loss: 0.41cifar10:0.2-instance | Epoch [ 23/ 75] Iter[601/1211]	  loss: 0.38cifar10:0.2-instance | Epoch [ 23/ 75] Iter[651/1211]	  loss: 0.46cifar10:0.2-instance | Epoch [ 23/ 75] Iter[701/1211]	  loss: 0.39cifar10:0.2-instance | Epoch [ 23/ 75] Iter[751/1211]	  loss: 0.51cifar10:0.2-instance | Epoch [ 23/ 75] Iter[801/1211]	  loss: 0.32cifar10:0.2-instance | Epoch [ 23/ 75] Iter[851/1211]	  loss: 0.43cifar10:0.2-instance | Epoch [ 23/ 75] Iter[901/1211]	  loss: 0.48cifar10:0.2-instance | Epoch [ 23/ 75] Iter[951/1211]	  loss: 0.25cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1001/1211]	  loss: 0.47cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1051/1211]	  loss: 0.59cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1101/1211]	  loss: 0.42cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1151/1211]	  loss: 0.31cifar10:0.2-instance | Epoch [ 23/ 75] Iter[1201/1211]	  loss: 0.57
| Test Epoch 23	 Accuracy: 83.58% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 24 | Accuracy on train set: 70.17% 
labeled data has a size of 38738, f-score: 0.981181
cifar10:0.2-instance | Epoch [ 24/ 75] Iter[  1/1211]	  loss: 0.45cifar10:0.2-instance | Epoch [ 24/ 75] Iter[ 51/1211]	  loss: 0.53cifar10:0.2-instance | Epoch [ 24/ 75] Iter[101/1211]	  loss: 0.30cifar10:0.2-instance | Epoch [ 24/ 75] Iter[151/1211]	  loss: 0.53cifar10:0.2-instance | Epoch [ 24/ 75] Iter[201/1211]	  loss: 0.35cifar10:0.2-instance | Epoch [ 24/ 75] Iter[251/1211]	  loss: 0.46cifar10:0.2-instance | Epoch [ 24/ 75] Iter[301/1211]	  loss: 0.31cifar10:0.2-instance | Epoch [ 24/ 75] Iter[351/1211]	  loss: 0.47cifar10:0.2-instance | Epoch [ 24/ 75] Iter[401/1211]	  loss: 0.24cifar10:0.2-instance | Epoch [ 24/ 75] Iter[451/1211]	  loss: 0.43cifar10:0.2-instance | Epoch [ 24/ 75] Iter[501/1211]	  loss: 0.52cifar10:0.2-instance | Epoch [ 24/ 75] Iter[551/1211]	  loss: 0.51cifar10:0.2-instance | Epoch [ 24/ 75] Iter[601/1211]	  loss: 0.43cifar10:0.2-instance | Epoch [ 24/ 75] Iter[651/1211]	  loss: 0.72cifar10:0.2-instance | Epoch [ 24/ 75] Iter[701/1211]	  loss: 0.38cifar10:0.2-instance | Epoch [ 24/ 75] Iter[751/1211]	  loss: 0.36cifar10:0.2-instance | Epoch [ 24/ 75] Iter[801/1211]	  loss: 0.36cifar10:0.2-instance | Epoch [ 24/ 75] Iter[851/1211]	  loss: 0.30cifar10:0.2-instance | Epoch [ 24/ 75] Iter[901/1211]	  loss: 0.54cifar10:0.2-instance | Epoch [ 24/ 75] Iter[951/1211]	  loss: 0.42cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1001/1211]	  loss: 0.40cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1051/1211]	  loss: 0.38cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1101/1211]	  loss: 0.44cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1151/1211]	  loss: 0.57cifar10:0.2-instance | Epoch [ 24/ 75] Iter[1201/1211]	  loss: 0.33
| Test Epoch 24	 Accuracy: 81.96% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 25 | Accuracy on train set: 68.84% 
labeled data has a size of 38549, f-score: 0.980285
cifar10:0.2-instance | Epoch [ 25/ 75] Iter[  1/1205]	  loss: 0.42cifar10:0.2-instance | Epoch [ 25/ 75] Iter[ 51/1205]	  loss: 0.37cifar10:0.2-instance | Epoch [ 25/ 75] Iter[101/1205]	  loss: 0.48cifar10:0.2-instance | Epoch [ 25/ 75] Iter[151/1205]	  loss: 0.51cifar10:0.2-instance | Epoch [ 25/ 75] Iter[201/1205]	  loss: 0.38cifar10:0.2-instance | Epoch [ 25/ 75] Iter[251/1205]	  loss: 0.31cifar10:0.2-instance | Epoch [ 25/ 75] Iter[301/1205]	  loss: 0.55cifar10:0.2-instance | Epoch [ 25/ 75] Iter[351/1205]	  loss: 0.55cifar10:0.2-instance | Epoch [ 25/ 75] Iter[401/1205]	  loss: 0.44cifar10:0.2-instance | Epoch [ 25/ 75] Iter[451/1205]	  loss: 0.38cifar10:0.2-instance | Epoch [ 25/ 75] Iter[501/1205]	  loss: 0.32cifar10:0.2-instance | Epoch [ 25/ 75] Iter[551/1205]	  loss: 0.42cifar10:0.2-instance | Epoch [ 25/ 75] Iter[601/1205]	  loss: 0.57cifar10:0.2-instance | Epoch [ 25/ 75] Iter[651/1205]	  loss: 0.35cifar10:0.2-instance | Epoch [ 25/ 75] Iter[701/1205]	  loss: 0.24cifar10:0.2-instance | Epoch [ 25/ 75] Iter[751/1205]	  loss: 0.41cifar10:0.2-instance | Epoch [ 25/ 75] Iter[801/1205]	  loss: 0.44cifar10:0.2-instance | Epoch [ 25/ 75] Iter[851/1205]	  loss: 0.52cifar10:0.2-instance | Epoch [ 25/ 75] Iter[901/1205]	  loss: 0.45cifar10:0.2-instance | Epoch [ 25/ 75] Iter[951/1205]	  loss: 0.65cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1001/1205]	  loss: 0.46cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1051/1205]	  loss: 0.41cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1101/1205]	  loss: 0.31cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1151/1205]	  loss: 0.38cifar10:0.2-instance | Epoch [ 25/ 75] Iter[1201/1205]	  loss: 0.36
| Test Epoch 25	 Accuracy: 84.07% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 26 | Accuracy on train set: 70.63% 
labeled data has a size of 38483, f-score: 0.981212
cifar10:0.2-instance | Epoch [ 26/ 75] Iter[  1/1203]	  loss: 0.45cifar10:0.2-instance | Epoch [ 26/ 75] Iter[ 51/1203]	  loss: 0.39cifar10:0.2-instance | Epoch [ 26/ 75] Iter[101/1203]	  loss: 0.37cifar10:0.2-instance | Epoch [ 26/ 75] Iter[151/1203]	  loss: 0.34cifar10:0.2-instance | Epoch [ 26/ 75] Iter[201/1203]	  loss: 0.60cifar10:0.2-instance | Epoch [ 26/ 75] Iter[251/1203]	  loss: 0.33cifar10:0.2-instance | Epoch [ 26/ 75] Iter[301/1203]	  loss: 0.55cifar10:0.2-instance | Epoch [ 26/ 75] Iter[351/1203]	  loss: 0.39cifar10:0.2-instance | Epoch [ 26/ 75] Iter[401/1203]	  loss: 0.36cifar10:0.2-instance | Epoch [ 26/ 75] Iter[451/1203]	  loss: 0.54cifar10:0.2-instance | Epoch [ 26/ 75] Iter[501/1203]	  loss: 0.53cifar10:0.2-instance | Epoch [ 26/ 75] Iter[551/1203]	  loss: 0.46cifar10:0.2-instance | Epoch [ 26/ 75] Iter[601/1203]	  loss: 0.52cifar10:0.2-instance | Epoch [ 26/ 75] Iter[651/1203]	  loss: 0.48cifar10:0.2-instance | Epoch [ 26/ 75] Iter[701/1203]	  loss: 0.50cifar10:0.2-instance | Epoch [ 26/ 75] Iter[751/1203]	  loss: 0.49cifar10:0.2-instance | Epoch [ 26/ 75] Iter[801/1203]	  loss: 0.61cifar10:0.2-instance | Epoch [ 26/ 75] Iter[851/1203]	  loss: 0.43cifar10:0.2-instance | Epoch [ 26/ 75] Iter[901/1203]	  loss: 0.56cifar10:0.2-instance | Epoch [ 26/ 75] Iter[951/1203]	  loss: 0.36cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1001/1203]	  loss: 0.36cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1051/1203]	  loss: 0.41cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1101/1203]	  loss: 0.52cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1151/1203]	  loss: 0.62cifar10:0.2-instance | Epoch [ 26/ 75] Iter[1201/1203]	  loss: 0.71
| Test Epoch 26	 Accuracy: 85.80% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 27 | Accuracy on train set: 71.44% 
labeled data has a size of 38675, f-score: 0.982728
cifar10:0.2-instance | Epoch [ 27/ 75] Iter[  1/1209]	  loss: 0.45cifar10:0.2-instance | Epoch [ 27/ 75] Iter[ 51/1209]	  loss: 0.42cifar10:0.2-instance | Epoch [ 27/ 75] Iter[101/1209]	  loss: 0.69cifar10:0.2-instance | Epoch [ 27/ 75] Iter[151/1209]	  loss: 0.63cifar10:0.2-instance | Epoch [ 27/ 75] Iter[201/1209]	  loss: 0.39cifar10:0.2-instance | Epoch [ 27/ 75] Iter[251/1209]	  loss: 0.30cifar10:0.2-instance | Epoch [ 27/ 75] Iter[301/1209]	  loss: 0.34cifar10:0.2-instance | Epoch [ 27/ 75] Iter[351/1209]	  loss: 0.38cifar10:0.2-instance | Epoch [ 27/ 75] Iter[401/1209]	  loss: 0.35cifar10:0.2-instance | Epoch [ 27/ 75] Iter[451/1209]	  loss: 0.46cifar10:0.2-instance | Epoch [ 27/ 75] Iter[501/1209]	  loss: 0.44cifar10:0.2-instance | Epoch [ 27/ 75] Iter[551/1209]	  loss: 0.39cifar10:0.2-instance | Epoch [ 27/ 75] Iter[601/1209]	  loss: 0.46cifar10:0.2-instance | Epoch [ 27/ 75] Iter[651/1209]	  loss: 0.41cifar10:0.2-instance | Epoch [ 27/ 75] Iter[701/1209]	  loss: 0.32cifar10:0.2-instance | Epoch [ 27/ 75] Iter[751/1209]	  loss: 0.56cifar10:0.2-instance | Epoch [ 27/ 75] Iter[801/1209]	  loss: 0.38cifar10:0.2-instance | Epoch [ 27/ 75] Iter[851/1209]	  loss: 0.45cifar10:0.2-instance | Epoch [ 27/ 75] Iter[901/1209]	  loss: 0.30cifar10:0.2-instance | Epoch [ 27/ 75] Iter[951/1209]	  loss: 0.33cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1001/1209]	  loss: 0.38cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1051/1209]	  loss: 0.48cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1101/1209]	  loss: 0.64cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1151/1209]	  loss: 0.37cifar10:0.2-instance | Epoch [ 27/ 75] Iter[1201/1209]	  loss: 0.38
| Test Epoch 27	 Accuracy: 84.78% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 28 | Accuracy on train set: 71.05% 
labeled data has a size of 38849, f-score: 0.983011
cifar10:0.2-instance | Epoch [ 28/ 75] Iter[  1/1215]	  loss: 0.44cifar10:0.2-instance | Epoch [ 28/ 75] Iter[ 51/1215]	  loss: 0.35cifar10:0.2-instance | Epoch [ 28/ 75] Iter[101/1215]	  loss: 0.53cifar10:0.2-instance | Epoch [ 28/ 75] Iter[151/1215]	  loss: 0.46cifar10:0.2-instance | Epoch [ 28/ 75] Iter[201/1215]	  loss: 0.27cifar10:0.2-instance | Epoch [ 28/ 75] Iter[251/1215]	  loss: 0.74cifar10:0.2-instance | Epoch [ 28/ 75] Iter[301/1215]	  loss: 0.46cifar10:0.2-instance | Epoch [ 28/ 75] Iter[351/1215]	  loss: 0.66cifar10:0.2-instance | Epoch [ 28/ 75] Iter[401/1215]	  loss: 0.56cifar10:0.2-instance | Epoch [ 28/ 75] Iter[451/1215]	  loss: 0.62cifar10:0.2-instance | Epoch [ 28/ 75] Iter[501/1215]	  loss: 0.68cifar10:0.2-instance | Epoch [ 28/ 75] Iter[551/1215]	  loss: 0.46cifar10:0.2-instance | Epoch [ 28/ 75] Iter[601/1215]	  loss: 0.41cifar10:0.2-instance | Epoch [ 28/ 75] Iter[651/1215]	  loss: 0.38cifar10:0.2-instance | Epoch [ 28/ 75] Iter[701/1215]	  loss: 0.36cifar10:0.2-instance | Epoch [ 28/ 75] Iter[751/1215]	  loss: 0.35cifar10:0.2-instance | Epoch [ 28/ 75] Iter[801/1215]	  loss: 0.32cifar10:0.2-instance | Epoch [ 28/ 75] Iter[851/1215]	  loss: 0.54cifar10:0.2-instance | Epoch [ 28/ 75] Iter[901/1215]	  loss: 0.29cifar10:0.2-instance | Epoch [ 28/ 75] Iter[951/1215]	  loss: 0.45cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1001/1215]	  loss: 0.24cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1051/1215]	  loss: 0.43cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1101/1215]	  loss: 0.41cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1151/1215]	  loss: 0.53cifar10:0.2-instance | Epoch [ 28/ 75] Iter[1201/1215]	  loss: 0.34
| Test Epoch 28	 Accuracy: 82.13% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 29 | Accuracy on train set: 69.57% 
labeled data has a size of 38977, f-score: 0.980168
cifar10:0.2-instance | Epoch [ 29/ 75] Iter[  1/1219]	  loss: 0.36cifar10:0.2-instance | Epoch [ 29/ 75] Iter[ 51/1219]	  loss: 0.42cifar10:0.2-instance | Epoch [ 29/ 75] Iter[101/1219]	  loss: 0.34cifar10:0.2-instance | Epoch [ 29/ 75] Iter[151/1219]	  loss: 0.29cifar10:0.2-instance | Epoch [ 29/ 75] Iter[201/1219]	  loss: 0.57cifar10:0.2-instance | Epoch [ 29/ 75] Iter[251/1219]	  loss: 0.32cifar10:0.2-instance | Epoch [ 29/ 75] Iter[301/1219]	  loss: 0.39cifar10:0.2-instance | Epoch [ 29/ 75] Iter[351/1219]	  loss: 0.41cifar10:0.2-instance | Epoch [ 29/ 75] Iter[401/1219]	  loss: 0.26cifar10:0.2-instance | Epoch [ 29/ 75] Iter[451/1219]	  loss: 0.51cifar10:0.2-instance | Epoch [ 29/ 75] Iter[501/1219]	  loss: 0.43cifar10:0.2-instance | Epoch [ 29/ 75] Iter[551/1219]	  loss: 0.41cifar10:0.2-instance | Epoch [ 29/ 75] Iter[601/1219]	  loss: 0.58cifar10:0.2-instance | Epoch [ 29/ 75] Iter[651/1219]	  loss: 0.58cifar10:0.2-instance | Epoch [ 29/ 75] Iter[701/1219]	  loss: 0.25cifar10:0.2-instance | Epoch [ 29/ 75] Iter[751/1219]	  loss: 0.57cifar10:0.2-instance | Epoch [ 29/ 75] Iter[801/1219]	  loss: 0.61cifar10:0.2-instance | Epoch [ 29/ 75] Iter[851/1219]	  loss: 0.33cifar10:0.2-instance | Epoch [ 29/ 75] Iter[901/1219]	  loss: 0.40cifar10:0.2-instance | Epoch [ 29/ 75] Iter[951/1219]	  loss: 0.26cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1001/1219]	  loss: 0.42cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1051/1219]	  loss: 0.42cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1101/1219]	  loss: 0.37cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1151/1219]	  loss: 0.38cifar10:0.2-instance | Epoch [ 29/ 75] Iter[1201/1219]	  loss: 0.31
| Test Epoch 29	 Accuracy: 84.25% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 30 | Accuracy on train set: 70.86% 
labeled data has a size of 38926, f-score: 0.980142
cifar10:0.2-instance | Epoch [ 30/ 75] Iter[  1/1217]	  loss: 0.32cifar10:0.2-instance | Epoch [ 30/ 75] Iter[ 51/1217]	  loss: 0.42cifar10:0.2-instance | Epoch [ 30/ 75] Iter[101/1217]	  loss: 0.68cifar10:0.2-instance | Epoch [ 30/ 75] Iter[151/1217]	  loss: 0.36cifar10:0.2-instance | Epoch [ 30/ 75] Iter[201/1217]	  loss: 0.48cifar10:0.2-instance | Epoch [ 30/ 75] Iter[251/1217]	  loss: 0.55cifar10:0.2-instance | Epoch [ 30/ 75] Iter[301/1217]	  loss: 0.32cifar10:0.2-instance | Epoch [ 30/ 75] Iter[351/1217]	  loss: 0.48cifar10:0.2-instance | Epoch [ 30/ 75] Iter[401/1217]	  loss: 0.57cifar10:0.2-instance | Epoch [ 30/ 75] Iter[451/1217]	  loss: 0.38cifar10:0.2-instance | Epoch [ 30/ 75] Iter[501/1217]	  loss: 0.33cifar10:0.2-instance | Epoch [ 30/ 75] Iter[551/1217]	  loss: 0.56cifar10:0.2-instance | Epoch [ 30/ 75] Iter[601/1217]	  loss: 0.33cifar10:0.2-instance | Epoch [ 30/ 75] Iter[651/1217]	  loss: 0.57cifar10:0.2-instance | Epoch [ 30/ 75] Iter[701/1217]	  loss: 0.47cifar10:0.2-instance | Epoch [ 30/ 75] Iter[751/1217]	  loss: 0.54cifar10:0.2-instance | Epoch [ 30/ 75] Iter[801/1217]	  loss: 0.40cifar10:0.2-instance | Epoch [ 30/ 75] Iter[851/1217]	  loss: 0.35cifar10:0.2-instance | Epoch [ 30/ 75] Iter[901/1217]	  loss: 0.32cifar10:0.2-instance | Epoch [ 30/ 75] Iter[951/1217]	  loss: 0.41cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1001/1217]	  loss: 0.51cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1051/1217]	  loss: 0.53cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1101/1217]	  loss: 0.44cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1151/1217]	  loss: 0.81cifar10:0.2-instance | Epoch [ 30/ 75] Iter[1201/1217]	  loss: 0.49
| Test Epoch 30	 Accuracy: 83.75% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 31 | Accuracy on train set: 70.17% 
labeled data has a size of 39028, f-score: 0.979169
cifar10:0.2-instance | Epoch [ 31/ 75] Iter[  1/1220]	  loss: 0.59cifar10:0.2-instance | Epoch [ 31/ 75] Iter[ 51/1220]	  loss: 0.44cifar10:0.2-instance | Epoch [ 31/ 75] Iter[101/1220]	  loss: 0.55cifar10:0.2-instance | Epoch [ 31/ 75] Iter[151/1220]	  loss: 0.44cifar10:0.2-instance | Epoch [ 31/ 75] Iter[201/1220]	  loss: 0.58cifar10:0.2-instance | Epoch [ 31/ 75] Iter[251/1220]	  loss: 0.38cifar10:0.2-instance | Epoch [ 31/ 75] Iter[301/1220]	  loss: 0.61cifar10:0.2-instance | Epoch [ 31/ 75] Iter[351/1220]	  loss: 0.55cifar10:0.2-instance | Epoch [ 31/ 75] Iter[401/1220]	  loss: 0.36cifar10:0.2-instance | Epoch [ 31/ 75] Iter[451/1220]	  loss: 0.27cifar10:0.2-instance | Epoch [ 31/ 75] Iter[501/1220]	  loss: 0.33cifar10:0.2-instance | Epoch [ 31/ 75] Iter[551/1220]	  loss: 0.71cifar10:0.2-instance | Epoch [ 31/ 75] Iter[601/1220]	  loss: 0.46cifar10:0.2-instance | Epoch [ 31/ 75] Iter[651/1220]	  loss: 0.25cifar10:0.2-instance | Epoch [ 31/ 75] Iter[701/1220]	  loss: 0.33cifar10:0.2-instance | Epoch [ 31/ 75] Iter[751/1220]	  loss: 0.38cifar10:0.2-instance | Epoch [ 31/ 75] Iter[801/1220]	  loss: 0.34cifar10:0.2-instance | Epoch [ 31/ 75] Iter[851/1220]	  loss: 0.36cifar10:0.2-instance | Epoch [ 31/ 75] Iter[901/1220]	  loss: 0.53cifar10:0.2-instance | Epoch [ 31/ 75] Iter[951/1220]	  loss: 0.25cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1001/1220]	  loss: 0.48cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1051/1220]	  loss: 0.34cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1101/1220]	  loss: 0.37cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1151/1220]	  loss: 0.44cifar10:0.2-instance | Epoch [ 31/ 75] Iter[1201/1220]	  loss: 0.35
| Test Epoch 31	 Accuracy: 84.46% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 32 | Accuracy on train set: 71.10% 
labeled data has a size of 38923, f-score: 0.981990
cifar10:0.2-instance | Epoch [ 32/ 75] Iter[  1/1217]	  loss: 0.32cifar10:0.2-instance | Epoch [ 32/ 75] Iter[ 51/1217]	  loss: 0.26cifar10:0.2-instance | Epoch [ 32/ 75] Iter[101/1217]	  loss: 0.40cifar10:0.2-instance | Epoch [ 32/ 75] Iter[151/1217]	  loss: 0.47cifar10:0.2-instance | Epoch [ 32/ 75] Iter[201/1217]	  loss: 0.40cifar10:0.2-instance | Epoch [ 32/ 75] Iter[251/1217]	  loss: 0.38cifar10:0.2-instance | Epoch [ 32/ 75] Iter[301/1217]	  loss: 0.44cifar10:0.2-instance | Epoch [ 32/ 75] Iter[351/1217]	  loss: 0.38cifar10:0.2-instance | Epoch [ 32/ 75] Iter[401/1217]	  loss: 0.30cifar10:0.2-instance | Epoch [ 32/ 75] Iter[451/1217]	  loss: 0.27cifar10:0.2-instance | Epoch [ 32/ 75] Iter[501/1217]	  loss: 0.48cifar10:0.2-instance | Epoch [ 32/ 75] Iter[551/1217]	  loss: 0.51cifar10:0.2-instance | Epoch [ 32/ 75] Iter[601/1217]	  loss: 0.38cifar10:0.2-instance | Epoch [ 32/ 75] Iter[651/1217]	  loss: 0.41cifar10:0.2-instance | Epoch [ 32/ 75] Iter[701/1217]	  loss: 0.48cifar10:0.2-instance | Epoch [ 32/ 75] Iter[751/1217]	  loss: 0.51cifar10:0.2-instance | Epoch [ 32/ 75] Iter[801/1217]	  loss: 0.28cifar10:0.2-instance | Epoch [ 32/ 75] Iter[851/1217]	  loss: 0.31cifar10:0.2-instance | Epoch [ 32/ 75] Iter[901/1217]	  loss: 0.41cifar10:0.2-instance | Epoch [ 32/ 75] Iter[951/1217]	  loss: 0.34cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1001/1217]	  loss: 0.64cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1051/1217]	  loss: 0.31cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1101/1217]	  loss: 0.34cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1151/1217]	  loss: 0.61cifar10:0.2-instance | Epoch [ 32/ 75] Iter[1201/1217]	  loss: 0.61
| Test Epoch 32	 Accuracy: 83.11% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 33 | Accuracy on train set: 69.50% 
labeled data has a size of 38976, f-score: 0.981424
cifar10:0.2-instance | Epoch [ 33/ 75] Iter[  1/1219]	  loss: 0.40cifar10:0.2-instance | Epoch [ 33/ 75] Iter[ 51/1219]	  loss: 0.50cifar10:0.2-instance | Epoch [ 33/ 75] Iter[101/1219]	  loss: 0.60cifar10:0.2-instance | Epoch [ 33/ 75] Iter[151/1219]	  loss: 0.37cifar10:0.2-instance | Epoch [ 33/ 75] Iter[201/1219]	  loss: 0.51cifar10:0.2-instance | Epoch [ 33/ 75] Iter[251/1219]	  loss: 0.37cifar10:0.2-instance | Epoch [ 33/ 75] Iter[301/1219]	  loss: 0.39cifar10:0.2-instance | Epoch [ 33/ 75] Iter[351/1219]	  loss: 0.33cifar10:0.2-instance | Epoch [ 33/ 75] Iter[401/1219]	  loss: 0.34cifar10:0.2-instance | Epoch [ 33/ 75] Iter[451/1219]	  loss: 0.37cifar10:0.2-instance | Epoch [ 33/ 75] Iter[501/1219]	  loss: 0.47cifar10:0.2-instance | Epoch [ 33/ 75] Iter[551/1219]	  loss: 0.22cifar10:0.2-instance | Epoch [ 33/ 75] Iter[601/1219]	  loss: 0.67cifar10:0.2-instance | Epoch [ 33/ 75] Iter[651/1219]	  loss: 0.43cifar10:0.2-instance | Epoch [ 33/ 75] Iter[701/1219]	  loss: 0.38cifar10:0.2-instance | Epoch [ 33/ 75] Iter[751/1219]	  loss: 0.24cifar10:0.2-instance | Epoch [ 33/ 75] Iter[801/1219]	  loss: 0.23cifar10:0.2-instance | Epoch [ 33/ 75] Iter[851/1219]	  loss: 0.27cifar10:0.2-instance | Epoch [ 33/ 75] Iter[901/1219]	  loss: 0.45cifar10:0.2-instance | Epoch [ 33/ 75] Iter[951/1219]	  loss: 0.29cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1001/1219]	  loss: 0.51cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1051/1219]	  loss: 0.47cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1101/1219]	  loss: 0.39cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1151/1219]	  loss: 0.45cifar10:0.2-instance | Epoch [ 33/ 75] Iter[1201/1219]	  loss: 0.48
| Test Epoch 33	 Accuracy: 85.02% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 34 | Accuracy on train set: 71.43% 
labeled data has a size of 38779, f-score: 0.983496
cifar10:0.2-instance | Epoch [ 34/ 75] Iter[  1/1212]	  loss: 0.52cifar10:0.2-instance | Epoch [ 34/ 75] Iter[ 51/1212]	  loss: 0.51cifar10:0.2-instance | Epoch [ 34/ 75] Iter[101/1212]	  loss: 0.27cifar10:0.2-instance | Epoch [ 34/ 75] Iter[151/1212]	  loss: 0.38cifar10:0.2-instance | Epoch [ 34/ 75] Iter[201/1212]	  loss: 0.32cifar10:0.2-instance | Epoch [ 34/ 75] Iter[251/1212]	  loss: 0.30cifar10:0.2-instance | Epoch [ 34/ 75] Iter[301/1212]	  loss: 0.33cifar10:0.2-instance | Epoch [ 34/ 75] Iter[351/1212]	  loss: 0.47cifar10:0.2-instance | Epoch [ 34/ 75] Iter[401/1212]	  loss: 0.32cifar10:0.2-instance | Epoch [ 34/ 75] Iter[451/1212]	  loss: 0.55cifar10:0.2-instance | Epoch [ 34/ 75] Iter[501/1212]	  loss: 0.34cifar10:0.2-instance | Epoch [ 34/ 75] Iter[551/1212]	  loss: 0.44cifar10:0.2-instance | Epoch [ 34/ 75] Iter[601/1212]	  loss: 0.46cifar10:0.2-instance | Epoch [ 34/ 75] Iter[651/1212]	  loss: 0.55cifar10:0.2-instance | Epoch [ 34/ 75] Iter[701/1212]	  loss: 0.31cifar10:0.2-instance | Epoch [ 34/ 75] Iter[751/1212]	  loss: 0.41cifar10:0.2-instance | Epoch [ 34/ 75] Iter[801/1212]	  loss: 0.33cifar10:0.2-instance | Epoch [ 34/ 75] Iter[851/1212]	  loss: 0.58cifar10:0.2-instance | Epoch [ 34/ 75] Iter[901/1212]	  loss: 0.28cifar10:0.2-instance | Epoch [ 34/ 75] Iter[951/1212]	  loss: 0.37cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1001/1212]	  loss: 0.39cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1051/1212]	  loss: 0.34cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1101/1212]	  loss: 0.37cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1151/1212]	  loss: 0.43cifar10:0.2-instance | Epoch [ 34/ 75] Iter[1201/1212]	  loss: 0.39
| Test Epoch 34	 Accuracy: 84.94% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 35 | Accuracy on train set: 71.53% 
labeled data has a size of 38895, f-score: 0.982286
cifar10:0.2-instance | Epoch [ 35/ 75] Iter[  1/1216]	  loss: 0.44cifar10:0.2-instance | Epoch [ 35/ 75] Iter[ 51/1216]	  loss: 0.31cifar10:0.2-instance | Epoch [ 35/ 75] Iter[101/1216]	  loss: 0.46cifar10:0.2-instance | Epoch [ 35/ 75] Iter[151/1216]	  loss: 0.24cifar10:0.2-instance | Epoch [ 35/ 75] Iter[201/1216]	  loss: 0.31cifar10:0.2-instance | Epoch [ 35/ 75] Iter[251/1216]	  loss: 0.38cifar10:0.2-instance | Epoch [ 35/ 75] Iter[301/1216]	  loss: 0.40cifar10:0.2-instance | Epoch [ 35/ 75] Iter[351/1216]	  loss: 0.56cifar10:0.2-instance | Epoch [ 35/ 75] Iter[401/1216]	  loss: 0.29cifar10:0.2-instance | Epoch [ 35/ 75] Iter[451/1216]	  loss: 0.37cifar10:0.2-instance | Epoch [ 35/ 75] Iter[501/1216]	  loss: 0.93cifar10:0.2-instance | Epoch [ 35/ 75] Iter[551/1216]	  loss: 0.37cifar10:0.2-instance | Epoch [ 35/ 75] Iter[601/1216]	  loss: 0.32cifar10:0.2-instance | Epoch [ 35/ 75] Iter[651/1216]	  loss: 0.47cifar10:0.2-instance | Epoch [ 35/ 75] Iter[701/1216]	  loss: 0.36cifar10:0.2-instance | Epoch [ 35/ 75] Iter[751/1216]	  loss: 0.30cifar10:0.2-instance | Epoch [ 35/ 75] Iter[801/1216]	  loss: 0.62cifar10:0.2-instance | Epoch [ 35/ 75] Iter[851/1216]	  loss: 0.42cifar10:0.2-instance | Epoch [ 35/ 75] Iter[901/1216]	  loss: 0.38cifar10:0.2-instance | Epoch [ 35/ 75] Iter[951/1216]	  loss: 0.65cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1001/1216]	  loss: 0.33cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1051/1216]	  loss: 0.58cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1101/1216]	  loss: 0.46cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1151/1216]	  loss: 0.50cifar10:0.2-instance | Epoch [ 35/ 75] Iter[1201/1216]	  loss: 0.26
| Test Epoch 35	 Accuracy: 83.78% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 36 | Accuracy on train set: 71.36% 
labeled data has a size of 39185, f-score: 0.978206
cifar10:0.2-instance | Epoch [ 36/ 75] Iter[  1/1225]	  loss: 0.53cifar10:0.2-instance | Epoch [ 36/ 75] Iter[ 51/1225]	  loss: 0.24cifar10:0.2-instance | Epoch [ 36/ 75] Iter[101/1225]	  loss: 0.53cifar10:0.2-instance | Epoch [ 36/ 75] Iter[151/1225]	  loss: 0.32cifar10:0.2-instance | Epoch [ 36/ 75] Iter[201/1225]	  loss: 0.56cifar10:0.2-instance | Epoch [ 36/ 75] Iter[251/1225]	  loss: 0.35cifar10:0.2-instance | Epoch [ 36/ 75] Iter[301/1225]	  loss: 0.43cifar10:0.2-instance | Epoch [ 36/ 75] Iter[351/1225]	  loss: 0.63cifar10:0.2-instance | Epoch [ 36/ 75] Iter[401/1225]	  loss: 0.33cifar10:0.2-instance | Epoch [ 36/ 75] Iter[451/1225]	  loss: 0.43cifar10:0.2-instance | Epoch [ 36/ 75] Iter[501/1225]	  loss: 0.22cifar10:0.2-instance | Epoch [ 36/ 75] Iter[551/1225]	  loss: 0.30cifar10:0.2-instance | Epoch [ 36/ 75] Iter[601/1225]	  loss: 0.75cifar10:0.2-instance | Epoch [ 36/ 75] Iter[651/1225]	  loss: 0.40cifar10:0.2-instance | Epoch [ 36/ 75] Iter[701/1225]	  loss: 0.38cifar10:0.2-instance | Epoch [ 36/ 75] Iter[751/1225]	  loss: 0.33cifar10:0.2-instance | Epoch [ 36/ 75] Iter[801/1225]	  loss: 0.41cifar10:0.2-instance | Epoch [ 36/ 75] Iter[851/1225]	  loss: 0.39cifar10:0.2-instance | Epoch [ 36/ 75] Iter[901/1225]	  loss: 0.36cifar10:0.2-instance | Epoch [ 36/ 75] Iter[951/1225]	  loss: 0.36cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1001/1225]	  loss: 0.40cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1051/1225]	  loss: 0.61cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1101/1225]	  loss: 0.33cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1151/1225]	  loss: 0.40cifar10:0.2-instance | Epoch [ 36/ 75] Iter[1201/1225]	  loss: 0.43
| Test Epoch 36	 Accuracy: 83.12% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 37 | Accuracy on train set: 70.34% 
labeled data has a size of 39155, f-score: 0.977091
cifar10:0.2-instance | Epoch [ 37/ 75] Iter[  1/1224]	  loss: 0.22cifar10:0.2-instance | Epoch [ 37/ 75] Iter[ 51/1224]	  loss: 0.38cifar10:0.2-instance | Epoch [ 37/ 75] Iter[101/1224]	  loss: 0.40cifar10:0.2-instance | Epoch [ 37/ 75] Iter[151/1224]	  loss: 0.33cifar10:0.2-instance | Epoch [ 37/ 75] Iter[201/1224]	  loss: 0.58cifar10:0.2-instance | Epoch [ 37/ 75] Iter[251/1224]	  loss: 0.50cifar10:0.2-instance | Epoch [ 37/ 75] Iter[301/1224]	  loss: 0.30cifar10:0.2-instance | Epoch [ 37/ 75] Iter[351/1224]	  loss: 0.40cifar10:0.2-instance | Epoch [ 37/ 75] Iter[401/1224]	  loss: 0.39cifar10:0.2-instance | Epoch [ 37/ 75] Iter[451/1224]	  loss: 0.69cifar10:0.2-instance | Epoch [ 37/ 75] Iter[501/1224]	  loss: 0.39cifar10:0.2-instance | Epoch [ 37/ 75] Iter[551/1224]	  loss: 0.45cifar10:0.2-instance | Epoch [ 37/ 75] Iter[601/1224]	  loss: 0.42cifar10:0.2-instance | Epoch [ 37/ 75] Iter[651/1224]	  loss: 0.50cifar10:0.2-instance | Epoch [ 37/ 75] Iter[701/1224]	  loss: 0.45cifar10:0.2-instance | Epoch [ 37/ 75] Iter[751/1224]	  loss: 0.44cifar10:0.2-instance | Epoch [ 37/ 75] Iter[801/1224]	  loss: 0.78cifar10:0.2-instance | Epoch [ 37/ 75] Iter[851/1224]	  loss: 0.22cifar10:0.2-instance | Epoch [ 37/ 75] Iter[901/1224]	  loss: 0.41cifar10:0.2-instance | Epoch [ 37/ 75] Iter[951/1224]	  loss: 0.59cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1001/1224]	  loss: 0.24cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1051/1224]	  loss: 0.36cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1101/1224]	  loss: 0.60cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1151/1224]	  loss: 0.34cifar10:0.2-instance | Epoch [ 37/ 75] Iter[1201/1224]	  loss: 0.37
| Test Epoch 37	 Accuracy: 84.73% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 38 | Accuracy on train set: 71.05% 
labeled data has a size of 39260, f-score: 0.977178
cifar10:0.2-instance | Epoch [ 38/ 75] Iter[  1/1227]	  loss: 0.32cifar10:0.2-instance | Epoch [ 38/ 75] Iter[ 51/1227]	  loss: 0.17cifar10:0.2-instance | Epoch [ 38/ 75] Iter[101/1227]	  loss: 0.28cifar10:0.2-instance | Epoch [ 38/ 75] Iter[151/1227]	  loss: 0.43cifar10:0.2-instance | Epoch [ 38/ 75] Iter[201/1227]	  loss: 0.37cifar10:0.2-instance | Epoch [ 38/ 75] Iter[251/1227]	  loss: 0.35cifar10:0.2-instance | Epoch [ 38/ 75] Iter[301/1227]	  loss: 0.39cifar10:0.2-instance | Epoch [ 38/ 75] Iter[351/1227]	  loss: 0.55cifar10:0.2-instance | Epoch [ 38/ 75] Iter[401/1227]	  loss: 0.53cifar10:0.2-instance | Epoch [ 38/ 75] Iter[451/1227]	  loss: 0.37cifar10:0.2-instance | Epoch [ 38/ 75] Iter[501/1227]	  loss: 0.36cifar10:0.2-instance | Epoch [ 38/ 75] Iter[551/1227]	  loss: 0.72cifar10:0.2-instance | Epoch [ 38/ 75] Iter[601/1227]	  loss: 0.40cifar10:0.2-instance | Epoch [ 38/ 75] Iter[651/1227]	  loss: 0.33cifar10:0.2-instance | Epoch [ 38/ 75] Iter[701/1227]	  loss: 0.58cifar10:0.2-instance | Epoch [ 38/ 75] Iter[751/1227]	  loss: 0.49cifar10:0.2-instance | Epoch [ 38/ 75] Iter[801/1227]	  loss: 0.38cifar10:0.2-instance | Epoch [ 38/ 75] Iter[851/1227]	  loss: 0.40cifar10:0.2-instance | Epoch [ 38/ 75] Iter[901/1227]	  loss: 0.39cifar10:0.2-instance | Epoch [ 38/ 75] Iter[951/1227]	  loss: 0.30cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1001/1227]	  loss: 0.48cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1051/1227]	  loss: 0.36cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1101/1227]	  loss: 0.54cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1151/1227]	  loss: 0.36cifar10:0.2-instance | Epoch [ 38/ 75] Iter[1201/1227]	  loss: 0.33
| Test Epoch 38	 Accuracy: 82.55% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 39 | Accuracy on train set: 68.84% 
labeled data has a size of 39176, f-score: 0.979681
cifar10:0.2-instance | Epoch [ 39/ 75] Iter[  1/1225]	  loss: 0.56cifar10:0.2-instance | Epoch [ 39/ 75] Iter[ 51/1225]	  loss: 0.24cifar10:0.2-instance | Epoch [ 39/ 75] Iter[101/1225]	  loss: 0.38cifar10:0.2-instance | Epoch [ 39/ 75] Iter[151/1225]	  loss: 0.74cifar10:0.2-instance | Epoch [ 39/ 75] Iter[201/1225]	  loss: 0.36cifar10:0.2-instance | Epoch [ 39/ 75] Iter[251/1225]	  loss: 0.44cifar10:0.2-instance | Epoch [ 39/ 75] Iter[301/1225]	  loss: 0.39cifar10:0.2-instance | Epoch [ 39/ 75] Iter[351/1225]	  loss: 0.46cifar10:0.2-instance | Epoch [ 39/ 75] Iter[401/1225]	  loss: 0.56cifar10:0.2-instance | Epoch [ 39/ 75] Iter[451/1225]	  loss: 0.42cifar10:0.2-instance | Epoch [ 39/ 75] Iter[501/1225]	  loss: 0.32cifar10:0.2-instance | Epoch [ 39/ 75] Iter[551/1225]	  loss: 0.56cifar10:0.2-instance | Epoch [ 39/ 75] Iter[601/1225]	  loss: 0.55cifar10:0.2-instance | Epoch [ 39/ 75] Iter[651/1225]	  loss: 0.44cifar10:0.2-instance | Epoch [ 39/ 75] Iter[701/1225]	  loss: 0.49cifar10:0.2-instance | Epoch [ 39/ 75] Iter[751/1225]	  loss: 0.40cifar10:0.2-instance | Epoch [ 39/ 75] Iter[801/1225]	  loss: 0.47cifar10:0.2-instance | Epoch [ 39/ 75] Iter[851/1225]	  loss: 0.70cifar10:0.2-instance | Epoch [ 39/ 75] Iter[901/1225]	  loss: 0.43cifar10:0.2-instance | Epoch [ 39/ 75] Iter[951/1225]	  loss: 0.45cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1001/1225]	  loss: 0.37cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1051/1225]	  loss: 0.32cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1101/1225]	  loss: 0.63cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1151/1225]	  loss: 0.35cifar10:0.2-instance | Epoch [ 39/ 75] Iter[1201/1225]	  loss: 0.42
| Test Epoch 39	 Accuracy: 77.40% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 40 | Accuracy on train set: 65.53% 
labeled data has a size of 39256, f-score: 0.977838
cifar10:0.2-instance | Epoch [ 40/ 75] Iter[  1/1227]	  loss: 0.38cifar10:0.2-instance | Epoch [ 40/ 75] Iter[ 51/1227]	  loss: 0.47cifar10:0.2-instance | Epoch [ 40/ 75] Iter[101/1227]	  loss: 0.53cifar10:0.2-instance | Epoch [ 40/ 75] Iter[151/1227]	  loss: 0.61cifar10:0.2-instance | Epoch [ 40/ 75] Iter[201/1227]	  loss: 0.29cifar10:0.2-instance | Epoch [ 40/ 75] Iter[251/1227]	  loss: 1.00cifar10:0.2-instance | Epoch [ 40/ 75] Iter[301/1227]	  loss: 0.22cifar10:0.2-instance | Epoch [ 40/ 75] Iter[351/1227]	  loss: 0.39cifar10:0.2-instance | Epoch [ 40/ 75] Iter[401/1227]	  loss: 0.57cifar10:0.2-instance | Epoch [ 40/ 75] Iter[451/1227]	  loss: 0.34cifar10:0.2-instance | Epoch [ 40/ 75] Iter[501/1227]	  loss: 0.37cifar10:0.2-instance | Epoch [ 40/ 75] Iter[551/1227]	  loss: 0.28cifar10:0.2-instance | Epoch [ 40/ 75] Iter[601/1227]	  loss: 0.36cifar10:0.2-instance | Epoch [ 40/ 75] Iter[651/1227]	  loss: 0.41cifar10:0.2-instance | Epoch [ 40/ 75] Iter[701/1227]	  loss: 0.39cifar10:0.2-instance | Epoch [ 40/ 75] Iter[751/1227]	  loss: 0.45cifar10:0.2-instance | Epoch [ 40/ 75] Iter[801/1227]	  loss: 0.79cifar10:0.2-instance | Epoch [ 40/ 75] Iter[851/1227]	  loss: 0.33cifar10:0.2-instance | Epoch [ 40/ 75] Iter[901/1227]	  loss: 0.38cifar10:0.2-instance | Epoch [ 40/ 75] Iter[951/1227]	  loss: 0.49cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1001/1227]	  loss: 0.36cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1051/1227]	  loss: 0.56cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1101/1227]	  loss: 0.60cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1151/1227]	  loss: 0.39cifar10:0.2-instance | Epoch [ 40/ 75] Iter[1201/1227]	  loss: 0.54
| Test Epoch 40	 Accuracy: 85.55% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 41 | Accuracy on train set: 71.99% 
labeled data has a size of 39354, f-score: 0.978528
cifar10:0.2-instance | Epoch [ 41/ 75] Iter[  1/1230]	  loss: 0.39cifar10:0.2-instance | Epoch [ 41/ 75] Iter[ 51/1230]	  loss: 0.33cifar10:0.2-instance | Epoch [ 41/ 75] Iter[101/1230]	  loss: 0.44cifar10:0.2-instance | Epoch [ 41/ 75] Iter[151/1230]	  loss: 0.37cifar10:0.2-instance | Epoch [ 41/ 75] Iter[201/1230]	  loss: 0.31cifar10:0.2-instance | Epoch [ 41/ 75] Iter[251/1230]	  loss: 0.59cifar10:0.2-instance | Epoch [ 41/ 75] Iter[301/1230]	  loss: 0.29cifar10:0.2-instance | Epoch [ 41/ 75] Iter[351/1230]	  loss: 0.60cifar10:0.2-instance | Epoch [ 41/ 75] Iter[401/1230]	  loss: 0.48cifar10:0.2-instance | Epoch [ 41/ 75] Iter[451/1230]	  loss: 0.31cifar10:0.2-instance | Epoch [ 41/ 75] Iter[501/1230]	  loss: 0.36cifar10:0.2-instance | Epoch [ 41/ 75] Iter[551/1230]	  loss: 0.36cifar10:0.2-instance | Epoch [ 41/ 75] Iter[601/1230]	  loss: 0.41cifar10:0.2-instance | Epoch [ 41/ 75] Iter[651/1230]	  loss: 0.52cifar10:0.2-instance | Epoch [ 41/ 75] Iter[701/1230]	  loss: 0.80cifar10:0.2-instance | Epoch [ 41/ 75] Iter[751/1230]	  loss: 0.36cifar10:0.2-instance | Epoch [ 41/ 75] Iter[801/1230]	  loss: 0.51cifar10:0.2-instance | Epoch [ 41/ 75] Iter[851/1230]	  loss: 0.38cifar10:0.2-instance | Epoch [ 41/ 75] Iter[901/1230]	  loss: 0.49cifar10:0.2-instance | Epoch [ 41/ 75] Iter[951/1230]	  loss: 0.49cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1001/1230]	  loss: 0.36cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1051/1230]	  loss: 0.33cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1101/1230]	  loss: 0.52cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1151/1230]	  loss: 0.31cifar10:0.2-instance | Epoch [ 41/ 75] Iter[1201/1230]	  loss: 0.53
| Test Epoch 41	 Accuracy: 84.66% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 42 | Accuracy on train set: 71.70% 
labeled data has a size of 39102, f-score: 0.977546
cifar10:0.2-instance | Epoch [ 42/ 75] Iter[  1/1222]	  loss: 0.47cifar10:0.2-instance | Epoch [ 42/ 75] Iter[ 51/1222]	  loss: 0.29cifar10:0.2-instance | Epoch [ 42/ 75] Iter[101/1222]	  loss: 0.48cifar10:0.2-instance | Epoch [ 42/ 75] Iter[151/1222]	  loss: 0.46cifar10:0.2-instance | Epoch [ 42/ 75] Iter[201/1222]	  loss: 0.40cifar10:0.2-instance | Epoch [ 42/ 75] Iter[251/1222]	  loss: 0.51cifar10:0.2-instance | Epoch [ 42/ 75] Iter[301/1222]	  loss: 0.41cifar10:0.2-instance | Epoch [ 42/ 75] Iter[351/1222]	  loss: 0.30cifar10:0.2-instance | Epoch [ 42/ 75] Iter[401/1222]	  loss: 0.49cifar10:0.2-instance | Epoch [ 42/ 75] Iter[451/1222]	  loss: 0.30cifar10:0.2-instance | Epoch [ 42/ 75] Iter[501/1222]	  loss: 0.37cifar10:0.2-instance | Epoch [ 42/ 75] Iter[551/1222]	  loss: 0.29cifar10:0.2-instance | Epoch [ 42/ 75] Iter[601/1222]	  loss: 0.28cifar10:0.2-instance | Epoch [ 42/ 75] Iter[651/1222]	  loss: 0.23cifar10:0.2-instance | Epoch [ 42/ 75] Iter[701/1222]	  loss: 0.39cifar10:0.2-instance | Epoch [ 42/ 75] Iter[751/1222]	  loss: 0.32cifar10:0.2-instance | Epoch [ 42/ 75] Iter[801/1222]	  loss: 0.39cifar10:0.2-instance | Epoch [ 42/ 75] Iter[851/1222]	  loss: 0.42cifar10:0.2-instance | Epoch [ 42/ 75] Iter[901/1222]	  loss: 0.73cifar10:0.2-instance | Epoch [ 42/ 75] Iter[951/1222]	  loss: 0.42cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1001/1222]	  loss: 0.54cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1051/1222]	  loss: 0.27cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1101/1222]	  loss: 0.40cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1151/1222]	  loss: 0.36cifar10:0.2-instance | Epoch [ 42/ 75] Iter[1201/1222]	  loss: 0.36
| Test Epoch 42	 Accuracy: 85.39% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 43 | Accuracy on train set: 72.07% 
labeled data has a size of 39159, f-score: 0.979775
cifar10:0.2-instance | Epoch [ 43/ 75] Iter[  1/1224]	  loss: 0.36cifar10:0.2-instance | Epoch [ 43/ 75] Iter[ 51/1224]	  loss: 0.41cifar10:0.2-instance | Epoch [ 43/ 75] Iter[101/1224]	  loss: 0.39cifar10:0.2-instance | Epoch [ 43/ 75] Iter[151/1224]	  loss: 0.48cifar10:0.2-instance | Epoch [ 43/ 75] Iter[201/1224]	  loss: 0.24cifar10:0.2-instance | Epoch [ 43/ 75] Iter[251/1224]	  loss: 0.43cifar10:0.2-instance | Epoch [ 43/ 75] Iter[301/1224]	  loss: 0.42cifar10:0.2-instance | Epoch [ 43/ 75] Iter[351/1224]	  loss: 0.28cifar10:0.2-instance | Epoch [ 43/ 75] Iter[401/1224]	  loss: 0.29cifar10:0.2-instance | Epoch [ 43/ 75] Iter[451/1224]	  loss: 0.30cifar10:0.2-instance | Epoch [ 43/ 75] Iter[501/1224]	  loss: 0.37cifar10:0.2-instance | Epoch [ 43/ 75] Iter[551/1224]	  loss: 0.36cifar10:0.2-instance | Epoch [ 43/ 75] Iter[601/1224]	  loss: 0.38cifar10:0.2-instance | Epoch [ 43/ 75] Iter[651/1224]	  loss: 0.40cifar10:0.2-instance | Epoch [ 43/ 75] Iter[701/1224]	  loss: 0.30cifar10:0.2-instance | Epoch [ 43/ 75] Iter[751/1224]	  loss: 0.28cifar10:0.2-instance | Epoch [ 43/ 75] Iter[801/1224]	  loss: 0.57cifar10:0.2-instance | Epoch [ 43/ 75] Iter[851/1224]	  loss: 0.38cifar10:0.2-instance | Epoch [ 43/ 75] Iter[901/1224]	  loss: 0.38cifar10:0.2-instance | Epoch [ 43/ 75] Iter[951/1224]	  loss: 0.34cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1001/1224]	  loss: 0.58cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1051/1224]	  loss: 0.49cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1101/1224]	  loss: 0.39cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1151/1224]	  loss: 0.33cifar10:0.2-instance | Epoch [ 43/ 75] Iter[1201/1224]	  loss: 0.56
| Test Epoch 43	 Accuracy: 85.95% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 44 | Accuracy on train set: 72.52% 
labeled data has a size of 39281, f-score: 0.979888
cifar10:0.2-instance | Epoch [ 44/ 75] Iter[  1/1228]	  loss: 0.24cifar10:0.2-instance | Epoch [ 44/ 75] Iter[ 51/1228]	  loss: 0.33cifar10:0.2-instance | Epoch [ 44/ 75] Iter[101/1228]	  loss: 0.38cifar10:0.2-instance | Epoch [ 44/ 75] Iter[151/1228]	  loss: 0.28cifar10:0.2-instance | Epoch [ 44/ 75] Iter[201/1228]	  loss: 0.19cifar10:0.2-instance | Epoch [ 44/ 75] Iter[251/1228]	  loss: 0.31cifar10:0.2-instance | Epoch [ 44/ 75] Iter[301/1228]	  loss: 0.30cifar10:0.2-instance | Epoch [ 44/ 75] Iter[351/1228]	  loss: 0.46cifar10:0.2-instance | Epoch [ 44/ 75] Iter[401/1228]	  loss: 0.36cifar10:0.2-instance | Epoch [ 44/ 75] Iter[451/1228]	  loss: 0.51cifar10:0.2-instance | Epoch [ 44/ 75] Iter[501/1228]	  loss: 0.41cifar10:0.2-instance | Epoch [ 44/ 75] Iter[551/1228]	  loss: 0.33cifar10:0.2-instance | Epoch [ 44/ 75] Iter[601/1228]	  loss: 0.46cifar10:0.2-instance | Epoch [ 44/ 75] Iter[651/1228]	  loss: 0.45cifar10:0.2-instance | Epoch [ 44/ 75] Iter[701/1228]	  loss: 0.39cifar10:0.2-instance | Epoch [ 44/ 75] Iter[751/1228]	  loss: 0.41cifar10:0.2-instance | Epoch [ 44/ 75] Iter[801/1228]	  loss: 0.41cifar10:0.2-instance | Epoch [ 44/ 75] Iter[851/1228]	  loss: 0.65cifar10:0.2-instance | Epoch [ 44/ 75] Iter[901/1228]	  loss: 0.56cifar10:0.2-instance | Epoch [ 44/ 75] Iter[951/1228]	  loss: 0.23cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1001/1228]	  loss: 0.40cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1051/1228]	  loss: 0.36cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1101/1228]	  loss: 0.50cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1151/1228]	  loss: 0.46cifar10:0.2-instance | Epoch [ 44/ 75] Iter[1201/1228]	  loss: 0.54
| Test Epoch 44	 Accuracy: 85.17% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 45 | Accuracy on train set: 71.90% 
labeled data has a size of 39169, f-score: 0.981312
cifar10:0.2-instance | Epoch [ 45/ 75] Iter[  1/1225]	  loss: 0.21cifar10:0.2-instance | Epoch [ 45/ 75] Iter[ 51/1225]	  loss: 0.38cifar10:0.2-instance | Epoch [ 45/ 75] Iter[101/1225]	  loss: 0.48cifar10:0.2-instance | Epoch [ 45/ 75] Iter[151/1225]	  loss: 0.28cifar10:0.2-instance | Epoch [ 45/ 75] Iter[201/1225]	  loss: 0.38cifar10:0.2-instance | Epoch [ 45/ 75] Iter[251/1225]	  loss: 0.33cifar10:0.2-instance | Epoch [ 45/ 75] Iter[301/1225]	  loss: 0.48cifar10:0.2-instance | Epoch [ 45/ 75] Iter[351/1225]	  loss: 0.48cifar10:0.2-instance | Epoch [ 45/ 75] Iter[401/1225]	  loss: 0.43cifar10:0.2-instance | Epoch [ 45/ 75] Iter[451/1225]	  loss: 0.45cifar10:0.2-instance | Epoch [ 45/ 75] Iter[501/1225]	  loss: 0.32cifar10:0.2-instance | Epoch [ 45/ 75] Iter[551/1225]	  loss: 0.33cifar10:0.2-instance | Epoch [ 45/ 75] Iter[601/1225]	  loss: 0.37cifar10:0.2-instance | Epoch [ 45/ 75] Iter[651/1225]	  loss: 0.42cifar10:0.2-instance | Epoch [ 45/ 75] Iter[701/1225]	  loss: 0.33cifar10:0.2-instance | Epoch [ 45/ 75] Iter[751/1225]	  loss: 0.65cifar10:0.2-instance | Epoch [ 45/ 75] Iter[801/1225]	  loss: 0.60cifar10:0.2-instance | Epoch [ 45/ 75] Iter[851/1225]	  loss: 0.22cifar10:0.2-instance | Epoch [ 45/ 75] Iter[901/1225]	  loss: 0.30cifar10:0.2-instance | Epoch [ 45/ 75] Iter[951/1225]	  loss: 0.33cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1001/1225]	  loss: 0.42cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1051/1225]	  loss: 0.25cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1101/1225]	  loss: 0.39cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1151/1225]	  loss: 0.37cifar10:0.2-instance | Epoch [ 45/ 75] Iter[1201/1225]	  loss: 0.33
| Test Epoch 45	 Accuracy: 85.49% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 46 | Accuracy on train set: 71.82% 
labeled data has a size of 39160, f-score: 0.981333
cifar10:0.2-instance | Epoch [ 46/ 75] Iter[  1/1224]	  loss: 0.46cifar10:0.2-instance | Epoch [ 46/ 75] Iter[ 51/1224]	  loss: 0.36cifar10:0.2-instance | Epoch [ 46/ 75] Iter[101/1224]	  loss: 0.59cifar10:0.2-instance | Epoch [ 46/ 75] Iter[151/1224]	  loss: 0.49cifar10:0.2-instance | Epoch [ 46/ 75] Iter[201/1224]	  loss: 0.30cifar10:0.2-instance | Epoch [ 46/ 75] Iter[251/1224]	  loss: 0.37cifar10:0.2-instance | Epoch [ 46/ 75] Iter[301/1224]	  loss: 0.38cifar10:0.2-instance | Epoch [ 46/ 75] Iter[351/1224]	  loss: 0.38cifar10:0.2-instance | Epoch [ 46/ 75] Iter[401/1224]	  loss: 0.39cifar10:0.2-instance | Epoch [ 46/ 75] Iter[451/1224]	  loss: 0.30cifar10:0.2-instance | Epoch [ 46/ 75] Iter[501/1224]	  loss: 0.43cifar10:0.2-instance | Epoch [ 46/ 75] Iter[551/1224]	  loss: 0.40cifar10:0.2-instance | Epoch [ 46/ 75] Iter[601/1224]	  loss: 0.45cifar10:0.2-instance | Epoch [ 46/ 75] Iter[651/1224]	  loss: 0.25cifar10:0.2-instance | Epoch [ 46/ 75] Iter[701/1224]	  loss: 0.34cifar10:0.2-instance | Epoch [ 46/ 75] Iter[751/1224]	  loss: 0.39cifar10:0.2-instance | Epoch [ 46/ 75] Iter[801/1224]	  loss: 0.27cifar10:0.2-instance | Epoch [ 46/ 75] Iter[851/1224]	  loss: 0.34cifar10:0.2-instance | Epoch [ 46/ 75] Iter[901/1224]	  loss: 0.37cifar10:0.2-instance | Epoch [ 46/ 75] Iter[951/1224]	  loss: 0.90cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1001/1224]	  loss: 0.24cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1051/1224]	  loss: 0.50cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1101/1224]	  loss: 0.49cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1151/1224]	  loss: 0.38cifar10:0.2-instance | Epoch [ 46/ 75] Iter[1201/1224]	  loss: 0.42
| Test Epoch 46	 Accuracy: 87.07% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 47 | Accuracy on train set: 72.56% 
labeled data has a size of 39206, f-score: 0.983268
cifar10:0.2-instance | Epoch [ 47/ 75] Iter[  1/1226]	  loss: 0.34cifar10:0.2-instance | Epoch [ 47/ 75] Iter[ 51/1226]	  loss: 0.37cifar10:0.2-instance | Epoch [ 47/ 75] Iter[101/1226]	  loss: 0.35cifar10:0.2-instance | Epoch [ 47/ 75] Iter[151/1226]	  loss: 0.48cifar10:0.2-instance | Epoch [ 47/ 75] Iter[201/1226]	  loss: 0.42cifar10:0.2-instance | Epoch [ 47/ 75] Iter[251/1226]	  loss: 0.53cifar10:0.2-instance | Epoch [ 47/ 75] Iter[301/1226]	  loss: 0.33cifar10:0.2-instance | Epoch [ 47/ 75] Iter[351/1226]	  loss: 0.48cifar10:0.2-instance | Epoch [ 47/ 75] Iter[401/1226]	  loss: 0.39cifar10:0.2-instance | Epoch [ 47/ 75] Iter[451/1226]	  loss: 0.36cifar10:0.2-instance | Epoch [ 47/ 75] Iter[501/1226]	  loss: 0.29cifar10:0.2-instance | Epoch [ 47/ 75] Iter[551/1226]	  loss: 0.48cifar10:0.2-instance | Epoch [ 47/ 75] Iter[601/1226]	  loss: 0.40cifar10:0.2-instance | Epoch [ 47/ 75] Iter[651/1226]	  loss: 0.61cifar10:0.2-instance | Epoch [ 47/ 75] Iter[701/1226]	  loss: 0.35cifar10:0.2-instance | Epoch [ 47/ 75] Iter[751/1226]	  loss: 0.47cifar10:0.2-instance | Epoch [ 47/ 75] Iter[801/1226]	  loss: 0.49cifar10:0.2-instance | Epoch [ 47/ 75] Iter[851/1226]	  loss: 0.41cifar10:0.2-instance | Epoch [ 47/ 75] Iter[901/1226]	  loss: 0.41cifar10:0.2-instance | Epoch [ 47/ 75] Iter[951/1226]	  loss: 0.53cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1001/1226]	  loss: 0.39cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1051/1226]	  loss: 0.35cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1101/1226]	  loss: 0.28cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1151/1226]	  loss: 0.45cifar10:0.2-instance | Epoch [ 47/ 75] Iter[1201/1226]	  loss: 0.31
| Test Epoch 47	 Accuracy: 84.32% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 48 | Accuracy on train set: 70.67% 
labeled data has a size of 39054, f-score: 0.984534
cifar10:0.2-instance | Epoch [ 48/ 75] Iter[  1/1221]	  loss: 0.30cifar10:0.2-instance | Epoch [ 48/ 75] Iter[ 51/1221]	  loss: 0.31cifar10:0.2-instance | Epoch [ 48/ 75] Iter[101/1221]	  loss: 0.26cifar10:0.2-instance | Epoch [ 48/ 75] Iter[151/1221]	  loss: 0.33cifar10:0.2-instance | Epoch [ 48/ 75] Iter[201/1221]	  loss: 0.24cifar10:0.2-instance | Epoch [ 48/ 75] Iter[251/1221]	  loss: 0.51cifar10:0.2-instance | Epoch [ 48/ 75] Iter[301/1221]	  loss: 0.21cifar10:0.2-instance | Epoch [ 48/ 75] Iter[351/1221]	  loss: 0.69cifar10:0.2-instance | Epoch [ 48/ 75] Iter[401/1221]	  loss: 0.43cifar10:0.2-instance | Epoch [ 48/ 75] Iter[451/1221]	  loss: 0.35cifar10:0.2-instance | Epoch [ 48/ 75] Iter[501/1221]	  loss: 0.30cifar10:0.2-instance | Epoch [ 48/ 75] Iter[551/1221]	  loss: 0.37cifar10:0.2-instance | Epoch [ 48/ 75] Iter[601/1221]	  loss: 0.23cifar10:0.2-instance | Epoch [ 48/ 75] Iter[651/1221]	  loss: 0.47cifar10:0.2-instance | Epoch [ 48/ 75] Iter[701/1221]	  loss: 0.35cifar10:0.2-instance | Epoch [ 48/ 75] Iter[751/1221]	  loss: 0.44cifar10:0.2-instance | Epoch [ 48/ 75] Iter[801/1221]	  loss: 0.26cifar10:0.2-instance | Epoch [ 48/ 75] Iter[851/1221]	  loss: 0.46cifar10:0.2-instance | Epoch [ 48/ 75] Iter[901/1221]	  loss: 0.67cifar10:0.2-instance | Epoch [ 48/ 75] Iter[951/1221]	  loss: 0.52cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1001/1221]	  loss: 0.58cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1051/1221]	  loss: 0.30cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1101/1221]	  loss: 0.35cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1151/1221]	  loss: 0.34cifar10:0.2-instance | Epoch [ 48/ 75] Iter[1201/1221]	  loss: 0.39
| Test Epoch 48	 Accuracy: 86.41% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 49 | Accuracy on train set: 72.77% 
labeled data has a size of 39126, f-score: 0.984358
cifar10:0.2-instance | Epoch [ 49/ 75] Iter[  1/1223]	  loss: 0.31cifar10:0.2-instance | Epoch [ 49/ 75] Iter[ 51/1223]	  loss: 0.25cifar10:0.2-instance | Epoch [ 49/ 75] Iter[101/1223]	  loss: 0.26cifar10:0.2-instance | Epoch [ 49/ 75] Iter[151/1223]	  loss: 0.39cifar10:0.2-instance | Epoch [ 49/ 75] Iter[201/1223]	  loss: 0.54cifar10:0.2-instance | Epoch [ 49/ 75] Iter[251/1223]	  loss: 0.27cifar10:0.2-instance | Epoch [ 49/ 75] Iter[301/1223]	  loss: 0.60cifar10:0.2-instance | Epoch [ 49/ 75] Iter[351/1223]	  loss: 0.53cifar10:0.2-instance | Epoch [ 49/ 75] Iter[401/1223]	  loss: 0.62cifar10:0.2-instance | Epoch [ 49/ 75] Iter[451/1223]	  loss: 0.31cifar10:0.2-instance | Epoch [ 49/ 75] Iter[501/1223]	  loss: 0.38cifar10:0.2-instance | Epoch [ 49/ 75] Iter[551/1223]	  loss: 0.49cifar10:0.2-instance | Epoch [ 49/ 75] Iter[601/1223]	  loss: 0.31cifar10:0.2-instance | Epoch [ 49/ 75] Iter[651/1223]	  loss: 0.49cifar10:0.2-instance | Epoch [ 49/ 75] Iter[701/1223]	  loss: 0.31cifar10:0.2-instance | Epoch [ 49/ 75] Iter[751/1223]	  loss: 0.58cifar10:0.2-instance | Epoch [ 49/ 75] Iter[801/1223]	  loss: 0.35cifar10:0.2-instance | Epoch [ 49/ 75] Iter[851/1223]	  loss: 0.43cifar10:0.2-instance | Epoch [ 49/ 75] Iter[901/1223]	  loss: 0.48cifar10:0.2-instance | Epoch [ 49/ 75] Iter[951/1223]	  loss: 0.40cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1001/1223]	  loss: 0.93cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1051/1223]	  loss: 0.30cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1101/1223]	  loss: 0.25cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1151/1223]	  loss: 0.36cifar10:0.2-instance | Epoch [ 49/ 75] Iter[1201/1223]	  loss: 0.44
| Test Epoch 49	 Accuracy: 84.85% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 50 | Accuracy on train set: 71.26% 
labeled data has a size of 39165, f-score: 0.982306
cifar10:0.2-instance | Epoch [ 50/ 75] Iter[  1/1224]	  loss: 0.37cifar10:0.2-instance | Epoch [ 50/ 75] Iter[ 51/1224]	  loss: 0.36cifar10:0.2-instance | Epoch [ 50/ 75] Iter[101/1224]	  loss: 0.35cifar10:0.2-instance | Epoch [ 50/ 75] Iter[151/1224]	  loss: 0.33cifar10:0.2-instance | Epoch [ 50/ 75] Iter[201/1224]	  loss: 0.24cifar10:0.2-instance | Epoch [ 50/ 75] Iter[251/1224]	  loss: 0.42cifar10:0.2-instance | Epoch [ 50/ 75] Iter[301/1224]	  loss: 0.38cifar10:0.2-instance | Epoch [ 50/ 75] Iter[351/1224]	  loss: 0.49cifar10:0.2-instance | Epoch [ 50/ 75] Iter[401/1224]	  loss: 0.54cifar10:0.2-instance | Epoch [ 50/ 75] Iter[451/1224]	  loss: 0.45cifar10:0.2-instance | Epoch [ 50/ 75] Iter[501/1224]	  loss: 0.50cifar10:0.2-instance | Epoch [ 50/ 75] Iter[551/1224]	  loss: 0.29cifar10:0.2-instance | Epoch [ 50/ 75] Iter[601/1224]	  loss: 0.33cifar10:0.2-instance | Epoch [ 50/ 75] Iter[651/1224]	  loss: 0.29cifar10:0.2-instance | Epoch [ 50/ 75] Iter[701/1224]	  loss: 0.34cifar10:0.2-instance | Epoch [ 50/ 75] Iter[751/1224]	  loss: 0.51cifar10:0.2-instance | Epoch [ 50/ 75] Iter[801/1224]	  loss: 0.50cifar10:0.2-instance | Epoch [ 50/ 75] Iter[851/1224]	  loss: 0.28cifar10:0.2-instance | Epoch [ 50/ 75] Iter[901/1224]	  loss: 0.47cifar10:0.2-instance | Epoch [ 50/ 75] Iter[951/1224]	  loss: 0.42cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1001/1224]	  loss: 0.33cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1051/1224]	  loss: 0.48cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1101/1224]	  loss: 0.39cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1151/1224]	  loss: 0.44cifar10:0.2-instance | Epoch [ 50/ 75] Iter[1201/1224]	  loss: 0.37
| Test Epoch 50	 Accuracy: 86.06% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 51 | Accuracy on train set: 72.60% 
labeled data has a size of 39204, f-score: 0.982272
cifar10:0.2-instance | Epoch [ 51/ 75] Iter[  1/1226]	  loss: 0.34cifar10:0.2-instance | Epoch [ 51/ 75] Iter[ 51/1226]	  loss: 0.21cifar10:0.2-instance | Epoch [ 51/ 75] Iter[101/1226]	  loss: 0.50cifar10:0.2-instance | Epoch [ 51/ 75] Iter[151/1226]	  loss: 0.39cifar10:0.2-instance | Epoch [ 51/ 75] Iter[201/1226]	  loss: 0.33cifar10:0.2-instance | Epoch [ 51/ 75] Iter[251/1226]	  loss: 0.54cifar10:0.2-instance | Epoch [ 51/ 75] Iter[301/1226]	  loss: 0.30cifar10:0.2-instance | Epoch [ 51/ 75] Iter[351/1226]	  loss: 0.24cifar10:0.2-instance | Epoch [ 51/ 75] Iter[401/1226]	  loss: 0.36cifar10:0.2-instance | Epoch [ 51/ 75] Iter[451/1226]	  loss: 0.48cifar10:0.2-instance | Epoch [ 51/ 75] Iter[501/1226]	  loss: 0.38cifar10:0.2-instance | Epoch [ 51/ 75] Iter[551/1226]	  loss: 0.39cifar10:0.2-instance | Epoch [ 51/ 75] Iter[601/1226]	  loss: 0.58cifar10:0.2-instance | Epoch [ 51/ 75] Iter[651/1226]	  loss: 0.27cifar10:0.2-instance | Epoch [ 51/ 75] Iter[701/1226]	  loss: 0.34cifar10:0.2-instance | Epoch [ 51/ 75] Iter[751/1226]	  loss: 0.39cifar10:0.2-instance | Epoch [ 51/ 75] Iter[801/1226]	  loss: 0.43cifar10:0.2-instance | Epoch [ 51/ 75] Iter[851/1226]	  loss: 0.59cifar10:0.2-instance | Epoch [ 51/ 75] Iter[901/1226]	  loss: 0.51cifar10:0.2-instance | Epoch [ 51/ 75] Iter[951/1226]	  loss: 0.42cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1001/1226]	  loss: 0.71cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1051/1226]	  loss: 0.40cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1101/1226]	  loss: 0.34cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1151/1226]	  loss: 0.41cifar10:0.2-instance | Epoch [ 51/ 75] Iter[1201/1226]	  loss: 0.49
| Test Epoch 51	 Accuracy: 82.79% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 52 | Accuracy on train set: 69.70% 
labeled data has a size of 39304, f-score: 0.980129
cifar10:0.2-instance | Epoch [ 52/ 75] Iter[  1/1229]	  loss: 0.34cifar10:0.2-instance | Epoch [ 52/ 75] Iter[ 51/1229]	  loss: 0.31cifar10:0.2-instance | Epoch [ 52/ 75] Iter[101/1229]	  loss: 0.56cifar10:0.2-instance | Epoch [ 52/ 75] Iter[151/1229]	  loss: 0.32cifar10:0.2-instance | Epoch [ 52/ 75] Iter[201/1229]	  loss: 0.46cifar10:0.2-instance | Epoch [ 52/ 75] Iter[251/1229]	  loss: 0.47cifar10:0.2-instance | Epoch [ 52/ 75] Iter[301/1229]	  loss: 0.53cifar10:0.2-instance | Epoch [ 52/ 75] Iter[351/1229]	  loss: 0.52cifar10:0.2-instance | Epoch [ 52/ 75] Iter[401/1229]	  loss: 0.34cifar10:0.2-instance | Epoch [ 52/ 75] Iter[451/1229]	  loss: 0.44cifar10:0.2-instance | Epoch [ 52/ 75] Iter[501/1229]	  loss: 0.44cifar10:0.2-instance | Epoch [ 52/ 75] Iter[551/1229]	  loss: 0.54cifar10:0.2-instance | Epoch [ 52/ 75] Iter[601/1229]	  loss: 0.28cifar10:0.2-instance | Epoch [ 52/ 75] Iter[651/1229]	  loss: 0.24cifar10:0.2-instance | Epoch [ 52/ 75] Iter[701/1229]	  loss: 0.49cifar10:0.2-instance | Epoch [ 52/ 75] Iter[751/1229]	  loss: 0.35cifar10:0.2-instance | Epoch [ 52/ 75] Iter[801/1229]	  loss: 0.43cifar10:0.2-instance | Epoch [ 52/ 75] Iter[851/1229]	  loss: 0.29cifar10:0.2-instance | Epoch [ 52/ 75] Iter[901/1229]	  loss: 0.36cifar10:0.2-instance | Epoch [ 52/ 75] Iter[951/1229]	  loss: 0.52cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1001/1229]	  loss: 0.42cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1051/1229]	  loss: 0.37cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1101/1229]	  loss: 0.63cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1151/1229]	  loss: 0.64cifar10:0.2-instance | Epoch [ 52/ 75] Iter[1201/1229]	  loss: 0.40
| Test Epoch 52	 Accuracy: 85.05% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 53 | Accuracy on train set: 71.79% 
labeled data has a size of 39308, f-score: 0.979750
cifar10:0.2-instance | Epoch [ 53/ 75] Iter[  1/1229]	  loss: 0.35cifar10:0.2-instance | Epoch [ 53/ 75] Iter[ 51/1229]	  loss: 0.45cifar10:0.2-instance | Epoch [ 53/ 75] Iter[101/1229]	  loss: 0.31cifar10:0.2-instance | Epoch [ 53/ 75] Iter[151/1229]	  loss: 0.30cifar10:0.2-instance | Epoch [ 53/ 75] Iter[201/1229]	  loss: 0.57cifar10:0.2-instance | Epoch [ 53/ 75] Iter[251/1229]	  loss: 0.23cifar10:0.2-instance | Epoch [ 53/ 75] Iter[301/1229]	  loss: 0.27cifar10:0.2-instance | Epoch [ 53/ 75] Iter[351/1229]	  loss: 0.44cifar10:0.2-instance | Epoch [ 53/ 75] Iter[401/1229]	  loss: 0.23cifar10:0.2-instance | Epoch [ 53/ 75] Iter[451/1229]	  loss: 0.31cifar10:0.2-instance | Epoch [ 53/ 75] Iter[501/1229]	  loss: 0.32cifar10:0.2-instance | Epoch [ 53/ 75] Iter[551/1229]	  loss: 0.31cifar10:0.2-instance | Epoch [ 53/ 75] Iter[601/1229]	  loss: 0.31cifar10:0.2-instance | Epoch [ 53/ 75] Iter[651/1229]	  loss: 0.29cifar10:0.2-instance | Epoch [ 53/ 75] Iter[701/1229]	  loss: 0.44cifar10:0.2-instance | Epoch [ 53/ 75] Iter[751/1229]	  loss: 0.44cifar10:0.2-instance | Epoch [ 53/ 75] Iter[801/1229]	  loss: 0.35cifar10:0.2-instance | Epoch [ 53/ 75] Iter[851/1229]	  loss: 0.41cifar10:0.2-instance | Epoch [ 53/ 75] Iter[901/1229]	  loss: 0.30cifar10:0.2-instance | Epoch [ 53/ 75] Iter[951/1229]	  loss: 0.29cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1001/1229]	  loss: 0.75cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1051/1229]	  loss: 0.37cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1101/1229]	  loss: 0.35cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1151/1229]	  loss: 0.72cifar10:0.2-instance | Epoch [ 53/ 75] Iter[1201/1229]	  loss: 0.29
| Test Epoch 53	 Accuracy: 84.75% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 54 | Accuracy on train set: 71.75% 
labeled data has a size of 39125, f-score: 0.979195
cifar10:0.2-instance | Epoch [ 54/ 75] Iter[  1/1223]	  loss: 0.50cifar10:0.2-instance | Epoch [ 54/ 75] Iter[ 51/1223]	  loss: 0.37cifar10:0.2-instance | Epoch [ 54/ 75] Iter[101/1223]	  loss: 0.33cifar10:0.2-instance | Epoch [ 54/ 75] Iter[151/1223]	  loss: 0.81cifar10:0.2-instance | Epoch [ 54/ 75] Iter[201/1223]	  loss: 0.43cifar10:0.2-instance | Epoch [ 54/ 75] Iter[251/1223]	  loss: 0.27cifar10:0.2-instance | Epoch [ 54/ 75] Iter[301/1223]	  loss: 0.47cifar10:0.2-instance | Epoch [ 54/ 75] Iter[351/1223]	  loss: 0.25cifar10:0.2-instance | Epoch [ 54/ 75] Iter[401/1223]	  loss: 0.51cifar10:0.2-instance | Epoch [ 54/ 75] Iter[451/1223]	  loss: 0.33cifar10:0.2-instance | Epoch [ 54/ 75] Iter[501/1223]	  loss: 0.18cifar10:0.2-instance | Epoch [ 54/ 75] Iter[551/1223]	  loss: 0.30cifar10:0.2-instance | Epoch [ 54/ 75] Iter[601/1223]	  loss: 0.47cifar10:0.2-instance | Epoch [ 54/ 75] Iter[651/1223]	  loss: 0.32cifar10:0.2-instance | Epoch [ 54/ 75] Iter[701/1223]	  loss: 0.54cifar10:0.2-instance | Epoch [ 54/ 75] Iter[751/1223]	  loss: 0.29cifar10:0.2-instance | Epoch [ 54/ 75] Iter[801/1223]	  loss: 0.46cifar10:0.2-instance | Epoch [ 54/ 75] Iter[851/1223]	  loss: 0.25cifar10:0.2-instance | Epoch [ 54/ 75] Iter[901/1223]	  loss: 0.73cifar10:0.2-instance | Epoch [ 54/ 75] Iter[951/1223]	  loss: 0.54cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1001/1223]	  loss: 0.30cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1051/1223]	  loss: 0.46cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1101/1223]	  loss: 0.31cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1151/1223]	  loss: 0.50cifar10:0.2-instance | Epoch [ 54/ 75] Iter[1201/1223]	  loss: 0.42
| Test Epoch 54	 Accuracy: 85.60% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 55 | Accuracy on train set: 72.19% 
labeled data has a size of 39245, f-score: 0.980711
cifar10:0.2-instance | Epoch [ 55/ 75] Iter[  1/1227]	  loss: 0.27cifar10:0.2-instance | Epoch [ 55/ 75] Iter[ 51/1227]	  loss: 0.49cifar10:0.2-instance | Epoch [ 55/ 75] Iter[101/1227]	  loss: 0.56cifar10:0.2-instance | Epoch [ 55/ 75] Iter[151/1227]	  loss: 0.49cifar10:0.2-instance | Epoch [ 55/ 75] Iter[201/1227]	  loss: 0.33cifar10:0.2-instance | Epoch [ 55/ 75] Iter[251/1227]	  loss: 0.43cifar10:0.2-instance | Epoch [ 55/ 75] Iter[301/1227]	  loss: 0.53cifar10:0.2-instance | Epoch [ 55/ 75] Iter[351/1227]	  loss: 0.26cifar10:0.2-instance | Epoch [ 55/ 75] Iter[401/1227]	  loss: 0.30cifar10:0.2-instance | Epoch [ 55/ 75] Iter[451/1227]	  loss: 0.46cifar10:0.2-instance | Epoch [ 55/ 75] Iter[501/1227]	  loss: 0.23cifar10:0.2-instance | Epoch [ 55/ 75] Iter[551/1227]	  loss: 0.50cifar10:0.2-instance | Epoch [ 55/ 75] Iter[601/1227]	  loss: 0.43cifar10:0.2-instance | Epoch [ 55/ 75] Iter[651/1227]	  loss: 0.28cifar10:0.2-instance | Epoch [ 55/ 75] Iter[701/1227]	  loss: 0.53cifar10:0.2-instance | Epoch [ 55/ 75] Iter[751/1227]	  loss: 0.79cifar10:0.2-instance | Epoch [ 55/ 75] Iter[801/1227]	  loss: 0.52cifar10:0.2-instance | Epoch [ 55/ 75] Iter[851/1227]	  loss: 0.35cifar10:0.2-instance | Epoch [ 55/ 75] Iter[901/1227]	  loss: 0.38cifar10:0.2-instance | Epoch [ 55/ 75] Iter[951/1227]	  loss: 0.39cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1001/1227]	  loss: 0.42cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1051/1227]	  loss: 0.52cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1101/1227]	  loss: 0.55cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1151/1227]	  loss: 0.56cifar10:0.2-instance | Epoch [ 55/ 75] Iter[1201/1227]	  loss: 0.48
| Test Epoch 55	 Accuracy: 86.19% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 56 | Accuracy on train set: 72.75% 
labeled data has a size of 39267, f-score: 0.980645
cifar10:0.2-instance | Epoch [ 56/ 75] Iter[  1/1228]	  loss: 0.38cifar10:0.2-instance | Epoch [ 56/ 75] Iter[ 51/1228]	  loss: 0.48cifar10:0.2-instance | Epoch [ 56/ 75] Iter[101/1228]	  loss: 0.44cifar10:0.2-instance | Epoch [ 56/ 75] Iter[151/1228]	  loss: 0.40cifar10:0.2-instance | Epoch [ 56/ 75] Iter[201/1228]	  loss: 0.43cifar10:0.2-instance | Epoch [ 56/ 75] Iter[251/1228]	  loss: 0.31cifar10:0.2-instance | Epoch [ 56/ 75] Iter[301/1228]	  loss: 0.55cifar10:0.2-instance | Epoch [ 56/ 75] Iter[351/1228]	  loss: 0.25cifar10:0.2-instance | Epoch [ 56/ 75] Iter[401/1228]	  loss: 0.61cifar10:0.2-instance | Epoch [ 56/ 75] Iter[451/1228]	  loss: 0.23cifar10:0.2-instance | Epoch [ 56/ 75] Iter[501/1228]	  loss: 0.33cifar10:0.2-instance | Epoch [ 56/ 75] Iter[551/1228]	  loss: 0.70cifar10:0.2-instance | Epoch [ 56/ 75] Iter[601/1228]	  loss: 0.56cifar10:0.2-instance | Epoch [ 56/ 75] Iter[651/1228]	  loss: 0.35cifar10:0.2-instance | Epoch [ 56/ 75] Iter[701/1228]	  loss: 0.25cifar10:0.2-instance | Epoch [ 56/ 75] Iter[751/1228]	  loss: 0.60cifar10:0.2-instance | Epoch [ 56/ 75] Iter[801/1228]	  loss: 0.29cifar10:0.2-instance | Epoch [ 56/ 75] Iter[851/1228]	  loss: 0.62cifar10:0.2-instance | Epoch [ 56/ 75] Iter[901/1228]	  loss: 0.37cifar10:0.2-instance | Epoch [ 56/ 75] Iter[951/1228]	  loss: 0.82cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1001/1228]	  loss: 0.47cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1051/1228]	  loss: 0.32cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1101/1228]	  loss: 0.84cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1151/1228]	  loss: 0.44cifar10:0.2-instance | Epoch [ 56/ 75] Iter[1201/1228]	  loss: 0.45
| Test Epoch 56	 Accuracy: 85.10% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 57 | Accuracy on train set: 71.40% 
labeled data has a size of 39320, f-score: 0.981409
cifar10:0.2-instance | Epoch [ 57/ 75] Iter[  1/1229]	  loss: 0.43cifar10:0.2-instance | Epoch [ 57/ 75] Iter[ 51/1229]	  loss: 0.49cifar10:0.2-instance | Epoch [ 57/ 75] Iter[101/1229]	  loss: 0.45cifar10:0.2-instance | Epoch [ 57/ 75] Iter[151/1229]	  loss: 0.26cifar10:0.2-instance | Epoch [ 57/ 75] Iter[201/1229]	  loss: 0.54cifar10:0.2-instance | Epoch [ 57/ 75] Iter[251/1229]	  loss: 0.43cifar10:0.2-instance | Epoch [ 57/ 75] Iter[301/1229]	  loss: 0.28cifar10:0.2-instance | Epoch [ 57/ 75] Iter[351/1229]	  loss: 0.28cifar10:0.2-instance | Epoch [ 57/ 75] Iter[401/1229]	  loss: 0.30cifar10:0.2-instance | Epoch [ 57/ 75] Iter[451/1229]	  loss: 0.49cifar10:0.2-instance | Epoch [ 57/ 75] Iter[501/1229]	  loss: 0.46cifar10:0.2-instance | Epoch [ 57/ 75] Iter[551/1229]	  loss: 0.46cifar10:0.2-instance | Epoch [ 57/ 75] Iter[601/1229]	  loss: 0.33cifar10:0.2-instance | Epoch [ 57/ 75] Iter[651/1229]	  loss: 0.44cifar10:0.2-instance | Epoch [ 57/ 75] Iter[701/1229]	  loss: 0.57cifar10:0.2-instance | Epoch [ 57/ 75] Iter[751/1229]	  loss: 0.45cifar10:0.2-instance | Epoch [ 57/ 75] Iter[801/1229]	  loss: 0.42cifar10:0.2-instance | Epoch [ 57/ 75] Iter[851/1229]	  loss: 0.29cifar10:0.2-instance | Epoch [ 57/ 75] Iter[901/1229]	  loss: 0.33cifar10:0.2-instance | Epoch [ 57/ 75] Iter[951/1229]	  loss: 0.35cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1001/1229]	  loss: 0.63cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1051/1229]	  loss: 0.31cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1101/1229]	  loss: 0.37cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1151/1229]	  loss: 0.52cifar10:0.2-instance | Epoch [ 57/ 75] Iter[1201/1229]	  loss: 0.31
| Test Epoch 57	 Accuracy: 83.64% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 58 | Accuracy on train set: 70.52% 
labeled data has a size of 39301, f-score: 0.979695
cifar10:0.2-instance | Epoch [ 58/ 75] Iter[  1/1229]	  loss: 0.62cifar10:0.2-instance | Epoch [ 58/ 75] Iter[ 51/1229]	  loss: 0.45cifar10:0.2-instance | Epoch [ 58/ 75] Iter[101/1229]	  loss: 0.39cifar10:0.2-instance | Epoch [ 58/ 75] Iter[151/1229]	  loss: 0.31cifar10:0.2-instance | Epoch [ 58/ 75] Iter[201/1229]	  loss: 0.46cifar10:0.2-instance | Epoch [ 58/ 75] Iter[251/1229]	  loss: 0.24cifar10:0.2-instance | Epoch [ 58/ 75] Iter[301/1229]	  loss: 0.38cifar10:0.2-instance | Epoch [ 58/ 75] Iter[351/1229]	  loss: 0.61cifar10:0.2-instance | Epoch [ 58/ 75] Iter[401/1229]	  loss: 0.42cifar10:0.2-instance | Epoch [ 58/ 75] Iter[451/1229]	  loss: 0.32cifar10:0.2-instance | Epoch [ 58/ 75] Iter[501/1229]	  loss: 0.43cifar10:0.2-instance | Epoch [ 58/ 75] Iter[551/1229]	  loss: 0.45cifar10:0.2-instance | Epoch [ 58/ 75] Iter[601/1229]	  loss: 0.61cifar10:0.2-instance | Epoch [ 58/ 75] Iter[651/1229]	  loss: 0.31cifar10:0.2-instance | Epoch [ 58/ 75] Iter[701/1229]	  loss: 0.27cifar10:0.2-instance | Epoch [ 58/ 75] Iter[751/1229]	  loss: 0.46cifar10:0.2-instance | Epoch [ 58/ 75] Iter[801/1229]	  loss: 0.54cifar10:0.2-instance | Epoch [ 58/ 75] Iter[851/1229]	  loss: 0.33cifar10:0.2-instance | Epoch [ 58/ 75] Iter[901/1229]	  loss: 0.55cifar10:0.2-instance | Epoch [ 58/ 75] Iter[951/1229]	  loss: 0.32cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1001/1229]	  loss: 0.40cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1051/1229]	  loss: 0.24cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1101/1229]	  loss: 0.30cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1151/1229]	  loss: 0.66cifar10:0.2-instance | Epoch [ 58/ 75] Iter[1201/1229]	  loss: 0.52
| Test Epoch 58	 Accuracy: 84.47% 



============ Train stage | lr = 0.020, T in penalty = 0.200
Epoch 59 | Accuracy on train set: 70.80% 
labeled data has a size of 39047, f-score: 0.982713
cifar10:0.2-instance | Epoch [ 59/ 75] Iter[  1/1221]	  loss: 0.43cifar10:0.2-instance | Epoch [ 59/ 75] Iter[ 51/1221]	  loss: 0.52cifar10:0.2-instance | Epoch [ 59/ 75] Iter[101/1221]	  loss: 0.37cifar10:0.2-instance | Epoch [ 59/ 75] Iter[151/1221]	  loss: 0.29cifar10:0.2-instance | Epoch [ 59/ 75] Iter[201/1221]	  loss: 0.34cifar10:0.2-instance | Epoch [ 59/ 75] Iter[251/1221]	  loss: 0.39cifar10:0.2-instance | Epoch [ 59/ 75] Iter[301/1221]	  loss: 0.40cifar10:0.2-instance | Epoch [ 59/ 75] Iter[351/1221]	  loss: 0.40cifar10:0.2-instance | Epoch [ 59/ 75] Iter[401/1221]	  loss: 0.44cifar10:0.2-instance | Epoch [ 59/ 75] Iter[451/1221]	  loss: 0.37cifar10:0.2-instance | Epoch [ 59/ 75] Iter[501/1221]	  loss: 0.28cifar10:0.2-instance | Epoch [ 59/ 75] Iter[551/1221]	  loss: 0.49cifar10:0.2-instance | Epoch [ 59/ 75] Iter[601/1221]	  loss: 0.68cifar10:0.2-instance | Epoch [ 59/ 75] Iter[651/1221]	  loss: 0.30cifar10:0.2-instance | Epoch [ 59/ 75] Iter[701/1221]	  loss: 0.29cifar10:0.2-instance | Epoch [ 59/ 75] Iter[751/1221]	  loss: 0.38cifar10:0.2-instance | Epoch [ 59/ 75] Iter[801/1221]	  loss: 0.53cifar10:0.2-instance | Epoch [ 59/ 75] Iter[851/1221]	  loss: 0.34cifar10:0.2-instance | Epoch [ 59/ 75] Iter[901/1221]	  loss: 0.40cifar10:0.2-instance | Epoch [ 59/ 75] Iter[951/1221]	  loss: 0.28cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1001/1221]	  loss: 0.46cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1051/1221]	  loss: 0.27cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1101/1221]	  loss: 0.30cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1151/1221]	  loss: 0.26cifar10:0.2-instance | Epoch [ 59/ 75] Iter[1201/1221]	  loss: 0.40
| Test Epoch 59	 Accuracy: 85.57% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 60 | Accuracy on train set: 71.95% 
labeled data has a size of 39135, f-score: 0.982650
cifar10:0.2-instance | Epoch [ 60/ 75] Iter[  1/1223]	  loss: 0.37cifar10:0.2-instance | Epoch [ 60/ 75] Iter[ 51/1223]	  loss: 0.19cifar10:0.2-instance | Epoch [ 60/ 75] Iter[101/1223]	  loss: 0.32cifar10:0.2-instance | Epoch [ 60/ 75] Iter[151/1223]	  loss: 0.46cifar10:0.2-instance | Epoch [ 60/ 75] Iter[201/1223]	  loss: 0.18cifar10:0.2-instance | Epoch [ 60/ 75] Iter[251/1223]	  loss: 0.25cifar10:0.2-instance | Epoch [ 60/ 75] Iter[301/1223]	  loss: 0.22cifar10:0.2-instance | Epoch [ 60/ 75] Iter[351/1223]	  loss: 0.21cifar10:0.2-instance | Epoch [ 60/ 75] Iter[401/1223]	  loss: 0.22cifar10:0.2-instance | Epoch [ 60/ 75] Iter[451/1223]	  loss: 0.34cifar10:0.2-instance | Epoch [ 60/ 75] Iter[501/1223]	  loss: 0.26cifar10:0.2-instance | Epoch [ 60/ 75] Iter[551/1223]	  loss: 0.29cifar10:0.2-instance | Epoch [ 60/ 75] Iter[601/1223]	  loss: 0.16cifar10:0.2-instance | Epoch [ 60/ 75] Iter[651/1223]	  loss: 0.48cifar10:0.2-instance | Epoch [ 60/ 75] Iter[701/1223]	  loss: 0.29cifar10:0.2-instance | Epoch [ 60/ 75] Iter[751/1223]	  loss: 0.37cifar10:0.2-instance | Epoch [ 60/ 75] Iter[801/1223]	  loss: 0.30cifar10:0.2-instance | Epoch [ 60/ 75] Iter[851/1223]	  loss: 0.36cifar10:0.2-instance | Epoch [ 60/ 75] Iter[901/1223]	  loss: 0.21cifar10:0.2-instance | Epoch [ 60/ 75] Iter[951/1223]	  loss: 0.33cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1001/1223]	  loss: 0.36cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1051/1223]	  loss: 0.20cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1101/1223]	  loss: 0.16cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1151/1223]	  loss: 0.20cifar10:0.2-instance | Epoch [ 60/ 75] Iter[1201/1223]	  loss: 0.33
| Test Epoch 60	 Accuracy: 91.30% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 61 | Accuracy on train set: 76.85% 
labeled data has a size of 39342, f-score: 0.985003
cifar10:0.2-instance | Epoch [ 61/ 75] Iter[  1/1230]	  loss: 0.18cifar10:0.2-instance | Epoch [ 61/ 75] Iter[ 51/1230]	  loss: 0.23cifar10:0.2-instance | Epoch [ 61/ 75] Iter[101/1230]	  loss: 0.23cifar10:0.2-instance | Epoch [ 61/ 75] Iter[151/1230]	  loss: 0.26cifar10:0.2-instance | Epoch [ 61/ 75] Iter[201/1230]	  loss: 0.23cifar10:0.2-instance | Epoch [ 61/ 75] Iter[251/1230]	  loss: 0.16cifar10:0.2-instance | Epoch [ 61/ 75] Iter[301/1230]	  loss: 0.19cifar10:0.2-instance | Epoch [ 61/ 75] Iter[351/1230]	  loss: 0.27cifar10:0.2-instance | Epoch [ 61/ 75] Iter[401/1230]	  loss: 0.21cifar10:0.2-instance | Epoch [ 61/ 75] Iter[451/1230]	  loss: 0.26cifar10:0.2-instance | Epoch [ 61/ 75] Iter[501/1230]	  loss: 0.29cifar10:0.2-instance | Epoch [ 61/ 75] Iter[551/1230]	  loss: 0.22cifar10:0.2-instance | Epoch [ 61/ 75] Iter[601/1230]	  loss: 0.32cifar10:0.2-instance | Epoch [ 61/ 75] Iter[651/1230]	  loss: 0.49cifar10:0.2-instance | Epoch [ 61/ 75] Iter[701/1230]	  loss: 0.29cifar10:0.2-instance | Epoch [ 61/ 75] Iter[751/1230]	  loss: 0.19cifar10:0.2-instance | Epoch [ 61/ 75] Iter[801/1230]	  loss: 0.35cifar10:0.2-instance | Epoch [ 61/ 75] Iter[851/1230]	  loss: 0.29cifar10:0.2-instance | Epoch [ 61/ 75] Iter[901/1230]	  loss: 0.40cifar10:0.2-instance | Epoch [ 61/ 75] Iter[951/1230]	  loss: 0.28cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1001/1230]	  loss: 0.25cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1051/1230]	  loss: 0.25cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1101/1230]	  loss: 0.23cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1151/1230]	  loss: 0.16cifar10:0.2-instance | Epoch [ 61/ 75] Iter[1201/1230]	  loss: 0.25
| Test Epoch 61	 Accuracy: 91.67% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 62 | Accuracy on train set: 77.26% 
labeled data has a size of 39405, f-score: 0.985535
cifar10:0.2-instance | Epoch [ 62/ 75] Iter[  1/1232]	  loss: 0.20cifar10:0.2-instance | Epoch [ 62/ 75] Iter[ 51/1232]	  loss: 0.43cifar10:0.2-instance | Epoch [ 62/ 75] Iter[101/1232]	  loss: 0.24cifar10:0.2-instance | Epoch [ 62/ 75] Iter[151/1232]	  loss: 0.21cifar10:0.2-instance | Epoch [ 62/ 75] Iter[201/1232]	  loss: 0.17cifar10:0.2-instance | Epoch [ 62/ 75] Iter[251/1232]	  loss: 0.29cifar10:0.2-instance | Epoch [ 62/ 75] Iter[301/1232]	  loss: 0.21cifar10:0.2-instance | Epoch [ 62/ 75] Iter[351/1232]	  loss: 0.15cifar10:0.2-instance | Epoch [ 62/ 75] Iter[401/1232]	  loss: 0.27cifar10:0.2-instance | Epoch [ 62/ 75] Iter[451/1232]	  loss: 0.19cifar10:0.2-instance | Epoch [ 62/ 75] Iter[501/1232]	  loss: 0.19cifar10:0.2-instance | Epoch [ 62/ 75] Iter[551/1232]	  loss: 0.15cifar10:0.2-instance | Epoch [ 62/ 75] Iter[601/1232]	  loss: 0.25cifar10:0.2-instance | Epoch [ 62/ 75] Iter[651/1232]	  loss: 0.20cifar10:0.2-instance | Epoch [ 62/ 75] Iter[701/1232]	  loss: 0.32cifar10:0.2-instance | Epoch [ 62/ 75] Iter[751/1232]	  loss: 0.21cifar10:0.2-instance | Epoch [ 62/ 75] Iter[801/1232]	  loss: 0.20cifar10:0.2-instance | Epoch [ 62/ 75] Iter[851/1232]	  loss: 0.21cifar10:0.2-instance | Epoch [ 62/ 75] Iter[901/1232]	  loss: 0.22cifar10:0.2-instance | Epoch [ 62/ 75] Iter[951/1232]	  loss: 0.26cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1001/1232]	  loss: 0.19cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1051/1232]	  loss: 0.18cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1101/1232]	  loss: 0.22cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1151/1232]	  loss: 0.40cifar10:0.2-instance | Epoch [ 62/ 75] Iter[1201/1232]	  loss: 0.22
| Test Epoch 62	 Accuracy: 91.62% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 63 | Accuracy on train set: 77.71% 
labeled data has a size of 39429, f-score: 0.986228
cifar10:0.2-instance | Epoch [ 63/ 75] Iter[  1/1233]	  loss: 0.19cifar10:0.2-instance | Epoch [ 63/ 75] Iter[ 51/1233]	  loss: 0.21cifar10:0.2-instance | Epoch [ 63/ 75] Iter[101/1233]	  loss: 0.15cifar10:0.2-instance | Epoch [ 63/ 75] Iter[151/1233]	  loss: 0.16cifar10:0.2-instance | Epoch [ 63/ 75] Iter[201/1233]	  loss: 0.24cifar10:0.2-instance | Epoch [ 63/ 75] Iter[251/1233]	  loss: 0.16cifar10:0.2-instance | Epoch [ 63/ 75] Iter[301/1233]	  loss: 0.19cifar10:0.2-instance | Epoch [ 63/ 75] Iter[351/1233]	  loss: 0.24cifar10:0.2-instance | Epoch [ 63/ 75] Iter[401/1233]	  loss: 0.17cifar10:0.2-instance | Epoch [ 63/ 75] Iter[451/1233]	  loss: 0.17cifar10:0.2-instance | Epoch [ 63/ 75] Iter[501/1233]	  loss: 0.15cifar10:0.2-instance | Epoch [ 63/ 75] Iter[551/1233]	  loss: 0.17cifar10:0.2-instance | Epoch [ 63/ 75] Iter[601/1233]	  loss: 0.49cifar10:0.2-instance | Epoch [ 63/ 75] Iter[651/1233]	  loss: 0.15cifar10:0.2-instance | Epoch [ 63/ 75] Iter[701/1233]	  loss: 0.16cifar10:0.2-instance | Epoch [ 63/ 75] Iter[751/1233]	  loss: 0.26cifar10:0.2-instance | Epoch [ 63/ 75] Iter[801/1233]	  loss: 0.15cifar10:0.2-instance | Epoch [ 63/ 75] Iter[851/1233]	  loss: 0.23cifar10:0.2-instance | Epoch [ 63/ 75] Iter[901/1233]	  loss: 0.19cifar10:0.2-instance | Epoch [ 63/ 75] Iter[951/1233]	  loss: 0.16cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1001/1233]	  loss: 0.19cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1051/1233]	  loss: 0.16cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1101/1233]	  loss: 0.24cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1151/1233]	  loss: 0.18cifar10:0.2-instance | Epoch [ 63/ 75] Iter[1201/1233]	  loss: 0.17
| Test Epoch 63	 Accuracy: 91.84% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 64 | Accuracy on train set: 78.02% 
labeled data has a size of 39505, f-score: 0.985976
cifar10:0.2-instance | Epoch [ 64/ 75] Iter[  1/1235]	  loss: 0.32cifar10:0.2-instance | Epoch [ 64/ 75] Iter[ 51/1235]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[101/1235]	  loss: 0.27cifar10:0.2-instance | Epoch [ 64/ 75] Iter[151/1235]	  loss: 0.28cifar10:0.2-instance | Epoch [ 64/ 75] Iter[201/1235]	  loss: 0.22cifar10:0.2-instance | Epoch [ 64/ 75] Iter[251/1235]	  loss: 0.18cifar10:0.2-instance | Epoch [ 64/ 75] Iter[301/1235]	  loss: 0.15cifar10:0.2-instance | Epoch [ 64/ 75] Iter[351/1235]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[401/1235]	  loss: 0.17cifar10:0.2-instance | Epoch [ 64/ 75] Iter[451/1235]	  loss: 0.23cifar10:0.2-instance | Epoch [ 64/ 75] Iter[501/1235]	  loss: 0.18cifar10:0.2-instance | Epoch [ 64/ 75] Iter[551/1235]	  loss: 0.25cifar10:0.2-instance | Epoch [ 64/ 75] Iter[601/1235]	  loss: 0.28cifar10:0.2-instance | Epoch [ 64/ 75] Iter[651/1235]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[701/1235]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[751/1235]	  loss: 0.20cifar10:0.2-instance | Epoch [ 64/ 75] Iter[801/1235]	  loss: 0.28cifar10:0.2-instance | Epoch [ 64/ 75] Iter[851/1235]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[901/1235]	  loss: 0.19cifar10:0.2-instance | Epoch [ 64/ 75] Iter[951/1235]	  loss: 0.21cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1001/1235]	  loss: 0.17cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1051/1235]	  loss: 0.19cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1101/1235]	  loss: 0.15cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1151/1235]	  loss: 0.16cifar10:0.2-instance | Epoch [ 64/ 75] Iter[1201/1235]	  loss: 0.15
| Test Epoch 64	 Accuracy: 91.87% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 65 | Accuracy on train set: 78.11% 
labeled data has a size of 39576, f-score: 0.985420
cifar10:0.2-instance | Epoch [ 65/ 75] Iter[  1/1237]	  loss: 0.17cifar10:0.2-instance | Epoch [ 65/ 75] Iter[ 51/1237]	  loss: 0.20cifar10:0.2-instance | Epoch [ 65/ 75] Iter[101/1237]	  loss: 0.21cifar10:0.2-instance | Epoch [ 65/ 75] Iter[151/1237]	  loss: 0.28cifar10:0.2-instance | Epoch [ 65/ 75] Iter[201/1237]	  loss: 0.26cifar10:0.2-instance | Epoch [ 65/ 75] Iter[251/1237]	  loss: 0.25cifar10:0.2-instance | Epoch [ 65/ 75] Iter[301/1237]	  loss: 0.16cifar10:0.2-instance | Epoch [ 65/ 75] Iter[351/1237]	  loss: 0.22cifar10:0.2-instance | Epoch [ 65/ 75] Iter[401/1237]	  loss: 0.17cifar10:0.2-instance | Epoch [ 65/ 75] Iter[451/1237]	  loss: 0.21cifar10:0.2-instance | Epoch [ 65/ 75] Iter[501/1237]	  loss: 0.28cifar10:0.2-instance | Epoch [ 65/ 75] Iter[551/1237]	  loss: 0.18cifar10:0.2-instance | Epoch [ 65/ 75] Iter[601/1237]	  loss: 0.20cifar10:0.2-instance | Epoch [ 65/ 75] Iter[651/1237]	  loss: 0.20cifar10:0.2-instance | Epoch [ 65/ 75] Iter[701/1237]	  loss: 0.22cifar10:0.2-instance | Epoch [ 65/ 75] Iter[751/1237]	  loss: 0.23cifar10:0.2-instance | Epoch [ 65/ 75] Iter[801/1237]	  loss: 0.24cifar10:0.2-instance | Epoch [ 65/ 75] Iter[851/1237]	  loss: 0.25cifar10:0.2-instance | Epoch [ 65/ 75] Iter[901/1237]	  loss: 0.17cifar10:0.2-instance | Epoch [ 65/ 75] Iter[951/1237]	  loss: 0.22cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1001/1237]	  loss: 0.21cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1051/1237]	  loss: 0.18cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1101/1237]	  loss: 0.24cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1151/1237]	  loss: 0.17cifar10:0.2-instance | Epoch [ 65/ 75] Iter[1201/1237]	  loss: 0.24
| Test Epoch 65	 Accuracy: 92.37% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 66 | Accuracy on train set: 78.31% 
labeled data has a size of 39633, f-score: 0.985012
cifar10:0.2-instance | Epoch [ 66/ 75] Iter[  1/1239]	  loss: 0.21cifar10:0.2-instance | Epoch [ 66/ 75] Iter[ 51/1239]	  loss: 0.18cifar10:0.2-instance | Epoch [ 66/ 75] Iter[101/1239]	  loss: 0.22cifar10:0.2-instance | Epoch [ 66/ 75] Iter[151/1239]	  loss: 0.17cifar10:0.2-instance | Epoch [ 66/ 75] Iter[201/1239]	  loss: 0.22cifar10:0.2-instance | Epoch [ 66/ 75] Iter[251/1239]	  loss: 0.25cifar10:0.2-instance | Epoch [ 66/ 75] Iter[301/1239]	  loss: 0.19cifar10:0.2-instance | Epoch [ 66/ 75] Iter[351/1239]	  loss: 0.19cifar10:0.2-instance | Epoch [ 66/ 75] Iter[401/1239]	  loss: 0.15cifar10:0.2-instance | Epoch [ 66/ 75] Iter[451/1239]	  loss: 0.27cifar10:0.2-instance | Epoch [ 66/ 75] Iter[501/1239]	  loss: 0.28cifar10:0.2-instance | Epoch [ 66/ 75] Iter[551/1239]	  loss: 0.15cifar10:0.2-instance | Epoch [ 66/ 75] Iter[601/1239]	  loss: 0.19cifar10:0.2-instance | Epoch [ 66/ 75] Iter[651/1239]	  loss: 0.25cifar10:0.2-instance | Epoch [ 66/ 75] Iter[701/1239]	  loss: 0.18cifar10:0.2-instance | Epoch [ 66/ 75] Iter[751/1239]	  loss: 0.17cifar10:0.2-instance | Epoch [ 66/ 75] Iter[801/1239]	  loss: 0.33cifar10:0.2-instance | Epoch [ 66/ 75] Iter[851/1239]	  loss: 0.18cifar10:0.2-instance | Epoch [ 66/ 75] Iter[901/1239]	  loss: 0.17cifar10:0.2-instance | Epoch [ 66/ 75] Iter[951/1239]	  loss: 0.19cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1001/1239]	  loss: 0.32cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1051/1239]	  loss: 0.15cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1101/1239]	  loss: 0.21cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1151/1239]	  loss: 0.17cifar10:0.2-instance | Epoch [ 66/ 75] Iter[1201/1239]	  loss: 0.15
| Test Epoch 66	 Accuracy: 92.03% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 67 | Accuracy on train set: 78.50% 
labeled data has a size of 39673, f-score: 0.984876
cifar10:0.2-instance | Epoch [ 67/ 75] Iter[  1/1240]	  loss: 0.17cifar10:0.2-instance | Epoch [ 67/ 75] Iter[ 51/1240]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[101/1240]	  loss: 0.20cifar10:0.2-instance | Epoch [ 67/ 75] Iter[151/1240]	  loss: 0.19cifar10:0.2-instance | Epoch [ 67/ 75] Iter[201/1240]	  loss: 0.15cifar10:0.2-instance | Epoch [ 67/ 75] Iter[251/1240]	  loss: 0.25cifar10:0.2-instance | Epoch [ 67/ 75] Iter[301/1240]	  loss: 0.21cifar10:0.2-instance | Epoch [ 67/ 75] Iter[351/1240]	  loss: 0.23cifar10:0.2-instance | Epoch [ 67/ 75] Iter[401/1240]	  loss: 0.17cifar10:0.2-instance | Epoch [ 67/ 75] Iter[451/1240]	  loss: 0.17cifar10:0.2-instance | Epoch [ 67/ 75] Iter[501/1240]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[551/1240]	  loss: 0.24cifar10:0.2-instance | Epoch [ 67/ 75] Iter[601/1240]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[651/1240]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[701/1240]	  loss: 0.18cifar10:0.2-instance | Epoch [ 67/ 75] Iter[751/1240]	  loss: 0.21cifar10:0.2-instance | Epoch [ 67/ 75] Iter[801/1240]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[851/1240]	  loss: 0.17cifar10:0.2-instance | Epoch [ 67/ 75] Iter[901/1240]	  loss: 0.15cifar10:0.2-instance | Epoch [ 67/ 75] Iter[951/1240]	  loss: 0.15cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1001/1240]	  loss: 0.17cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1051/1240]	  loss: 0.21cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1101/1240]	  loss: 0.20cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1151/1240]	  loss: 0.16cifar10:0.2-instance | Epoch [ 67/ 75] Iter[1201/1240]	  loss: 0.15
| Test Epoch 67	 Accuracy: 92.19% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 68 | Accuracy on train set: 78.75% 
labeled data has a size of 39729, f-score: 0.984470
cifar10:0.2-instance | Epoch [ 68/ 75] Iter[  1/1242]	  loss: 0.21cifar10:0.2-instance | Epoch [ 68/ 75] Iter[ 51/1242]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[101/1242]	  loss: 0.22cifar10:0.2-instance | Epoch [ 68/ 75] Iter[151/1242]	  loss: 0.16cifar10:0.2-instance | Epoch [ 68/ 75] Iter[201/1242]	  loss: 0.21cifar10:0.2-instance | Epoch [ 68/ 75] Iter[251/1242]	  loss: 0.18cifar10:0.2-instance | Epoch [ 68/ 75] Iter[301/1242]	  loss: 0.21cifar10:0.2-instance | Epoch [ 68/ 75] Iter[351/1242]	  loss: 0.19cifar10:0.2-instance | Epoch [ 68/ 75] Iter[401/1242]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[451/1242]	  loss: 0.22cifar10:0.2-instance | Epoch [ 68/ 75] Iter[501/1242]	  loss: 0.26cifar10:0.2-instance | Epoch [ 68/ 75] Iter[551/1242]	  loss: 0.21cifar10:0.2-instance | Epoch [ 68/ 75] Iter[601/1242]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[651/1242]	  loss: 0.35cifar10:0.2-instance | Epoch [ 68/ 75] Iter[701/1242]	  loss: 0.19cifar10:0.2-instance | Epoch [ 68/ 75] Iter[751/1242]	  loss: 0.16cifar10:0.2-instance | Epoch [ 68/ 75] Iter[801/1242]	  loss: 0.22cifar10:0.2-instance | Epoch [ 68/ 75] Iter[851/1242]	  loss: 0.15cifar10:0.2-instance | Epoch [ 68/ 75] Iter[901/1242]	  loss: 0.33cifar10:0.2-instance | Epoch [ 68/ 75] Iter[951/1242]	  loss: 0.23cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1001/1242]	  loss: 0.23cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1051/1242]	  loss: 0.18cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1101/1242]	  loss: 0.19cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1151/1242]	  loss: 0.18cifar10:0.2-instance | Epoch [ 68/ 75] Iter[1201/1242]	  loss: 0.15
| Test Epoch 68	 Accuracy: 91.89% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 69 | Accuracy on train set: 78.77% 
labeled data has a size of 39804, f-score: 0.983519
cifar10:0.2-instance | Epoch [ 69/ 75] Iter[  1/1244]	  loss: 0.18cifar10:0.2-instance | Epoch [ 69/ 75] Iter[ 51/1244]	  loss: 0.19cifar10:0.2-instance | Epoch [ 69/ 75] Iter[101/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[151/1244]	  loss: 0.16cifar10:0.2-instance | Epoch [ 69/ 75] Iter[201/1244]	  loss: 0.16cifar10:0.2-instance | Epoch [ 69/ 75] Iter[251/1244]	  loss: 0.16cifar10:0.2-instance | Epoch [ 69/ 75] Iter[301/1244]	  loss: 0.30cifar10:0.2-instance | Epoch [ 69/ 75] Iter[351/1244]	  loss: 0.16cifar10:0.2-instance | Epoch [ 69/ 75] Iter[401/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[451/1244]	  loss: 0.23cifar10:0.2-instance | Epoch [ 69/ 75] Iter[501/1244]	  loss: 0.17cifar10:0.2-instance | Epoch [ 69/ 75] Iter[551/1244]	  loss: 0.20cifar10:0.2-instance | Epoch [ 69/ 75] Iter[601/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[651/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[701/1244]	  loss: 0.16cifar10:0.2-instance | Epoch [ 69/ 75] Iter[751/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[801/1244]	  loss: 0.33cifar10:0.2-instance | Epoch [ 69/ 75] Iter[851/1244]	  loss: 0.20cifar10:0.2-instance | Epoch [ 69/ 75] Iter[901/1244]	  loss: 0.35cifar10:0.2-instance | Epoch [ 69/ 75] Iter[951/1244]	  loss: 0.20cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1001/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1051/1244]	  loss: 0.16cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1101/1244]	  loss: 0.20cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1151/1244]	  loss: 0.15cifar10:0.2-instance | Epoch [ 69/ 75] Iter[1201/1244]	  loss: 0.19
| Test Epoch 69	 Accuracy: 91.83% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 70 | Accuracy on train set: 78.79% 
labeled data has a size of 39851, f-score: 0.983062
cifar10:0.2-instance | Epoch [ 70/ 75] Iter[  1/1246]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[ 51/1246]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[101/1246]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[151/1246]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[201/1246]	  loss: 0.20cifar10:0.2-instance | Epoch [ 70/ 75] Iter[251/1246]	  loss: 0.32cifar10:0.2-instance | Epoch [ 70/ 75] Iter[301/1246]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[351/1246]	  loss: 0.21cifar10:0.2-instance | Epoch [ 70/ 75] Iter[401/1246]	  loss: 0.17cifar10:0.2-instance | Epoch [ 70/ 75] Iter[451/1246]	  loss: 0.23cifar10:0.2-instance | Epoch [ 70/ 75] Iter[501/1246]	  loss: 0.21cifar10:0.2-instance | Epoch [ 70/ 75] Iter[551/1246]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[601/1246]	  loss: 0.20cifar10:0.2-instance | Epoch [ 70/ 75] Iter[651/1246]	  loss: 0.34cifar10:0.2-instance | Epoch [ 70/ 75] Iter[701/1246]	  loss: 0.23cifar10:0.2-instance | Epoch [ 70/ 75] Iter[751/1246]	  loss: 0.24cifar10:0.2-instance | Epoch [ 70/ 75] Iter[801/1246]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[851/1246]	  loss: 0.16cifar10:0.2-instance | Epoch [ 70/ 75] Iter[901/1246]	  loss: 0.30cifar10:0.2-instance | Epoch [ 70/ 75] Iter[951/1246]	  loss: 0.21cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1001/1246]	  loss: 0.20cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1051/1246]	  loss: 0.17cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1101/1246]	  loss: 0.15cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1151/1246]	  loss: 0.30cifar10:0.2-instance | Epoch [ 70/ 75] Iter[1201/1246]	  loss: 0.20
| Test Epoch 70	 Accuracy: 92.21% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 71 | Accuracy on train set: 79.07% 
labeled data has a size of 39881, f-score: 0.982899
cifar10:0.2-instance | Epoch [ 71/ 75] Iter[  1/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[ 51/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[101/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[151/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[201/1247]	  loss: 0.19cifar10:0.2-instance | Epoch [ 71/ 75] Iter[251/1247]	  loss: 0.23cifar10:0.2-instance | Epoch [ 71/ 75] Iter[301/1247]	  loss: 0.24cifar10:0.2-instance | Epoch [ 71/ 75] Iter[351/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[401/1247]	  loss: 0.22cifar10:0.2-instance | Epoch [ 71/ 75] Iter[451/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[501/1247]	  loss: 0.20cifar10:0.2-instance | Epoch [ 71/ 75] Iter[551/1247]	  loss: 0.33cifar10:0.2-instance | Epoch [ 71/ 75] Iter[601/1247]	  loss: 0.21cifar10:0.2-instance | Epoch [ 71/ 75] Iter[651/1247]	  loss: 0.20cifar10:0.2-instance | Epoch [ 71/ 75] Iter[701/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[751/1247]	  loss: 0.23cifar10:0.2-instance | Epoch [ 71/ 75] Iter[801/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[851/1247]	  loss: 0.19cifar10:0.2-instance | Epoch [ 71/ 75] Iter[901/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[951/1247]	  loss: 0.17cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1001/1247]	  loss: 0.19cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1051/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1101/1247]	  loss: 0.15cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1151/1247]	  loss: 0.16cifar10:0.2-instance | Epoch [ 71/ 75] Iter[1201/1247]	  loss: 0.15
| Test Epoch 71	 Accuracy: 92.04% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 72 | Accuracy on train set: 79.16% 
labeled data has a size of 39921, f-score: 0.982741
cifar10:0.2-instance | Epoch [ 72/ 75] Iter[  1/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[ 51/1248]	  loss: 0.37cifar10:0.2-instance | Epoch [ 72/ 75] Iter[101/1248]	  loss: 0.19cifar10:0.2-instance | Epoch [ 72/ 75] Iter[151/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[201/1248]	  loss: 0.20cifar10:0.2-instance | Epoch [ 72/ 75] Iter[251/1248]	  loss: 0.21cifar10:0.2-instance | Epoch [ 72/ 75] Iter[301/1248]	  loss: 0.25cifar10:0.2-instance | Epoch [ 72/ 75] Iter[351/1248]	  loss: 0.21cifar10:0.2-instance | Epoch [ 72/ 75] Iter[401/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[451/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[501/1248]	  loss: 0.22cifar10:0.2-instance | Epoch [ 72/ 75] Iter[551/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[601/1248]	  loss: 0.20cifar10:0.2-instance | Epoch [ 72/ 75] Iter[651/1248]	  loss: 0.20cifar10:0.2-instance | Epoch [ 72/ 75] Iter[701/1248]	  loss: 0.20cifar10:0.2-instance | Epoch [ 72/ 75] Iter[751/1248]	  loss: 0.20cifar10:0.2-instance | Epoch [ 72/ 75] Iter[801/1248]	  loss: 0.20cifar10:0.2-instance | Epoch [ 72/ 75] Iter[851/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[901/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[951/1248]	  loss: 0.15cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1001/1248]	  loss: 0.19cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1051/1248]	  loss: 0.16cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1101/1248]	  loss: 0.24cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1151/1248]	  loss: 0.19cifar10:0.2-instance | Epoch [ 72/ 75] Iter[1201/1248]	  loss: 0.16
| Test Epoch 72	 Accuracy: 92.44% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 73 | Accuracy on train set: 79.33% 
labeled data has a size of 39961, f-score: 0.982383
cifar10:0.2-instance | Epoch [ 73/ 75] Iter[  1/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[ 51/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[101/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[151/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[201/1249]	  loss: 0.30cifar10:0.2-instance | Epoch [ 73/ 75] Iter[251/1249]	  loss: 0.20cifar10:0.2-instance | Epoch [ 73/ 75] Iter[301/1249]	  loss: 0.17cifar10:0.2-instance | Epoch [ 73/ 75] Iter[351/1249]	  loss: 0.17cifar10:0.2-instance | Epoch [ 73/ 75] Iter[401/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[451/1249]	  loss: 0.19cifar10:0.2-instance | Epoch [ 73/ 75] Iter[501/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[551/1249]	  loss: 0.18cifar10:0.2-instance | Epoch [ 73/ 75] Iter[601/1249]	  loss: 0.16cifar10:0.2-instance | Epoch [ 73/ 75] Iter[651/1249]	  loss: 0.30cifar10:0.2-instance | Epoch [ 73/ 75] Iter[701/1249]	  loss: 0.24cifar10:0.2-instance | Epoch [ 73/ 75] Iter[751/1249]	  loss: 0.17cifar10:0.2-instance | Epoch [ 73/ 75] Iter[801/1249]	  loss: 0.19cifar10:0.2-instance | Epoch [ 73/ 75] Iter[851/1249]	  loss: 0.19cifar10:0.2-instance | Epoch [ 73/ 75] Iter[901/1249]	  loss: 0.33cifar10:0.2-instance | Epoch [ 73/ 75] Iter[951/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1001/1249]	  loss: 0.18cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1051/1249]	  loss: 0.30cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1101/1249]	  loss: 0.15cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1151/1249]	  loss: 0.20cifar10:0.2-instance | Epoch [ 73/ 75] Iter[1201/1249]	  loss: 0.15
| Test Epoch 73	 Accuracy: 92.02% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 74 | Accuracy on train set: 79.34% 
labeled data has a size of 40002, f-score: 0.981726
cifar10:0.2-instance | Epoch [ 74/ 75] Iter[  1/1251]	  loss: 0.20cifar10:0.2-instance | Epoch [ 74/ 75] Iter[ 51/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[101/1251]	  loss: 0.26cifar10:0.2-instance | Epoch [ 74/ 75] Iter[151/1251]	  loss: 0.30cifar10:0.2-instance | Epoch [ 74/ 75] Iter[201/1251]	  loss: 0.19cifar10:0.2-instance | Epoch [ 74/ 75] Iter[251/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[301/1251]	  loss: 0.31cifar10:0.2-instance | Epoch [ 74/ 75] Iter[351/1251]	  loss: 0.18cifar10:0.2-instance | Epoch [ 74/ 75] Iter[401/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[451/1251]	  loss: 0.17cifar10:0.2-instance | Epoch [ 74/ 75] Iter[501/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[551/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[601/1251]	  loss: 0.18cifar10:0.2-instance | Epoch [ 74/ 75] Iter[651/1251]	  loss: 0.21cifar10:0.2-instance | Epoch [ 74/ 75] Iter[701/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[751/1251]	  loss: 0.15cifar10:0.2-instance | Epoch [ 74/ 75] Iter[801/1251]	  loss: 0.31cifar10:0.2-instance | Epoch [ 74/ 75] Iter[851/1251]	  loss: 0.19cifar10:0.2-instance | Epoch [ 74/ 75] Iter[901/1251]	  loss: 0.21cifar10:0.2-instance | Epoch [ 74/ 75] Iter[951/1251]	  loss: 0.17cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1001/1251]	  loss: 0.16cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1051/1251]	  loss: 0.22cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1101/1251]	  loss: 0.17cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1151/1251]	  loss: 0.20cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1201/1251]	  loss: 0.34cifar10:0.2-instance | Epoch [ 74/ 75] Iter[1251/1251]	  loss: 0.29
| Test Epoch 74	 Accuracy: 92.30% 



============ Train stage | lr = 0.002, T in penalty = 0.200
Epoch 75 | Accuracy on train set: 79.42% 
labeled data has a size of 40040, f-score: 0.981244
cifar10:0.2-instance | Epoch [ 75/ 75] Iter[  1/1252]	  loss: 0.17cifar10:0.2-instance | Epoch [ 75/ 75] Iter[ 51/1252]	  loss: 0.24cifar10:0.2-instance | Epoch [ 75/ 75] Iter[101/1252]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[151/1252]	  loss: 0.25cifar10:0.2-instance | Epoch [ 75/ 75] Iter[201/1252]	  loss: 0.22cifar10:0.2-instance | Epoch [ 75/ 75] Iter[251/1252]	  loss: 0.21cifar10:0.2-instance | Epoch [ 75/ 75] Iter[301/1252]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[351/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[401/1252]	  loss: 0.14cifar10:0.2-instance | Epoch [ 75/ 75] Iter[451/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[501/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[551/1252]	  loss: 0.21cifar10:0.2-instance | Epoch [ 75/ 75] Iter[601/1252]	  loss: 0.21cifar10:0.2-instance | Epoch [ 75/ 75] Iter[651/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[701/1252]	  loss: 0.28cifar10:0.2-instance | Epoch [ 75/ 75] Iter[751/1252]	  loss: 0.17cifar10:0.2-instance | Epoch [ 75/ 75] Iter[801/1252]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[851/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[901/1252]	  loss: 0.21cifar10:0.2-instance | Epoch [ 75/ 75] Iter[951/1252]	  loss: 0.16cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1001/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1051/1252]	  loss: 0.15cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1101/1252]	  loss: 0.21cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1151/1252]	  loss: 0.20cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1201/1252]	  loss: 0.18cifar10:0.2-instance | Epoch [ 75/ 75] Iter[1251/1252]	  loss: 0.16
| Test Epoch 75	 Accuracy: 91.80% 



best test Acc:  92.44
